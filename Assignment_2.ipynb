{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttourneux/Final-Project/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## questions: \n",
        "\n",
        "#---------\n",
        "4. why don't we have activation function in predict? Why do we just pick the best class? \n",
        "\n",
        "5. svm.loss takes : Inputs:\n",
        "    - scores: A numpy array of shape (N, C) containing a minibatch of N\n",
        "      data points; each point has dimension C, where C is the number of classes.\n",
        "\n",
        "    - but forward outputs: \n",
        "        A list containing the value of the loss function at each training iteration.\n",
        "\n",
        "  - How to get the correct scores to put into .loss? \n",
        "  - \" The forward() method generates the scores for given an input sample, by applying a linear_forward() transformation on the inputs x and weights matrix self.params['W1']\"\n",
        "\n",
        "6. how come I can print before and after .forward but if i print in forward nothing happens????\n",
        "\n",
        "#-------------\n",
        "1. how to get the pictures to print correctly? \n",
        "2. how to get dy for cross-entropy loss\n",
        "3. do we do vd_reLU on d_upstream or on x"
      ],
      "metadata": {
        "id": "d5-NVZyBvAXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Author Information\n",
        "Name: Theodore Tourneux\n",
        "\n",
        "B-Number: B00810586\n",
        "\n",
        "Email: ttourne1@binghamton.edu"
      ],
      "metadata": {
        "id": "tUheapJCOaxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Instructions \n",
        "### Due October 7th, 11:59 PM.\n",
        "\n",
        "In the following assignment, you will be implementing functions and their analytical derivatives to train linear classifiers and neural networks on the MNIST dataset. \n",
        "\n",
        "Functions and cells that need to be implemented are marked with a bold **implement** keyword or clearly marked in the experiments section. \n",
        "\n",
        "The experiments section for each classifier also need to be implemented. You should follow the instructions above the cell. You may also add additional cells. \n",
        "\n",
        "Cells marked **run** need to be run to set up the appropriate infrastructure, but do not need to be modified. Make sure you have run the previous cells before running the current cell, or you may get an error.\n",
        "\n",
        "Submission will be via GitHub Classroom. **You are required to have at least 10 commits for this assignment.**\n"
      ],
      "metadata": {
        "id": "jqLULe5pxwpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import statements\n",
        "\n",
        "**Run** the cell to import the packages needed for the code below. You may other packages but ask first. "
      ],
      "metadata": {
        "id": "Hnw_h7A1Orc9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JLEavoS9O9g-"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Backpropagation\n"
      ],
      "metadata": {
        "id": "VIBNL5SMPMt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Transformation\n",
        "\n",
        "Linear transformations are vector-valued functions that take D-dimensional  vectors $x \\in \\mathbb{R}^{D}$ and transform them into M-dimensional vectors, $y \\in \\mathbb{R}^{M}$. We are going to use linear transformation with [\"bias trick\"](https://en.wikipedia.org/wiki/Affine_transformation#Augmented_matrix) to implement the transformation:\n",
        "\n",
        "$$\n",
        "y = xW + b\n",
        "$$\n",
        "\n",
        "\n",
        "In this assignment, you will use this transformation in the SVM, softmax, and neural network classifiers.\n",
        "\n",
        "You will need to implement both the forward and backward direction of this linear layer. Take a look here for more details on the [backpropagation of a linear layer.](https://web.eecs.umich.edu/~justincj/teaching/eecs442/notes/linear-backprop.html)"
      ],
      "metadata": {
        "id": "VhFZKNmUXzt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** linear_forward(X, W) that returns linear transformations on data X using the augmented parameter matrix, W. "
      ],
      "metadata": {
        "id": "KszunLwwRJqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_forward(x, w):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a linear transformation.\n",
        "\n",
        "    The input x has shape (N, D) and contains a minibatch of N\n",
        "    samples, where each sample x[i] has shape (D). We will \n",
        "    transform it to an output vector of dimension M.\n",
        "\n",
        "    Inputs:\n",
        "    - x: A numpy array containing input data, of shape (N, D)\n",
        "    - w: A numpy array of weights, of shape (D+1, M)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: output, of shape (N, M)\n",
        "    - cache: (x, w)\n",
        "\n",
        "    The returned (x, w) is redundant, but makes the constructing the entire layer\n",
        "    a little more concise.\n",
        "\n",
        "    \"\"\"\n",
        "    N,D = x.shape\n",
        "    E,M = w.shape\n",
        "    assert(E == D+1)\n",
        "\n",
        "    out = None # Initialize the out variable.\n",
        "    bias = np.ones(N).reshape(N,1)\n",
        "    x_prime = np.append(x,bias, axis = 1)## axis1 should be columns \n",
        "    out = np.matmul( x_prime, w)\n",
        "\n",
        "    #\n",
        "    # PUT YOUR CODE BELOW: Below, implement the linear forward pass. Store the result in out.\n",
        "    # Make sure to do the bias trick! \n",
        "\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "    \n",
        "    cache = (x, w)\n",
        "    #print(\"cache in linear_forward\",cache)\n",
        "    assert(out.shape == (N,M) )\n",
        "    return out, cache"
      ],
      "metadata": {
        "id": "fsl6QHm_PJdi"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** linear_backward(dout, cache) that returns the analytical gradients with respect to X and W."
      ],
      "metadata": {
        "id": "VLnk9xwpRf2T"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3bDhhohYKtiW"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.matmul(\n",
        "    np.ones((3,4)),\n",
        "    np.ones( (4,5))\n",
        ").shape\n",
        "\n",
        "np.array([[1,2,3],[4,5,6],[7,8,9]])[:,:-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6uC5jYcRqz_",
        "outputId": "26fb7788-c6ac-4fdd-cce6-48891869d1a6"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [4, 5],\n",
              "       [7, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_backward(d_upstream, cache):\n",
        "  #linear_backward(dout, cache)\n",
        "    \"\"\"\n",
        "    Computes the backward pass for an linear layer.\n",
        "\n",
        "    Inputs:\n",
        "    - d_upstream: Upstream derivative, of shape (N, M)\n",
        "    - cache: Tuple of:\n",
        "      - x: Input data, of shape (N, D)\n",
        "      - w: Weights, of shape (D+1, M)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - dx: Gradient of the output of this layer with respect to x, of shape (N, D).\n",
        "          This is the downstream gradient.\n",
        "          dL/dx\n",
        "    - dw: Gradient with respect to w, of shape (D+1, M)\n",
        "          dL/dw\n",
        "    \"\"\"\n",
        "    #print(cache)\n",
        "    x, w = cache\n",
        "    N,D  = x.shape \n",
        "    E,M = w.shape\n",
        "    assert( E == D+1)\n",
        "    bias = np.ones(N).reshape(N,1)\n",
        "    x_prime = np.append(x,bias, axis = 1)\n",
        "    #dx, dw = None, None\n",
        "\n",
        "    # PUT YOUR CODE BELOW: Implement the linear backward pass by calculating the\n",
        "    # gradient with respect to the cached inputs x and w. Store them in the \n",
        "    # variables dx and dw.\n",
        "\n",
        "    dy = d_upstream \n",
        "    dx = np.matmul(dy, w.T[:,:-1])# (NxM)X (M,D+1)\n",
        "\n",
        "    dw = np.matmul(x_prime.T, dy)## this is better once we use the correct x_prime\n",
        "  \n",
        "\n",
        "   \n",
        "    #dy is 2x3 and w is 2x3\n",
        "    # The lines below do not need to be changed.\n",
        "    #dx.shape (16, 5)\n",
        "    #dw.shape (4, 3)\n",
        "    #print(\"dx.shape\",dx.shape)\n",
        "    #print('dw.shape',dw.shape)\n",
        "    assert(dw.shape == (D+1,M))\n",
        "    assert(dx.shape == (N,D))\n",
        "    \n",
        "    return dx, dw"
      ],
      "metadata": {
        "id": "41ac6dd5TSEX"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finite difference is the discrete analog of derivatives, used to implement gradients numerically. While analytical derivates are faster to compute, they tend to be difficult to implement and error prone. It is standard practice to perform a gradient check by comparing the analytical gradient implementation with a numerical gradient. \n",
        "\n",
        "The multi-variate central difference for a function $f(x,y)$ is given by:\n",
        "$$\n",
        "\\frac{\\partial  f}{\\partial x} = \\frac{f(x+h, y)-f(x-h, y)}{2h}\n",
        "$$\n",
        "and \n",
        "$$\n",
        "\\frac{\\partial  f}{\\partial y} = \\frac{f(x, y+h)-f(x, y-h)}{2h}\n",
        "$$\n",
        "\n",
        "The pattern holds for functions with higher number of variables. For central finite difference, generally $h=10^{-6}$. \n",
        "\n",
        "The multi-variate chain can be written as: \n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial x_i} = \\sum^{m}_{\\mathcal{l}=1} \\frac{\\partial L}{\\partial y_l}\\frac{\\partial y_l}{\\partial x_i}\n",
        "$$\n",
        "\n",
        "This simplifies nicely as the gradient for each variable in the matrix the sum of the products of the upstream gradient. `d_upstream` and the finite difference matrix. \n"
      ],
      "metadata": {
        "id": "lk1XRA9LSKml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement**  the `finite_difference_linear` function the next cell to test your implementation of the linear_forward and linear_backward functions. "
      ],
      "metadata": {
        "id": "Je8LC4OnT-rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def finite_difference_linear(d_upstream, cache):\n",
        "    '''\n",
        "    Computes the numerical gradient for a linear layer\n",
        "\n",
        "    Inputs:\n",
        "    - d_upstream: Upstream derivative, of shape (N, M)\n",
        "    - cache: Tuple of:\n",
        "      - x: Input data, of shape (N, D)\n",
        "      - w: Weights, of shape (D+1, M)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - dx: Gradient with respect to x, of shape (N, D).  This is the downstream\n",
        "          gradient.\n",
        "    - dw: Gradient with respect to w, of shape (D+1, M)\n",
        "    '''\n",
        "\n",
        "    ## let Y = XW ## this is the forward pass calculation\n",
        "    ## then finite difference is \n",
        "    #N,M = d_upstream.shape \n",
        "\n",
        "    (x,w) = cache\n",
        "    (N,D) = x.shape\n",
        "    (E,M) = w.shape\n",
        "    assert(E == D+1)\n",
        "\n",
        "\n",
        "    #out = None # Initialize the out variable.\n",
        "    bias = np.ones(N).reshape(N,1)\n",
        "    #print(\"x,bias\", x.shape,bias.shape)\n",
        "    x_prime = np.append(x,bias, axis = 1)\n",
        "    #print(\"x_prime\", x_prime.shape)\n",
        "    #print(\"w.shape\",w.shape)\n",
        "\n",
        "    #h_x = np.ones(x.shape)/(10**10)\n",
        "    #h_w = np.ones(w.shape)/(10**10)\n",
        "    h = (1/(10**10))\n",
        "\n",
        "    dl_dx = np.zeros((N,D))\n",
        "    for i in range(N):\n",
        "      for j in range(D):\n",
        "        x_diff = x_prime.copy()\n",
        "        x_diff[i,j] = x_diff[i,j]+h#(1/(10**10))\n",
        "        dy_dxij=((np.matmul(x_diff,w))-(np.matmul(x_prime, w)))/h#/(10**10)\n",
        "\n",
        "        acc = 0\n",
        "        for a in range(N):\n",
        "          for b in range(M):\n",
        "            acc+=d_upstream[a,b]*dy_dxij[a,b]\n",
        "        dl_dx[i,j] = acc\n",
        "\n",
        "\n",
        "    dl_dw = np.zeros((D+1,M))\n",
        "    for i in range(D+1):\n",
        "      for j in range(M):\n",
        "        w_diff = w.copy()\n",
        "        w_diff[i,j] = w_diff[i,j]+h#(1/(10**10))\n",
        "        dy_dwij=((np.matmul(x_prime,w_diff))-(np.matmul(x_prime, w)))/h#/(1/(10**10))\n",
        "        # (np.matmul(x,w+h_w))-(np.matmul(x, w))/(10**10)\n",
        "        \n",
        "        acc = 0\n",
        "        for a in range(N):\n",
        "          for b in range(M):\n",
        "            acc+=d_upstream[a,b]*dy_dwij[a,b]\n",
        "        dl_dw[i,j] = acc\n",
        "\n",
        "\n",
        "\n",
        "    dx = dl_dx\n",
        "    dw = dl_dw\n",
        "    # The lines below do not need to be changed.\n",
        "    #print(x.type)\n",
        "    #print(\"dx shape\", dx.shape)\n",
        "    #print(\"should be\" ,(N,D))## this is the same \n",
        "    assert((dx.shape) == (N,D))## this throws the error\n",
        "    assert((dw.shape) == (D+1,M))## this also throws an error \n",
        "    return dx, dw"
      ],
      "metadata": {
        "id": "HvUDtyAWUx7u"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5e3IbOzNO5qB"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finite_difference_linear()\n"
      ],
      "metadata": {
        "id": "OP7bm5h989HV"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** this cell to do a gradient check to test the analytical gradients from the `linear_backward` function with `finite_difference_linear`.  "
      ],
      "metadata": {
        "id": "iTNHRnDDvCMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_check_linear():\n",
        "    N = 16\n",
        "    D = 4\n",
        "    C = 3\n",
        "\n",
        "    test_weight = np.random.random((D+1, C))\n",
        "    test_input = np.random.random((N, D))\n",
        "    dout = np.random.random((N, C))\n",
        "\n",
        "    cache = (test_input, test_weight)\n",
        "    \n",
        "    grad_x_numerical, grad_w_numerical = finite_difference_linear(dout, cache)\n",
        "    grad_x_analytical, grad_w_analytical = linear_backward(dout, cache)\n",
        "\n",
        "    '''print('grad_w_numerical, grad_w_analytical',grad_w_numerical, grad_w_analytical)\n",
        "    print('space')\n",
        "    print('grad_x_numerical, grad_x_analytical',grad_x_numerical, grad_x_analytical)'''\n",
        "\n",
        "    check_input_gradient = np.allclose(grad_x_numerical, grad_x_analytical)\n",
        "    check_weight_gradient = np.allclose(grad_w_numerical, grad_w_analytical)\n",
        "\n",
        "    if not check_input_gradient:\n",
        "        print(\"The gradient with respect to x failed\")\n",
        "\n",
        "    if not check_weight_gradient:\n",
        "        print(\"The gradient respect to w failed\")\n",
        "    \n",
        "    print(\"gradient check for linear passed!\")\n",
        "\n",
        "gradient_check_linear()"
      ],
      "metadata": {
        "id": "jvmbfkfRPSZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5814d780-1f21-4160-f8b4-e87accf160cd"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The gradient with respect to x failed\n",
            "gradient check for linear passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Linear Classifiers\n"
      ],
      "metadata": {
        "id": "i1DiweHpU-_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MNIST Dataset\n",
        "\n",
        "MNIST is a dataset images of handwritten digits compiled by the National Institute of Standards and Technology (NIST). The dataset is widely used as a testing ground for machine learning algorithms for image classification.  \n",
        "\n",
        "The images are 28x28 pixels with only a single grayscale channel. You will be using 20,000 samples from the original training dataset for our next set of experiments. \n",
        "\n",
        "You will perform tests on the 10,000 sample test set.\n",
        "\n",
        "In this section, we will implement the linear classifiers with the MNIST dataset"
      ],
      "metadata": {
        "id": "38HrO_eBXjrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to define some helper functions to load the MNIST data."
      ],
      "metadata": {
        "id": "dU3af5u3vY2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist_data_parser_helper(csv_file_name):\n",
        "    X = []\n",
        "    Y = []\n",
        "    with open(csv_file_name,'r') as _file:\n",
        "        csv_reader = csv.reader(_file, delimiter=\",\")\n",
        "        for row in csv_reader:\n",
        "            Y.append(float(row[0]))\n",
        "            X.append([float(i) for i in row[1:]])\n",
        "    return (np.array(X), np.array(Y))\n",
        "\n",
        "def get_mnist_train_data():\n",
        "    X_train, Y_train = mnist_data_parser_helper(\"sample_data/mnist_train_small.csv\")\n",
        "    return X_train, Y_train\n",
        "\n",
        "def get_mnist_test_data():\n",
        "    X_test, Y_test = mnist_data_parser_helper(\"sample_data/mnist_test.csv\")\n",
        "    return X_test, Y_test"
      ],
      "metadata": {
        "id": "y6p9vHGhfBzg"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to visualize some of the samples from the MNIST dataset."
      ],
      "metadata": {
        "id": "nsEncnA3vh9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = get_mnist_train_data()\n",
        "\n",
        "# Visualize some examples from the dataset.\n",
        "# We show a few examples of training images from each class.\n",
        "classes = list(range(10))\n",
        "\n",
        "num_classes = len(classes)\n",
        "samples_per_class = 7\n",
        "for y, cls in enumerate(classes):\n",
        "    idxs = np.flatnonzero(y_train.astype('uint8') == y)\n",
        "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
        "    for i, idx in enumerate(idxs):\n",
        "        plt_idx = i * num_classes + y + 1\n",
        "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
        "        plt.imshow(x_train[idx].astype('uint8').reshape(28,28), cmap='gray')\n",
        "        plt.axis('off')\n",
        "        if i == 0:\n",
        "            plt.title(cls)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "21II-zCpe-ER",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "ec3b124c-95df-4071-ecee-0ce2422e6bc8"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 70 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to gather the training dataset.\n"
      ],
      "metadata": {
        "id": "SLbwp3V-vxg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = get_mnist_train_data()  # Get the training dataset"
      ],
      "metadata": {
        "id": "ZY8RrHx4Fegk"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following gather the testing dataset. "
      ],
      "metadata": {
        "id": "RHijm2aiv0cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = get_mnist_test_data()     # Get the test dataset"
      ],
      "metadata": {
        "id": "84cjF778Ag9O"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following normalize the input dataset to have a mean of 0 and standard deviation of 1. "
      ],
      "metadata": {
        "id": "d4cTK2RDv5wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_mean = x_train.mean()\n",
        "x_std = x_train.std()\n",
        "\n",
        "x_train = (x_train - x_mean)/(x_std)\n",
        "x_test = (x_test - x_mean)/(x_std)"
      ],
      "metadata": {
        "id": "n7RKsVNmfTx7"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to check the dimensions of the data."
      ],
      "metadata": {
        "id": "LfRlRMS9PTZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N, dim = x_train.shape\n",
        "N_test, _ = x_test.shape\n",
        "print(f\"Number of training sample {N} with {dim} pixels per image\")\n",
        "print(f\"Number of training sample {N_test} with {dim} pixels per image\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59jB-sjwQNVL",
        "outputId": "c537708d-5fc9-45b5-800b-20f39ac95e50"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sample 20000 with 784 pixels per image\n",
            "Number of training sample 10000 with 784 pixels per image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implement and Evaluate ML Models\n",
        "\n",
        "In this problem we are optimizing parametric ML models on high-dimensional real world data. As we've seen before in our optimization tasks, even simple polynomial functions can have many local minima that our optimizers can get stuck on.\n",
        "\n",
        "\n",
        "Therefore, we need to be able to evaluate how well our model was optimized on the data, especially on the with different hyperparameters. Hyperparameters are parameters that control the learning process that are not updated during the training process, such learning rate or model size.\n",
        "\n",
        "\n",
        "For large enough datasets, a common strategy is to use [validation sets](https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets) to evaluate the [best model](https://en.wikipedia.org/wiki/Model_selection). In the next cell, split the training dataset into training and validation set with an 80-20 split ratio. "
      ],
      "metadata": {
        "id": "TDV7xaD_BkEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the following cell to split the `x_train` and `y_train` arrays to training and validations sets with an 80-20 split ratio. Place the split arrays in to the `DATA` dictionary. This dictionary will be used to feed data into the `Solver`."
      ],
      "metadata": {
        "id": "wi9rQwaUWBHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform training and validation dataset splits\n",
        "\n",
        "# PUT YOUR CODE BELOW\n",
        "number_of_rows = x_train.shape[0]\n",
        "random_indices = np.random.choice(number_of_rows, size=(int(.8*number_of_rows)), replace=False)\n",
        "\n",
        "random_rows = x_train[random_indices, :]\n",
        "rows_left = np.delete(x_train, random_indices, axis=0)##x_train[-random_indices,:]\n",
        "\n",
        "DATA = {\"X_train\": x_train[random_indices, :],      # Replace with the value here\n",
        "        \"X_val\" : np.delete(x_train, random_indices, axis=0),       # Replace with the value here\n",
        "        \"Y_train\" : y_train[random_indices],     # Replace with the value here\n",
        "        \"Y_val\" : np.delete(y_train, random_indices)}       # Replace with the value here\n"
      ],
      "metadata": {
        "id": "e0gRbRkAEO5C"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(DATA['X_train'].shape)\n",
        "DATA['X_val'].shape\n",
        "## the shapes are correct even if the first couple of rows are the same... this is probably because the first entries are 1s \n"
      ],
      "metadata": {
        "id": "KMdfJF2b3vKX",
        "outputId": "fe05f741-12ca-4fb8-fe6e-6851c823a974",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16000, 784)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA"
      ],
      "metadata": {
        "id": "vtlNuEEP6bvb",
        "outputId": "5de1880e-e7d5-45d0-e1e6-6acb7ca3f33c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'X_train': array([[-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        ...,\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694]]),\n",
              " 'X_val': array([[-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        ...,\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694]]),\n",
              " 'Y_train': array([3., 4., 4., ..., 4., 7., 8.]),\n",
              " 'Y_val': array([9., 5., 6., ..., 6., 0., 5.])}"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimizing Algorithm\n",
        "\n",
        "**Run** the following cell to define the stochastic gradient descent algorithm that we will use to optimize our models. "
      ],
      "metadata": {
        "id": "xXdYUcfTa78v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd(w, dw, lr=1e-2):\n",
        "    \"\"\"\n",
        "    Performs vanilla stochastic gradient descent.\n",
        "\n",
        "    config format:\n",
        "    - learning_rate: Scalar learning rate.\n",
        "    \"\"\"\n",
        "\n",
        "    w -= lr * dw\n",
        "    return w"
      ],
      "metadata": {
        "id": "elsI_qFOa8HB"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Solver\n",
        "\n",
        "\n",
        "The following solver class optimizes a given model using mini-batch gradient optimizations. \n",
        "\n",
        "**Run** the following cell to define the `Solver` class. "
      ],
      "metadata": {
        "id": "haKibBipbrmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Solver(object):\n",
        "    \"\"\"\n",
        "    Solver class for the learnable models using \n",
        "    mini-batch gradient descent.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 data,\n",
        "                 learning_rate=1e-3,\n",
        "                 num_epochs=50,\n",
        "                 batch_size=200,\n",
        "                 validation_frequency=16):\n",
        "        \"\"\"\n",
        "        Construct a new Solver instance.\n",
        "\n",
        "        Inputs:\n",
        "          model: Python class equiped with forward, backward, predict methods and a params dictionary\n",
        "          data: Dictionary with X_train, X_val,  Y_train, Y_val keys\n",
        "          learning_rate: Float, step size of the optimizer\n",
        "          num_epochs: Int, Number of times to completely traverse X_train\n",
        "          batch_size: Int, The number of samples in update\n",
        "          validation_frequency: Int, Solver performs validation loop every validation_frequency batches.\n",
        "                               Set this to a high number if num_epochs is large\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        \n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.validation_frequency = validation_frequency\n",
        "\n",
        "        self.num_training = data[\"X_train\"].shape[0]\n",
        "        self.input_dim = data[\"X_train\"].shape[1]\n",
        "        \n",
        "        intervals = list(range(0, self.num_training, batch_size))[1:]\n",
        "        \n",
        "        self.X_train = np.array_split(data[\"X_train\"], intervals, axis=0)\n",
        "        self.y_train = np.array_split(data[\"Y_train\"], intervals)\n",
        "\n",
        "        self.num_batches_in_training = len(self.X_train)\n",
        "\n",
        "        self.X_val = data[\"X_val\"]\n",
        "        self.y_val = data[\"Y_val\"]\n",
        "\n",
        "        self.update_rule = sgd\n",
        "        self.loss_history = []\n",
        "        self.validation_history = []\n",
        "\n",
        "        self.iteration_num = 0\n",
        "\n",
        "\n",
        "    def _step(self, batch_id):\n",
        "        \"\"\"\n",
        "        Make a single gradient update. This is called by train() and should not\n",
        "        be called manually.\n",
        "        \"\"\"\n",
        "        # Make a minibatch of training data\n",
        "        X_batch = self.X_train[batch_id]\n",
        "        y_batch = self.y_train[batch_id]\n",
        "        #print('X_batch.shape,y_batch.shape',X_batch.shape,y_batch.shape)\n",
        "\n",
        "        # Compute loss and gradient\n",
        "        score, cache = self.model.forward(X_batch)\n",
        "        #print(\"score in step\", score)\n",
        "        loss, dL = self.model.loss(score, y_batch)\n",
        "        #print(\"cache in step\",cache)\n",
        "        _, grads = self.model.backward(dL, cache)\n",
        "\n",
        "        self.loss_history.append(loss)\n",
        "\n",
        "        # Perform a parameter update\n",
        "        for p, w in self.model.params.items():\n",
        "            dw = grads[p]\n",
        "            next_w = self.update_rule(w, dw, self.learning_rate)#svm.params['W1']-= step_size*weight_gradients['W1']\n",
        "            self.model.params[p] = next_w\n",
        "    \n",
        "    \n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Optimization to train the model\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            for batch_id in range(self.num_batches_in_training):\n",
        "                #print(\"batch_id.shape\",batch_id.shape)\n",
        "                \n",
        "                self._step(batch_id)\n",
        "\n",
        "                self.iteration_num += 1\n",
        "\n",
        "                if (self.iteration_num % self.validation_frequency == 0):\n",
        "                    self.validate()\n",
        "\n",
        "        self.validate()\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"\n",
        "        Checks the validation error of the model at the time it is being called.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        N = self.y_val.shape[0]\n",
        "        predictions = self.model.predict(self.X_val)\n",
        " \n",
        "        accuracy = np.count_nonzero(predictions == self.y_val.astype(int))\n",
        "\n",
        "        print(f\"The validation accuracy at iteration {self.iteration_num}  is \\\n",
        "              {(float(accuracy)/N)*100}%\")\n",
        "    \n",
        "\n",
        "    def accuracy(self):\n",
        "        \"\"\"\n",
        "        Checks the validation error of the model at the time it is being called.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        N = self.y_val.shape[0]\n",
        "        predictions = self.model.predict(self.X_val)\n",
        " \n",
        "        accuracy = np.count_nonzero(predictions == self.y_val.astype(int))\n",
        "        print(f\"The validation accuracy at iteration {self.iteration_num}  is \\\n",
        "              {(float(accuracy)/N)*100}%\")\n",
        "        return (float(accuracy)/N)#*100"
      ],
      "metadata": {
        "id": "kQP6qra2bpOL"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (a) Linear Classifier\n",
        "\n",
        "We will be using two linear classifiers on the (MNIST) dataset. Using the linear transform youve implemented before, you will use SGD to train a multiclass support vector machine (SVM) and softmax classifiers to predict the handwritten digits.\n",
        "\n",
        "The linear classifier base class implements training and prediction methods shared by the linear classifiers. \n",
        "\n",
        "**Implement** the following cell to complete the definition of the following `LinearClassifier` class."
      ],
      "metadata": {
        "id": "vZfssCcKavEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the `__init__`, `forward`, `backward`, and `predict` methods. \n",
        "\n",
        "Complete the following:\n",
        "- The `__init__()` method initializes the class. You must generate a random weight matrix of shape `(input_dim+1,num_classes)`  \n",
        "- The `forward()` method generates the scores for given an input sample, by applying a `linear_forward()` transformation on the inputs `x` and weights matrix `self.params['W1']`\n",
        "- The `backward()` method returns the gradients with respect to the inputs and weights, using the `linear_backward()` method. Make sure the key for the returned dictionary `weights_gradient` matches the paramts dictionary.\n",
        "- The `predict()` method returns the labels predicted from the scores returned using the `self.forward()` method. "
      ],
      "metadata": {
        "id": "VbsDBRjmYeUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''input_dim, num_classes = 3,4 \n",
        "\n",
        "\n",
        "w1 = np.random.normal(0, 1e-3, size =(input_dim,num_classes)) ## we need an extra row for the 1s \n",
        "bias = np.ones(num_classes).reshape(1,num_classes);bias\n",
        "w1 = np.append(w1,bias, axis = 0).shape'''\n"
      ],
      "metadata": {
        "id": "rsEfwmwZ8xi6",
        "outputId": "ad12ba1b-d875-4d1b-ff9c-3a58b472fb1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearClassifier(object):\n",
        "    \"\"\"\n",
        "    The base class for the linear classifier. \n",
        "\n",
        "    Note that this class does not implement gradient descent; instead, it\n",
        "    will interact with a separate Solver object that is responsible for running\n",
        "    optimization.\n",
        "\n",
        "    The learnable parameters of the model are stored in the dictionary\n",
        "    self.params that maps parameter names to numpy arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_dim=784,\n",
        "                 num_classes=10):\n",
        "        self.params = {}## these should be our weights \n",
        "        self.input_features = input_dim\n",
        "        self.num_classes = 10\n",
        "\n",
        "        # PUT YOUR CODE BELOW:                                                    \n",
        "        # Initialize the weights of the linear classifier. Weights should be      \n",
        "        # initialized from a Gaussian centered at 0.0 with standard deviation     \n",
        "        # equal to 1e-3, and biases should be initialized to zero.                   \n",
        "        # Store in the self.W dictionary with key name 'W1'                       \n",
        "\n",
        "        ## one layer NN\n",
        "          ## weights in f\n",
        "          ## 1 input (one row) features*edges-> (activation)\n",
        "          ## n inputs (n rows) \n",
        "          ## rows is the sample dimesnion \n",
        "            ## for each minibatch, the same model is used for all the samples in the same batch \n",
        "          \n",
        "        w1 = np.random.normal(0, 1e-3, size =(input_dim,num_classes)) ## we need an extra row for the 1s \n",
        "        bias = np.ones(num_classes).reshape(1,num_classes);bias\n",
        "        w1 = np.append(w1,bias, axis = 0).shape\n",
        "        self.params['W1'] = w1 #np.random.normal(0, 1e-3, size =(input_dim+1,num_classes)) ## these are our weights\n",
        "        ##############################################NN works before this change^^\n",
        "        \n",
        "        ## make sure we have the bias term \n",
        "\n",
        "        ## we should have every \n",
        "\n",
        "        # The lines below do not need to be changed in the method\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        #print('start of forward')\n",
        "        \"\"\"\n",
        "        Train this linear classifier using stochastic gradient descent.\n",
        "\n",
        "        Inputs:\n",
        "        - x: A numpy array of shape (N, D) containing training data; there are N\n",
        "          training samples each of dimension D.\n",
        "\n",
        "        Outputs:\n",
        "        A list containing the value of the loss function at each training iteration.\n",
        "        \"\"\"\n",
        "        num_train, dim = x.shape\n",
        "        num_classes = self.num_classes\n",
        "\n",
        "\n",
        "        #out = None\n",
        "        #cache = None\n",
        "        \n",
        "        # PUT YOUR CODE BELOW:                                                    \n",
        "        # Implement this method. Generate the scores in out and store the old      \n",
        "        # values into the cache.                                                  \n",
        "\n",
        "        w = self.params['W1']\n",
        "        #out, cache\n",
        "        out, cache = linear_forward(x, w)#np.matmul(x,W)\n",
        "        #print('cache in model.forward', cache)\n",
        "        ##cache = (x, w)\n",
        "\n",
        "\n",
        "        #print()\n",
        "        #print(\"in .forward\", out)\n",
        "        #print()\n",
        "        ##############cache = x    changed\n",
        "        # The lines below do not need to be changed\n",
        "\n",
        "        '''- d_upstream: Upstream derivative, of shape (N, M)\n",
        "        - cache: Tuple of:\n",
        "          - x: Input data, of shape (N, D)\n",
        "          - w: Weights, of shape (D+1, M)'''\n",
        "        \n",
        "\n",
        "        out = np.array(out)\n",
        "        #return out, (cache, )\n",
        "        return out, cache\n",
        "    def backward(self, dout, cache):\n",
        "        '''The backward() method returns the gradients with respect to the inputs and weights, \n",
        "        using the linear_backward() method. Make sure the key for the returned dictionary \n",
        "        weights_gradient matches the paramts dictionary.'''\n",
        "        '''- dout: Upstream derivative, of shape (N, C)'''\n",
        "        #d_upstream = dout \n",
        "        #print(\"in .backward cache\",cache)\n",
        "        dx, dw = linear_backward(dout, cache)#dx, dw\n",
        "\n",
        "        weight_gradients = {}\n",
        "        weight_gradients['W1'] = dw\n",
        "        \n",
        "        \n",
        "        # PUT YOUR CODE BELOW:                                                                   \n",
        "        # Implement this method. Generate the gradients with respect to x from \n",
        "        # cache and set it dx, the upstream error signal.\n",
        "        # Store the gradient with respect to the weights in the weights_gradients\n",
        "        # dictionary. Make sure the key matches the ket of the params dictionary    \n",
        "\n",
        "        # The lines below do not need to be changed \n",
        "\n",
        "        return (dx, weight_gradients)\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"\n",
        "        Use the trained weights of this linear classifier to predict labels for\n",
        "        data points.\n",
        "\n",
        "        Inputs:\n",
        "        - x: A numpy array of shape (N, D) containing training data; there are N\n",
        "          training samples each of dimension D.\n",
        "\n",
        "        Returns:\n",
        "        - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional\n",
        "          array of length N, and each element is an integer giving the predicted\n",
        "          class.\n",
        "        \"\"\"\n",
        "        #y_pred = np.zeros(x.shape[0])\n",
        "        #out, cache = linear_forward(x, w)## there are two outputs\n",
        "        scores, cache = linear_forward(x,self.params['W1'])## use the parameters to do a forward pass\n",
        "        \n",
        "        #y_pred = np.amax(scores, axis = 1)\n",
        "        y_pred = np.argmax(scores, axis = 1)\n",
        "        #print(\"shape of y_pred\", )\n",
        "        #print('scores.shape',scores.shape)\n",
        "        #print(\"y_pred in predict\", y_pred.shape)\n",
        "        # PUT YOUR CODE BELOW:                                                                   \n",
        "        # Implement this method. Store the predicted labels in y_pred.            \n",
        "\n",
        "\n",
        "        # The lines below do not need to be changed\n",
        "\n",
        "        return y_pred\n",
        "    \n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        \"\"\"\n",
        "        Compute the loss function and its derivative.\n",
        "        Subclasses will override this.\n",
        "\n",
        "        Inputs:\n",
        "        - scores: A numpy array of shape (N, C) containing a minibatch of N\n",
        "          data points; each point has dimension C, where C is the number of classes.\n",
        "        - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
        "        - reg: (float) regularization strength.\n",
        "\n",
        "        Returns: A tuple containing:\n",
        "        - loss as a single float\n",
        "        - gradient with respect to scores; an array of the same shape as scores\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        \n",
        "        # The lines below do not need to be changed\n",
        "        # Do not implement anything here. The subclasses will override this method\n",
        "        pass"
      ],
      "metadata": {
        "id": "oLgT_g66T71G"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (b) Support Vector Machine\n",
        "\n",
        "\n",
        "The LinearSVM class defines an SVM-based linear classifier. The classifier uses the hinge loss to optimize the model parameters. \n",
        "\n",
        "The Hinge loss for an input sample $x_i$ (a vector) is given by: \n",
        "\n",
        "$$\n",
        "L_i = \\sum_{j \\neq y_i} \\text{max}(0, s_j-s_{y_i}+1)\n",
        "$$\n",
        "\n",
        "\n",
        "Where, $y_i$ is the label of the $i$-th sample.  The label is the correct class label where $0 \\leq y_i \\lt C$, where C is the number of classes.   The scalar $s_{y_i}$ is the $y_i$-th element of the score vector. \n",
        "\n",
        "The average loss over N samples is therefore:\n",
        "\n",
        "$$\n",
        "L = \\frac{1}{N}\\sum^{N}_{i=1}L_i\n",
        "$$\n",
        "\n",
        "The per-sample gradient of the loss w.r.t. the score $s_j$ is given by:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial  L_i}{\\partial s_j} = \\left \\{\n",
        "\\begin{array}{ll}\n",
        "0 & j = s_{y_i} \\text{ or } s_j-s_{y_i}+1 \\leq 0    \\\\\n",
        "1 & j \\neq s_{y_i} \\text{ and } s_j-s_{y_i}+1 > 0 \\\\\n",
        "\\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "**Implement** the `svm_loss` function in the following cell. Store the average loss the `loss` variable and the gradient w.r.t `scores` in the `dy` variable. This is the loss over multiple samples, therefore you should take the mean of the loss. \n"
      ],
      "metadata": {
        "id": "rS6qcaqUcyqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_loss(scores, y_batch):\n",
        "    \"\"\"\n",
        "    Returns hinge loss of the scores and y_batch. \n",
        "\n",
        "    Inputs:\n",
        "    - scores: A numpy array of shape (N, C) containing a minibatch of N\n",
        "      data points; each point has dimension C, where C is the number of classes.\n",
        "    - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
        "    - reg: (float) regularization strength.\n",
        "\n",
        "    Returns: A tuple containing:\n",
        "    - loss as a single float\n",
        "    - gradient with respect to scores; an array of the same shape as scores\n",
        "    \"\"\"\n",
        "\n",
        "    #assert(scores.shape = N,C)\n",
        "\n",
        "    ## the score of each class[without the correct class] - the score of the correct class\n",
        "    loss = 0\n",
        "    dy = np.zeros(scores.shape)  \n",
        "    # PUT YOUR CODE BELOW:                                                       \n",
        "    # Implement the structured SVM loss, storing the  \n",
        "    # result in loss. Make sure to take the mean of the loss.\n",
        "    # Hint: The intermediate results maybe useful for the gradient calculation                                                        \n",
        "\n",
        "    N,C = scores.shape\n",
        "\n",
        "    L = np.zeros((N))\n",
        "    for i in range(N):\n",
        "      yi = int(y_batch[i])## yi is our correct class\n",
        "      #print(\"yi\",yi)\n",
        "      syi = scores[i,yi]## this is the score for our correct class \n",
        "\n",
        "      #sj = scores[i,j!=yi]\n",
        "\n",
        "      acc = 0\n",
        "      for j in range(C): ## across the scores for one sample: \n",
        "        \n",
        "        ## part1 \n",
        "        if j==yi: \n",
        "          #dy[i,j] = 0## this is by default\n",
        "          continue \n",
        "        sj = scores[i,j]\n",
        "        acc+=max(0,\n",
        "                sj-syi+1)\n",
        "        #### part2 \n",
        "        if sj-syi+1>0:## if this is greater than 0 and j!=yi then it should be 1 else 0 which it already is\n",
        "          dy[i,j] = 1\n",
        "        \n",
        "        \n",
        "      \n",
        "    L[i] = acc\n",
        "    #print(L)\n",
        "\n",
        "    loss = np.mean(L)\n",
        "    #print('loss',loss)\n",
        "  \n",
        "    # PUT YOUR CODE BELOW:                                                                    \n",
        "    # Implement the gradient for the SVM loss, storing the result    \n",
        "    # in dy.                                                                    \n",
        "    #                                                                           \n",
        "    # Hint: Instead of computing the gradient from scratch, it may be easier    \n",
        "    # to reuse some of the intermediate values that you used to compute the     \n",
        "    # loss.                                                                     \n",
        "\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "    return loss, dy"
      ],
      "metadata": {
        "id": "S-_mC08N89UC"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to define the `LinearSVM` class with your implementation of the `svm_loss`"
      ],
      "metadata": {
        "id": "MMaObHBhamT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearSVM(LinearClassifier):\n",
        "    \"\"\" A subclass that uses the Multiclass SVM loss function \"\"\"\n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        return svm_loss(scores, y_batch)"
      ],
      "metadata": {
        "id": "VD43ltPTcw-B"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SVM Experiments\n",
        "\n",
        "In the next few cells run the `Solver` with SVM models on the training and validation data you've defined previously. Use the `DATA` dictionary you defined previously as the data parameter.\n",
        "\n",
        "As you have seen with previous assignments, optimizations can be highly dependent on the hyperparameters of the model. You should try multiple models with different learning rates. You may also increase the amount of time you train by increasing the number of epochs. \n",
        "\n",
        "Keep the top-5 best performing models and the worst performing model on the validation set.\n"
      ],
      "metadata": {
        "id": "DNPZ7RoU2Oyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** hyperparameter validation loop in the next cell to train multiple models with different hyperparameters. Keep the top-5 best performing models on the validation set. You can try different learning rates. You may change the num_epochs, but be wary of timeouts. "
      ],
      "metadata": {
        "id": "DD7et1xEF9h6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA"
      ],
      "metadata": {
        "id": "AzghjWpDTvaI",
        "outputId": "306cc888-3241-4a5e-f0b2-ebe78908d231",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'X_train': array([[-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        ...,\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694]]),\n",
              " 'X_val': array([[-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        ...,\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694]]),\n",
              " 'Y_train': array([3., 4., 4., ..., 4., 7., 8.]),\n",
              " 'Y_val': array([9., 5., 6., ..., 6., 0., 5.])}"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sABaWAr8-I1O"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''## this is just training... no validation \n",
        "\n",
        "#The forward() method generates the scores for given an input sample\n",
        "#The predict() method returns the labels predicted from the scores returned using the self.forward()\n",
        "\n",
        "X_train = DATA['X_train']\n",
        "\n",
        "svm = LinearSVM()## this shouldn't need to be passed any paramters\n",
        "step_size = .01\n",
        "batch_size = 8\n",
        "#for epoch in range(epochs)\n",
        "#for minibatch in samples\n",
        "not_end = True\n",
        "i = 0\n",
        "while (not_end) :\n",
        "  X_batch = X_train[i*batch_size:(i+1)*batch_size,:]\n",
        "  y_batch = y_train[i*batch_size: (i+1)*batch_size]\n",
        "  \n",
        "  if ((i*batch_size) > X_train.shape[0]) :\n",
        "    not_end = False\n",
        "  print(\"before forward\")\n",
        "  scores,cache = svm.forward(X_batch)\n",
        "  print(\"after forward\")\n",
        "  #print(type(scores),scores, \"scores\")## scores should be one matrix....\n",
        "  #print(len(scores))\n",
        "  loss,dy = svm.loss(scores,y_batch)\n",
        "  (dx,weight_gradients) = svm.backward(dy,cache)\n",
        "  svm.params['W1']-= step_size*weight_gradients['W1']\n",
        "  #print(batch)\n",
        "  #print()\n",
        "  i+=1\n",
        "  print('end of batch')\n",
        "'''\n",
        "'''\n",
        "## scores was dout \n",
        "scores, (cache, ) =svm.forward(x)## we need to do this to get answers for th back prop\n",
        "##.forward : A list containing the value of the loss function at each training iteration.\n",
        "\n",
        "loss, dy = svm.loss(scores, y_batch)## this is our dL/dy\n",
        "\n",
        "## dy was dout \n",
        "(dx, weight_gradients) = svm.backward(dy, cache)## this uses our dL/dy to update the weights\n",
        "svm.params['W1'] -= step_size*weight_gradients['W1']\n",
        "DATA'''\n"
      ],
      "metadata": {
        "id": "US364cOjGC5p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0e7ee312-f477-4cf7-92c5-5c19888f9ab7"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n## scores was dout \\nscores, (cache, ) =svm.forward(x)## we need to do this to get answers for th back prop\\n##.forward : A list containing the value of the loss function at each training iteration.\\n\\nloss, dy = svm.loss(scores, y_batch)## this is our dL/dy\\n\\n## dy was dout \\n(dx, weight_gradients) = svm.backward(dy, cache)## this uses our dL/dy to update the weights\\nsvm.params['W1'] -= step_size*weight_gradients['W1']\\nDATA\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "10*10*10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kH6-e9H5NRL",
        "outputId": "4b678389-fa50-4375-f002-a9986e1a0a19"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = [None]\n",
        "\n",
        "LR = [.1**x for x in range(1,11,2)]\n",
        "BS =[x for x in range(50,550,100)]\n",
        "print(\"itters\", len(LR)*len(BS))\n",
        "#E = [x for x in range(10,110,20)]\n",
        "#print(E)\n",
        "#print(LR)\n",
        "\n",
        "for lr in LR: \n",
        "  for bs in BS: \n",
        "    svm = LinearSVM()\n",
        "    solver = Solver(svm,DATA, learning_rate=lr, batch_size=bs)\n",
        "    solver.train()\n",
        "\n",
        "    acc = solver.accuracy()\n",
        "    for i in range(len(best_models)): \n",
        "      if (best_models[i] == None):\n",
        "        best_models[i] = solver\n",
        "      elif len(best_models)<5:\n",
        "        best_models.append( solver)\n",
        "      elif(best_models[i].accuracy()<solver.accuracy()):\n",
        "        best_models[i] = solver\n",
        "        break\n",
        "    print(best_models)\n",
        "    \n",
        "\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtdEjmlE3ox8",
        "outputId": "e41a27fe-4d10-4523-e6a4-1392921603bf"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "The validation accuracy at iteration 8544  is               82.69999999999999%\n",
            "The validation accuracy at iteration 8560  is               82.89999999999999%\n",
            "The validation accuracy at iteration 8576  is               82.92500000000001%\n",
            "The validation accuracy at iteration 8592  is               82.75%\n",
            "The validation accuracy at iteration 8608  is               82.45%\n",
            "The validation accuracy at iteration 8624  is               82.55%\n",
            "The validation accuracy at iteration 8640  is               82.425%\n",
            "The validation accuracy at iteration 8656  is               82.425%\n",
            "The validation accuracy at iteration 8672  is               82.65%\n",
            "The validation accuracy at iteration 8688  is               82.65%\n",
            "The validation accuracy at iteration 8704  is               82.425%\n",
            "The validation accuracy at iteration 8720  is               82.575%\n",
            "The validation accuracy at iteration 8736  is               82.69999999999999%\n",
            "The validation accuracy at iteration 8752  is               82.5%\n",
            "The validation accuracy at iteration 8768  is               82.675%\n",
            "The validation accuracy at iteration 8784  is               82.625%\n",
            "The validation accuracy at iteration 8800  is               82.775%\n",
            "The validation accuracy at iteration 8816  is               82.75%\n",
            "The validation accuracy at iteration 8832  is               82.6%\n",
            "The validation accuracy at iteration 8848  is               82.92500000000001%\n",
            "The validation accuracy at iteration 8864  is               82.675%\n",
            "The validation accuracy at iteration 8880  is               82.89999999999999%\n",
            "The validation accuracy at iteration 8896  is               82.92500000000001%\n",
            "The validation accuracy at iteration 8912  is               82.8%\n",
            "The validation accuracy at iteration 8928  is               82.375%\n",
            "The validation accuracy at iteration 8944  is               82.55%\n",
            "The validation accuracy at iteration 8960  is               82.35%\n",
            "The validation accuracy at iteration 8976  is               82.425%\n",
            "The validation accuracy at iteration 8992  is               82.625%\n",
            "The validation accuracy at iteration 9008  is               82.72500000000001%\n",
            "The validation accuracy at iteration 9024  is               82.425%\n",
            "The validation accuracy at iteration 9040  is               82.5%\n",
            "The validation accuracy at iteration 9056  is               82.72500000000001%\n",
            "The validation accuracy at iteration 9072  is               82.575%\n",
            "The validation accuracy at iteration 9088  is               82.69999999999999%\n",
            "The validation accuracy at iteration 9104  is               82.675%\n",
            "The validation accuracy at iteration 9120  is               82.75%\n",
            "The validation accuracy at iteration 9136  is               82.69999999999999%\n",
            "The validation accuracy at iteration 9152  is               82.55%\n",
            "The validation accuracy at iteration 9168  is               82.825%\n",
            "The validation accuracy at iteration 9184  is               82.675%\n",
            "The validation accuracy at iteration 9200  is               82.89999999999999%\n",
            "The validation accuracy at iteration 9216  is               83.0%\n",
            "The validation accuracy at iteration 9232  is               82.775%\n",
            "The validation accuracy at iteration 9248  is               82.325%\n",
            "The validation accuracy at iteration 9264  is               82.5%\n",
            "The validation accuracy at iteration 9280  is               82.375%\n",
            "The validation accuracy at iteration 9296  is               82.525%\n",
            "The validation accuracy at iteration 9312  is               82.675%\n",
            "The validation accuracy at iteration 9328  is               82.75%\n",
            "The validation accuracy at iteration 9344  is               82.5%\n",
            "The validation accuracy at iteration 9360  is               82.5%\n",
            "The validation accuracy at iteration 9376  is               82.625%\n",
            "The validation accuracy at iteration 9392  is               82.475%\n",
            "The validation accuracy at iteration 9408  is               82.75%\n",
            "The validation accuracy at iteration 9424  is               82.575%\n",
            "The validation accuracy at iteration 9440  is               82.675%\n",
            "The validation accuracy at iteration 9456  is               82.72500000000001%\n",
            "The validation accuracy at iteration 9472  is               82.6%\n",
            "The validation accuracy at iteration 9488  is               82.875%\n",
            "The validation accuracy at iteration 9504  is               82.69999999999999%\n",
            "The validation accuracy at iteration 9520  is               82.85%\n",
            "The validation accuracy at iteration 9536  is               82.89999999999999%\n",
            "The validation accuracy at iteration 9552  is               82.675%\n",
            "The validation accuracy at iteration 9568  is               82.27499999999999%\n",
            "The validation accuracy at iteration 9584  is               82.425%\n",
            "The validation accuracy at iteration 9600  is               82.475%\n",
            "The validation accuracy at iteration 9616  is               82.375%\n",
            "The validation accuracy at iteration 9632  is               82.675%\n",
            "The validation accuracy at iteration 9648  is               82.69999999999999%\n",
            "The validation accuracy at iteration 9664  is               82.325%\n",
            "The validation accuracy at iteration 9680  is               82.625%\n",
            "The validation accuracy at iteration 9696  is               82.55%\n",
            "The validation accuracy at iteration 9712  is               82.39999999999999%\n",
            "The validation accuracy at iteration 9728  is               82.75%\n",
            "The validation accuracy at iteration 9744  is               82.65%\n",
            "The validation accuracy at iteration 9760  is               82.675%\n",
            "The validation accuracy at iteration 9776  is               82.69999999999999%\n",
            "The validation accuracy at iteration 9792  is               82.69999999999999%\n",
            "The validation accuracy at iteration 9808  is               82.775%\n",
            "The validation accuracy at iteration 9824  is               82.775%\n",
            "The validation accuracy at iteration 9840  is               82.875%\n",
            "The validation accuracy at iteration 9856  is               82.825%\n",
            "The validation accuracy at iteration 9872  is               82.625%\n",
            "The validation accuracy at iteration 9888  is               82.375%\n",
            "The validation accuracy at iteration 9904  is               82.525%\n",
            "The validation accuracy at iteration 9920  is               82.55%\n",
            "The validation accuracy at iteration 9936  is               82.475%\n",
            "The validation accuracy at iteration 9952  is               82.65%\n",
            "The validation accuracy at iteration 9968  is               82.75%\n",
            "The validation accuracy at iteration 9984  is               82.39999999999999%\n",
            "The validation accuracy at iteration 10000  is               82.5%\n",
            "The validation accuracy at iteration 10016  is               82.35%\n",
            "The validation accuracy at iteration 10032  is               82.375%\n",
            "The validation accuracy at iteration 10048  is               82.775%\n",
            "The validation accuracy at iteration 10064  is               82.72500000000001%\n",
            "The validation accuracy at iteration 10080  is               82.675%\n",
            "The validation accuracy at iteration 10096  is               82.825%\n",
            "The validation accuracy at iteration 10112  is               82.575%\n",
            "The validation accuracy at iteration 10128  is               82.775%\n",
            "The validation accuracy at iteration 10144  is               82.72500000000001%\n",
            "The validation accuracy at iteration 10160  is               82.825%\n",
            "The validation accuracy at iteration 10176  is               82.775%\n",
            "The validation accuracy at iteration 10192  is               82.6%\n",
            "The validation accuracy at iteration 10208  is               82.25%\n",
            "The validation accuracy at iteration 10224  is               82.55%\n",
            "The validation accuracy at iteration 10240  is               82.5%\n",
            "The validation accuracy at iteration 10256  is               82.425%\n",
            "The validation accuracy at iteration 10272  is               82.625%\n",
            "The validation accuracy at iteration 10288  is               82.775%\n",
            "The validation accuracy at iteration 10304  is               82.425%\n",
            "The validation accuracy at iteration 10320  is               82.475%\n",
            "The validation accuracy at iteration 10336  is               82.325%\n",
            "The validation accuracy at iteration 10352  is               82.5%\n",
            "The validation accuracy at iteration 10368  is               82.69999999999999%\n",
            "The validation accuracy at iteration 10384  is               82.69999999999999%\n",
            "The validation accuracy at iteration 10400  is               82.625%\n",
            "The validation accuracy at iteration 10416  is               82.69999999999999%\n",
            "The validation accuracy at iteration 10432  is               82.69999999999999%\n",
            "The validation accuracy at iteration 10448  is               82.75%\n",
            "The validation accuracy at iteration 10464  is               82.69999999999999%\n",
            "The validation accuracy at iteration 10480  is               82.85%\n",
            "The validation accuracy at iteration 10496  is               82.85%\n",
            "The validation accuracy at iteration 10512  is               82.675%\n",
            "The validation accuracy at iteration 10528  is               82.27499999999999%\n",
            "The validation accuracy at iteration 10544  is               82.45%\n",
            "The validation accuracy at iteration 10560  is               82.5%\n",
            "The validation accuracy at iteration 10576  is               82.425%\n",
            "The validation accuracy at iteration 10592  is               82.625%\n",
            "The validation accuracy at iteration 10608  is               82.89999999999999%\n",
            "The validation accuracy at iteration 10624  is               82.39999999999999%\n",
            "The validation accuracy at iteration 10640  is               82.425%\n",
            "The validation accuracy at iteration 10656  is               82.3%\n",
            "The validation accuracy at iteration 10672  is               82.45%\n",
            "The validation accuracy at iteration 10688  is               82.72500000000001%\n",
            "The validation accuracy at iteration 10704  is               82.625%\n",
            "The validation accuracy at iteration 10720  is               82.575%\n",
            "The validation accuracy at iteration 10736  is               82.675%\n",
            "The validation accuracy at iteration 10752  is               82.675%\n",
            "The validation accuracy at iteration 10768  is               82.89999999999999%\n",
            "The validation accuracy at iteration 10784  is               82.75%\n",
            "The validation accuracy at iteration 10800  is               82.8%\n",
            "The validation accuracy at iteration 10816  is               82.875%\n",
            "The validation accuracy at iteration 10832  is               82.6%\n",
            "The validation accuracy at iteration 10848  is               82.3%\n",
            "The validation accuracy at iteration 10864  is               82.55%\n",
            "The validation accuracy at iteration 10880  is               82.575%\n",
            "The validation accuracy at iteration 10896  is               82.375%\n",
            "The validation accuracy at iteration 10912  is               82.6%\n",
            "The validation accuracy at iteration 10928  is               82.75%\n",
            "The validation accuracy at iteration 10944  is               82.39999999999999%\n",
            "The validation accuracy at iteration 10960  is               82.375%\n",
            "The validation accuracy at iteration 10976  is               82.35%\n",
            "The validation accuracy at iteration 10992  is               82.475%\n",
            "The validation accuracy at iteration 11008  is               82.625%\n",
            "The validation accuracy at iteration 11024  is               82.675%\n",
            "The validation accuracy at iteration 11040  is               82.55%\n",
            "The validation accuracy at iteration 11056  is               82.69999999999999%\n",
            "The validation accuracy at iteration 11072  is               82.675%\n",
            "The validation accuracy at iteration 11088  is               82.92500000000001%\n",
            "The validation accuracy at iteration 11104  is               82.75%\n",
            "The validation accuracy at iteration 11120  is               82.675%\n",
            "The validation accuracy at iteration 11136  is               82.89999999999999%\n",
            "The validation accuracy at iteration 11152  is               82.625%\n",
            "The validation accuracy at iteration 11168  is               82.27499999999999%\n",
            "The validation accuracy at iteration 11184  is               82.425%\n",
            "The validation accuracy at iteration 11200  is               82.5%\n",
            "The validation accuracy at iteration 11216  is               82.35%\n",
            "The validation accuracy at iteration 11232  is               82.525%\n",
            "The validation accuracy at iteration 11248  is               82.6%\n",
            "The validation accuracy at iteration 11264  is               82.375%\n",
            "The validation accuracy at iteration 11280  is               82.325%\n",
            "The validation accuracy at iteration 11296  is               82.27499999999999%\n",
            "The validation accuracy at iteration 11312  is               82.45%\n",
            "The validation accuracy at iteration 11328  is               82.625%\n",
            "The validation accuracy at iteration 11344  is               82.55%\n",
            "The validation accuracy at iteration 11360  is               82.5%\n",
            "The validation accuracy at iteration 11376  is               82.875%\n",
            "The validation accuracy at iteration 11392  is               82.75%\n",
            "The validation accuracy at iteration 11408  is               82.975%\n",
            "The validation accuracy at iteration 11424  is               82.75%\n",
            "The validation accuracy at iteration 11440  is               82.6%\n",
            "The validation accuracy at iteration 11456  is               82.89999999999999%\n",
            "The validation accuracy at iteration 11472  is               82.65%\n",
            "The validation accuracy at iteration 11488  is               82.22500000000001%\n",
            "The validation accuracy at iteration 11504  is               82.45%\n",
            "The validation accuracy at iteration 11520  is               82.575%\n",
            "The validation accuracy at iteration 11536  is               82.35%\n",
            "The validation accuracy at iteration 11552  is               82.5%\n",
            "The validation accuracy at iteration 11568  is               82.6%\n",
            "The validation accuracy at iteration 11584  is               82.45%\n",
            "The validation accuracy at iteration 11600  is               82.35%\n",
            "The validation accuracy at iteration 11616  is               82.325%\n",
            "The validation accuracy at iteration 11632  is               82.425%\n",
            "The validation accuracy at iteration 11648  is               82.5%\n",
            "The validation accuracy at iteration 11664  is               82.6%\n",
            "The validation accuracy at iteration 11680  is               82.475%\n",
            "The validation accuracy at iteration 11696  is               82.75%\n",
            "The validation accuracy at iteration 11712  is               82.65%\n",
            "The validation accuracy at iteration 11728  is               82.975%\n",
            "The validation accuracy at iteration 11744  is               82.69999999999999%\n",
            "The validation accuracy at iteration 11760  is               82.6%\n",
            "The validation accuracy at iteration 11776  is               82.95%\n",
            "The validation accuracy at iteration 11792  is               82.69999999999999%\n",
            "The validation accuracy at iteration 11808  is               82.19999999999999%\n",
            "The validation accuracy at iteration 11824  is               82.6%\n",
            "The validation accuracy at iteration 11840  is               82.6%\n",
            "The validation accuracy at iteration 11856  is               82.5%\n",
            "The validation accuracy at iteration 11872  is               82.475%\n",
            "The validation accuracy at iteration 11888  is               82.575%\n",
            "The validation accuracy at iteration 11904  is               82.325%\n",
            "The validation accuracy at iteration 11920  is               82.425%\n",
            "The validation accuracy at iteration 11936  is               82.27499999999999%\n",
            "The validation accuracy at iteration 11952  is               82.475%\n",
            "The validation accuracy at iteration 11968  is               82.575%\n",
            "The validation accuracy at iteration 11984  is               82.525%\n",
            "The validation accuracy at iteration 12000  is               82.39999999999999%\n",
            "The validation accuracy at iteration 12016  is               82.72500000000001%\n",
            "The validation accuracy at iteration 12032  is               82.575%\n",
            "The validation accuracy at iteration 12048  is               82.95%\n",
            "The validation accuracy at iteration 12064  is               82.675%\n",
            "The validation accuracy at iteration 12080  is               82.675%\n",
            "The validation accuracy at iteration 12096  is               82.89999999999999%\n",
            "The validation accuracy at iteration 12112  is               82.75%\n",
            "The validation accuracy at iteration 12128  is               82.22500000000001%\n",
            "The validation accuracy at iteration 12144  is               82.575%\n",
            "The validation accuracy at iteration 12160  is               82.5%\n",
            "The validation accuracy at iteration 12176  is               82.425%\n",
            "The validation accuracy at iteration 12192  is               82.475%\n",
            "The validation accuracy at iteration 12208  is               82.55%\n",
            "The validation accuracy at iteration 12224  is               82.425%\n",
            "The validation accuracy at iteration 12240  is               82.375%\n",
            "The validation accuracy at iteration 12256  is               82.375%\n",
            "The validation accuracy at iteration 12272  is               82.35%\n",
            "The validation accuracy at iteration 12288  is               82.6%\n",
            "The validation accuracy at iteration 12304  is               82.525%\n",
            "The validation accuracy at iteration 12320  is               82.475%\n",
            "The validation accuracy at iteration 12336  is               82.72500000000001%\n",
            "The validation accuracy at iteration 12352  is               82.575%\n",
            "The validation accuracy at iteration 12368  is               82.875%\n",
            "The validation accuracy at iteration 12384  is               82.65%\n",
            "The validation accuracy at iteration 12400  is               82.6%\n",
            "The validation accuracy at iteration 12416  is               82.92500000000001%\n",
            "The validation accuracy at iteration 12432  is               82.625%\n",
            "The validation accuracy at iteration 12448  is               82.25%\n",
            "The validation accuracy at iteration 12464  is               82.5%\n",
            "The validation accuracy at iteration 12480  is               82.5%\n",
            "The validation accuracy at iteration 12496  is               82.425%\n",
            "The validation accuracy at iteration 12512  is               82.475%\n",
            "The validation accuracy at iteration 12528  is               82.55%\n",
            "The validation accuracy at iteration 12544  is               82.27499999999999%\n",
            "The validation accuracy at iteration 12560  is               82.35%\n",
            "The validation accuracy at iteration 12576  is               82.3%\n",
            "The validation accuracy at iteration 12592  is               82.475%\n",
            "The validation accuracy at iteration 12608  is               82.625%\n",
            "The validation accuracy at iteration 12624  is               82.525%\n",
            "The validation accuracy at iteration 12640  is               82.475%\n",
            "The validation accuracy at iteration 12656  is               82.69999999999999%\n",
            "The validation accuracy at iteration 12672  is               82.5%\n",
            "The validation accuracy at iteration 12688  is               82.89999999999999%\n",
            "The validation accuracy at iteration 12704  is               82.675%\n",
            "The validation accuracy at iteration 12720  is               82.55%\n",
            "The validation accuracy at iteration 12736  is               83.0%\n",
            "The validation accuracy at iteration 12752  is               82.65%\n",
            "The validation accuracy at iteration 12768  is               82.175%\n",
            "The validation accuracy at iteration 12784  is               82.475%\n",
            "The validation accuracy at iteration 12800  is               82.5%\n",
            "The validation accuracy at iteration 12816  is               82.5%\n",
            "The validation accuracy at iteration 12832  is               82.39999999999999%\n",
            "The validation accuracy at iteration 12848  is               82.525%\n",
            "The validation accuracy at iteration 12864  is               82.3%\n",
            "The validation accuracy at iteration 12880  is               82.375%\n",
            "The validation accuracy at iteration 12896  is               82.325%\n",
            "The validation accuracy at iteration 12912  is               82.45%\n",
            "The validation accuracy at iteration 12928  is               82.65%\n",
            "The validation accuracy at iteration 12944  is               82.45%\n",
            "The validation accuracy at iteration 12960  is               82.45%\n",
            "The validation accuracy at iteration 12976  is               82.675%\n",
            "The validation accuracy at iteration 12992  is               82.575%\n",
            "The validation accuracy at iteration 13008  is               82.975%\n",
            "The validation accuracy at iteration 13024  is               82.6%\n",
            "The validation accuracy at iteration 13040  is               82.675%\n",
            "The validation accuracy at iteration 13056  is               83.025%\n",
            "The validation accuracy at iteration 13072  is               82.675%\n",
            "The validation accuracy at iteration 13088  is               82.175%\n",
            "The validation accuracy at iteration 13104  is               82.55%\n",
            "The validation accuracy at iteration 13120  is               82.575%\n",
            "The validation accuracy at iteration 13136  is               82.5%\n",
            "The validation accuracy at iteration 13152  is               82.575%\n",
            "The validation accuracy at iteration 13168  is               82.6%\n",
            "The validation accuracy at iteration 13184  is               82.35%\n",
            "The validation accuracy at iteration 13200  is               82.35%\n",
            "The validation accuracy at iteration 13216  is               82.25%\n",
            "The validation accuracy at iteration 13232  is               82.39999999999999%\n",
            "The validation accuracy at iteration 13248  is               82.65%\n",
            "The validation accuracy at iteration 13264  is               82.5%\n",
            "The validation accuracy at iteration 13280  is               82.55%\n",
            "The validation accuracy at iteration 13296  is               82.8%\n",
            "The validation accuracy at iteration 13312  is               82.65%\n",
            "The validation accuracy at iteration 13328  is               82.975%\n",
            "The validation accuracy at iteration 13344  is               82.55%\n",
            "The validation accuracy at iteration 13360  is               82.8%\n",
            "The validation accuracy at iteration 13376  is               82.95%\n",
            "The validation accuracy at iteration 13392  is               82.675%\n",
            "The validation accuracy at iteration 13408  is               82.19999999999999%\n",
            "The validation accuracy at iteration 13424  is               82.39999999999999%\n",
            "The validation accuracy at iteration 13440  is               82.6%\n",
            "The validation accuracy at iteration 13456  is               82.8%\n",
            "The validation accuracy at iteration 13472  is               82.375%\n",
            "The validation accuracy at iteration 13488  is               82.65%\n",
            "The validation accuracy at iteration 13504  is               82.325%\n",
            "The validation accuracy at iteration 13520  is               82.375%\n",
            "The validation accuracy at iteration 13536  is               82.22500000000001%\n",
            "The validation accuracy at iteration 13552  is               82.39999999999999%\n",
            "The validation accuracy at iteration 13568  is               82.65%\n",
            "The validation accuracy at iteration 13584  is               82.575%\n",
            "The validation accuracy at iteration 13600  is               82.55%\n",
            "The validation accuracy at iteration 13616  is               82.72500000000001%\n",
            "The validation accuracy at iteration 13632  is               82.72500000000001%\n",
            "The validation accuracy at iteration 13648  is               82.975%\n",
            "The validation accuracy at iteration 13664  is               82.55%\n",
            "The validation accuracy at iteration 13680  is               82.775%\n",
            "The validation accuracy at iteration 13696  is               82.875%\n",
            "The validation accuracy at iteration 13712  is               82.65%\n",
            "The validation accuracy at iteration 13728  is               82.22500000000001%\n",
            "The validation accuracy at iteration 13744  is               82.39999999999999%\n",
            "The validation accuracy at iteration 13760  is               82.575%\n",
            "The validation accuracy at iteration 13776  is               82.6%\n",
            "The validation accuracy at iteration 13792  is               82.525%\n",
            "The validation accuracy at iteration 13808  is               82.575%\n",
            "The validation accuracy at iteration 13824  is               82.3%\n",
            "The validation accuracy at iteration 13840  is               82.325%\n",
            "The validation accuracy at iteration 13856  is               82.3%\n",
            "The validation accuracy at iteration 13872  is               82.39999999999999%\n",
            "The validation accuracy at iteration 13888  is               82.65%\n",
            "The validation accuracy at iteration 13904  is               82.525%\n",
            "The validation accuracy at iteration 13920  is               82.525%\n",
            "The validation accuracy at iteration 13936  is               82.675%\n",
            "The validation accuracy at iteration 13952  is               82.69999999999999%\n",
            "The validation accuracy at iteration 13968  is               83.025%\n",
            "The validation accuracy at iteration 13984  is               82.55%\n",
            "The validation accuracy at iteration 14000  is               82.775%\n",
            "The validation accuracy at iteration 14016  is               82.89999999999999%\n",
            "The validation accuracy at iteration 14032  is               82.6%\n",
            "The validation accuracy at iteration 14048  is               82.19999999999999%\n",
            "The validation accuracy at iteration 14064  is               82.375%\n",
            "The validation accuracy at iteration 14080  is               82.575%\n",
            "The validation accuracy at iteration 14096  is               82.65%\n",
            "The validation accuracy at iteration 14112  is               82.5%\n",
            "The validation accuracy at iteration 14128  is               82.425%\n",
            "The validation accuracy at iteration 14144  is               82.25%\n",
            "The validation accuracy at iteration 14160  is               82.27499999999999%\n",
            "The validation accuracy at iteration 14176  is               82.25%\n",
            "The validation accuracy at iteration 14192  is               82.375%\n",
            "The validation accuracy at iteration 14208  is               82.6%\n",
            "The validation accuracy at iteration 14224  is               82.375%\n",
            "The validation accuracy at iteration 14240  is               82.45%\n",
            "The validation accuracy at iteration 14256  is               82.6%\n",
            "The validation accuracy at iteration 14272  is               82.72500000000001%\n",
            "The validation accuracy at iteration 14288  is               82.92500000000001%\n",
            "The validation accuracy at iteration 14304  is               82.575%\n",
            "The validation accuracy at iteration 14320  is               82.72500000000001%\n",
            "The validation accuracy at iteration 14336  is               82.85%\n",
            "The validation accuracy at iteration 14352  is               82.625%\n",
            "The validation accuracy at iteration 14368  is               82.19999999999999%\n",
            "The validation accuracy at iteration 14384  is               82.525%\n",
            "The validation accuracy at iteration 14400  is               82.575%\n",
            "The validation accuracy at iteration 14416  is               82.575%\n",
            "The validation accuracy at iteration 14432  is               82.475%\n",
            "The validation accuracy at iteration 14448  is               82.475%\n",
            "The validation accuracy at iteration 14464  is               82.25%\n",
            "The validation accuracy at iteration 14480  is               82.325%\n",
            "The validation accuracy at iteration 14496  is               82.39999999999999%\n",
            "The validation accuracy at iteration 14512  is               82.39999999999999%\n",
            "The validation accuracy at iteration 14528  is               82.6%\n",
            "The validation accuracy at iteration 14544  is               82.475%\n",
            "The validation accuracy at iteration 14560  is               82.425%\n",
            "The validation accuracy at iteration 14576  is               82.625%\n",
            "The validation accuracy at iteration 14592  is               82.69999999999999%\n",
            "The validation accuracy at iteration 14608  is               82.85%\n",
            "The validation accuracy at iteration 14624  is               82.475%\n",
            "The validation accuracy at iteration 14640  is               82.69999999999999%\n",
            "The validation accuracy at iteration 14656  is               82.875%\n",
            "The validation accuracy at iteration 14672  is               82.475%\n",
            "The validation accuracy at iteration 14688  is               82.15%\n",
            "The validation accuracy at iteration 14704  is               82.5%\n",
            "The validation accuracy at iteration 14720  is               82.625%\n",
            "The validation accuracy at iteration 14736  is               82.6%\n",
            "The validation accuracy at iteration 14752  is               82.5%\n",
            "The validation accuracy at iteration 14768  is               82.5%\n",
            "The validation accuracy at iteration 14784  is               82.3%\n",
            "The validation accuracy at iteration 14800  is               82.3%\n",
            "The validation accuracy at iteration 14816  is               82.39999999999999%\n",
            "The validation accuracy at iteration 14832  is               82.425%\n",
            "The validation accuracy at iteration 14848  is               82.575%\n",
            "The validation accuracy at iteration 14864  is               82.375%\n",
            "The validation accuracy at iteration 14880  is               82.39999999999999%\n",
            "The validation accuracy at iteration 14896  is               82.69999999999999%\n",
            "The validation accuracy at iteration 14912  is               82.69999999999999%\n",
            "The validation accuracy at iteration 14928  is               82.85%\n",
            "The validation accuracy at iteration 14944  is               82.55%\n",
            "The validation accuracy at iteration 14960  is               82.72500000000001%\n",
            "The validation accuracy at iteration 14976  is               82.72500000000001%\n",
            "The validation accuracy at iteration 14992  is               82.425%\n",
            "The validation accuracy at iteration 15008  is               82.22500000000001%\n",
            "The validation accuracy at iteration 15024  is               82.525%\n",
            "The validation accuracy at iteration 15040  is               82.5%\n",
            "The validation accuracy at iteration 15056  is               82.475%\n",
            "The validation accuracy at iteration 15072  is               82.525%\n",
            "The validation accuracy at iteration 15088  is               82.475%\n",
            "The validation accuracy at iteration 15104  is               82.25%\n",
            "The validation accuracy at iteration 15120  is               82.25%\n",
            "The validation accuracy at iteration 15136  is               82.525%\n",
            "The validation accuracy at iteration 15152  is               82.425%\n",
            "The validation accuracy at iteration 15168  is               82.55%\n",
            "The validation accuracy at iteration 15184  is               82.39999999999999%\n",
            "The validation accuracy at iteration 15200  is               82.375%\n",
            "The validation accuracy at iteration 15216  is               82.6%\n",
            "The validation accuracy at iteration 15232  is               82.69999999999999%\n",
            "The validation accuracy at iteration 15248  is               82.8%\n",
            "The validation accuracy at iteration 15264  is               82.525%\n",
            "The validation accuracy at iteration 15280  is               82.72500000000001%\n",
            "The validation accuracy at iteration 15296  is               82.825%\n",
            "The validation accuracy at iteration 15312  is               82.425%\n",
            "The validation accuracy at iteration 15328  is               82.22500000000001%\n",
            "The validation accuracy at iteration 15344  is               82.525%\n",
            "The validation accuracy at iteration 15360  is               82.625%\n",
            "The validation accuracy at iteration 15376  is               82.65%\n",
            "The validation accuracy at iteration 15392  is               82.475%\n",
            "The validation accuracy at iteration 15408  is               82.525%\n",
            "The validation accuracy at iteration 15424  is               82.27499999999999%\n",
            "The validation accuracy at iteration 15440  is               82.27499999999999%\n",
            "The validation accuracy at iteration 15456  is               82.525%\n",
            "The validation accuracy at iteration 15472  is               82.45%\n",
            "The validation accuracy at iteration 15488  is               82.45%\n",
            "The validation accuracy at iteration 15504  is               82.35%\n",
            "The validation accuracy at iteration 15520  is               82.35%\n",
            "The validation accuracy at iteration 15536  is               82.625%\n",
            "The validation accuracy at iteration 15552  is               82.6%\n",
            "The validation accuracy at iteration 15568  is               82.69999999999999%\n",
            "The validation accuracy at iteration 15584  is               82.475%\n",
            "The validation accuracy at iteration 15600  is               82.72500000000001%\n",
            "The validation accuracy at iteration 15616  is               82.875%\n",
            "The validation accuracy at iteration 15632  is               82.525%\n",
            "The validation accuracy at iteration 15648  is               82.22500000000001%\n",
            "The validation accuracy at iteration 15664  is               82.575%\n",
            "The validation accuracy at iteration 15680  is               82.6%\n",
            "The validation accuracy at iteration 15696  is               82.525%\n",
            "The validation accuracy at iteration 15712  is               82.475%\n",
            "The validation accuracy at iteration 15728  is               82.525%\n",
            "The validation accuracy at iteration 15744  is               82.19999999999999%\n",
            "The validation accuracy at iteration 15760  is               82.39999999999999%\n",
            "The validation accuracy at iteration 15776  is               82.525%\n",
            "The validation accuracy at iteration 15792  is               82.35%\n",
            "The validation accuracy at iteration 15808  is               82.575%\n",
            "The validation accuracy at iteration 15824  is               82.3%\n",
            "The validation accuracy at iteration 15840  is               82.425%\n",
            "The validation accuracy at iteration 15856  is               82.75%\n",
            "The validation accuracy at iteration 15872  is               82.675%\n",
            "The validation accuracy at iteration 15888  is               82.69999999999999%\n",
            "The validation accuracy at iteration 15904  is               82.425%\n",
            "The validation accuracy at iteration 15920  is               82.72500000000001%\n",
            "The validation accuracy at iteration 15936  is               82.85%\n",
            "The validation accuracy at iteration 15952  is               82.39999999999999%\n",
            "The validation accuracy at iteration 15968  is               82.175%\n",
            "The validation accuracy at iteration 15984  is               82.525%\n",
            "The validation accuracy at iteration 16000  is               82.525%\n",
            "The validation accuracy at iteration 16000  is               82.525%\n",
            "The validation accuracy at iteration 16000  is               82.525%\n",
            "The validation accuracy at iteration 1800  is               75.25%\n",
            "The validation accuracy at iteration 16000  is               82.525%\n",
            "[<__main__.Solver object at 0x7f2ca258c1d0>, <__main__.Solver object at 0x7f2ca258c3d0>, <__main__.Solver object at 0x7f2ca258c910>, <__main__.Solver object at 0x7f2ca1c82910>, <__main__.Solver object at 0x7f2ca258c3d0>]\n",
            "The validation accuracy at iteration 16  is               65.425%\n",
            "The validation accuracy at iteration 32  is               70.275%\n",
            "The validation accuracy at iteration 48  is               72.8%\n",
            "The validation accuracy at iteration 64  is               74.97500000000001%\n",
            "The validation accuracy at iteration 80  is               76.075%\n",
            "The validation accuracy at iteration 96  is               77.45%\n",
            "The validation accuracy at iteration 112  is               77.925%\n",
            "The validation accuracy at iteration 128  is               78.5%\n",
            "The validation accuracy at iteration 144  is               78.825%\n",
            "The validation accuracy at iteration 160  is               79.3%\n",
            "The validation accuracy at iteration 176  is               79.35%\n",
            "The validation accuracy at iteration 192  is               80.175%\n",
            "The validation accuracy at iteration 208  is               80.075%\n",
            "The validation accuracy at iteration 224  is               80.675%\n",
            "The validation accuracy at iteration 240  is               80.35%\n",
            "The validation accuracy at iteration 256  is               80.80000000000001%\n",
            "The validation accuracy at iteration 272  is               80.65%\n",
            "The validation accuracy at iteration 288  is               80.475%\n",
            "The validation accuracy at iteration 304  is               81.075%\n",
            "The validation accuracy at iteration 320  is               81.125%\n",
            "The validation accuracy at iteration 336  is               81.15%\n",
            "The validation accuracy at iteration 352  is               80.75%\n",
            "The validation accuracy at iteration 368  is               81.45%\n",
            "The validation accuracy at iteration 384  is               81.45%\n",
            "The validation accuracy at iteration 400  is               81.325%\n",
            "The validation accuracy at iteration 416  is               81.375%\n",
            "The validation accuracy at iteration 432  is               81.325%\n",
            "The validation accuracy at iteration 448  is               81.525%\n",
            "The validation accuracy at iteration 464  is               81.6%\n",
            "The validation accuracy at iteration 480  is               81.6%\n",
            "The validation accuracy at iteration 496  is               81.77499999999999%\n",
            "The validation accuracy at iteration 512  is               82.22500000000001%\n",
            "The validation accuracy at iteration 528  is               81.675%\n",
            "The validation accuracy at iteration 544  is               81.8%\n",
            "The validation accuracy at iteration 560  is               81.95%\n",
            "The validation accuracy at iteration 576  is               81.89999999999999%\n",
            "The validation accuracy at iteration 592  is               82.125%\n",
            "The validation accuracy at iteration 608  is               82.19999999999999%\n",
            "The validation accuracy at iteration 624  is               82.175%\n",
            "The validation accuracy at iteration 640  is               82.22500000000001%\n",
            "The validation accuracy at iteration 656  is               81.95%\n",
            "The validation accuracy at iteration 672  is               81.925%\n",
            "The validation accuracy at iteration 688  is               82.475%\n",
            "The validation accuracy at iteration 704  is               82.25%\n",
            "The validation accuracy at iteration 720  is               82.45%\n",
            "The validation accuracy at iteration 736  is               82.39999999999999%\n",
            "The validation accuracy at iteration 752  is               82.55%\n",
            "The validation accuracy at iteration 768  is               82.425%\n",
            "The validation accuracy at iteration 784  is               82.65%\n",
            "The validation accuracy at iteration 800  is               82.45%\n",
            "The validation accuracy at iteration 816  is               82.675%\n",
            "The validation accuracy at iteration 832  is               82.72500000000001%\n",
            "The validation accuracy at iteration 848  is               82.025%\n",
            "The validation accuracy at iteration 864  is               82.45%\n",
            "The validation accuracy at iteration 880  is               82.6%\n",
            "The validation accuracy at iteration 896  is               82.69999999999999%\n",
            "The validation accuracy at iteration 912  is               82.575%\n",
            "The validation accuracy at iteration 928  is               82.775%\n",
            "The validation accuracy at iteration 944  is               82.625%\n",
            "The validation accuracy at iteration 960  is               82.375%\n",
            "The validation accuracy at iteration 976  is               82.55%\n",
            "The validation accuracy at iteration 992  is               82.5%\n",
            "The validation accuracy at iteration 1008  is               82.525%\n",
            "The validation accuracy at iteration 1024  is               82.85%\n",
            "The validation accuracy at iteration 1040  is               82.775%\n",
            "The validation accuracy at iteration 1056  is               82.625%\n",
            "The validation accuracy at iteration 1072  is               82.425%\n",
            "The validation accuracy at iteration 1088  is               82.875%\n",
            "The validation accuracy at iteration 1104  is               82.89999999999999%\n",
            "The validation accuracy at iteration 1120  is               82.65%\n",
            "The validation accuracy at iteration 1136  is               82.8%\n",
            "The validation accuracy at iteration 1152  is               82.89999999999999%\n",
            "The validation accuracy at iteration 1168  is               82.55%\n",
            "The validation accuracy at iteration 1184  is               82.95%\n",
            "The validation accuracy at iteration 1200  is               82.39999999999999%\n",
            "The validation accuracy at iteration 1216  is               82.8%\n",
            "The validation accuracy at iteration 1232  is               82.5%\n",
            "The validation accuracy at iteration 1248  is               83.125%\n",
            "The validation accuracy at iteration 1264  is               83.025%\n",
            "The validation accuracy at iteration 1280  is               82.775%\n",
            "The validation accuracy at iteration 1296  is               82.75%\n",
            "The validation accuracy at iteration 1312  is               82.875%\n",
            "The validation accuracy at iteration 1328  is               83.025%\n",
            "The validation accuracy at iteration 1344  is               82.92500000000001%\n",
            "The validation accuracy at iteration 1360  is               83.075%\n",
            "The validation accuracy at iteration 1376  is               82.92500000000001%\n",
            "The validation accuracy at iteration 1392  is               82.72500000000001%\n",
            "The validation accuracy at iteration 1408  is               83.125%\n",
            "The validation accuracy at iteration 1424  is               82.95%\n",
            "The validation accuracy at iteration 1440  is               83.075%\n",
            "The validation accuracy at iteration 1456  is               82.69999999999999%\n",
            "The validation accuracy at iteration 1472  is               83.125%\n",
            "The validation accuracy at iteration 1488  is               82.625%\n",
            "The validation accuracy at iteration 1504  is               82.825%\n",
            "The validation accuracy at iteration 1520  is               82.875%\n",
            "The validation accuracy at iteration 1536  is               82.95%\n",
            "The validation accuracy at iteration 1552  is               82.8%\n",
            "The validation accuracy at iteration 1568  is               82.975%\n",
            "The validation accuracy at iteration 1584  is               82.975%\n",
            "The validation accuracy at iteration 1600  is               82.89999999999999%\n",
            "The validation accuracy at iteration 1616  is               82.69999999999999%\n",
            "The validation accuracy at iteration 1632  is               83.05%\n",
            "The validation accuracy at iteration 1648  is               82.875%\n",
            "The validation accuracy at iteration 1664  is               83.0%\n",
            "The validation accuracy at iteration 1680  is               82.65%\n",
            "The validation accuracy at iteration 1696  is               83.1%\n",
            "The validation accuracy at iteration 1712  is               82.95%\n",
            "The validation accuracy at iteration 1728  is               82.95%\n",
            "The validation accuracy at iteration 1744  is               82.55%\n",
            "The validation accuracy at iteration 1760  is               83.0%\n",
            "The validation accuracy at iteration 1776  is               82.75%\n",
            "The validation accuracy at iteration 1792  is               83.175%\n",
            "The validation accuracy at iteration 1808  is               82.375%\n",
            "The validation accuracy at iteration 1824  is               82.69999999999999%\n",
            "The validation accuracy at iteration 1840  is               82.72500000000001%\n",
            "The validation accuracy at iteration 1856  is               82.69999999999999%\n",
            "The validation accuracy at iteration 1872  is               82.92500000000001%\n",
            "The validation accuracy at iteration 1888  is               82.825%\n",
            "The validation accuracy at iteration 1904  is               82.875%\n",
            "The validation accuracy at iteration 1920  is               82.69999999999999%\n",
            "The validation accuracy at iteration 1936  is               82.875%\n",
            "The validation accuracy at iteration 1952  is               82.72500000000001%\n",
            "The validation accuracy at iteration 1968  is               82.85%\n",
            "The validation accuracy at iteration 1984  is               82.675%\n",
            "The validation accuracy at iteration 2000  is               82.92500000000001%\n",
            "The validation accuracy at iteration 2016  is               82.89999999999999%\n",
            "The validation accuracy at iteration 2032  is               82.69999999999999%\n",
            "The validation accuracy at iteration 2048  is               82.825%\n",
            "The validation accuracy at iteration 2064  is               82.55%\n",
            "The validation accuracy at iteration 2080  is               83.05%\n",
            "The validation accuracy at iteration 2096  is               82.625%\n",
            "The validation accuracy at iteration 2112  is               82.95%\n",
            "The validation accuracy at iteration 2128  is               82.69999999999999%\n",
            "The validation accuracy at iteration 2144  is               82.575%\n",
            "The validation accuracy at iteration 2160  is               82.6%\n",
            "The validation accuracy at iteration 2176  is               82.5%\n",
            "The validation accuracy at iteration 2192  is               82.625%\n",
            "The validation accuracy at iteration 2208  is               82.825%\n",
            "The validation accuracy at iteration 2224  is               83.175%\n",
            "The validation accuracy at iteration 2240  is               82.575%\n",
            "The validation accuracy at iteration 2256  is               82.8%\n",
            "The validation accuracy at iteration 2272  is               82.8%\n",
            "The validation accuracy at iteration 2288  is               82.69999999999999%\n",
            "The validation accuracy at iteration 2304  is               82.92500000000001%\n",
            "The validation accuracy at iteration 2320  is               83.0%\n",
            "The validation accuracy at iteration 2336  is               82.69999999999999%\n",
            "The validation accuracy at iteration 2352  is               82.575%\n",
            "The validation accuracy at iteration 2368  is               82.625%\n",
            "The validation accuracy at iteration 2384  is               82.69999999999999%\n",
            "The validation accuracy at iteration 2400  is               82.6%\n",
            "The validation accuracy at iteration 2416  is               82.6%\n",
            "The validation accuracy at iteration 2432  is               82.95%\n",
            "The validation accuracy at iteration 2448  is               82.72500000000001%\n",
            "The validation accuracy at iteration 2464  is               82.625%\n",
            "The validation accuracy at iteration 2480  is               82.75%\n",
            "The validation accuracy at iteration 2496  is               82.825%\n",
            "The validation accuracy at iteration 2512  is               82.69999999999999%\n",
            "The validation accuracy at iteration 2528  is               82.85%\n",
            "The validation accuracy at iteration 2544  is               82.89999999999999%\n",
            "The validation accuracy at iteration 2560  is               82.3%\n",
            "The validation accuracy at iteration 2576  is               82.72500000000001%\n",
            "The validation accuracy at iteration 2592  is               82.625%\n",
            "The validation accuracy at iteration 2608  is               82.72500000000001%\n",
            "The validation accuracy at iteration 2624  is               82.775%\n",
            "The validation accuracy at iteration 2640  is               83.05%\n",
            "The validation accuracy at iteration 2656  is               82.72500000000001%\n",
            "The validation accuracy at iteration 2672  is               82.6%\n",
            "The validation accuracy at iteration 2688  is               82.69999999999999%\n",
            "The validation accuracy at iteration 2704  is               82.75%\n",
            "The validation accuracy at iteration 2720  is               82.525%\n",
            "The validation accuracy at iteration 2736  is               82.72500000000001%\n",
            "The validation accuracy at iteration 2752  is               82.89999999999999%\n",
            "The validation accuracy at iteration 2768  is               82.6%\n",
            "The validation accuracy at iteration 2784  is               82.6%\n",
            "The validation accuracy at iteration 2800  is               82.89999999999999%\n",
            "The validation accuracy at iteration 2816  is               82.89999999999999%\n",
            "The validation accuracy at iteration 2832  is               82.6%\n",
            "The validation accuracy at iteration 2848  is               82.5%\n",
            "The validation accuracy at iteration 2864  is               82.775%\n",
            "The validation accuracy at iteration 2880  is               82.39999999999999%\n",
            "The validation accuracy at iteration 2896  is               82.65%\n",
            "The validation accuracy at iteration 2912  is               82.6%\n",
            "The validation accuracy at iteration 2928  is               82.45%\n",
            "The validation accuracy at iteration 2944  is               82.65%\n",
            "The validation accuracy at iteration 2960  is               83.05%\n",
            "The validation accuracy at iteration 2976  is               82.89999999999999%\n",
            "The validation accuracy at iteration 2992  is               82.525%\n",
            "The validation accuracy at iteration 3008  is               82.65%\n",
            "The validation accuracy at iteration 3024  is               82.775%\n",
            "The validation accuracy at iteration 3040  is               82.775%\n",
            "The validation accuracy at iteration 3056  is               82.72500000000001%\n",
            "The validation accuracy at iteration 3072  is               83.025%\n",
            "The validation accuracy at iteration 3088  is               82.625%\n",
            "The validation accuracy at iteration 3104  is               82.6%\n",
            "The validation accuracy at iteration 3120  is               83.05%\n",
            "The validation accuracy at iteration 3136  is               82.95%\n",
            "The validation accuracy at iteration 3152  is               82.8%\n",
            "The validation accuracy at iteration 3168  is               82.39999999999999%\n",
            "The validation accuracy at iteration 3184  is               82.8%\n",
            "The validation accuracy at iteration 3200  is               82.375%\n",
            "The validation accuracy at iteration 3216  is               82.65%\n",
            "The validation accuracy at iteration 3232  is               82.55%\n",
            "The validation accuracy at iteration 3248  is               82.475%\n",
            "The validation accuracy at iteration 3264  is               82.675%\n",
            "The validation accuracy at iteration 3280  is               83.1%\n",
            "The validation accuracy at iteration 3296  is               82.975%\n",
            "The validation accuracy at iteration 3312  is               83.0%\n",
            "The validation accuracy at iteration 3328  is               82.6%\n",
            "The validation accuracy at iteration 3344  is               82.525%\n",
            "The validation accuracy at iteration 3360  is               82.625%\n",
            "The validation accuracy at iteration 3376  is               82.675%\n",
            "The validation accuracy at iteration 3392  is               82.575%\n",
            "The validation accuracy at iteration 3408  is               82.575%\n",
            "The validation accuracy at iteration 3424  is               82.65%\n",
            "The validation accuracy at iteration 3440  is               82.85%\n",
            "The validation accuracy at iteration 3456  is               82.45%\n",
            "The validation accuracy at iteration 3472  is               82.575%\n",
            "The validation accuracy at iteration 3488  is               82.69999999999999%\n",
            "The validation accuracy at iteration 3504  is               82.75%\n",
            "The validation accuracy at iteration 3520  is               82.39999999999999%\n",
            "The validation accuracy at iteration 3536  is               82.575%\n",
            "The validation accuracy at iteration 3552  is               82.6%\n",
            "The validation accuracy at iteration 3568  is               82.39999999999999%\n",
            "The validation accuracy at iteration 3584  is               82.575%\n",
            "The validation accuracy at iteration 3600  is               82.69999999999999%\n",
            "The validation accuracy at iteration 3616  is               82.825%\n",
            "The validation accuracy at iteration 3632  is               82.5%\n",
            "The validation accuracy at iteration 3648  is               82.575%\n",
            "The validation accuracy at iteration 3664  is               82.325%\n",
            "The validation accuracy at iteration 3680  is               82.35%\n",
            "The validation accuracy at iteration 3696  is               82.5%\n",
            "The validation accuracy at iteration 3712  is               82.75%\n",
            "The validation accuracy at iteration 3728  is               82.6%\n",
            "The validation accuracy at iteration 3744  is               82.65%\n",
            "The validation accuracy at iteration 3760  is               82.825%\n",
            "The validation accuracy at iteration 3776  is               82.175%\n",
            "The validation accuracy at iteration 3792  is               82.625%\n",
            "The validation accuracy at iteration 3808  is               82.775%\n",
            "The validation accuracy at iteration 3824  is               82.55%\n",
            "The validation accuracy at iteration 3840  is               82.27499999999999%\n",
            "The validation accuracy at iteration 3856  is               82.72500000000001%\n",
            "The validation accuracy at iteration 3872  is               82.325%\n",
            "The validation accuracy at iteration 3888  is               82.39999999999999%\n",
            "The validation accuracy at iteration 3904  is               82.325%\n",
            "The validation accuracy at iteration 3920  is               82.85%\n",
            "The validation accuracy at iteration 3936  is               82.95%\n",
            "The validation accuracy at iteration 3952  is               82.6%\n",
            "The validation accuracy at iteration 3968  is               82.6%\n",
            "The validation accuracy at iteration 3984  is               82.475%\n",
            "The validation accuracy at iteration 4000  is               82.45%\n",
            "The validation accuracy at iteration 4016  is               82.5%\n",
            "The validation accuracy at iteration 4032  is               82.75%\n",
            "The validation accuracy at iteration 4048  is               82.72500000000001%\n",
            "The validation accuracy at iteration 4064  is               82.6%\n",
            "The validation accuracy at iteration 4080  is               82.475%\n",
            "The validation accuracy at iteration 4096  is               82.3%\n",
            "The validation accuracy at iteration 4112  is               82.525%\n",
            "The validation accuracy at iteration 4128  is               82.6%\n",
            "The validation accuracy at iteration 4144  is               82.875%\n",
            "The validation accuracy at iteration 4160  is               82.27499999999999%\n",
            "The validation accuracy at iteration 4176  is               82.675%\n",
            "The validation accuracy at iteration 4192  is               82.325%\n",
            "The validation accuracy at iteration 4208  is               82.45%\n",
            "The validation accuracy at iteration 4224  is               82.325%\n",
            "The validation accuracy at iteration 4240  is               82.875%\n",
            "The validation accuracy at iteration 4256  is               82.65%\n",
            "The validation accuracy at iteration 4272  is               82.22500000000001%\n",
            "The validation accuracy at iteration 4288  is               82.55%\n",
            "The validation accuracy at iteration 4304  is               82.35%\n",
            "The validation accuracy at iteration 4320  is               82.325%\n",
            "The validation accuracy at iteration 4336  is               82.45%\n",
            "The validation accuracy at iteration 4352  is               82.95%\n",
            "The validation accuracy at iteration 4368  is               82.6%\n",
            "The validation accuracy at iteration 4384  is               82.575%\n",
            "The validation accuracy at iteration 4400  is               82.625%\n",
            "The validation accuracy at iteration 4416  is               82.575%\n",
            "The validation accuracy at iteration 4432  is               82.39999999999999%\n",
            "The validation accuracy at iteration 4448  is               82.55%\n",
            "The validation accuracy at iteration 4464  is               82.65%\n",
            "The validation accuracy at iteration 4480  is               82.15%\n",
            "The validation accuracy at iteration 4496  is               82.5%\n",
            "The validation accuracy at iteration 4512  is               82.525%\n",
            "The validation accuracy at iteration 4528  is               82.55%\n",
            "The validation accuracy at iteration 4544  is               82.525%\n",
            "The validation accuracy at iteration 4560  is               82.675%\n",
            "The validation accuracy at iteration 4576  is               82.25%\n",
            "The validation accuracy at iteration 4592  is               82.19999999999999%\n",
            "The validation accuracy at iteration 4608  is               82.69999999999999%\n",
            "The validation accuracy at iteration 4624  is               82.125%\n",
            "The validation accuracy at iteration 4640  is               82.175%\n",
            "The validation accuracy at iteration 4656  is               82.375%\n",
            "The validation accuracy at iteration 4672  is               82.89999999999999%\n",
            "The validation accuracy at iteration 4688  is               82.825%\n",
            "The validation accuracy at iteration 4704  is               82.45%\n",
            "The validation accuracy at iteration 4720  is               82.45%\n",
            "The validation accuracy at iteration 4736  is               82.5%\n",
            "The validation accuracy at iteration 4752  is               82.35%\n",
            "The validation accuracy at iteration 4768  is               82.525%\n",
            "The validation accuracy at iteration 4784  is               82.675%\n",
            "The validation accuracy at iteration 4800  is               82.25%\n",
            "The validation accuracy at iteration 4816  is               82.425%\n",
            "The validation accuracy at iteration 4832  is               82.65%\n",
            "The validation accuracy at iteration 4848  is               82.575%\n",
            "The validation accuracy at iteration 4864  is               82.475%\n",
            "The validation accuracy at iteration 4880  is               82.3%\n",
            "The validation accuracy at iteration 4896  is               82.675%\n",
            "The validation accuracy at iteration 4912  is               82.22500000000001%\n",
            "The validation accuracy at iteration 4928  is               82.5%\n",
            "The validation accuracy at iteration 4944  is               82.45%\n",
            "The validation accuracy at iteration 4960  is               82.125%\n",
            "The validation accuracy at iteration 4976  is               82.1%\n",
            "The validation accuracy at iteration 4992  is               82.775%\n",
            "The validation accuracy at iteration 5008  is               82.775%\n",
            "The validation accuracy at iteration 5024  is               82.85%\n",
            "The validation accuracy at iteration 5040  is               82.25%\n",
            "The validation accuracy at iteration 5056  is               82.5%\n",
            "The validation accuracy at iteration 5072  is               82.39999999999999%\n",
            "The validation accuracy at iteration 5088  is               82.55%\n",
            "The validation accuracy at iteration 5104  is               82.475%\n",
            "The validation accuracy at iteration 5120  is               82.425%\n",
            "The validation accuracy at iteration 5136  is               82.6%\n",
            "The validation accuracy at iteration 5152  is               82.475%\n",
            "The validation accuracy at iteration 5168  is               82.325%\n",
            "The validation accuracy at iteration 5184  is               82.375%\n",
            "The validation accuracy at iteration 5200  is               82.525%\n",
            "The validation accuracy at iteration 5216  is               82.65%\n",
            "The validation accuracy at iteration 5232  is               82.22500000000001%\n",
            "The validation accuracy at iteration 5248  is               82.55%\n",
            "The validation accuracy at iteration 5264  is               82.5%\n",
            "The validation accuracy at iteration 5280  is               82.175%\n",
            "The validation accuracy at iteration 5296  is               82.3%\n",
            "The validation accuracy at iteration 5312  is               82.825%\n",
            "The validation accuracy at iteration 5328  is               82.675%\n",
            "The validation accuracy at iteration 5344  is               82.325%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "The validation accuracy at iteration 16000  is               82.525%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "The validation accuracy at iteration 2300  is               77.5%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "[<__main__.Solver object at 0x7f2ca258c1d0>, <__main__.Solver object at 0x7f2cad78fb50>, <__main__.Solver object at 0x7f2ca258c910>, <__main__.Solver object at 0x7f2ca1c82910>, <__main__.Solver object at 0x7f2ca258c3d0>]\n",
            "The validation accuracy at iteration 16  is               70.15%\n",
            "The validation accuracy at iteration 32  is               73.275%\n",
            "The validation accuracy at iteration 48  is               75.5%\n",
            "The validation accuracy at iteration 64  is               77.825%\n",
            "The validation accuracy at iteration 80  is               78.2%\n",
            "The validation accuracy at iteration 96  is               79.60000000000001%\n",
            "The validation accuracy at iteration 112  is               79.825%\n",
            "The validation accuracy at iteration 128  is               80.27499999999999%\n",
            "The validation accuracy at iteration 144  is               80.30000000000001%\n",
            "The validation accuracy at iteration 160  is               81.15%\n",
            "The validation accuracy at iteration 176  is               81.025%\n",
            "The validation accuracy at iteration 192  is               81.22500000000001%\n",
            "The validation accuracy at iteration 208  is               80.95%\n",
            "The validation accuracy at iteration 224  is               81.65%\n",
            "The validation accuracy at iteration 240  is               81.65%\n",
            "The validation accuracy at iteration 256  is               81.525%\n",
            "The validation accuracy at iteration 272  is               81.475%\n",
            "The validation accuracy at iteration 288  is               81.975%\n",
            "The validation accuracy at iteration 304  is               81.875%\n",
            "The validation accuracy at iteration 320  is               81.75%\n",
            "The validation accuracy at iteration 336  is               81.85%\n",
            "The validation accuracy at iteration 352  is               82.075%\n",
            "The validation accuracy at iteration 368  is               82.1%\n",
            "The validation accuracy at iteration 384  is               82.15%\n",
            "The validation accuracy at iteration 400  is               81.975%\n",
            "The validation accuracy at iteration 416  is               82.425%\n",
            "The validation accuracy at iteration 432  is               82.375%\n",
            "The validation accuracy at iteration 448  is               82.45%\n",
            "The validation accuracy at iteration 464  is               82.05%\n",
            "The validation accuracy at iteration 480  is               82.625%\n",
            "The validation accuracy at iteration 496  is               82.375%\n",
            "The validation accuracy at iteration 512  is               82.39999999999999%\n",
            "The validation accuracy at iteration 528  is               82.3%\n",
            "The validation accuracy at iteration 544  is               82.675%\n",
            "The validation accuracy at iteration 560  is               82.5%\n",
            "The validation accuracy at iteration 576  is               82.65%\n",
            "The validation accuracy at iteration 592  is               82.5%\n",
            "The validation accuracy at iteration 608  is               82.625%\n",
            "The validation accuracy at iteration 624  is               82.575%\n",
            "The validation accuracy at iteration 640  is               82.65%\n",
            "The validation accuracy at iteration 656  is               82.65%\n",
            "The validation accuracy at iteration 672  is               82.6%\n",
            "The validation accuracy at iteration 688  is               82.55%\n",
            "The validation accuracy at iteration 704  is               82.625%\n",
            "The validation accuracy at iteration 720  is               82.525%\n",
            "The validation accuracy at iteration 736  is               82.6%\n",
            "The validation accuracy at iteration 752  is               82.6%\n",
            "The validation accuracy at iteration 768  is               82.69999999999999%\n",
            "The validation accuracy at iteration 784  is               82.55%\n",
            "The validation accuracy at iteration 800  is               82.75%\n",
            "The validation accuracy at iteration 816  is               82.75%\n",
            "The validation accuracy at iteration 832  is               82.75%\n",
            "The validation accuracy at iteration 848  is               82.475%\n",
            "The validation accuracy at iteration 864  is               82.65%\n",
            "The validation accuracy at iteration 880  is               82.875%\n",
            "The validation accuracy at iteration 896  is               82.75%\n",
            "The validation accuracy at iteration 912  is               82.625%\n",
            "The validation accuracy at iteration 928  is               82.8%\n",
            "The validation accuracy at iteration 944  is               82.92500000000001%\n",
            "The validation accuracy at iteration 960  is               82.72500000000001%\n",
            "The validation accuracy at iteration 976  is               82.75%\n",
            "The validation accuracy at iteration 992  is               82.95%\n",
            "The validation accuracy at iteration 1008  is               83.15%\n",
            "The validation accuracy at iteration 1024  is               82.69999999999999%\n",
            "The validation accuracy at iteration 1040  is               82.875%\n",
            "The validation accuracy at iteration 1056  is               82.89999999999999%\n",
            "The validation accuracy at iteration 1072  is               83.2%\n",
            "The validation accuracy at iteration 1088  is               82.72500000000001%\n",
            "The validation accuracy at iteration 1104  is               82.89999999999999%\n",
            "The validation accuracy at iteration 1120  is               82.89999999999999%\n",
            "The validation accuracy at iteration 1136  is               83.175%\n",
            "The validation accuracy at iteration 1152  is               82.72500000000001%\n",
            "The validation accuracy at iteration 1168  is               82.775%\n",
            "The validation accuracy at iteration 1184  is               83.0%\n",
            "The validation accuracy at iteration 1200  is               83.1%\n",
            "The validation accuracy at iteration 1216  is               82.8%\n",
            "The validation accuracy at iteration 1232  is               82.65%\n",
            "The validation accuracy at iteration 1248  is               83.075%\n",
            "The validation accuracy at iteration 1264  is               83.15%\n",
            "The validation accuracy at iteration 1280  is               82.775%\n",
            "The validation accuracy at iteration 1296  is               82.625%\n",
            "The validation accuracy at iteration 1312  is               83.05%\n",
            "The validation accuracy at iteration 1328  is               82.975%\n",
            "The validation accuracy at iteration 1344  is               82.675%\n",
            "The validation accuracy at iteration 1360  is               82.625%\n",
            "The validation accuracy at iteration 1376  is               83.0%\n",
            "The validation accuracy at iteration 1392  is               82.89999999999999%\n",
            "The validation accuracy at iteration 1408  is               82.625%\n",
            "The validation accuracy at iteration 1424  is               82.55%\n",
            "The validation accuracy at iteration 1440  is               82.975%\n",
            "The validation accuracy at iteration 1456  is               82.95%\n",
            "The validation accuracy at iteration 1472  is               82.775%\n",
            "The validation accuracy at iteration 1488  is               82.475%\n",
            "The validation accuracy at iteration 1504  is               82.825%\n",
            "The validation accuracy at iteration 1520  is               82.95%\n",
            "The validation accuracy at iteration 1536  is               82.675%\n",
            "The validation accuracy at iteration 1552  is               82.575%\n",
            "The validation accuracy at iteration 1568  is               82.8%\n",
            "The validation accuracy at iteration 1584  is               82.95%\n",
            "The validation accuracy at iteration 1600  is               82.825%\n",
            "The validation accuracy at iteration 1616  is               82.625%\n",
            "The validation accuracy at iteration 1632  is               82.75%\n",
            "The validation accuracy at iteration 1648  is               82.85%\n",
            "The validation accuracy at iteration 1664  is               82.775%\n",
            "The validation accuracy at iteration 1680  is               82.625%\n",
            "The validation accuracy at iteration 1696  is               82.75%\n",
            "The validation accuracy at iteration 1712  is               82.875%\n",
            "The validation accuracy at iteration 1728  is               82.72500000000001%\n",
            "The validation accuracy at iteration 1744  is               82.675%\n",
            "The validation accuracy at iteration 1760  is               82.675%\n",
            "The validation accuracy at iteration 1776  is               82.825%\n",
            "The validation accuracy at iteration 1792  is               82.85%\n",
            "The validation accuracy at iteration 1808  is               82.625%\n",
            "The validation accuracy at iteration 1824  is               82.72500000000001%\n",
            "The validation accuracy at iteration 1840  is               82.89999999999999%\n",
            "The validation accuracy at iteration 1856  is               82.6%\n",
            "The validation accuracy at iteration 1872  is               82.6%\n",
            "The validation accuracy at iteration 1888  is               82.72500000000001%\n",
            "The validation accuracy at iteration 1904  is               82.775%\n",
            "The validation accuracy at iteration 1920  is               82.675%\n",
            "The validation accuracy at iteration 1936  is               82.575%\n",
            "The validation accuracy at iteration 1952  is               82.675%\n",
            "The validation accuracy at iteration 1968  is               82.72500000000001%\n",
            "The validation accuracy at iteration 1984  is               82.6%\n",
            "The validation accuracy at iteration 2000  is               82.375%\n",
            "The validation accuracy at iteration 2016  is               82.72500000000001%\n",
            "The validation accuracy at iteration 2032  is               82.72500000000001%\n",
            "The validation accuracy at iteration 2048  is               82.6%\n",
            "The validation accuracy at iteration 2064  is               82.375%\n",
            "The validation accuracy at iteration 2080  is               82.69999999999999%\n",
            "The validation accuracy at iteration 2096  is               82.625%\n",
            "The validation accuracy at iteration 2112  is               82.6%\n",
            "The validation accuracy at iteration 2128  is               82.375%\n",
            "The validation accuracy at iteration 2144  is               82.69999999999999%\n",
            "The validation accuracy at iteration 2160  is               82.55%\n",
            "The validation accuracy at iteration 2176  is               82.55%\n",
            "The validation accuracy at iteration 2192  is               82.425%\n",
            "The validation accuracy at iteration 2208  is               82.65%\n",
            "The validation accuracy at iteration 2224  is               82.625%\n",
            "The validation accuracy at iteration 2240  is               82.525%\n",
            "The validation accuracy at iteration 2256  is               82.25%\n",
            "The validation accuracy at iteration 2272  is               82.675%\n",
            "The validation accuracy at iteration 2288  is               82.525%\n",
            "The validation accuracy at iteration 2304  is               82.45%\n",
            "The validation accuracy at iteration 2320  is               82.22500000000001%\n",
            "The validation accuracy at iteration 2336  is               82.575%\n",
            "The validation accuracy at iteration 2352  is               82.6%\n",
            "The validation accuracy at iteration 2368  is               82.525%\n",
            "The validation accuracy at iteration 2384  is               82.25%\n",
            "The validation accuracy at iteration 2400  is               82.6%\n",
            "The validation accuracy at iteration 2416  is               82.425%\n",
            "The validation accuracy at iteration 2432  is               82.5%\n",
            "The validation accuracy at iteration 2448  is               82.3%\n",
            "The validation accuracy at iteration 2464  is               82.6%\n",
            "The validation accuracy at iteration 2480  is               82.475%\n",
            "The validation accuracy at iteration 2496  is               82.6%\n",
            "The validation accuracy at iteration 2512  is               82.3%\n",
            "The validation accuracy at iteration 2528  is               82.55%\n",
            "The validation accuracy at iteration 2544  is               82.39999999999999%\n",
            "The validation accuracy at iteration 2560  is               82.575%\n",
            "The validation accuracy at iteration 2576  is               82.25%\n",
            "The validation accuracy at iteration 2592  is               82.65%\n",
            "The validation accuracy at iteration 2608  is               82.5%\n",
            "The validation accuracy at iteration 2624  is               82.6%\n",
            "The validation accuracy at iteration 2640  is               82.325%\n",
            "The validation accuracy at iteration 2656  is               82.625%\n",
            "The validation accuracy at iteration 2672  is               82.475%\n",
            "The validation accuracy at iteration 2688  is               82.525%\n",
            "The validation accuracy at iteration 2704  is               82.475%\n",
            "The validation accuracy at iteration 2720  is               82.6%\n",
            "The validation accuracy at iteration 2736  is               82.5%\n",
            "The validation accuracy at iteration 2752  is               82.575%\n",
            "The validation accuracy at iteration 2768  is               82.39999999999999%\n",
            "The validation accuracy at iteration 2784  is               82.5%\n",
            "The validation accuracy at iteration 2800  is               82.575%\n",
            "The validation accuracy at iteration 2816  is               82.575%\n",
            "The validation accuracy at iteration 2832  is               82.45%\n",
            "The validation accuracy at iteration 2848  is               82.6%\n",
            "The validation accuracy at iteration 2864  is               82.5%\n",
            "The validation accuracy at iteration 2880  is               82.6%\n",
            "The validation accuracy at iteration 2896  is               82.45%\n",
            "The validation accuracy at iteration 2912  is               82.475%\n",
            "The validation accuracy at iteration 2928  is               82.5%\n",
            "The validation accuracy at iteration 2944  is               82.625%\n",
            "The validation accuracy at iteration 2960  is               82.425%\n",
            "The validation accuracy at iteration 2976  is               82.525%\n",
            "The validation accuracy at iteration 2992  is               82.575%\n",
            "The validation accuracy at iteration 3008  is               82.6%\n",
            "The validation accuracy at iteration 3024  is               82.375%\n",
            "The validation accuracy at iteration 3040  is               82.39999999999999%\n",
            "The validation accuracy at iteration 3056  is               82.5%\n",
            "The validation accuracy at iteration 3072  is               82.45%\n",
            "The validation accuracy at iteration 3088  is               82.425%\n",
            "The validation accuracy at iteration 3104  is               82.425%\n",
            "The validation accuracy at iteration 3120  is               82.45%\n",
            "The validation accuracy at iteration 3136  is               82.425%\n",
            "The validation accuracy at iteration 3152  is               82.425%\n",
            "The validation accuracy at iteration 3168  is               82.375%\n",
            "The validation accuracy at iteration 3184  is               82.475%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 16000  is               82.525%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 1800  is               75.125%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "[<__main__.Solver object at 0x7f2ca258c1d0>, <__main__.Solver object at 0x7f2cad78fb50>, <__main__.Solver object at 0x7f2ca1fac6d0>, <__main__.Solver object at 0x7f2ca1c82910>, <__main__.Solver object at 0x7f2ca258c3d0>]\n",
            "The validation accuracy at iteration 16  is               71.35000000000001%\n",
            "The validation accuracy at iteration 32  is               74.75%\n",
            "The validation accuracy at iteration 48  is               78.0%\n",
            "The validation accuracy at iteration 64  is               79.80000000000001%\n",
            "The validation accuracy at iteration 80  is               79.975%\n",
            "The validation accuracy at iteration 96  is               80.77499999999999%\n",
            "The validation accuracy at iteration 112  is               81.05%\n",
            "The validation accuracy at iteration 128  is               81.575%\n",
            "The validation accuracy at iteration 144  is               81.175%\n",
            "The validation accuracy at iteration 160  is               81.375%\n",
            "The validation accuracy at iteration 176  is               81.6%\n",
            "The validation accuracy at iteration 192  is               81.675%\n",
            "The validation accuracy at iteration 208  is               82.1%\n",
            "The validation accuracy at iteration 224  is               81.825%\n",
            "The validation accuracy at iteration 240  is               81.69999999999999%\n",
            "The validation accuracy at iteration 256  is               82.325%\n",
            "The validation accuracy at iteration 272  is               82.075%\n",
            "The validation accuracy at iteration 288  is               82.3%\n",
            "The validation accuracy at iteration 304  is               82.39999999999999%\n",
            "The validation accuracy at iteration 320  is               82.125%\n",
            "The validation accuracy at iteration 336  is               82.6%\n",
            "The validation accuracy at iteration 352  is               82.525%\n",
            "The validation accuracy at iteration 368  is               82.45%\n",
            "The validation accuracy at iteration 384  is               82.625%\n",
            "The validation accuracy at iteration 400  is               82.425%\n",
            "The validation accuracy at iteration 416  is               82.45%\n",
            "The validation accuracy at iteration 432  is               83.0%\n",
            "The validation accuracy at iteration 448  is               82.72500000000001%\n",
            "The validation accuracy at iteration 464  is               82.6%\n",
            "The validation accuracy at iteration 480  is               82.69999999999999%\n",
            "The validation accuracy at iteration 496  is               82.975%\n",
            "The validation accuracy at iteration 512  is               82.575%\n",
            "The validation accuracy at iteration 528  is               82.375%\n",
            "The validation accuracy at iteration 544  is               82.775%\n",
            "The validation accuracy at iteration 560  is               82.575%\n",
            "The validation accuracy at iteration 576  is               82.72500000000001%\n",
            "The validation accuracy at iteration 592  is               82.6%\n",
            "The validation accuracy at iteration 608  is               82.475%\n",
            "The validation accuracy at iteration 624  is               82.89999999999999%\n",
            "The validation accuracy at iteration 640  is               82.425%\n",
            "The validation accuracy at iteration 656  is               82.92500000000001%\n",
            "The validation accuracy at iteration 672  is               82.85%\n",
            "The validation accuracy at iteration 688  is               82.775%\n",
            "The validation accuracy at iteration 704  is               83.0%\n",
            "The validation accuracy at iteration 720  is               82.92500000000001%\n",
            "The validation accuracy at iteration 736  is               82.85%\n",
            "The validation accuracy at iteration 752  is               82.95%\n",
            "The validation accuracy at iteration 768  is               82.72500000000001%\n",
            "The validation accuracy at iteration 784  is               82.475%\n",
            "The validation accuracy at iteration 800  is               83.0%\n",
            "The validation accuracy at iteration 816  is               82.85%\n",
            "The validation accuracy at iteration 832  is               82.8%\n",
            "The validation accuracy at iteration 848  is               82.875%\n",
            "The validation accuracy at iteration 864  is               83.25%\n",
            "The validation accuracy at iteration 880  is               82.675%\n",
            "The validation accuracy at iteration 896  is               82.55%\n",
            "The validation accuracy at iteration 912  is               82.95%\n",
            "The validation accuracy at iteration 928  is               82.65%\n",
            "The validation accuracy at iteration 944  is               82.72500000000001%\n",
            "The validation accuracy at iteration 960  is               82.69999999999999%\n",
            "The validation accuracy at iteration 976  is               82.525%\n",
            "The validation accuracy at iteration 992  is               82.875%\n",
            "The validation accuracy at iteration 1008  is               82.25%\n",
            "The validation accuracy at iteration 1024  is               83.0%\n",
            "The validation accuracy at iteration 1040  is               82.72500000000001%\n",
            "The validation accuracy at iteration 1056  is               82.72500000000001%\n",
            "The validation accuracy at iteration 1072  is               83.1%\n",
            "The validation accuracy at iteration 1088  is               83.1%\n",
            "The validation accuracy at iteration 1104  is               82.65%\n",
            "The validation accuracy at iteration 1120  is               82.55%\n",
            "The validation accuracy at iteration 1136  is               82.72500000000001%\n",
            "The validation accuracy at iteration 1152  is               82.55%\n",
            "The validation accuracy at iteration 1168  is               82.825%\n",
            "The validation accuracy at iteration 1184  is               82.975%\n",
            "The validation accuracy at iteration 1200  is               82.675%\n",
            "The validation accuracy at iteration 1216  is               82.575%\n",
            "The validation accuracy at iteration 1232  is               83.175%\n",
            "The validation accuracy at iteration 1248  is               82.775%\n",
            "The validation accuracy at iteration 1264  is               82.175%\n",
            "The validation accuracy at iteration 1280  is               82.69999999999999%\n",
            "The validation accuracy at iteration 1296  is               82.675%\n",
            "The validation accuracy at iteration 1312  is               82.6%\n",
            "The validation accuracy at iteration 1328  is               82.325%\n",
            "The validation accuracy at iteration 1344  is               82.39999999999999%\n",
            "The validation accuracy at iteration 1360  is               82.85%\n",
            "The validation accuracy at iteration 1376  is               82.45%\n",
            "The validation accuracy at iteration 1392  is               82.95%\n",
            "The validation accuracy at iteration 1408  is               82.65%\n",
            "The validation accuracy at iteration 1424  is               82.775%\n",
            "The validation accuracy at iteration 1440  is               83.0%\n",
            "The validation accuracy at iteration 1456  is               83.175%\n",
            "The validation accuracy at iteration 1472  is               82.6%\n",
            "The validation accuracy at iteration 1488  is               82.625%\n",
            "The validation accuracy at iteration 1504  is               82.625%\n",
            "The validation accuracy at iteration 1520  is               82.425%\n",
            "The validation accuracy at iteration 1536  is               82.6%\n",
            "The validation accuracy at iteration 1552  is               82.85%\n",
            "The validation accuracy at iteration 1568  is               82.6%\n",
            "The validation accuracy at iteration 1584  is               82.575%\n",
            "The validation accuracy at iteration 1600  is               83.05%\n",
            "The validation accuracy at iteration 1616  is               82.69999999999999%\n",
            "The validation accuracy at iteration 1632  is               82.22500000000001%\n",
            "The validation accuracy at iteration 1648  is               82.65%\n",
            "The validation accuracy at iteration 1664  is               82.675%\n",
            "The validation accuracy at iteration 1680  is               82.55%\n",
            "The validation accuracy at iteration 1696  is               82.39999999999999%\n",
            "The validation accuracy at iteration 1712  is               82.025%\n",
            "The validation accuracy at iteration 1728  is               82.55%\n",
            "The validation accuracy at iteration 1744  is               82.25%\n",
            "The validation accuracy at iteration 1760  is               82.875%\n",
            "The validation accuracy at iteration 1776  is               82.475%\n",
            "The validation accuracy at iteration 1792  is               82.525%\n",
            "The validation accuracy at iteration 1808  is               82.72500000000001%\n",
            "The validation accuracy at iteration 1824  is               83.125%\n",
            "The validation accuracy at iteration 1840  is               82.525%\n",
            "The validation accuracy at iteration 1856  is               82.25%\n",
            "The validation accuracy at iteration 1872  is               82.6%\n",
            "The validation accuracy at iteration 1888  is               82.55%\n",
            "The validation accuracy at iteration 1904  is               82.39999999999999%\n",
            "The validation accuracy at iteration 1920  is               82.575%\n",
            "The validation accuracy at iteration 1936  is               82.27499999999999%\n",
            "The validation accuracy at iteration 1952  is               82.425%\n",
            "The validation accuracy at iteration 1968  is               82.95%\n",
            "The validation accuracy at iteration 1984  is               82.625%\n",
            "The validation accuracy at iteration 2000  is               82.075%\n",
            "The validation accuracy at iteration 2016  is               82.675%\n",
            "The validation accuracy at iteration 2032  is               82.55%\n",
            "The validation accuracy at iteration 2048  is               82.39999999999999%\n",
            "The validation accuracy at iteration 2064  is               82.475%\n",
            "The validation accuracy at iteration 2080  is               82.1%\n",
            "The validation accuracy at iteration 2096  is               82.475%\n",
            "The validation accuracy at iteration 2112  is               82.175%\n",
            "The validation accuracy at iteration 2128  is               82.775%\n",
            "The validation accuracy at iteration 2144  is               82.55%\n",
            "The validation accuracy at iteration 2160  is               82.55%\n",
            "The validation accuracy at iteration 2176  is               82.5%\n",
            "The validation accuracy at iteration 2192  is               83.0%\n",
            "The validation accuracy at iteration 2208  is               82.45%\n",
            "The validation accuracy at iteration 2224  is               82.425%\n",
            "The validation accuracy at iteration 2240  is               82.475%\n",
            "The validation accuracy at iteration 2256  is               82.65%\n",
            "The validation accuracy at iteration 2272  is               82.425%\n",
            "The validation accuracy at iteration 2288  is               82.6%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "The validation accuracy at iteration 16000  is               82.525%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "The validation accuracy at iteration 3200  is               66.64999999999999%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "[<__main__.Solver object at 0x7f2ca258c1d0>, <__main__.Solver object at 0x7f2cad78fb50>, <__main__.Solver object at 0x7f2ca1fac6d0>, <__main__.Solver object at 0x7f2ca258c910>, <__main__.Solver object at 0x7f2ca258c3d0>]\n",
            "The validation accuracy at iteration 16  is               72.7%\n",
            "The validation accuracy at iteration 32  is               77.525%\n",
            "The validation accuracy at iteration 48  is               78.425%\n",
            "The validation accuracy at iteration 64  is               80.5%\n",
            "The validation accuracy at iteration 80  is               80.15%\n",
            "The validation accuracy at iteration 96  is               81.075%\n",
            "The validation accuracy at iteration 112  is               81.10000000000001%\n",
            "The validation accuracy at iteration 128  is               81.27499999999999%\n",
            "The validation accuracy at iteration 144  is               81.575%\n",
            "The validation accuracy at iteration 160  is               81.975%\n",
            "The validation accuracy at iteration 176  is               81.69999999999999%\n",
            "The validation accuracy at iteration 192  is               81.95%\n",
            "The validation accuracy at iteration 208  is               82.72500000000001%\n",
            "The validation accuracy at iteration 224  is               82.475%\n",
            "The validation accuracy at iteration 240  is               82.775%\n",
            "The validation accuracy at iteration 256  is               82.15%\n",
            "The validation accuracy at iteration 272  is               82.5%\n",
            "The validation accuracy at iteration 288  is               82.375%\n",
            "The validation accuracy at iteration 304  is               82.825%\n",
            "The validation accuracy at iteration 320  is               82.25%\n",
            "The validation accuracy at iteration 336  is               82.45%\n",
            "The validation accuracy at iteration 352  is               83.0%\n",
            "The validation accuracy at iteration 368  is               82.875%\n",
            "The validation accuracy at iteration 384  is               82.975%\n",
            "The validation accuracy at iteration 400  is               82.55%\n",
            "The validation accuracy at iteration 416  is               82.72500000000001%\n",
            "The validation accuracy at iteration 432  is               82.75%\n",
            "The validation accuracy at iteration 448  is               83.275%\n",
            "The validation accuracy at iteration 464  is               82.5%\n",
            "The validation accuracy at iteration 480  is               82.675%\n",
            "The validation accuracy at iteration 496  is               83.275%\n",
            "The validation accuracy at iteration 512  is               82.8%\n",
            "The validation accuracy at iteration 528  is               83.05%\n",
            "The validation accuracy at iteration 544  is               82.825%\n",
            "The validation accuracy at iteration 560  is               82.825%\n",
            "The validation accuracy at iteration 576  is               82.8%\n",
            "The validation accuracy at iteration 592  is               83.1%\n",
            "The validation accuracy at iteration 608  is               82.35%\n",
            "The validation accuracy at iteration 624  is               82.72500000000001%\n",
            "The validation accuracy at iteration 640  is               83.075%\n",
            "The validation accuracy at iteration 656  is               82.775%\n",
            "The validation accuracy at iteration 672  is               83.1%\n",
            "The validation accuracy at iteration 688  is               82.775%\n",
            "The validation accuracy at iteration 704  is               82.775%\n",
            "The validation accuracy at iteration 720  is               82.69999999999999%\n",
            "The validation accuracy at iteration 736  is               82.975%\n",
            "The validation accuracy at iteration 752  is               82.6%\n",
            "The validation accuracy at iteration 768  is               82.72500000000001%\n",
            "The validation accuracy at iteration 784  is               83.325%\n",
            "The validation accuracy at iteration 800  is               82.75%\n",
            "The validation accuracy at iteration 816  is               83.175%\n",
            "The validation accuracy at iteration 832  is               82.72500000000001%\n",
            "The validation accuracy at iteration 848  is               82.775%\n",
            "The validation accuracy at iteration 864  is               82.6%\n",
            "The validation accuracy at iteration 880  is               82.92500000000001%\n",
            "The validation accuracy at iteration 896  is               82.69999999999999%\n",
            "The validation accuracy at iteration 912  is               82.69999999999999%\n",
            "The validation accuracy at iteration 928  is               83.275%\n",
            "The validation accuracy at iteration 944  is               82.625%\n",
            "The validation accuracy at iteration 960  is               83.2%\n",
            "The validation accuracy at iteration 976  is               82.72500000000001%\n",
            "The validation accuracy at iteration 992  is               82.6%\n",
            "The validation accuracy at iteration 1008  is               82.575%\n",
            "The validation accuracy at iteration 1024  is               82.85%\n",
            "The validation accuracy at iteration 1040  is               82.525%\n",
            "The validation accuracy at iteration 1056  is               82.575%\n",
            "The validation accuracy at iteration 1072  is               83.2%\n",
            "The validation accuracy at iteration 1088  is               82.45%\n",
            "The validation accuracy at iteration 1104  is               83.15%\n",
            "The validation accuracy at iteration 1120  is               82.6%\n",
            "The validation accuracy at iteration 1136  is               82.575%\n",
            "The validation accuracy at iteration 1152  is               82.525%\n",
            "The validation accuracy at iteration 1168  is               82.72500000000001%\n",
            "The validation accuracy at iteration 1184  is               82.39999999999999%\n",
            "The validation accuracy at iteration 1200  is               82.375%\n",
            "The validation accuracy at iteration 1216  is               83.1%\n",
            "The validation accuracy at iteration 1232  is               82.27499999999999%\n",
            "The validation accuracy at iteration 1248  is               83.22500000000001%\n",
            "The validation accuracy at iteration 1264  is               82.5%\n",
            "The validation accuracy at iteration 1280  is               82.475%\n",
            "The validation accuracy at iteration 1296  is               82.425%\n",
            "The validation accuracy at iteration 1312  is               82.65%\n",
            "The validation accuracy at iteration 1328  is               82.5%\n",
            "The validation accuracy at iteration 1344  is               82.19999999999999%\n",
            "The validation accuracy at iteration 1360  is               83.175%\n",
            "The validation accuracy at iteration 1376  is               82.425%\n",
            "The validation accuracy at iteration 1392  is               83.2%\n",
            "The validation accuracy at iteration 1408  is               82.575%\n",
            "The validation accuracy at iteration 1424  is               82.72500000000001%\n",
            "The validation accuracy at iteration 1440  is               82.45%\n",
            "The validation accuracy at iteration 1456  is               82.525%\n",
            "The validation accuracy at iteration 1472  is               82.65%\n",
            "The validation accuracy at iteration 1488  is               82.22500000000001%\n",
            "The validation accuracy at iteration 1504  is               83.0%\n",
            "The validation accuracy at iteration 1520  is               82.22500000000001%\n",
            "The validation accuracy at iteration 1536  is               82.975%\n",
            "The validation accuracy at iteration 1552  is               82.425%\n",
            "The validation accuracy at iteration 1568  is               82.5%\n",
            "The validation accuracy at iteration 1584  is               82.625%\n",
            "The validation accuracy at iteration 1600  is               82.475%\n",
            "The validation accuracy at iteration 1616  is               82.55%\n",
            "The validation accuracy at iteration 1632  is               82.325%\n",
            "The validation accuracy at iteration 1648  is               83.075%\n",
            "The validation accuracy at iteration 1664  is               82.35%\n",
            "The validation accuracy at iteration 1680  is               83.05%\n",
            "The validation accuracy at iteration 1696  is               82.475%\n",
            "The validation accuracy at iteration 1712  is               82.69999999999999%\n",
            "The validation accuracy at iteration 1728  is               82.69999999999999%\n",
            "The validation accuracy at iteration 1744  is               82.525%\n",
            "The validation accuracy at iteration 1760  is               82.475%\n",
            "The validation accuracy at iteration 1776  is               82.3%\n",
            "The validation accuracy at iteration 1792  is               82.875%\n",
            "The validation accuracy at iteration 1800  is               82.6%\n",
            "The validation accuracy at iteration 1800  is               82.6%\n",
            "The validation accuracy at iteration 16000  is               82.525%\n",
            "The validation accuracy at iteration 1800  is               82.6%\n",
            "[<__main__.Solver object at 0x7f2ca1c8c210>, <__main__.Solver object at 0x7f2cad78fb50>, <__main__.Solver object at 0x7f2ca1fac6d0>, <__main__.Solver object at 0x7f2ca258c910>, <__main__.Solver object at 0x7f2ca258c3d0>]\n",
            "The validation accuracy at iteration 16  is               9.2%\n",
            "The validation accuracy at iteration 32  is               9.975000000000001%\n",
            "The validation accuracy at iteration 48  is               10.7%\n",
            "The validation accuracy at iteration 64  is               11.25%\n",
            "The validation accuracy at iteration 80  is               11.675%\n",
            "The validation accuracy at iteration 96  is               12.0%\n",
            "The validation accuracy at iteration 112  is               12.475%\n",
            "The validation accuracy at iteration 128  is               13.325000000000001%\n",
            "The validation accuracy at iteration 144  is               13.900000000000002%\n",
            "The validation accuracy at iteration 160  is               14.45%\n",
            "The validation accuracy at iteration 176  is               15.25%\n",
            "The validation accuracy at iteration 192  is               16.525000000000002%\n",
            "The validation accuracy at iteration 208  is               17.375%\n",
            "The validation accuracy at iteration 224  is               18.2%\n",
            "The validation accuracy at iteration 240  is               19.2%\n",
            "The validation accuracy at iteration 256  is               20.3%\n",
            "The validation accuracy at iteration 272  is               21.625%\n",
            "The validation accuracy at iteration 288  is               22.925%\n",
            "The validation accuracy at iteration 304  is               24.075%\n",
            "The validation accuracy at iteration 320  is               25.525%\n",
            "The validation accuracy at iteration 336  is               26.55%\n",
            "The validation accuracy at iteration 352  is               27.750000000000004%\n",
            "The validation accuracy at iteration 368  is               28.725%\n",
            "The validation accuracy at iteration 384  is               29.7%\n",
            "The validation accuracy at iteration 400  is               30.85%\n",
            "The validation accuracy at iteration 416  is               32.425%\n",
            "The validation accuracy at iteration 432  is               33.85%\n",
            "The validation accuracy at iteration 448  is               34.925%\n",
            "The validation accuracy at iteration 464  is               35.775%\n",
            "The validation accuracy at iteration 480  is               36.7%\n",
            "The validation accuracy at iteration 496  is               37.775%\n",
            "The validation accuracy at iteration 512  is               38.550000000000004%\n",
            "The validation accuracy at iteration 528  is               39.45%\n",
            "The validation accuracy at iteration 544  is               40.699999999999996%\n",
            "The validation accuracy at iteration 560  is               41.875%\n",
            "The validation accuracy at iteration 576  is               42.65%\n",
            "The validation accuracy at iteration 592  is               43.45%\n",
            "The validation accuracy at iteration 608  is               44.275%\n",
            "The validation accuracy at iteration 624  is               44.9%\n",
            "The validation accuracy at iteration 640  is               45.75%\n",
            "The validation accuracy at iteration 656  is               46.45%\n",
            "The validation accuracy at iteration 672  is               47.225%\n",
            "The validation accuracy at iteration 688  is               48.05%\n",
            "The validation accuracy at iteration 704  is               48.675000000000004%\n",
            "The validation accuracy at iteration 720  is               49.425000000000004%\n",
            "The validation accuracy at iteration 736  is               50.125%\n",
            "The validation accuracy at iteration 752  is               50.875%\n",
            "The validation accuracy at iteration 768  is               51.65%\n",
            "The validation accuracy at iteration 784  is               52.37500000000001%\n",
            "The validation accuracy at iteration 800  is               52.675000000000004%\n",
            "The validation accuracy at iteration 816  is               53.349999999999994%\n",
            "The validation accuracy at iteration 832  is               53.87499999999999%\n",
            "The validation accuracy at iteration 848  is               54.425000000000004%\n",
            "The validation accuracy at iteration 864  is               55.15%\n",
            "The validation accuracy at iteration 880  is               55.45%\n",
            "The validation accuracy at iteration 896  is               55.925000000000004%\n",
            "The validation accuracy at iteration 912  is               56.525000000000006%\n",
            "The validation accuracy at iteration 928  is               56.99999999999999%\n",
            "The validation accuracy at iteration 944  is               57.4%\n",
            "The validation accuracy at iteration 960  is               57.775%\n",
            "The validation accuracy at iteration 976  is               58.199999999999996%\n",
            "The validation accuracy at iteration 992  is               58.5%\n",
            "The validation accuracy at iteration 1008  is               58.9%\n",
            "The validation accuracy at iteration 1024  is               59.175%\n",
            "The validation accuracy at iteration 1040  is               59.62499999999999%\n",
            "The validation accuracy at iteration 1056  is               60.075%\n",
            "The validation accuracy at iteration 1072  is               60.3%\n",
            "The validation accuracy at iteration 1088  is               60.575%\n",
            "The validation accuracy at iteration 1104  is               60.824999999999996%\n",
            "The validation accuracy at iteration 1120  is               61.050000000000004%\n",
            "The validation accuracy at iteration 1136  is               61.375%\n",
            "The validation accuracy at iteration 1152  is               61.724999999999994%\n",
            "The validation accuracy at iteration 1168  is               62.125%\n",
            "The validation accuracy at iteration 1184  is               62.275000000000006%\n",
            "The validation accuracy at iteration 1200  is               62.425%\n",
            "The validation accuracy at iteration 1216  is               62.7%\n",
            "The validation accuracy at iteration 1232  is               63.0%\n",
            "The validation accuracy at iteration 1248  is               63.175000000000004%\n",
            "The validation accuracy at iteration 1264  is               63.175000000000004%\n",
            "The validation accuracy at iteration 1280  is               63.349999999999994%\n",
            "The validation accuracy at iteration 1296  is               63.449999999999996%\n",
            "The validation accuracy at iteration 1312  is               63.6%\n",
            "The validation accuracy at iteration 1328  is               63.775000000000006%\n",
            "The validation accuracy at iteration 1344  is               63.949999999999996%\n",
            "The validation accuracy at iteration 1360  is               64.225%\n",
            "The validation accuracy at iteration 1376  is               64.275%\n",
            "The validation accuracy at iteration 1392  is               64.4%\n",
            "The validation accuracy at iteration 1408  is               64.525%\n",
            "The validation accuracy at iteration 1424  is               64.775%\n",
            "The validation accuracy at iteration 1440  is               64.97500000000001%\n",
            "The validation accuracy at iteration 1456  is               65.05%\n",
            "The validation accuracy at iteration 1472  is               65.17500000000001%\n",
            "The validation accuracy at iteration 1488  is               65.60000000000001%\n",
            "The validation accuracy at iteration 1504  is               65.575%\n",
            "The validation accuracy at iteration 1520  is               65.825%\n",
            "The validation accuracy at iteration 1536  is               66.07499999999999%\n",
            "The validation accuracy at iteration 1552  is               66.125%\n",
            "The validation accuracy at iteration 1568  is               66.14999999999999%\n",
            "The validation accuracy at iteration 1584  is               66.225%\n",
            "The validation accuracy at iteration 1600  is               66.525%\n",
            "The validation accuracy at iteration 1616  is               66.525%\n",
            "The validation accuracy at iteration 1632  is               66.60000000000001%\n",
            "The validation accuracy at iteration 1648  is               66.725%\n",
            "The validation accuracy at iteration 1664  is               66.8%\n",
            "The validation accuracy at iteration 1680  is               66.85%\n",
            "The validation accuracy at iteration 1696  is               66.95%\n",
            "The validation accuracy at iteration 1712  is               67.175%\n",
            "The validation accuracy at iteration 1728  is               67.2%\n",
            "The validation accuracy at iteration 1744  is               67.225%\n",
            "The validation accuracy at iteration 1760  is               67.30000000000001%\n",
            "The validation accuracy at iteration 1776  is               67.425%\n",
            "The validation accuracy at iteration 1792  is               67.425%\n",
            "The validation accuracy at iteration 1808  is               67.65%\n",
            "The validation accuracy at iteration 1824  is               67.77499999999999%\n",
            "The validation accuracy at iteration 1840  is               67.85%\n",
            "The validation accuracy at iteration 1856  is               68.05%\n",
            "The validation accuracy at iteration 1872  is               68.05%\n",
            "The validation accuracy at iteration 1888  is               68.125%\n",
            "The validation accuracy at iteration 1904  is               68.15%\n",
            "The validation accuracy at iteration 1920  is               68.15%\n",
            "The validation accuracy at iteration 1936  is               68.175%\n",
            "The validation accuracy at iteration 1952  is               68.30000000000001%\n",
            "The validation accuracy at iteration 1968  is               68.30000000000001%\n",
            "The validation accuracy at iteration 1984  is               68.27499999999999%\n",
            "The validation accuracy at iteration 2000  is               68.30000000000001%\n",
            "The validation accuracy at iteration 2016  is               68.425%\n",
            "The validation accuracy at iteration 2032  is               68.575%\n",
            "The validation accuracy at iteration 2048  is               68.625%\n",
            "The validation accuracy at iteration 2064  is               68.625%\n",
            "The validation accuracy at iteration 2080  is               68.675%\n",
            "The validation accuracy at iteration 2096  is               68.72500000000001%\n",
            "The validation accuracy at iteration 2112  is               68.825%\n",
            "The validation accuracy at iteration 2128  is               69.1%\n",
            "The validation accuracy at iteration 2144  is               69.19999999999999%\n",
            "The validation accuracy at iteration 2160  is               69.25%\n",
            "The validation accuracy at iteration 2176  is               69.3%\n",
            "The validation accuracy at iteration 2192  is               69.325%\n",
            "The validation accuracy at iteration 2208  is               69.35%\n",
            "The validation accuracy at iteration 2224  is               69.39999999999999%\n",
            "The validation accuracy at iteration 2240  is               69.5%\n",
            "The validation accuracy at iteration 2256  is               69.55%\n",
            "The validation accuracy at iteration 2272  is               69.675%\n",
            "The validation accuracy at iteration 2288  is               69.675%\n",
            "The validation accuracy at iteration 2304  is               69.8%\n",
            "The validation accuracy at iteration 2320  is               69.77499999999999%\n",
            "The validation accuracy at iteration 2336  is               69.85%\n",
            "The validation accuracy at iteration 2352  is               69.8%\n",
            "The validation accuracy at iteration 2368  is               69.875%\n",
            "The validation accuracy at iteration 2384  is               69.8%\n",
            "The validation accuracy at iteration 2400  is               69.925%\n",
            "The validation accuracy at iteration 2416  is               70.025%\n",
            "The validation accuracy at iteration 2432  is               70.15%\n",
            "The validation accuracy at iteration 2448  is               70.325%\n",
            "The validation accuracy at iteration 2464  is               70.325%\n",
            "The validation accuracy at iteration 2480  is               70.35%\n",
            "The validation accuracy at iteration 2496  is               70.39999999999999%\n",
            "The validation accuracy at iteration 2512  is               70.39999999999999%\n",
            "The validation accuracy at iteration 2528  is               70.42500000000001%\n",
            "The validation accuracy at iteration 2544  is               70.475%\n",
            "The validation accuracy at iteration 2560  is               70.42500000000001%\n",
            "The validation accuracy at iteration 2576  is               70.475%\n",
            "The validation accuracy at iteration 2592  is               70.475%\n",
            "The validation accuracy at iteration 2608  is               70.45%\n",
            "The validation accuracy at iteration 2624  is               70.475%\n",
            "The validation accuracy at iteration 2640  is               70.525%\n",
            "The validation accuracy at iteration 2656  is               70.6%\n",
            "The validation accuracy at iteration 2672  is               70.625%\n",
            "The validation accuracy at iteration 2688  is               70.675%\n",
            "The validation accuracy at iteration 2704  is               70.75%\n",
            "The validation accuracy at iteration 2720  is               70.775%\n",
            "The validation accuracy at iteration 2736  is               70.7%\n",
            "The validation accuracy at iteration 2752  is               70.8%\n",
            "The validation accuracy at iteration 2768  is               70.975%\n",
            "The validation accuracy at iteration 2784  is               71.025%\n",
            "The validation accuracy at iteration 2800  is               71.05%\n",
            "The validation accuracy at iteration 2816  is               71.075%\n",
            "The validation accuracy at iteration 2832  is               71.1%\n",
            "The validation accuracy at iteration 2848  is               71.075%\n",
            "The validation accuracy at iteration 2864  is               71.125%\n",
            "The validation accuracy at iteration 2880  is               71.175%\n",
            "The validation accuracy at iteration 2896  is               71.175%\n",
            "The validation accuracy at iteration 2912  is               71.15%\n",
            "The validation accuracy at iteration 2928  is               71.175%\n",
            "The validation accuracy at iteration 2944  is               71.125%\n",
            "The validation accuracy at iteration 2960  is               71.125%\n",
            "The validation accuracy at iteration 2976  is               71.1%\n",
            "The validation accuracy at iteration 2992  is               71.125%\n",
            "The validation accuracy at iteration 3008  is               71.125%\n",
            "The validation accuracy at iteration 3024  is               71.15%\n",
            "The validation accuracy at iteration 3040  is               71.175%\n",
            "The validation accuracy at iteration 3056  is               71.22500000000001%\n",
            "The validation accuracy at iteration 3072  is               71.3%\n",
            "The validation accuracy at iteration 3088  is               71.22500000000001%\n",
            "The validation accuracy at iteration 3104  is               71.275%\n",
            "The validation accuracy at iteration 3120  is               71.35000000000001%\n",
            "The validation accuracy at iteration 3136  is               71.35000000000001%\n",
            "The validation accuracy at iteration 3152  is               71.375%\n",
            "The validation accuracy at iteration 3168  is               71.3%\n",
            "The validation accuracy at iteration 3184  is               71.35000000000001%\n",
            "The validation accuracy at iteration 3200  is               71.3%\n",
            "The validation accuracy at iteration 3216  is               71.3%\n",
            "The validation accuracy at iteration 3232  is               71.39999999999999%\n",
            "The validation accuracy at iteration 3248  is               71.25%\n",
            "The validation accuracy at iteration 3264  is               71.25%\n",
            "The validation accuracy at iteration 3280  is               71.22500000000001%\n",
            "The validation accuracy at iteration 3296  is               71.2%\n",
            "The validation accuracy at iteration 3312  is               71.22500000000001%\n",
            "The validation accuracy at iteration 3328  is               71.22500000000001%\n",
            "The validation accuracy at iteration 3344  is               71.25%\n",
            "The validation accuracy at iteration 3360  is               71.25%\n",
            "The validation accuracy at iteration 3376  is               71.325%\n",
            "The validation accuracy at iteration 3392  is               71.3%\n",
            "The validation accuracy at iteration 3408  is               71.35000000000001%\n",
            "The validation accuracy at iteration 3424  is               71.39999999999999%\n",
            "The validation accuracy at iteration 3440  is               71.39999999999999%\n",
            "The validation accuracy at iteration 3456  is               71.375%\n",
            "The validation accuracy at iteration 3472  is               71.39999999999999%\n",
            "The validation accuracy at iteration 3488  is               71.39999999999999%\n",
            "The validation accuracy at iteration 3504  is               71.45%\n",
            "The validation accuracy at iteration 3520  is               71.475%\n",
            "The validation accuracy at iteration 3536  is               71.475%\n",
            "The validation accuracy at iteration 3552  is               71.5%\n",
            "The validation accuracy at iteration 3568  is               71.525%\n",
            "The validation accuracy at iteration 3584  is               71.5%\n",
            "The validation accuracy at iteration 3600  is               71.475%\n",
            "The validation accuracy at iteration 3616  is               71.45%\n",
            "The validation accuracy at iteration 3632  is               71.475%\n",
            "The validation accuracy at iteration 3648  is               71.45%\n",
            "The validation accuracy at iteration 3664  is               71.475%\n",
            "The validation accuracy at iteration 3680  is               71.42500000000001%\n",
            "The validation accuracy at iteration 3696  is               71.5%\n",
            "The validation accuracy at iteration 3712  is               71.5%\n",
            "The validation accuracy at iteration 3728  is               71.625%\n",
            "The validation accuracy at iteration 3744  is               71.6%\n",
            "The validation accuracy at iteration 3760  is               71.65%\n",
            "The validation accuracy at iteration 3776  is               71.65%\n",
            "The validation accuracy at iteration 3792  is               71.65%\n",
            "The validation accuracy at iteration 3808  is               71.72500000000001%\n",
            "The validation accuracy at iteration 3824  is               71.72500000000001%\n",
            "The validation accuracy at iteration 3840  is               71.7%\n",
            "The validation accuracy at iteration 3856  is               71.675%\n",
            "The validation accuracy at iteration 3872  is               71.7%\n",
            "The validation accuracy at iteration 3888  is               71.65%\n",
            "The validation accuracy at iteration 3904  is               71.675%\n",
            "The validation accuracy at iteration 3920  is               71.675%\n",
            "The validation accuracy at iteration 3936  is               71.75%\n",
            "The validation accuracy at iteration 3952  is               71.72500000000001%\n",
            "The validation accuracy at iteration 3968  is               71.75%\n",
            "The validation accuracy at iteration 3984  is               71.72500000000001%\n",
            "The validation accuracy at iteration 4000  is               71.675%\n",
            "The validation accuracy at iteration 4016  is               71.75%\n",
            "The validation accuracy at iteration 4032  is               71.8%\n",
            "The validation accuracy at iteration 4048  is               71.8%\n",
            "The validation accuracy at iteration 4064  is               71.825%\n",
            "The validation accuracy at iteration 4080  is               71.85000000000001%\n",
            "The validation accuracy at iteration 4096  is               71.875%\n",
            "The validation accuracy at iteration 4112  is               71.85000000000001%\n",
            "The validation accuracy at iteration 4128  is               71.89999999999999%\n",
            "The validation accuracy at iteration 4144  is               71.925%\n",
            "The validation accuracy at iteration 4160  is               71.89999999999999%\n",
            "The validation accuracy at iteration 4176  is               71.825%\n",
            "The validation accuracy at iteration 4192  is               71.875%\n",
            "The validation accuracy at iteration 4208  is               71.825%\n",
            "The validation accuracy at iteration 4224  is               71.8%\n",
            "The validation accuracy at iteration 4240  is               71.825%\n",
            "The validation accuracy at iteration 4256  is               71.8%\n",
            "The validation accuracy at iteration 4272  is               71.875%\n",
            "The validation accuracy at iteration 4288  is               71.89999999999999%\n",
            "The validation accuracy at iteration 4304  is               71.8%\n",
            "The validation accuracy at iteration 4320  is               71.72500000000001%\n",
            "The validation accuracy at iteration 4336  is               71.8%\n",
            "The validation accuracy at iteration 4352  is               71.825%\n",
            "The validation accuracy at iteration 4368  is               71.875%\n",
            "The validation accuracy at iteration 4384  is               71.95%\n",
            "The validation accuracy at iteration 4400  is               71.975%\n",
            "The validation accuracy at iteration 4416  is               71.975%\n",
            "The validation accuracy at iteration 4432  is               71.975%\n",
            "The validation accuracy at iteration 4448  is               71.925%\n",
            "The validation accuracy at iteration 4464  is               71.925%\n",
            "The validation accuracy at iteration 4480  is               71.925%\n",
            "The validation accuracy at iteration 4496  is               71.925%\n",
            "The validation accuracy at iteration 4512  is               71.89999999999999%\n",
            "The validation accuracy at iteration 4528  is               71.875%\n",
            "The validation accuracy at iteration 4544  is               71.925%\n",
            "The validation accuracy at iteration 4560  is               71.85000000000001%\n",
            "The validation accuracy at iteration 4576  is               71.775%\n",
            "The validation accuracy at iteration 4592  is               71.89999999999999%\n",
            "The validation accuracy at iteration 4608  is               71.95%\n",
            "The validation accuracy at iteration 4624  is               71.89999999999999%\n",
            "The validation accuracy at iteration 4640  is               71.85000000000001%\n",
            "The validation accuracy at iteration 4656  is               71.825%\n",
            "The validation accuracy at iteration 4672  is               71.85000000000001%\n",
            "The validation accuracy at iteration 4688  is               72.0%\n",
            "The validation accuracy at iteration 4704  is               72.05%\n",
            "The validation accuracy at iteration 4720  is               72.05%\n",
            "The validation accuracy at iteration 4736  is               72.075%\n",
            "The validation accuracy at iteration 4752  is               72.02499999999999%\n",
            "The validation accuracy at iteration 4768  is               71.95%\n",
            "The validation accuracy at iteration 4784  is               72.0%\n",
            "The validation accuracy at iteration 4800  is               71.925%\n",
            "The validation accuracy at iteration 4816  is               71.925%\n",
            "The validation accuracy at iteration 4832  is               71.875%\n",
            "The validation accuracy at iteration 4848  is               71.925%\n",
            "The validation accuracy at iteration 4864  is               71.95%\n",
            "The validation accuracy at iteration 4880  is               71.875%\n",
            "The validation accuracy at iteration 4896  is               71.875%\n",
            "The validation accuracy at iteration 4912  is               71.95%\n",
            "The validation accuracy at iteration 4928  is               71.95%\n",
            "The validation accuracy at iteration 4944  is               71.975%\n",
            "The validation accuracy at iteration 4960  is               71.975%\n",
            "The validation accuracy at iteration 4976  is               72.0%\n",
            "The validation accuracy at iteration 4992  is               72.0%\n",
            "The validation accuracy at iteration 5008  is               72.0%\n",
            "The validation accuracy at iteration 5024  is               72.0%\n",
            "The validation accuracy at iteration 5040  is               71.95%\n",
            "The validation accuracy at iteration 5056  is               71.95%\n",
            "The validation accuracy at iteration 5072  is               71.95%\n",
            "The validation accuracy at iteration 5088  is               71.89999999999999%\n",
            "The validation accuracy at iteration 5104  is               71.95%\n",
            "The validation accuracy at iteration 5120  is               71.925%\n",
            "The validation accuracy at iteration 5136  is               71.95%\n",
            "The validation accuracy at iteration 5152  is               71.89999999999999%\n",
            "The validation accuracy at iteration 5168  is               71.89999999999999%\n",
            "The validation accuracy at iteration 5184  is               71.925%\n",
            "The validation accuracy at iteration 5200  is               71.925%\n",
            "The validation accuracy at iteration 5216  is               71.925%\n",
            "The validation accuracy at iteration 5232  is               71.925%\n",
            "The validation accuracy at iteration 5248  is               71.925%\n",
            "The validation accuracy at iteration 5264  is               71.925%\n",
            "The validation accuracy at iteration 5280  is               71.925%\n",
            "The validation accuracy at iteration 5296  is               71.85000000000001%\n",
            "The validation accuracy at iteration 5312  is               71.89999999999999%\n",
            "The validation accuracy at iteration 5328  is               71.925%\n",
            "The validation accuracy at iteration 5344  is               71.85000000000001%\n",
            "The validation accuracy at iteration 5360  is               71.85000000000001%\n",
            "The validation accuracy at iteration 5376  is               71.775%\n",
            "The validation accuracy at iteration 5392  is               71.85000000000001%\n",
            "The validation accuracy at iteration 5408  is               71.775%\n",
            "The validation accuracy at iteration 5424  is               71.89999999999999%\n",
            "The validation accuracy at iteration 5440  is               71.85000000000001%\n",
            "The validation accuracy at iteration 5456  is               71.89999999999999%\n",
            "The validation accuracy at iteration 5472  is               71.875%\n",
            "The validation accuracy at iteration 5488  is               71.85000000000001%\n",
            "The validation accuracy at iteration 5504  is               71.925%\n",
            "The validation accuracy at iteration 5520  is               71.875%\n",
            "The validation accuracy at iteration 5536  is               71.825%\n",
            "The validation accuracy at iteration 5552  is               71.85000000000001%\n",
            "The validation accuracy at iteration 5568  is               71.89999999999999%\n",
            "The validation accuracy at iteration 5584  is               71.89999999999999%\n",
            "The validation accuracy at iteration 5600  is               71.85000000000001%\n",
            "The validation accuracy at iteration 5616  is               71.95%\n",
            "The validation accuracy at iteration 5632  is               71.975%\n",
            "The validation accuracy at iteration 5648  is               71.89999999999999%\n",
            "The validation accuracy at iteration 5664  is               71.89999999999999%\n",
            "The validation accuracy at iteration 5680  is               71.925%\n",
            "The validation accuracy at iteration 5696  is               71.95%\n",
            "The validation accuracy at iteration 5712  is               71.95%\n",
            "The validation accuracy at iteration 5728  is               71.89999999999999%\n",
            "The validation accuracy at iteration 5744  is               71.89999999999999%\n",
            "The validation accuracy at iteration 5760  is               71.875%\n",
            "The validation accuracy at iteration 5776  is               71.89999999999999%\n",
            "The validation accuracy at iteration 5792  is               71.875%\n",
            "The validation accuracy at iteration 5808  is               71.875%\n",
            "The validation accuracy at iteration 5824  is               71.875%\n",
            "The validation accuracy at iteration 5840  is               71.85000000000001%\n",
            "The validation accuracy at iteration 5856  is               71.875%\n",
            "The validation accuracy at iteration 5872  is               71.875%\n",
            "The validation accuracy at iteration 5888  is               71.89999999999999%\n",
            "The validation accuracy at iteration 5904  is               71.95%\n",
            "The validation accuracy at iteration 5920  is               71.95%\n",
            "The validation accuracy at iteration 5936  is               71.975%\n",
            "The validation accuracy at iteration 5952  is               71.95%\n",
            "The validation accuracy at iteration 5968  is               71.89999999999999%\n",
            "The validation accuracy at iteration 5984  is               71.89999999999999%\n",
            "The validation accuracy at iteration 6000  is               71.89999999999999%\n",
            "The validation accuracy at iteration 6016  is               71.89999999999999%\n",
            "The validation accuracy at iteration 6032  is               71.89999999999999%\n",
            "The validation accuracy at iteration 6048  is               71.95%\n",
            "The validation accuracy at iteration 6064  is               71.925%\n",
            "The validation accuracy at iteration 6080  is               71.89999999999999%\n",
            "The validation accuracy at iteration 6096  is               71.925%\n",
            "The validation accuracy at iteration 6112  is               71.89999999999999%\n",
            "The validation accuracy at iteration 6128  is               71.925%\n",
            "The validation accuracy at iteration 6144  is               71.95%\n",
            "The validation accuracy at iteration 6160  is               71.975%\n",
            "The validation accuracy at iteration 6176  is               71.925%\n",
            "The validation accuracy at iteration 6192  is               71.95%\n",
            "The validation accuracy at iteration 6208  is               71.975%\n",
            "The validation accuracy at iteration 6224  is               71.975%\n",
            "The validation accuracy at iteration 6240  is               71.975%\n",
            "The validation accuracy at iteration 6256  is               72.0%\n",
            "The validation accuracy at iteration 6272  is               71.975%\n",
            "The validation accuracy at iteration 6288  is               72.02499999999999%\n",
            "The validation accuracy at iteration 6304  is               71.95%\n",
            "The validation accuracy at iteration 6320  is               72.0%\n",
            "The validation accuracy at iteration 6336  is               72.0%\n",
            "The validation accuracy at iteration 6352  is               72.02499999999999%\n",
            "The validation accuracy at iteration 6368  is               72.05%\n",
            "The validation accuracy at iteration 6384  is               72.075%\n",
            "The validation accuracy at iteration 6400  is               72.05%\n",
            "The validation accuracy at iteration 6416  is               72.02499999999999%\n",
            "The validation accuracy at iteration 6432  is               72.02499999999999%\n",
            "The validation accuracy at iteration 6448  is               72.02499999999999%\n",
            "The validation accuracy at iteration 6464  is               72.02499999999999%\n",
            "The validation accuracy at iteration 6480  is               72.02499999999999%\n",
            "The validation accuracy at iteration 6496  is               71.975%\n",
            "The validation accuracy at iteration 6512  is               72.0%\n",
            "The validation accuracy at iteration 6528  is               71.975%\n",
            "The validation accuracy at iteration 6544  is               72.02499999999999%\n",
            "The validation accuracy at iteration 6560  is               72.0%\n",
            "The validation accuracy at iteration 6576  is               72.02499999999999%\n",
            "The validation accuracy at iteration 6592  is               72.02499999999999%\n",
            "The validation accuracy at iteration 6608  is               72.02499999999999%\n",
            "The validation accuracy at iteration 6624  is               72.0%\n",
            "The validation accuracy at iteration 6640  is               72.02499999999999%\n",
            "The validation accuracy at iteration 6656  is               71.95%\n",
            "The validation accuracy at iteration 6672  is               72.0%\n",
            "The validation accuracy at iteration 6688  is               72.0%\n",
            "The validation accuracy at iteration 6704  is               72.05%\n",
            "The validation accuracy at iteration 6720  is               72.075%\n",
            "The validation accuracy at iteration 6736  is               72.1%\n",
            "The validation accuracy at iteration 6752  is               72.1%\n",
            "The validation accuracy at iteration 6768  is               72.125%\n",
            "The validation accuracy at iteration 6784  is               72.125%\n",
            "The validation accuracy at iteration 6800  is               72.1%\n",
            "The validation accuracy at iteration 6816  is               72.02499999999999%\n",
            "The validation accuracy at iteration 6832  is               72.075%\n",
            "The validation accuracy at iteration 6848  is               72.1%\n",
            "The validation accuracy at iteration 6864  is               72.125%\n",
            "The validation accuracy at iteration 6880  is               72.15%\n",
            "The validation accuracy at iteration 6896  is               72.125%\n",
            "The validation accuracy at iteration 6912  is               72.15%\n",
            "The validation accuracy at iteration 6928  is               72.15%\n",
            "The validation accuracy at iteration 6944  is               72.15%\n",
            "The validation accuracy at iteration 6960  is               72.175%\n",
            "The validation accuracy at iteration 6976  is               72.225%\n",
            "The validation accuracy at iteration 6992  is               72.25%\n",
            "The validation accuracy at iteration 7008  is               72.2%\n",
            "The validation accuracy at iteration 7024  is               72.2%\n",
            "The validation accuracy at iteration 7040  is               72.2%\n",
            "The validation accuracy at iteration 7056  is               72.2%\n",
            "The validation accuracy at iteration 7072  is               72.2%\n",
            "The validation accuracy at iteration 7088  is               72.2%\n",
            "The validation accuracy at iteration 7104  is               72.225%\n",
            "The validation accuracy at iteration 7120  is               72.2%\n",
            "The validation accuracy at iteration 7136  is               72.2%\n",
            "The validation accuracy at iteration 7152  is               72.15%\n",
            "The validation accuracy at iteration 7168  is               72.125%\n",
            "The validation accuracy at iteration 7184  is               72.125%\n",
            "The validation accuracy at iteration 7200  is               72.15%\n",
            "The validation accuracy at iteration 7216  is               72.125%\n",
            "The validation accuracy at iteration 7232  is               72.2%\n",
            "The validation accuracy at iteration 7248  is               72.15%\n",
            "The validation accuracy at iteration 7264  is               72.125%\n",
            "The validation accuracy at iteration 7280  is               72.1%\n",
            "The validation accuracy at iteration 7296  is               72.175%\n",
            "The validation accuracy at iteration 7312  is               72.175%\n",
            "The validation accuracy at iteration 7328  is               72.1%\n",
            "The validation accuracy at iteration 7344  is               72.075%\n",
            "The validation accuracy at iteration 7360  is               72.1%\n",
            "The validation accuracy at iteration 7376  is               72.125%\n",
            "The validation accuracy at iteration 7392  is               72.15%\n",
            "The validation accuracy at iteration 7408  is               72.125%\n",
            "The validation accuracy at iteration 7424  is               72.125%\n",
            "The validation accuracy at iteration 7440  is               72.15%\n",
            "The validation accuracy at iteration 7456  is               72.175%\n",
            "The validation accuracy at iteration 7472  is               72.175%\n",
            "The validation accuracy at iteration 7488  is               72.225%\n",
            "The validation accuracy at iteration 7504  is               72.2%\n",
            "The validation accuracy at iteration 7520  is               72.2%\n",
            "The validation accuracy at iteration 7536  is               72.175%\n",
            "The validation accuracy at iteration 7552  is               72.175%\n",
            "The validation accuracy at iteration 7568  is               72.225%\n",
            "The validation accuracy at iteration 7584  is               72.175%\n",
            "The validation accuracy at iteration 7600  is               72.15%\n",
            "The validation accuracy at iteration 7616  is               72.15%\n",
            "The validation accuracy at iteration 7632  is               72.175%\n",
            "The validation accuracy at iteration 7648  is               72.2%\n",
            "The validation accuracy at iteration 7664  is               72.2%\n",
            "The validation accuracy at iteration 7680  is               72.175%\n",
            "The validation accuracy at iteration 7696  is               72.175%\n",
            "The validation accuracy at iteration 7712  is               72.15%\n",
            "The validation accuracy at iteration 7728  is               72.175%\n",
            "The validation accuracy at iteration 7744  is               72.175%\n",
            "The validation accuracy at iteration 7760  is               72.175%\n",
            "The validation accuracy at iteration 7776  is               72.2%\n",
            "The validation accuracy at iteration 7792  is               72.2%\n",
            "The validation accuracy at iteration 7808  is               72.2%\n",
            "The validation accuracy at iteration 7824  is               72.175%\n",
            "The validation accuracy at iteration 7840  is               72.175%\n",
            "The validation accuracy at iteration 7856  is               72.2%\n",
            "The validation accuracy at iteration 7872  is               72.175%\n",
            "The validation accuracy at iteration 7888  is               72.25%\n",
            "The validation accuracy at iteration 7904  is               72.25%\n",
            "The validation accuracy at iteration 7920  is               72.225%\n",
            "The validation accuracy at iteration 7936  is               72.225%\n",
            "The validation accuracy at iteration 7952  is               72.15%\n",
            "The validation accuracy at iteration 7968  is               72.175%\n",
            "The validation accuracy at iteration 7984  is               72.125%\n",
            "The validation accuracy at iteration 8000  is               72.1%\n",
            "The validation accuracy at iteration 8016  is               72.1%\n",
            "The validation accuracy at iteration 8032  is               72.075%\n",
            "The validation accuracy at iteration 8048  is               72.05%\n",
            "The validation accuracy at iteration 8064  is               72.05%\n",
            "The validation accuracy at iteration 8080  is               72.02499999999999%\n",
            "The validation accuracy at iteration 8096  is               72.02499999999999%\n",
            "The validation accuracy at iteration 8112  is               72.075%\n",
            "The validation accuracy at iteration 8128  is               72.05%\n",
            "The validation accuracy at iteration 8144  is               72.05%\n",
            "The validation accuracy at iteration 8160  is               72.075%\n",
            "The validation accuracy at iteration 8176  is               72.125%\n",
            "The validation accuracy at iteration 8192  is               72.075%\n",
            "The validation accuracy at iteration 8208  is               72.15%\n",
            "The validation accuracy at iteration 8224  is               72.175%\n",
            "The validation accuracy at iteration 8240  is               72.15%\n",
            "The validation accuracy at iteration 8256  is               72.15%\n",
            "The validation accuracy at iteration 8272  is               72.125%\n",
            "The validation accuracy at iteration 8288  is               72.1%\n",
            "The validation accuracy at iteration 8304  is               72.125%\n",
            "The validation accuracy at iteration 8320  is               72.05%\n",
            "The validation accuracy at iteration 8336  is               72.05%\n",
            "The validation accuracy at iteration 8352  is               72.05%\n",
            "The validation accuracy at iteration 8368  is               72.075%\n",
            "The validation accuracy at iteration 8384  is               72.075%\n",
            "The validation accuracy at iteration 8400  is               72.05%\n",
            "The validation accuracy at iteration 8416  is               72.02499999999999%\n",
            "The validation accuracy at iteration 8432  is               72.05%\n",
            "The validation accuracy at iteration 8448  is               72.05%\n",
            "The validation accuracy at iteration 8464  is               72.05%\n",
            "The validation accuracy at iteration 8480  is               72.075%\n",
            "The validation accuracy at iteration 8496  is               72.05%\n",
            "The validation accuracy at iteration 8512  is               72.05%\n",
            "The validation accuracy at iteration 8528  is               72.1%\n",
            "The validation accuracy at iteration 8544  is               72.05%\n",
            "The validation accuracy at iteration 8560  is               72.1%\n",
            "The validation accuracy at iteration 8576  is               72.1%\n",
            "The validation accuracy at iteration 8592  is               72.075%\n",
            "The validation accuracy at iteration 8608  is               72.1%\n",
            "The validation accuracy at iteration 8624  is               72.075%\n",
            "The validation accuracy at iteration 8640  is               72.075%\n",
            "The validation accuracy at iteration 8656  is               72.05%\n",
            "The validation accuracy at iteration 8672  is               72.02499999999999%\n",
            "The validation accuracy at iteration 8688  is               72.05%\n",
            "The validation accuracy at iteration 8704  is               72.05%\n",
            "The validation accuracy at iteration 8720  is               72.02499999999999%\n",
            "The validation accuracy at iteration 8736  is               72.02499999999999%\n",
            "The validation accuracy at iteration 8752  is               72.02499999999999%\n",
            "The validation accuracy at iteration 8768  is               72.02499999999999%\n",
            "The validation accuracy at iteration 8784  is               72.075%\n",
            "The validation accuracy at iteration 8800  is               72.1%\n",
            "The validation accuracy at iteration 8816  is               72.125%\n",
            "The validation accuracy at iteration 8832  is               72.175%\n",
            "The validation accuracy at iteration 8848  is               72.225%\n",
            "The validation accuracy at iteration 8864  is               72.25%\n",
            "The validation accuracy at iteration 8880  is               72.275%\n",
            "The validation accuracy at iteration 8896  is               72.275%\n",
            "The validation accuracy at iteration 8912  is               72.3%\n",
            "The validation accuracy at iteration 8928  is               72.3%\n",
            "The validation accuracy at iteration 8944  is               72.35000000000001%\n",
            "The validation accuracy at iteration 8960  is               72.275%\n",
            "The validation accuracy at iteration 8976  is               72.275%\n",
            "The validation accuracy at iteration 8992  is               72.275%\n",
            "The validation accuracy at iteration 9008  is               72.225%\n",
            "The validation accuracy at iteration 9024  is               72.225%\n",
            "The validation accuracy at iteration 9040  is               72.225%\n",
            "The validation accuracy at iteration 9056  is               72.225%\n",
            "The validation accuracy at iteration 9072  is               72.225%\n",
            "The validation accuracy at iteration 9088  is               72.175%\n",
            "The validation accuracy at iteration 9104  is               72.175%\n",
            "The validation accuracy at iteration 9120  is               72.175%\n",
            "The validation accuracy at iteration 9136  is               72.2%\n",
            "The validation accuracy at iteration 9152  is               72.175%\n",
            "The validation accuracy at iteration 9168  is               72.175%\n",
            "The validation accuracy at iteration 9184  is               72.125%\n",
            "The validation accuracy at iteration 9200  is               72.125%\n",
            "The validation accuracy at iteration 9216  is               72.125%\n",
            "The validation accuracy at iteration 9232  is               72.125%\n",
            "The validation accuracy at iteration 9248  is               72.125%\n",
            "The validation accuracy at iteration 9264  is               72.125%\n",
            "The validation accuracy at iteration 9280  is               72.15%\n",
            "The validation accuracy at iteration 9296  is               72.15%\n",
            "The validation accuracy at iteration 9312  is               72.1%\n",
            "The validation accuracy at iteration 9328  is               72.1%\n",
            "The validation accuracy at iteration 9344  is               72.1%\n",
            "The validation accuracy at iteration 9360  is               72.1%\n",
            "The validation accuracy at iteration 9376  is               72.02499999999999%\n",
            "The validation accuracy at iteration 9392  is               72.02499999999999%\n",
            "The validation accuracy at iteration 9408  is               72.02499999999999%\n",
            "The validation accuracy at iteration 9424  is               72.0%\n",
            "The validation accuracy at iteration 9440  is               72.0%\n",
            "The validation accuracy at iteration 9456  is               72.0%\n",
            "The validation accuracy at iteration 9472  is               72.0%\n",
            "The validation accuracy at iteration 9488  is               72.0%\n",
            "The validation accuracy at iteration 9504  is               72.0%\n",
            "The validation accuracy at iteration 9520  is               72.0%\n",
            "The validation accuracy at iteration 9536  is               72.02499999999999%\n",
            "The validation accuracy at iteration 9552  is               71.975%\n",
            "The validation accuracy at iteration 9568  is               71.975%\n",
            "The validation accuracy at iteration 9584  is               71.975%\n",
            "The validation accuracy at iteration 9600  is               71.975%\n",
            "The validation accuracy at iteration 9616  is               72.0%\n",
            "The validation accuracy at iteration 9632  is               72.0%\n",
            "The validation accuracy at iteration 9648  is               72.0%\n",
            "The validation accuracy at iteration 9664  is               72.02499999999999%\n",
            "The validation accuracy at iteration 9680  is               72.05%\n",
            "The validation accuracy at iteration 9696  is               72.02499999999999%\n",
            "The validation accuracy at iteration 9712  is               72.0%\n",
            "The validation accuracy at iteration 9728  is               71.95%\n",
            "The validation accuracy at iteration 9744  is               71.975%\n",
            "The validation accuracy at iteration 9760  is               71.975%\n",
            "The validation accuracy at iteration 9776  is               71.975%\n",
            "The validation accuracy at iteration 9792  is               71.95%\n",
            "The validation accuracy at iteration 9808  is               71.89999999999999%\n",
            "The validation accuracy at iteration 9824  is               71.875%\n",
            "The validation accuracy at iteration 9840  is               71.85000000000001%\n",
            "The validation accuracy at iteration 9856  is               71.825%\n",
            "The validation accuracy at iteration 9872  is               71.825%\n",
            "The validation accuracy at iteration 9888  is               71.85000000000001%\n",
            "The validation accuracy at iteration 9904  is               71.85000000000001%\n",
            "The validation accuracy at iteration 9920  is               71.85000000000001%\n",
            "The validation accuracy at iteration 9936  is               71.85000000000001%\n",
            "The validation accuracy at iteration 9952  is               71.85000000000001%\n",
            "The validation accuracy at iteration 9968  is               71.825%\n",
            "The validation accuracy at iteration 9984  is               71.775%\n",
            "The validation accuracy at iteration 10000  is               71.75%\n",
            "The validation accuracy at iteration 10016  is               71.75%\n",
            "The validation accuracy at iteration 10032  is               71.75%\n",
            "The validation accuracy at iteration 10048  is               71.75%\n",
            "The validation accuracy at iteration 10064  is               71.75%\n",
            "The validation accuracy at iteration 10080  is               71.775%\n",
            "The validation accuracy at iteration 10096  is               71.8%\n",
            "The validation accuracy at iteration 10112  is               71.775%\n",
            "The validation accuracy at iteration 10128  is               71.72500000000001%\n",
            "The validation accuracy at iteration 10144  is               71.825%\n",
            "The validation accuracy at iteration 10160  is               71.75%\n",
            "The validation accuracy at iteration 10176  is               71.75%\n",
            "The validation accuracy at iteration 10192  is               71.75%\n",
            "The validation accuracy at iteration 10208  is               71.7%\n",
            "The validation accuracy at iteration 10224  is               71.72500000000001%\n",
            "The validation accuracy at iteration 10240  is               71.75%\n",
            "The validation accuracy at iteration 10256  is               71.775%\n",
            "The validation accuracy at iteration 10272  is               71.825%\n",
            "The validation accuracy at iteration 10288  is               71.75%\n",
            "The validation accuracy at iteration 10304  is               71.72500000000001%\n",
            "The validation accuracy at iteration 10320  is               71.75%\n",
            "The validation accuracy at iteration 10336  is               71.72500000000001%\n",
            "The validation accuracy at iteration 10352  is               71.7%\n",
            "The validation accuracy at iteration 10368  is               71.675%\n",
            "The validation accuracy at iteration 10384  is               71.65%\n",
            "The validation accuracy at iteration 10400  is               71.65%\n",
            "The validation accuracy at iteration 10416  is               71.65%\n",
            "The validation accuracy at iteration 10432  is               71.65%\n",
            "The validation accuracy at iteration 10448  is               71.65%\n",
            "The validation accuracy at iteration 10464  is               71.625%\n",
            "The validation accuracy at iteration 10480  is               71.6%\n",
            "The validation accuracy at iteration 10496  is               71.65%\n",
            "The validation accuracy at iteration 10512  is               71.6%\n",
            "The validation accuracy at iteration 10528  is               71.65%\n",
            "The validation accuracy at iteration 10544  is               71.675%\n",
            "The validation accuracy at iteration 10560  is               71.65%\n",
            "The validation accuracy at iteration 10576  is               71.675%\n",
            "The validation accuracy at iteration 10592  is               71.72500000000001%\n",
            "The validation accuracy at iteration 10608  is               71.65%\n",
            "The validation accuracy at iteration 10624  is               71.65%\n",
            "The validation accuracy at iteration 10640  is               71.6%\n",
            "The validation accuracy at iteration 10656  is               71.625%\n",
            "The validation accuracy at iteration 10672  is               71.55%\n",
            "The validation accuracy at iteration 10688  is               71.55%\n",
            "The validation accuracy at iteration 10704  is               71.625%\n",
            "The validation accuracy at iteration 10720  is               71.65%\n",
            "The validation accuracy at iteration 10736  is               71.65%\n",
            "The validation accuracy at iteration 10752  is               71.625%\n",
            "The validation accuracy at iteration 10768  is               71.6%\n",
            "The validation accuracy at iteration 10784  is               71.6%\n",
            "The validation accuracy at iteration 10800  is               71.6%\n",
            "The validation accuracy at iteration 10816  is               71.6%\n",
            "The validation accuracy at iteration 10832  is               71.625%\n",
            "The validation accuracy at iteration 10848  is               71.675%\n",
            "The validation accuracy at iteration 10864  is               71.675%\n",
            "The validation accuracy at iteration 10880  is               71.65%\n",
            "The validation accuracy at iteration 10896  is               71.675%\n",
            "The validation accuracy at iteration 10912  is               71.7%\n",
            "The validation accuracy at iteration 10928  is               71.65%\n",
            "The validation accuracy at iteration 10944  is               71.625%\n",
            "The validation accuracy at iteration 10960  is               71.625%\n",
            "The validation accuracy at iteration 10976  is               71.625%\n",
            "The validation accuracy at iteration 10992  is               71.625%\n",
            "The validation accuracy at iteration 11008  is               71.6%\n",
            "The validation accuracy at iteration 11024  is               71.65%\n",
            "The validation accuracy at iteration 11040  is               71.7%\n",
            "The validation accuracy at iteration 11056  is               71.7%\n",
            "The validation accuracy at iteration 11072  is               71.7%\n",
            "The validation accuracy at iteration 11088  is               71.7%\n",
            "The validation accuracy at iteration 11104  is               71.675%\n",
            "The validation accuracy at iteration 11120  is               71.65%\n",
            "The validation accuracy at iteration 11136  is               71.7%\n",
            "The validation accuracy at iteration 11152  is               71.72500000000001%\n",
            "The validation accuracy at iteration 11168  is               71.7%\n",
            "The validation accuracy at iteration 11184  is               71.75%\n",
            "The validation accuracy at iteration 11200  is               71.775%\n",
            "The validation accuracy at iteration 11216  is               71.825%\n",
            "The validation accuracy at iteration 11232  is               71.825%\n",
            "The validation accuracy at iteration 11248  is               71.8%\n",
            "The validation accuracy at iteration 11264  is               71.75%\n",
            "The validation accuracy at iteration 11280  is               71.75%\n",
            "The validation accuracy at iteration 11296  is               71.7%\n",
            "The validation accuracy at iteration 11312  is               71.65%\n",
            "The validation accuracy at iteration 11328  is               71.7%\n",
            "The validation accuracy at iteration 11344  is               71.7%\n",
            "The validation accuracy at iteration 11360  is               71.72500000000001%\n",
            "The validation accuracy at iteration 11376  is               71.75%\n",
            "The validation accuracy at iteration 11392  is               71.775%\n",
            "The validation accuracy at iteration 11408  is               71.75%\n",
            "The validation accuracy at iteration 11424  is               71.75%\n",
            "The validation accuracy at iteration 11440  is               71.775%\n",
            "The validation accuracy at iteration 11456  is               71.825%\n",
            "The validation accuracy at iteration 11472  is               71.775%\n",
            "The validation accuracy at iteration 11488  is               71.8%\n",
            "The validation accuracy at iteration 11504  is               71.825%\n",
            "The validation accuracy at iteration 11520  is               71.85000000000001%\n",
            "The validation accuracy at iteration 11536  is               71.85000000000001%\n",
            "The validation accuracy at iteration 11552  is               71.89999999999999%\n",
            "The validation accuracy at iteration 11568  is               71.85000000000001%\n",
            "The validation accuracy at iteration 11584  is               71.85000000000001%\n",
            "The validation accuracy at iteration 11600  is               71.825%\n",
            "The validation accuracy at iteration 11616  is               71.85000000000001%\n",
            "The validation accuracy at iteration 11632  is               71.875%\n",
            "The validation accuracy at iteration 11648  is               71.825%\n",
            "The validation accuracy at iteration 11664  is               71.8%\n",
            "The validation accuracy at iteration 11680  is               71.825%\n",
            "The validation accuracy at iteration 11696  is               71.85000000000001%\n",
            "The validation accuracy at iteration 11712  is               71.825%\n",
            "The validation accuracy at iteration 11728  is               71.8%\n",
            "The validation accuracy at iteration 11744  is               71.85000000000001%\n",
            "The validation accuracy at iteration 11760  is               71.825%\n",
            "The validation accuracy at iteration 11776  is               71.85000000000001%\n",
            "The validation accuracy at iteration 11792  is               71.875%\n",
            "The validation accuracy at iteration 11808  is               71.85000000000001%\n",
            "The validation accuracy at iteration 11824  is               71.89999999999999%\n",
            "The validation accuracy at iteration 11840  is               71.925%\n",
            "The validation accuracy at iteration 11856  is               71.95%\n",
            "The validation accuracy at iteration 11872  is               72.02499999999999%\n",
            "The validation accuracy at iteration 11888  is               72.0%\n",
            "The validation accuracy at iteration 11904  is               71.975%\n",
            "The validation accuracy at iteration 11920  is               71.975%\n",
            "The validation accuracy at iteration 11936  is               71.975%\n",
            "The validation accuracy at iteration 11952  is               72.0%\n",
            "The validation accuracy at iteration 11968  is               71.975%\n",
            "The validation accuracy at iteration 11984  is               72.02499999999999%\n",
            "The validation accuracy at iteration 12000  is               72.1%\n",
            "The validation accuracy at iteration 12016  is               72.125%\n",
            "The validation accuracy at iteration 12032  is               72.125%\n",
            "The validation accuracy at iteration 12048  is               72.075%\n",
            "The validation accuracy at iteration 12064  is               72.075%\n",
            "The validation accuracy at iteration 12080  is               72.125%\n",
            "The validation accuracy at iteration 12096  is               72.175%\n",
            "The validation accuracy at iteration 12112  is               72.175%\n",
            "The validation accuracy at iteration 12128  is               72.2%\n",
            "The validation accuracy at iteration 12144  is               72.2%\n",
            "The validation accuracy at iteration 12160  is               72.25%\n",
            "The validation accuracy at iteration 12176  is               72.175%\n",
            "The validation accuracy at iteration 12192  is               72.25%\n",
            "The validation accuracy at iteration 12208  is               72.225%\n",
            "The validation accuracy at iteration 12224  is               72.225%\n",
            "The validation accuracy at iteration 12240  is               72.2%\n",
            "The validation accuracy at iteration 12256  is               72.2%\n",
            "The validation accuracy at iteration 12272  is               72.225%\n",
            "The validation accuracy at iteration 12288  is               72.175%\n",
            "The validation accuracy at iteration 12304  is               72.225%\n",
            "The validation accuracy at iteration 12320  is               72.35000000000001%\n",
            "The validation accuracy at iteration 12336  is               72.35000000000001%\n",
            "The validation accuracy at iteration 12352  is               72.32499999999999%\n",
            "The validation accuracy at iteration 12368  is               72.275%\n",
            "The validation accuracy at iteration 12384  is               72.32499999999999%\n",
            "The validation accuracy at iteration 12400  is               72.3%\n",
            "The validation accuracy at iteration 12416  is               72.35000000000001%\n",
            "The validation accuracy at iteration 12432  is               72.375%\n",
            "The validation accuracy at iteration 12448  is               72.39999999999999%\n",
            "The validation accuracy at iteration 12464  is               72.45%\n",
            "The validation accuracy at iteration 12480  is               72.425%\n",
            "The validation accuracy at iteration 12496  is               72.425%\n",
            "The validation accuracy at iteration 12512  is               72.425%\n",
            "The validation accuracy at iteration 12528  is               72.39999999999999%\n",
            "The validation accuracy at iteration 12544  is               72.39999999999999%\n",
            "The validation accuracy at iteration 12560  is               72.425%\n",
            "The validation accuracy at iteration 12576  is               72.425%\n",
            "The validation accuracy at iteration 12592  is               72.425%\n",
            "The validation accuracy at iteration 12608  is               72.425%\n",
            "The validation accuracy at iteration 12624  is               72.39999999999999%\n",
            "The validation accuracy at iteration 12640  is               72.45%\n",
            "The validation accuracy at iteration 12656  is               72.45%\n",
            "The validation accuracy at iteration 12672  is               72.425%\n",
            "The validation accuracy at iteration 12688  is               72.45%\n",
            "The validation accuracy at iteration 12704  is               72.375%\n",
            "The validation accuracy at iteration 12720  is               72.375%\n",
            "The validation accuracy at iteration 12736  is               72.475%\n",
            "The validation accuracy at iteration 12752  is               72.45%\n",
            "The validation accuracy at iteration 12768  is               72.5%\n",
            "The validation accuracy at iteration 12784  is               72.5%\n",
            "The validation accuracy at iteration 12800  is               72.45%\n",
            "The validation accuracy at iteration 12816  is               72.45%\n",
            "The validation accuracy at iteration 12832  is               72.52499999999999%\n",
            "The validation accuracy at iteration 12848  is               72.45%\n",
            "The validation accuracy at iteration 12864  is               72.475%\n",
            "The validation accuracy at iteration 12880  is               72.475%\n",
            "The validation accuracy at iteration 12896  is               72.475%\n",
            "The validation accuracy at iteration 12912  is               72.5%\n",
            "The validation accuracy at iteration 12928  is               72.475%\n",
            "The validation accuracy at iteration 12944  is               72.55%\n",
            "The validation accuracy at iteration 12960  is               72.625%\n",
            "The validation accuracy at iteration 12976  is               72.7%\n",
            "The validation accuracy at iteration 12992  is               72.65%\n",
            "The validation accuracy at iteration 13008  is               72.65%\n",
            "The validation accuracy at iteration 13024  is               72.55%\n",
            "The validation accuracy at iteration 13040  is               72.55%\n",
            "The validation accuracy at iteration 13056  is               72.675%\n",
            "The validation accuracy at iteration 13072  is               72.625%\n",
            "The validation accuracy at iteration 13088  is               72.725%\n",
            "The validation accuracy at iteration 13104  is               72.8%\n",
            "The validation accuracy at iteration 13120  is               72.675%\n",
            "The validation accuracy at iteration 13136  is               72.675%\n",
            "The validation accuracy at iteration 13152  is               72.75%\n",
            "The validation accuracy at iteration 13168  is               72.7%\n",
            "The validation accuracy at iteration 13184  is               72.75%\n",
            "The validation accuracy at iteration 13200  is               72.7%\n",
            "The validation accuracy at iteration 13216  is               72.75%\n",
            "The validation accuracy at iteration 13232  is               72.725%\n",
            "The validation accuracy at iteration 13248  is               72.7%\n",
            "The validation accuracy at iteration 13264  is               72.725%\n",
            "The validation accuracy at iteration 13280  is               72.82499999999999%\n",
            "The validation accuracy at iteration 13296  is               72.775%\n",
            "The validation accuracy at iteration 13312  is               72.8%\n",
            "The validation accuracy at iteration 13328  is               72.775%\n",
            "The validation accuracy at iteration 13344  is               72.725%\n",
            "The validation accuracy at iteration 13360  is               72.7%\n",
            "The validation accuracy at iteration 13376  is               72.75%\n",
            "The validation accuracy at iteration 13392  is               72.75%\n",
            "The validation accuracy at iteration 13408  is               72.775%\n",
            "The validation accuracy at iteration 13424  is               72.82499999999999%\n",
            "The validation accuracy at iteration 13440  is               72.8%\n",
            "The validation accuracy at iteration 13456  is               72.82499999999999%\n",
            "The validation accuracy at iteration 13472  is               72.82499999999999%\n",
            "The validation accuracy at iteration 13488  is               72.775%\n",
            "The validation accuracy at iteration 13504  is               72.775%\n",
            "The validation accuracy at iteration 13520  is               72.75%\n",
            "The validation accuracy at iteration 13536  is               72.82499999999999%\n",
            "The validation accuracy at iteration 13552  is               72.82499999999999%\n",
            "The validation accuracy at iteration 13568  is               72.8%\n",
            "The validation accuracy at iteration 13584  is               72.775%\n",
            "The validation accuracy at iteration 13600  is               72.875%\n",
            "The validation accuracy at iteration 13616  is               72.925%\n",
            "The validation accuracy at iteration 13632  is               72.82499999999999%\n",
            "The validation accuracy at iteration 13648  is               72.8%\n",
            "The validation accuracy at iteration 13664  is               72.675%\n",
            "The validation accuracy at iteration 13680  is               72.725%\n",
            "The validation accuracy at iteration 13696  is               72.725%\n",
            "The validation accuracy at iteration 13712  is               72.775%\n",
            "The validation accuracy at iteration 13728  is               72.8%\n",
            "The validation accuracy at iteration 13744  is               72.8%\n",
            "The validation accuracy at iteration 13760  is               72.8%\n",
            "The validation accuracy at iteration 13776  is               72.8%\n",
            "The validation accuracy at iteration 13792  is               72.775%\n",
            "The validation accuracy at iteration 13808  is               72.775%\n",
            "The validation accuracy at iteration 13824  is               72.775%\n",
            "The validation accuracy at iteration 13840  is               72.75%\n",
            "The validation accuracy at iteration 13856  is               72.775%\n",
            "The validation accuracy at iteration 13872  is               72.775%\n",
            "The validation accuracy at iteration 13888  is               72.8%\n",
            "The validation accuracy at iteration 13904  is               72.82499999999999%\n",
            "The validation accuracy at iteration 13920  is               72.85000000000001%\n",
            "The validation accuracy at iteration 13936  is               72.875%\n",
            "The validation accuracy at iteration 13952  is               72.89999999999999%\n",
            "The validation accuracy at iteration 13968  is               72.89999999999999%\n",
            "The validation accuracy at iteration 13984  is               72.875%\n",
            "The validation accuracy at iteration 14000  is               72.85000000000001%\n",
            "The validation accuracy at iteration 14016  is               72.89999999999999%\n",
            "The validation accuracy at iteration 14032  is               72.925%\n",
            "The validation accuracy at iteration 14048  is               72.925%\n",
            "The validation accuracy at iteration 14064  is               72.95%\n",
            "The validation accuracy at iteration 14080  is               72.95%\n",
            "The validation accuracy at iteration 14096  is               72.925%\n",
            "The validation accuracy at iteration 14112  is               73.0%\n",
            "The validation accuracy at iteration 14128  is               72.95%\n",
            "The validation accuracy at iteration 14144  is               72.95%\n",
            "The validation accuracy at iteration 14160  is               72.975%\n",
            "The validation accuracy at iteration 14176  is               72.95%\n",
            "The validation accuracy at iteration 14192  is               72.975%\n",
            "The validation accuracy at iteration 14208  is               72.975%\n",
            "The validation accuracy at iteration 14224  is               73.0%\n",
            "The validation accuracy at iteration 14240  is               73.02499999999999%\n",
            "The validation accuracy at iteration 14256  is               73.02499999999999%\n",
            "The validation accuracy at iteration 14272  is               73.0%\n",
            "The validation accuracy at iteration 14288  is               73.02499999999999%\n",
            "The validation accuracy at iteration 14304  is               72.975%\n",
            "The validation accuracy at iteration 14320  is               72.975%\n",
            "The validation accuracy at iteration 14336  is               73.075%\n",
            "The validation accuracy at iteration 14352  is               73.02499999999999%\n",
            "The validation accuracy at iteration 14368  is               73.075%\n",
            "The validation accuracy at iteration 14384  is               73.075%\n",
            "The validation accuracy at iteration 14400  is               73.075%\n",
            "The validation accuracy at iteration 14416  is               73.075%\n",
            "The validation accuracy at iteration 14432  is               73.075%\n",
            "The validation accuracy at iteration 14448  is               73.075%\n",
            "The validation accuracy at iteration 14464  is               73.05%\n",
            "The validation accuracy at iteration 14480  is               73.05%\n",
            "The validation accuracy at iteration 14496  is               73.05%\n",
            "The validation accuracy at iteration 14512  is               73.05%\n",
            "The validation accuracy at iteration 14528  is               73.05%\n",
            "The validation accuracy at iteration 14544  is               73.05%\n",
            "The validation accuracy at iteration 14560  is               73.05%\n",
            "The validation accuracy at iteration 14576  is               73.075%\n",
            "The validation accuracy at iteration 14592  is               73.075%\n",
            "The validation accuracy at iteration 14608  is               73.05%\n",
            "The validation accuracy at iteration 14624  is               73.0%\n",
            "The validation accuracy at iteration 14640  is               73.0%\n",
            "The validation accuracy at iteration 14656  is               73.1%\n",
            "The validation accuracy at iteration 14672  is               73.05%\n",
            "The validation accuracy at iteration 14688  is               73.1%\n",
            "The validation accuracy at iteration 14704  is               73.125%\n",
            "The validation accuracy at iteration 14720  is               73.125%\n",
            "The validation accuracy at iteration 14736  is               73.125%\n",
            "The validation accuracy at iteration 14752  is               73.125%\n",
            "The validation accuracy at iteration 14768  is               73.125%\n",
            "The validation accuracy at iteration 14784  is               73.125%\n",
            "The validation accuracy at iteration 14800  is               73.125%\n",
            "The validation accuracy at iteration 14816  is               73.075%\n",
            "The validation accuracy at iteration 14832  is               73.05%\n",
            "The validation accuracy at iteration 14848  is               73.02499999999999%\n",
            "The validation accuracy at iteration 14864  is               73.05%\n",
            "The validation accuracy at iteration 14880  is               73.05%\n",
            "The validation accuracy at iteration 14896  is               73.075%\n",
            "The validation accuracy at iteration 14912  is               73.075%\n",
            "The validation accuracy at iteration 14928  is               73.075%\n",
            "The validation accuracy at iteration 14944  is               73.05%\n",
            "The validation accuracy at iteration 14960  is               73.05%\n",
            "The validation accuracy at iteration 14976  is               73.125%\n",
            "The validation accuracy at iteration 14992  is               73.1%\n",
            "The validation accuracy at iteration 15008  is               73.125%\n",
            "The validation accuracy at iteration 15024  is               73.1%\n",
            "The validation accuracy at iteration 15040  is               73.1%\n",
            "The validation accuracy at iteration 15056  is               73.1%\n",
            "The validation accuracy at iteration 15072  is               73.1%\n",
            "The validation accuracy at iteration 15088  is               73.125%\n",
            "The validation accuracy at iteration 15104  is               73.125%\n",
            "The validation accuracy at iteration 15120  is               73.125%\n",
            "The validation accuracy at iteration 15136  is               73.125%\n",
            "The validation accuracy at iteration 15152  is               73.175%\n",
            "The validation accuracy at iteration 15168  is               73.175%\n",
            "The validation accuracy at iteration 15184  is               73.225%\n",
            "The validation accuracy at iteration 15200  is               73.225%\n",
            "The validation accuracy at iteration 15216  is               73.225%\n",
            "The validation accuracy at iteration 15232  is               73.2%\n",
            "The validation accuracy at iteration 15248  is               73.25%\n",
            "The validation accuracy at iteration 15264  is               73.2%\n",
            "The validation accuracy at iteration 15280  is               73.2%\n",
            "The validation accuracy at iteration 15296  is               73.225%\n",
            "The validation accuracy at iteration 15312  is               73.225%\n",
            "The validation accuracy at iteration 15328  is               73.25%\n",
            "The validation accuracy at iteration 15344  is               73.25%\n",
            "The validation accuracy at iteration 15360  is               73.25%\n",
            "The validation accuracy at iteration 15376  is               73.25%\n",
            "The validation accuracy at iteration 15392  is               73.25%\n",
            "The validation accuracy at iteration 15408  is               73.275%\n",
            "The validation accuracy at iteration 15424  is               73.225%\n",
            "The validation accuracy at iteration 15440  is               73.25%\n",
            "The validation accuracy at iteration 15456  is               73.25%\n",
            "The validation accuracy at iteration 15472  is               73.275%\n",
            "The validation accuracy at iteration 15488  is               73.275%\n",
            "The validation accuracy at iteration 15504  is               73.275%\n",
            "The validation accuracy at iteration 15520  is               73.275%\n",
            "The validation accuracy at iteration 15536  is               73.3%\n",
            "The validation accuracy at iteration 15552  is               73.3%\n",
            "The validation accuracy at iteration 15568  is               73.35000000000001%\n",
            "The validation accuracy at iteration 15584  is               73.32499999999999%\n",
            "The validation accuracy at iteration 15600  is               73.3%\n",
            "The validation accuracy at iteration 15616  is               73.375%\n",
            "The validation accuracy at iteration 15632  is               73.3%\n",
            "The validation accuracy at iteration 15648  is               73.35000000000001%\n",
            "The validation accuracy at iteration 15664  is               73.375%\n",
            "The validation accuracy at iteration 15680  is               73.375%\n",
            "The validation accuracy at iteration 15696  is               73.375%\n",
            "The validation accuracy at iteration 15712  is               73.375%\n",
            "The validation accuracy at iteration 15728  is               73.375%\n",
            "The validation accuracy at iteration 15744  is               73.4%\n",
            "The validation accuracy at iteration 15760  is               73.375%\n",
            "The validation accuracy at iteration 15776  is               73.375%\n",
            "The validation accuracy at iteration 15792  is               73.375%\n",
            "The validation accuracy at iteration 15808  is               73.4%\n",
            "The validation accuracy at iteration 15824  is               73.425%\n",
            "The validation accuracy at iteration 15840  is               73.425%\n",
            "The validation accuracy at iteration 15856  is               73.425%\n",
            "The validation accuracy at iteration 15872  is               73.425%\n",
            "The validation accuracy at iteration 15888  is               73.425%\n",
            "The validation accuracy at iteration 15904  is               73.375%\n",
            "The validation accuracy at iteration 15920  is               73.375%\n",
            "The validation accuracy at iteration 15936  is               73.4%\n",
            "The validation accuracy at iteration 15952  is               73.4%\n",
            "The validation accuracy at iteration 15968  is               73.425%\n",
            "The validation accuracy at iteration 15984  is               73.45%\n",
            "The validation accuracy at iteration 16000  is               73.425%\n",
            "The validation accuracy at iteration 16000  is               73.425%\n",
            "The validation accuracy at iteration 16000  is               73.425%\n",
            "The validation accuracy at iteration 1800  is               82.6%\n",
            "The validation accuracy at iteration 16000  is               73.425%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "The validation accuracy at iteration 16000  is               73.425%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 16000  is               73.425%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "The validation accuracy at iteration 16000  is               73.425%\n",
            "The validation accuracy at iteration 2300  is               77.5%\n",
            "The validation accuracy at iteration 16000  is               73.425%\n",
            "[<__main__.Solver object at 0x7f2ca1c8c210>, <__main__.Solver object at 0x7f2cad78fb50>, <__main__.Solver object at 0x7f2ca1fac6d0>, <__main__.Solver object at 0x7f2ca258c910>, <__main__.Solver object at 0x7f2ca258c3d0>]\n",
            "The validation accuracy at iteration 16  is               11.55%\n",
            "The validation accuracy at iteration 32  is               12.9%\n",
            "The validation accuracy at iteration 48  is               14.174999999999999%\n",
            "The validation accuracy at iteration 64  is               16.025%\n",
            "The validation accuracy at iteration 80  is               18.2%\n",
            "The validation accuracy at iteration 96  is               20.225%\n",
            "The validation accuracy at iteration 112  is               22.400000000000002%\n",
            "The validation accuracy at iteration 128  is               25.2%\n",
            "The validation accuracy at iteration 144  is               27.3%\n",
            "The validation accuracy at iteration 160  is               29.75%\n",
            "The validation accuracy at iteration 176  is               32.275%\n",
            "The validation accuracy at iteration 192  is               34.5%\n",
            "The validation accuracy at iteration 208  is               36.625%\n",
            "The validation accuracy at iteration 224  is               38.95%\n",
            "The validation accuracy at iteration 240  is               41.225%\n",
            "The validation accuracy at iteration 256  is               43.2%\n",
            "The validation accuracy at iteration 272  is               45.175%\n",
            "The validation accuracy at iteration 288  is               46.975%\n",
            "The validation accuracy at iteration 304  is               48.6%\n",
            "The validation accuracy at iteration 320  is               50.525%\n",
            "The validation accuracy at iteration 336  is               51.275000000000006%\n",
            "The validation accuracy at iteration 352  is               52.525%\n",
            "The validation accuracy at iteration 368  is               53.825%\n",
            "The validation accuracy at iteration 384  is               54.55%\n",
            "The validation accuracy at iteration 400  is               55.25%\n",
            "The validation accuracy at iteration 416  is               56.325%\n",
            "The validation accuracy at iteration 432  is               56.875%\n",
            "The validation accuracy at iteration 448  is               57.475%\n",
            "The validation accuracy at iteration 464  is               57.925000000000004%\n",
            "The validation accuracy at iteration 480  is               58.825%\n",
            "The validation accuracy at iteration 496  is               59.52499999999999%\n",
            "The validation accuracy at iteration 512  is               60.12499999999999%\n",
            "The validation accuracy at iteration 528  is               60.475%\n",
            "The validation accuracy at iteration 544  is               61.0%\n",
            "The validation accuracy at iteration 560  is               61.25000000000001%\n",
            "The validation accuracy at iteration 576  is               61.724999999999994%\n",
            "The validation accuracy at iteration 592  is               62.050000000000004%\n",
            "The validation accuracy at iteration 608  is               62.35000000000001%\n",
            "The validation accuracy at iteration 624  is               62.64999999999999%\n",
            "The validation accuracy at iteration 640  is               62.925%\n",
            "The validation accuracy at iteration 656  is               63.275000000000006%\n",
            "The validation accuracy at iteration 672  is               63.625%\n",
            "The validation accuracy at iteration 688  is               63.975%\n",
            "The validation accuracy at iteration 704  is               64.4%\n",
            "The validation accuracy at iteration 720  is               64.64999999999999%\n",
            "The validation accuracy at iteration 736  is               65.2%\n",
            "The validation accuracy at iteration 752  is               65.225%\n",
            "The validation accuracy at iteration 768  is               65.375%\n",
            "The validation accuracy at iteration 784  is               65.625%\n",
            "The validation accuracy at iteration 800  is               65.9%\n",
            "The validation accuracy at iteration 816  is               66.125%\n",
            "The validation accuracy at iteration 832  is               66.425%\n",
            "The validation accuracy at iteration 848  is               66.475%\n",
            "The validation accuracy at iteration 864  is               66.725%\n",
            "The validation accuracy at iteration 880  is               66.725%\n",
            "The validation accuracy at iteration 896  is               67.125%\n",
            "The validation accuracy at iteration 912  is               67.35%\n",
            "The validation accuracy at iteration 928  is               67.525%\n",
            "The validation accuracy at iteration 944  is               67.575%\n",
            "The validation accuracy at iteration 960  is               67.72500000000001%\n",
            "The validation accuracy at iteration 976  is               67.9%\n",
            "The validation accuracy at iteration 992  is               68.05%\n",
            "The validation accuracy at iteration 1008  is               68.25%\n",
            "The validation accuracy at iteration 1024  is               68.35%\n",
            "The validation accuracy at iteration 1040  is               68.4%\n",
            "The validation accuracy at iteration 1056  is               68.5%\n",
            "The validation accuracy at iteration 1072  is               68.625%\n",
            "The validation accuracy at iteration 1088  is               68.7%\n",
            "The validation accuracy at iteration 1104  is               68.975%\n",
            "The validation accuracy at iteration 1120  is               69.05%\n",
            "The validation accuracy at iteration 1136  is               69.19999999999999%\n",
            "The validation accuracy at iteration 1152  is               69.375%\n",
            "The validation accuracy at iteration 1168  is               69.39999999999999%\n",
            "The validation accuracy at iteration 1184  is               69.475%\n",
            "The validation accuracy at iteration 1200  is               69.525%\n",
            "The validation accuracy at iteration 1216  is               69.625%\n",
            "The validation accuracy at iteration 1232  is               69.625%\n",
            "The validation accuracy at iteration 1248  is               69.8%\n",
            "The validation accuracy at iteration 1264  is               69.925%\n",
            "The validation accuracy at iteration 1280  is               69.8%\n",
            "The validation accuracy at iteration 1296  is               69.95%\n",
            "The validation accuracy at iteration 1312  is               69.85%\n",
            "The validation accuracy at iteration 1328  is               69.85%\n",
            "The validation accuracy at iteration 1344  is               69.95%\n",
            "The validation accuracy at iteration 1360  is               69.89999999999999%\n",
            "The validation accuracy at iteration 1376  is               70.025%\n",
            "The validation accuracy at iteration 1392  is               69.95%\n",
            "The validation accuracy at iteration 1408  is               70.0%\n",
            "The validation accuracy at iteration 1424  is               70.025%\n",
            "The validation accuracy at iteration 1440  is               70.125%\n",
            "The validation accuracy at iteration 1456  is               70.175%\n",
            "The validation accuracy at iteration 1472  is               70.25%\n",
            "The validation accuracy at iteration 1488  is               70.19999999999999%\n",
            "The validation accuracy at iteration 1504  is               70.35%\n",
            "The validation accuracy at iteration 1520  is               70.375%\n",
            "The validation accuracy at iteration 1536  is               70.39999999999999%\n",
            "The validation accuracy at iteration 1552  is               70.375%\n",
            "The validation accuracy at iteration 1568  is               70.5%\n",
            "The validation accuracy at iteration 1584  is               70.575%\n",
            "The validation accuracy at iteration 1600  is               70.575%\n",
            "The validation accuracy at iteration 1616  is               70.65%\n",
            "The validation accuracy at iteration 1632  is               70.6%\n",
            "The validation accuracy at iteration 1648  is               70.6%\n",
            "The validation accuracy at iteration 1664  is               70.625%\n",
            "The validation accuracy at iteration 1680  is               70.72500000000001%\n",
            "The validation accuracy at iteration 1696  is               70.825%\n",
            "The validation accuracy at iteration 1712  is               70.8%\n",
            "The validation accuracy at iteration 1728  is               70.8%\n",
            "The validation accuracy at iteration 1744  is               70.8%\n",
            "The validation accuracy at iteration 1760  is               70.8%\n",
            "The validation accuracy at iteration 1776  is               70.85000000000001%\n",
            "The validation accuracy at iteration 1792  is               71.025%\n",
            "The validation accuracy at iteration 1808  is               70.975%\n",
            "The validation accuracy at iteration 1824  is               70.92500000000001%\n",
            "The validation accuracy at iteration 1840  is               70.92500000000001%\n",
            "The validation accuracy at iteration 1856  is               70.92500000000001%\n",
            "The validation accuracy at iteration 1872  is               70.975%\n",
            "The validation accuracy at iteration 1888  is               71.075%\n",
            "The validation accuracy at iteration 1904  is               71.1%\n",
            "The validation accuracy at iteration 1920  is               71.1%\n",
            "The validation accuracy at iteration 1936  is               71.1%\n",
            "The validation accuracy at iteration 1952  is               71.075%\n",
            "The validation accuracy at iteration 1968  is               71.15%\n",
            "The validation accuracy at iteration 1984  is               71.15%\n",
            "The validation accuracy at iteration 2000  is               71.375%\n",
            "The validation accuracy at iteration 2016  is               71.375%\n",
            "The validation accuracy at iteration 2032  is               71.3%\n",
            "The validation accuracy at iteration 2048  is               71.35000000000001%\n",
            "The validation accuracy at iteration 2064  is               71.275%\n",
            "The validation accuracy at iteration 2080  is               71.35000000000001%\n",
            "The validation accuracy at iteration 2096  is               71.42500000000001%\n",
            "The validation accuracy at iteration 2112  is               71.575%\n",
            "The validation accuracy at iteration 2128  is               71.55%\n",
            "The validation accuracy at iteration 2144  is               71.55%\n",
            "The validation accuracy at iteration 2160  is               71.625%\n",
            "The validation accuracy at iteration 2176  is               71.625%\n",
            "The validation accuracy at iteration 2192  is               71.55%\n",
            "The validation accuracy at iteration 2208  is               71.825%\n",
            "The validation accuracy at iteration 2224  is               71.8%\n",
            "The validation accuracy at iteration 2240  is               71.8%\n",
            "The validation accuracy at iteration 2256  is               71.775%\n",
            "The validation accuracy at iteration 2272  is               71.875%\n",
            "The validation accuracy at iteration 2288  is               71.925%\n",
            "The validation accuracy at iteration 2304  is               71.975%\n",
            "The validation accuracy at iteration 2320  is               71.95%\n",
            "The validation accuracy at iteration 2336  is               72.05%\n",
            "The validation accuracy at iteration 2352  is               71.95%\n",
            "The validation accuracy at iteration 2368  is               71.95%\n",
            "The validation accuracy at iteration 2384  is               71.975%\n",
            "The validation accuracy at iteration 2400  is               72.0%\n",
            "The validation accuracy at iteration 2416  is               72.0%\n",
            "The validation accuracy at iteration 2432  is               72.02499999999999%\n",
            "The validation accuracy at iteration 2448  is               72.05%\n",
            "The validation accuracy at iteration 2464  is               72.02499999999999%\n",
            "The validation accuracy at iteration 2480  is               72.0%\n",
            "The validation accuracy at iteration 2496  is               72.0%\n",
            "The validation accuracy at iteration 2512  is               72.0%\n",
            "The validation accuracy at iteration 2528  is               72.05%\n",
            "The validation accuracy at iteration 2544  is               72.05%\n",
            "The validation accuracy at iteration 2560  is               72.0%\n",
            "The validation accuracy at iteration 2576  is               72.02499999999999%\n",
            "The validation accuracy at iteration 2592  is               72.0%\n",
            "The validation accuracy at iteration 2608  is               71.975%\n",
            "The validation accuracy at iteration 2624  is               72.075%\n",
            "The validation accuracy at iteration 2640  is               72.05%\n",
            "The validation accuracy at iteration 2656  is               72.05%\n",
            "The validation accuracy at iteration 2672  is               72.05%\n",
            "The validation accuracy at iteration 2688  is               72.075%\n",
            "The validation accuracy at iteration 2704  is               72.0%\n",
            "The validation accuracy at iteration 2720  is               71.975%\n",
            "The validation accuracy at iteration 2736  is               72.02499999999999%\n",
            "The validation accuracy at iteration 2752  is               72.0%\n",
            "The validation accuracy at iteration 2768  is               72.075%\n",
            "The validation accuracy at iteration 2784  is               72.02499999999999%\n",
            "The validation accuracy at iteration 2800  is               72.02499999999999%\n",
            "The validation accuracy at iteration 2816  is               72.05%\n",
            "The validation accuracy at iteration 2832  is               72.02499999999999%\n",
            "The validation accuracy at iteration 2848  is               72.05%\n",
            "The validation accuracy at iteration 2864  is               72.05%\n",
            "The validation accuracy at iteration 2880  is               72.05%\n",
            "The validation accuracy at iteration 2896  is               72.02499999999999%\n",
            "The validation accuracy at iteration 2912  is               71.95%\n",
            "The validation accuracy at iteration 2928  is               71.875%\n",
            "The validation accuracy at iteration 2944  is               71.875%\n",
            "The validation accuracy at iteration 2960  is               71.89999999999999%\n",
            "The validation accuracy at iteration 2976  is               72.0%\n",
            "The validation accuracy at iteration 2992  is               71.875%\n",
            "The validation accuracy at iteration 3008  is               71.89999999999999%\n",
            "The validation accuracy at iteration 3024  is               71.875%\n",
            "The validation accuracy at iteration 3040  is               71.89999999999999%\n",
            "The validation accuracy at iteration 3056  is               71.975%\n",
            "The validation accuracy at iteration 3072  is               71.875%\n",
            "The validation accuracy at iteration 3088  is               71.875%\n",
            "The validation accuracy at iteration 3104  is               71.89999999999999%\n",
            "The validation accuracy at iteration 3120  is               71.85000000000001%\n",
            "The validation accuracy at iteration 3136  is               71.825%\n",
            "The validation accuracy at iteration 3152  is               71.85000000000001%\n",
            "The validation accuracy at iteration 3168  is               71.89999999999999%\n",
            "The validation accuracy at iteration 3184  is               71.875%\n",
            "The validation accuracy at iteration 3200  is               71.875%\n",
            "The validation accuracy at iteration 3216  is               71.875%\n",
            "The validation accuracy at iteration 3232  is               71.875%\n",
            "The validation accuracy at iteration 3248  is               71.875%\n",
            "The validation accuracy at iteration 3264  is               71.75%\n",
            "The validation accuracy at iteration 3280  is               71.75%\n",
            "The validation accuracy at iteration 3296  is               71.72500000000001%\n",
            "The validation accuracy at iteration 3312  is               71.65%\n",
            "The validation accuracy at iteration 3328  is               71.7%\n",
            "The validation accuracy at iteration 3344  is               71.7%\n",
            "The validation accuracy at iteration 3360  is               71.65%\n",
            "The validation accuracy at iteration 3376  is               71.775%\n",
            "The validation accuracy at iteration 3392  is               71.8%\n",
            "The validation accuracy at iteration 3408  is               71.8%\n",
            "The validation accuracy at iteration 3424  is               71.775%\n",
            "The validation accuracy at iteration 3440  is               71.775%\n",
            "The validation accuracy at iteration 3456  is               71.775%\n",
            "The validation accuracy at iteration 3472  is               71.775%\n",
            "The validation accuracy at iteration 3488  is               71.825%\n",
            "The validation accuracy at iteration 3504  is               71.875%\n",
            "The validation accuracy at iteration 3520  is               71.825%\n",
            "The validation accuracy at iteration 3536  is               71.875%\n",
            "The validation accuracy at iteration 3552  is               71.85000000000001%\n",
            "The validation accuracy at iteration 3568  is               71.8%\n",
            "The validation accuracy at iteration 3584  is               71.8%\n",
            "The validation accuracy at iteration 3600  is               71.8%\n",
            "The validation accuracy at iteration 3616  is               71.825%\n",
            "The validation accuracy at iteration 3632  is               71.775%\n",
            "The validation accuracy at iteration 3648  is               71.85000000000001%\n",
            "The validation accuracy at iteration 3664  is               71.825%\n",
            "The validation accuracy at iteration 3680  is               71.775%\n",
            "The validation accuracy at iteration 3696  is               71.75%\n",
            "The validation accuracy at iteration 3712  is               71.775%\n",
            "The validation accuracy at iteration 3728  is               71.85000000000001%\n",
            "The validation accuracy at iteration 3744  is               71.8%\n",
            "The validation accuracy at iteration 3760  is               71.85000000000001%\n",
            "The validation accuracy at iteration 3776  is               71.825%\n",
            "The validation accuracy at iteration 3792  is               71.85000000000001%\n",
            "The validation accuracy at iteration 3808  is               71.925%\n",
            "The validation accuracy at iteration 3824  is               71.89999999999999%\n",
            "The validation accuracy at iteration 3840  is               71.89999999999999%\n",
            "The validation accuracy at iteration 3856  is               71.85000000000001%\n",
            "The validation accuracy at iteration 3872  is               71.85000000000001%\n",
            "The validation accuracy at iteration 3888  is               71.875%\n",
            "The validation accuracy at iteration 3904  is               71.89999999999999%\n",
            "The validation accuracy at iteration 3920  is               71.89999999999999%\n",
            "The validation accuracy at iteration 3936  is               71.925%\n",
            "The validation accuracy at iteration 3952  is               71.95%\n",
            "The validation accuracy at iteration 3968  is               72.0%\n",
            "The validation accuracy at iteration 3984  is               72.0%\n",
            "The validation accuracy at iteration 4000  is               71.95%\n",
            "The validation accuracy at iteration 4016  is               71.89999999999999%\n",
            "The validation accuracy at iteration 4032  is               71.95%\n",
            "The validation accuracy at iteration 4048  is               72.05%\n",
            "The validation accuracy at iteration 4064  is               72.05%\n",
            "The validation accuracy at iteration 4080  is               72.075%\n",
            "The validation accuracy at iteration 4096  is               72.05%\n",
            "The validation accuracy at iteration 4112  is               72.075%\n",
            "The validation accuracy at iteration 4128  is               72.175%\n",
            "The validation accuracy at iteration 4144  is               72.2%\n",
            "The validation accuracy at iteration 4160  is               72.275%\n",
            "The validation accuracy at iteration 4176  is               72.175%\n",
            "The validation accuracy at iteration 4192  is               72.25%\n",
            "The validation accuracy at iteration 4208  is               72.25%\n",
            "The validation accuracy at iteration 4224  is               72.3%\n",
            "The validation accuracy at iteration 4240  is               72.3%\n",
            "The validation accuracy at iteration 4256  is               72.35000000000001%\n",
            "The validation accuracy at iteration 4272  is               72.375%\n",
            "The validation accuracy at iteration 4288  is               72.35000000000001%\n",
            "The validation accuracy at iteration 4304  is               72.35000000000001%\n",
            "The validation accuracy at iteration 4320  is               72.375%\n",
            "The validation accuracy at iteration 4336  is               72.35000000000001%\n",
            "The validation accuracy at iteration 4352  is               72.32499999999999%\n",
            "The validation accuracy at iteration 4368  is               72.375%\n",
            "The validation accuracy at iteration 4384  is               72.375%\n",
            "The validation accuracy at iteration 4400  is               72.39999999999999%\n",
            "The validation accuracy at iteration 4416  is               72.39999999999999%\n",
            "The validation accuracy at iteration 4432  is               72.375%\n",
            "The validation accuracy at iteration 4448  is               72.375%\n",
            "The validation accuracy at iteration 4464  is               72.45%\n",
            "The validation accuracy at iteration 4480  is               72.475%\n",
            "The validation accuracy at iteration 4496  is               72.475%\n",
            "The validation accuracy at iteration 4512  is               72.45%\n",
            "The validation accuracy at iteration 4528  is               72.475%\n",
            "The validation accuracy at iteration 4544  is               72.475%\n",
            "The validation accuracy at iteration 4560  is               72.52499999999999%\n",
            "The validation accuracy at iteration 4576  is               72.55%\n",
            "The validation accuracy at iteration 4592  is               72.6%\n",
            "The validation accuracy at iteration 4608  is               72.575%\n",
            "The validation accuracy at iteration 4624  is               72.575%\n",
            "The validation accuracy at iteration 4640  is               72.575%\n",
            "The validation accuracy at iteration 4656  is               72.625%\n",
            "The validation accuracy at iteration 4672  is               72.7%\n",
            "The validation accuracy at iteration 4688  is               72.775%\n",
            "The validation accuracy at iteration 4704  is               72.7%\n",
            "The validation accuracy at iteration 4720  is               72.725%\n",
            "The validation accuracy at iteration 4736  is               72.8%\n",
            "The validation accuracy at iteration 4752  is               72.8%\n",
            "The validation accuracy at iteration 4768  is               72.82499999999999%\n",
            "The validation accuracy at iteration 4784  is               72.82499999999999%\n",
            "The validation accuracy at iteration 4800  is               72.85000000000001%\n",
            "The validation accuracy at iteration 4816  is               72.85000000000001%\n",
            "The validation accuracy at iteration 4832  is               72.89999999999999%\n",
            "The validation accuracy at iteration 4848  is               72.925%\n",
            "The validation accuracy at iteration 4864  is               73.0%\n",
            "The validation accuracy at iteration 4880  is               73.0%\n",
            "The validation accuracy at iteration 4896  is               72.975%\n",
            "The validation accuracy at iteration 4912  is               73.05%\n",
            "The validation accuracy at iteration 4928  is               73.1%\n",
            "The validation accuracy at iteration 4944  is               73.125%\n",
            "The validation accuracy at iteration 4960  is               73.125%\n",
            "The validation accuracy at iteration 4976  is               73.15%\n",
            "The validation accuracy at iteration 4992  is               73.125%\n",
            "The validation accuracy at iteration 5008  is               73.125%\n",
            "The validation accuracy at iteration 5024  is               73.125%\n",
            "The validation accuracy at iteration 5040  is               73.2%\n",
            "The validation accuracy at iteration 5056  is               73.225%\n",
            "The validation accuracy at iteration 5072  is               73.25%\n",
            "The validation accuracy at iteration 5088  is               73.3%\n",
            "The validation accuracy at iteration 5104  is               73.25%\n",
            "The validation accuracy at iteration 5120  is               73.32499999999999%\n",
            "The validation accuracy at iteration 5136  is               73.35000000000001%\n",
            "The validation accuracy at iteration 5152  is               73.375%\n",
            "The validation accuracy at iteration 5168  is               73.35000000000001%\n",
            "The validation accuracy at iteration 5184  is               73.35000000000001%\n",
            "The validation accuracy at iteration 5200  is               73.4%\n",
            "The validation accuracy at iteration 5216  is               73.4%\n",
            "The validation accuracy at iteration 5232  is               73.475%\n",
            "The validation accuracy at iteration 5248  is               73.425%\n",
            "The validation accuracy at iteration 5264  is               73.475%\n",
            "The validation accuracy at iteration 5280  is               73.45%\n",
            "The validation accuracy at iteration 5296  is               73.45%\n",
            "The validation accuracy at iteration 5312  is               73.475%\n",
            "The validation accuracy at iteration 5328  is               73.55000000000001%\n",
            "The validation accuracy at iteration 5344  is               73.55000000000001%\n",
            "The validation accuracy at iteration 5350  is               73.575%\n",
            "The validation accuracy at iteration 5350  is               73.575%\n",
            "The validation accuracy at iteration 1800  is               82.6%\n",
            "The validation accuracy at iteration 5350  is               73.575%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "The validation accuracy at iteration 5350  is               73.575%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 5350  is               73.575%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "The validation accuracy at iteration 5350  is               73.575%\n",
            "The validation accuracy at iteration 2300  is               77.5%\n",
            "The validation accuracy at iteration 5350  is               73.575%\n",
            "[<__main__.Solver object at 0x7f2ca1c8c210>, <__main__.Solver object at 0x7f2cad78fb50>, <__main__.Solver object at 0x7f2ca1fac6d0>, <__main__.Solver object at 0x7f2ca258c910>, <__main__.Solver object at 0x7f2ca258c3d0>]\n",
            "The validation accuracy at iteration 16  is               13.15%\n",
            "The validation accuracy at iteration 32  is               17.525%\n",
            "The validation accuracy at iteration 48  is               22.45%\n",
            "The validation accuracy at iteration 64  is               27.500000000000004%\n",
            "The validation accuracy at iteration 80  is               32.300000000000004%\n",
            "The validation accuracy at iteration 96  is               36.9%\n",
            "The validation accuracy at iteration 112  is               40.875%\n",
            "The validation accuracy at iteration 128  is               43.9%\n",
            "The validation accuracy at iteration 144  is               47.175%\n",
            "The validation accuracy at iteration 160  is               49.7%\n",
            "The validation accuracy at iteration 176  is               52.75%\n",
            "The validation accuracy at iteration 192  is               55.300000000000004%\n",
            "The validation accuracy at iteration 208  is               56.875%\n",
            "The validation accuracy at iteration 224  is               58.72500000000001%\n",
            "The validation accuracy at iteration 240  is               60.12499999999999%\n",
            "The validation accuracy at iteration 256  is               61.199999999999996%\n",
            "The validation accuracy at iteration 272  is               61.975%\n",
            "The validation accuracy at iteration 288  is               63.025%\n",
            "The validation accuracy at iteration 304  is               64.375%\n",
            "The validation accuracy at iteration 320  is               65.14999999999999%\n",
            "The validation accuracy at iteration 336  is               65.675%\n",
            "The validation accuracy at iteration 352  is               66.325%\n",
            "The validation accuracy at iteration 368  is               67.05%\n",
            "The validation accuracy at iteration 384  is               67.4%\n",
            "The validation accuracy at iteration 400  is               67.625%\n",
            "The validation accuracy at iteration 416  is               67.95%\n",
            "The validation accuracy at iteration 432  is               68.35%\n",
            "The validation accuracy at iteration 448  is               68.525%\n",
            "The validation accuracy at iteration 464  is               68.65%\n",
            "The validation accuracy at iteration 480  is               68.72500000000001%\n",
            "The validation accuracy at iteration 496  is               68.95%\n",
            "The validation accuracy at iteration 512  is               68.95%\n",
            "The validation accuracy at iteration 528  is               69.025%\n",
            "The validation accuracy at iteration 544  is               69.19999999999999%\n",
            "The validation accuracy at iteration 560  is               69.475%\n",
            "The validation accuracy at iteration 576  is               69.525%\n",
            "The validation accuracy at iteration 592  is               69.575%\n",
            "The validation accuracy at iteration 608  is               69.525%\n",
            "The validation accuracy at iteration 624  is               70.025%\n",
            "The validation accuracy at iteration 640  is               70.075%\n",
            "The validation accuracy at iteration 656  is               70.025%\n",
            "The validation accuracy at iteration 672  is               70.075%\n",
            "The validation accuracy at iteration 688  is               70.275%\n",
            "The validation accuracy at iteration 704  is               70.25%\n",
            "The validation accuracy at iteration 720  is               70.25%\n",
            "The validation accuracy at iteration 736  is               70.325%\n",
            "The validation accuracy at iteration 752  is               70.5%\n",
            "The validation accuracy at iteration 768  is               70.55%\n",
            "The validation accuracy at iteration 784  is               70.675%\n",
            "The validation accuracy at iteration 800  is               70.75%\n",
            "The validation accuracy at iteration 816  is               70.95%\n",
            "The validation accuracy at iteration 832  is               71.0%\n",
            "The validation accuracy at iteration 848  is               71.05%\n",
            "The validation accuracy at iteration 864  is               71.15%\n",
            "The validation accuracy at iteration 880  is               71.25%\n",
            "The validation accuracy at iteration 896  is               71.175%\n",
            "The validation accuracy at iteration 912  is               71.2%\n",
            "The validation accuracy at iteration 928  is               71.2%\n",
            "The validation accuracy at iteration 944  is               71.475%\n",
            "The validation accuracy at iteration 960  is               71.325%\n",
            "The validation accuracy at iteration 976  is               71.325%\n",
            "The validation accuracy at iteration 992  is               71.325%\n",
            "The validation accuracy at iteration 1008  is               71.42500000000001%\n",
            "The validation accuracy at iteration 1024  is               71.55%\n",
            "The validation accuracy at iteration 1040  is               71.525%\n",
            "The validation accuracy at iteration 1056  is               71.42500000000001%\n",
            "The validation accuracy at iteration 1072  is               71.5%\n",
            "The validation accuracy at iteration 1088  is               71.39999999999999%\n",
            "The validation accuracy at iteration 1104  is               71.42500000000001%\n",
            "The validation accuracy at iteration 1120  is               71.375%\n",
            "The validation accuracy at iteration 1136  is               71.525%\n",
            "The validation accuracy at iteration 1152  is               71.6%\n",
            "The validation accuracy at iteration 1168  is               71.625%\n",
            "The validation accuracy at iteration 1184  is               71.6%\n",
            "The validation accuracy at iteration 1200  is               71.72500000000001%\n",
            "The validation accuracy at iteration 1216  is               71.8%\n",
            "The validation accuracy at iteration 1232  is               71.775%\n",
            "The validation accuracy at iteration 1248  is               71.8%\n",
            "The validation accuracy at iteration 1264  is               71.775%\n",
            "The validation accuracy at iteration 1280  is               71.875%\n",
            "The validation accuracy at iteration 1296  is               71.825%\n",
            "The validation accuracy at iteration 1312  is               71.8%\n",
            "The validation accuracy at iteration 1328  is               71.89999999999999%\n",
            "The validation accuracy at iteration 1344  is               71.975%\n",
            "The validation accuracy at iteration 1360  is               72.02499999999999%\n",
            "The validation accuracy at iteration 1376  is               72.05%\n",
            "The validation accuracy at iteration 1392  is               72.15%\n",
            "The validation accuracy at iteration 1408  is               72.175%\n",
            "The validation accuracy at iteration 1424  is               72.15%\n",
            "The validation accuracy at iteration 1440  is               72.175%\n",
            "The validation accuracy at iteration 1456  is               72.275%\n",
            "The validation accuracy at iteration 1472  is               72.15%\n",
            "The validation accuracy at iteration 1488  is               72.2%\n",
            "The validation accuracy at iteration 1504  is               72.2%\n",
            "The validation accuracy at iteration 1520  is               72.32499999999999%\n",
            "The validation accuracy at iteration 1536  is               72.25%\n",
            "The validation accuracy at iteration 1552  is               72.3%\n",
            "The validation accuracy at iteration 1568  is               72.39999999999999%\n",
            "The validation accuracy at iteration 1584  is               72.475%\n",
            "The validation accuracy at iteration 1600  is               72.475%\n",
            "The validation accuracy at iteration 1616  is               72.5%\n",
            "The validation accuracy at iteration 1632  is               72.55%\n",
            "The validation accuracy at iteration 1648  is               72.575%\n",
            "The validation accuracy at iteration 1664  is               72.52499999999999%\n",
            "The validation accuracy at iteration 1680  is               72.55%\n",
            "The validation accuracy at iteration 1696  is               72.6%\n",
            "The validation accuracy at iteration 1712  is               72.675%\n",
            "The validation accuracy at iteration 1728  is               72.65%\n",
            "The validation accuracy at iteration 1744  is               72.6%\n",
            "The validation accuracy at iteration 1760  is               72.625%\n",
            "The validation accuracy at iteration 1776  is               72.8%\n",
            "The validation accuracy at iteration 1792  is               72.675%\n",
            "The validation accuracy at iteration 1808  is               72.65%\n",
            "The validation accuracy at iteration 1824  is               72.55%\n",
            "The validation accuracy at iteration 1840  is               72.6%\n",
            "The validation accuracy at iteration 1856  is               72.6%\n",
            "The validation accuracy at iteration 1872  is               72.55%\n",
            "The validation accuracy at iteration 1888  is               72.575%\n",
            "The validation accuracy at iteration 1904  is               72.575%\n",
            "The validation accuracy at iteration 1920  is               72.5%\n",
            "The validation accuracy at iteration 1936  is               72.39999999999999%\n",
            "The validation accuracy at iteration 1952  is               72.32499999999999%\n",
            "The validation accuracy at iteration 1968  is               72.375%\n",
            "The validation accuracy at iteration 1984  is               72.3%\n",
            "The validation accuracy at iteration 2000  is               72.2%\n",
            "The validation accuracy at iteration 2016  is               72.3%\n",
            "The validation accuracy at iteration 2032  is               72.32499999999999%\n",
            "The validation accuracy at iteration 2048  is               72.32499999999999%\n",
            "The validation accuracy at iteration 2064  is               72.25%\n",
            "The validation accuracy at iteration 2080  is               72.25%\n",
            "The validation accuracy at iteration 2096  is               72.32499999999999%\n",
            "The validation accuracy at iteration 2112  is               72.275%\n",
            "The validation accuracy at iteration 2128  is               72.275%\n",
            "The validation accuracy at iteration 2144  is               72.275%\n",
            "The validation accuracy at iteration 2160  is               72.275%\n",
            "The validation accuracy at iteration 2176  is               72.32499999999999%\n",
            "The validation accuracy at iteration 2192  is               72.35000000000001%\n",
            "The validation accuracy at iteration 2208  is               72.3%\n",
            "The validation accuracy at iteration 2224  is               72.2%\n",
            "The validation accuracy at iteration 2240  is               72.225%\n",
            "The validation accuracy at iteration 2256  is               72.3%\n",
            "The validation accuracy at iteration 2272  is               72.32499999999999%\n",
            "The validation accuracy at iteration 2288  is               72.39999999999999%\n",
            "The validation accuracy at iteration 2304  is               72.425%\n",
            "The validation accuracy at iteration 2320  is               72.45%\n",
            "The validation accuracy at iteration 2352  is               72.475%\n",
            "The validation accuracy at iteration 2368  is               72.55%\n",
            "The validation accuracy at iteration 2384  is               72.55%\n",
            "The validation accuracy at iteration 2400  is               72.575%\n",
            "The validation accuracy at iteration 2416  is               72.55%\n",
            "The validation accuracy at iteration 2432  is               72.575%\n",
            "The validation accuracy at iteration 2448  is               72.575%\n",
            "The validation accuracy at iteration 2464  is               72.6%\n",
            "The validation accuracy at iteration 2480  is               72.575%\n",
            "The validation accuracy at iteration 2496  is               72.625%\n",
            "The validation accuracy at iteration 2512  is               72.65%\n",
            "The validation accuracy at iteration 2528  is               72.7%\n",
            "The validation accuracy at iteration 2544  is               72.75%\n",
            "The validation accuracy at iteration 2560  is               72.75%\n",
            "The validation accuracy at iteration 2576  is               72.8%\n",
            "The validation accuracy at iteration 2592  is               72.89999999999999%\n",
            "The validation accuracy at iteration 2608  is               72.925%\n",
            "The validation accuracy at iteration 2624  is               73.05%\n",
            "The validation accuracy at iteration 2640  is               73.0%\n",
            "The validation accuracy at iteration 2656  is               73.05%\n",
            "The validation accuracy at iteration 2672  is               73.0%\n",
            "The validation accuracy at iteration 2688  is               73.02499999999999%\n",
            "The validation accuracy at iteration 2704  is               73.05%\n",
            "The validation accuracy at iteration 2720  is               73.05%\n",
            "The validation accuracy at iteration 2736  is               73.05%\n",
            "The validation accuracy at iteration 2752  is               73.05%\n",
            "The validation accuracy at iteration 2768  is               73.05%\n",
            "The validation accuracy at iteration 2784  is               73.15%\n",
            "The validation accuracy at iteration 2800  is               73.075%\n",
            "The validation accuracy at iteration 2816  is               73.15%\n",
            "The validation accuracy at iteration 2832  is               73.175%\n",
            "The validation accuracy at iteration 2848  is               73.225%\n",
            "The validation accuracy at iteration 2864  is               73.275%\n",
            "The validation accuracy at iteration 2880  is               73.3%\n",
            "The validation accuracy at iteration 2896  is               73.3%\n",
            "The validation accuracy at iteration 2912  is               73.35000000000001%\n",
            "The validation accuracy at iteration 2928  is               73.4%\n",
            "The validation accuracy at iteration 2944  is               73.45%\n",
            "The validation accuracy at iteration 2960  is               73.45%\n",
            "The validation accuracy at iteration 2976  is               73.55000000000001%\n",
            "The validation accuracy at iteration 2992  is               73.675%\n",
            "The validation accuracy at iteration 3008  is               73.65%\n",
            "The validation accuracy at iteration 3024  is               73.65%\n",
            "The validation accuracy at iteration 3040  is               73.625%\n",
            "The validation accuracy at iteration 3056  is               73.725%\n",
            "The validation accuracy at iteration 3072  is               73.675%\n",
            "The validation accuracy at iteration 3088  is               73.7%\n",
            "The validation accuracy at iteration 3104  is               73.75%\n",
            "The validation accuracy at iteration 3120  is               73.775%\n",
            "The validation accuracy at iteration 3136  is               73.8%\n",
            "The validation accuracy at iteration 3152  is               73.85000000000001%\n",
            "The validation accuracy at iteration 3168  is               73.875%\n",
            "The validation accuracy at iteration 3184  is               73.9%\n",
            "The validation accuracy at iteration 3200  is               73.9%\n",
            "The validation accuracy at iteration 3200  is               73.9%\n",
            "The validation accuracy at iteration 3200  is               73.9%\n",
            "The validation accuracy at iteration 1800  is               82.6%\n",
            "The validation accuracy at iteration 3200  is               73.9%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "The validation accuracy at iteration 3200  is               73.9%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 3200  is               73.9%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "The validation accuracy at iteration 3200  is               73.9%\n",
            "The validation accuracy at iteration 2300  is               77.5%\n",
            "The validation accuracy at iteration 3200  is               73.9%\n",
            "[<__main__.Solver object at 0x7f2ca1c8c210>, <__main__.Solver object at 0x7f2cad78fb50>, <__main__.Solver object at 0x7f2ca1fac6d0>, <__main__.Solver object at 0x7f2ca258c910>, <__main__.Solver object at 0x7f2ca258c3d0>]\n",
            "The validation accuracy at iteration 16  is               9.475%\n",
            "The validation accuracy at iteration 32  is               13.525%\n",
            "The validation accuracy at iteration 48  is               18.2%\n",
            "The validation accuracy at iteration 64  is               24.3%\n",
            "The validation accuracy at iteration 80  is               30.349999999999998%\n",
            "The validation accuracy at iteration 96  is               36.425000000000004%\n",
            "The validation accuracy at iteration 112  is               42.925000000000004%\n",
            "The validation accuracy at iteration 128  is               48.025%\n",
            "The validation accuracy at iteration 144  is               52.175000000000004%\n",
            "The validation accuracy at iteration 160  is               56.35%\n",
            "The validation accuracy at iteration 176  is               59.12500000000001%\n",
            "The validation accuracy at iteration 192  is               61.925%\n",
            "The validation accuracy at iteration 208  is               63.87500000000001%\n",
            "The validation accuracy at iteration 224  is               65.525%\n",
            "The validation accuracy at iteration 240  is               66.75%\n",
            "The validation accuracy at iteration 256  is               67.575%\n",
            "The validation accuracy at iteration 272  is               68.35%\n",
            "The validation accuracy at iteration 288  is               69.1%\n",
            "The validation accuracy at iteration 304  is               69.575%\n",
            "The validation accuracy at iteration 320  is               70.05%\n",
            "The validation accuracy at iteration 336  is               70.525%\n",
            "The validation accuracy at iteration 352  is               70.875%\n",
            "The validation accuracy at iteration 368  is               71.22500000000001%\n",
            "The validation accuracy at iteration 384  is               71.35000000000001%\n",
            "The validation accuracy at iteration 400  is               71.65%\n",
            "The validation accuracy at iteration 416  is               71.875%\n",
            "The validation accuracy at iteration 432  is               71.95%\n",
            "The validation accuracy at iteration 448  is               72.39999999999999%\n",
            "The validation accuracy at iteration 464  is               72.275%\n",
            "The validation accuracy at iteration 480  is               72.275%\n",
            "The validation accuracy at iteration 496  is               72.575%\n",
            "The validation accuracy at iteration 512  is               72.625%\n",
            "The validation accuracy at iteration 528  is               72.725%\n",
            "The validation accuracy at iteration 544  is               72.82499999999999%\n",
            "The validation accuracy at iteration 560  is               72.775%\n",
            "The validation accuracy at iteration 576  is               72.75%\n",
            "The validation accuracy at iteration 592  is               72.89999999999999%\n",
            "The validation accuracy at iteration 608  is               72.85000000000001%\n",
            "The validation accuracy at iteration 624  is               72.89999999999999%\n",
            "The validation accuracy at iteration 640  is               72.82499999999999%\n",
            "The validation accuracy at iteration 656  is               72.8%\n",
            "The validation accuracy at iteration 672  is               72.8%\n",
            "The validation accuracy at iteration 688  is               72.82499999999999%\n",
            "The validation accuracy at iteration 704  is               72.82499999999999%\n",
            "The validation accuracy at iteration 720  is               72.95%\n",
            "The validation accuracy at iteration 736  is               72.875%\n",
            "The validation accuracy at iteration 752  is               72.89999999999999%\n",
            "The validation accuracy at iteration 768  is               72.875%\n",
            "The validation accuracy at iteration 784  is               72.925%\n",
            "The validation accuracy at iteration 800  is               72.95%\n",
            "The validation accuracy at iteration 816  is               73.05%\n",
            "The validation accuracy at iteration 832  is               73.1%\n",
            "The validation accuracy at iteration 848  is               73.075%\n",
            "The validation accuracy at iteration 864  is               73.15%\n",
            "The validation accuracy at iteration 880  is               72.975%\n",
            "The validation accuracy at iteration 896  is               72.89999999999999%\n",
            "The validation accuracy at iteration 912  is               72.95%\n",
            "The validation accuracy at iteration 928  is               72.875%\n",
            "The validation accuracy at iteration 944  is               72.775%\n",
            "The validation accuracy at iteration 960  is               72.75%\n",
            "The validation accuracy at iteration 976  is               72.725%\n",
            "The validation accuracy at iteration 992  is               72.8%\n",
            "The validation accuracy at iteration 1008  is               72.925%\n",
            "The validation accuracy at iteration 1024  is               73.0%\n",
            "The validation accuracy at iteration 1040  is               73.075%\n",
            "The validation accuracy at iteration 1056  is               73.075%\n",
            "The validation accuracy at iteration 1072  is               73.125%\n",
            "The validation accuracy at iteration 1088  is               73.25%\n",
            "The validation accuracy at iteration 1104  is               73.2%\n",
            "The validation accuracy at iteration 1120  is               73.1%\n",
            "The validation accuracy at iteration 1136  is               73.15%\n",
            "The validation accuracy at iteration 1152  is               73.1%\n",
            "The validation accuracy at iteration 1168  is               73.2%\n",
            "The validation accuracy at iteration 1184  is               73.225%\n",
            "The validation accuracy at iteration 1200  is               73.225%\n",
            "The validation accuracy at iteration 1216  is               73.15%\n",
            "The validation accuracy at iteration 1232  is               73.1%\n",
            "The validation accuracy at iteration 1248  is               73.075%\n",
            "The validation accuracy at iteration 1264  is               73.2%\n",
            "The validation accuracy at iteration 1280  is               73.225%\n",
            "The validation accuracy at iteration 1296  is               73.125%\n",
            "The validation accuracy at iteration 1312  is               73.125%\n",
            "The validation accuracy at iteration 1328  is               73.075%\n",
            "The validation accuracy at iteration 1344  is               73.05%\n",
            "The validation accuracy at iteration 1360  is               73.02499999999999%\n",
            "The validation accuracy at iteration 1376  is               72.975%\n",
            "The validation accuracy at iteration 1392  is               72.925%\n",
            "The validation accuracy at iteration 1408  is               72.975%\n",
            "The validation accuracy at iteration 1424  is               72.85000000000001%\n",
            "The validation accuracy at iteration 1440  is               72.875%\n",
            "The validation accuracy at iteration 1456  is               72.85000000000001%\n",
            "The validation accuracy at iteration 1472  is               72.82499999999999%\n",
            "The validation accuracy at iteration 1488  is               72.7%\n",
            "The validation accuracy at iteration 1504  is               72.82499999999999%\n",
            "The validation accuracy at iteration 1520  is               72.775%\n",
            "The validation accuracy at iteration 1536  is               72.75%\n",
            "The validation accuracy at iteration 1552  is               72.65%\n",
            "The validation accuracy at iteration 1568  is               72.675%\n",
            "The validation accuracy at iteration 1584  is               72.6%\n",
            "The validation accuracy at iteration 1600  is               72.6%\n",
            "The validation accuracy at iteration 1616  is               72.625%\n",
            "The validation accuracy at iteration 1632  is               72.52499999999999%\n",
            "The validation accuracy at iteration 1648  is               72.575%\n",
            "The validation accuracy at iteration 1664  is               72.55%\n",
            "The validation accuracy at iteration 1680  is               72.5%\n",
            "The validation accuracy at iteration 1696  is               72.5%\n",
            "The validation accuracy at iteration 1712  is               72.5%\n",
            "The validation accuracy at iteration 1728  is               72.575%\n",
            "The validation accuracy at iteration 1744  is               72.675%\n",
            "The validation accuracy at iteration 1760  is               72.675%\n",
            "The validation accuracy at iteration 1776  is               72.675%\n",
            "The validation accuracy at iteration 1792  is               72.675%\n",
            "The validation accuracy at iteration 1808  is               72.725%\n",
            "The validation accuracy at iteration 1824  is               72.7%\n",
            "The validation accuracy at iteration 1840  is               72.7%\n",
            "The validation accuracy at iteration 1856  is               72.775%\n",
            "The validation accuracy at iteration 1872  is               72.8%\n",
            "The validation accuracy at iteration 1888  is               72.875%\n",
            "The validation accuracy at iteration 1904  is               72.875%\n",
            "The validation accuracy at iteration 1920  is               72.975%\n",
            "The validation accuracy at iteration 1936  is               72.95%\n",
            "The validation accuracy at iteration 1952  is               73.05%\n",
            "The validation accuracy at iteration 1968  is               73.125%\n",
            "The validation accuracy at iteration 1984  is               73.125%\n",
            "The validation accuracy at iteration 2000  is               73.15%\n",
            "The validation accuracy at iteration 2016  is               73.15%\n",
            "The validation accuracy at iteration 2032  is               73.15%\n",
            "The validation accuracy at iteration 2048  is               73.225%\n",
            "The validation accuracy at iteration 2064  is               73.2%\n",
            "The validation accuracy at iteration 2080  is               73.175%\n",
            "The validation accuracy at iteration 2096  is               73.32499999999999%\n",
            "The validation accuracy at iteration 2112  is               73.3%\n",
            "The validation accuracy at iteration 2128  is               73.375%\n",
            "The validation accuracy at iteration 2144  is               73.475%\n",
            "The validation accuracy at iteration 2160  is               73.575%\n",
            "The validation accuracy at iteration 2176  is               73.625%\n",
            "The validation accuracy at iteration 2192  is               73.625%\n",
            "The validation accuracy at iteration 2208  is               73.75%\n",
            "The validation accuracy at iteration 2224  is               73.775%\n",
            "The validation accuracy at iteration 2240  is               73.925%\n",
            "The validation accuracy at iteration 2256  is               73.925%\n",
            "The validation accuracy at iteration 2272  is               73.95%\n",
            "The validation accuracy at iteration 2288  is               74.02499999999999%\n",
            "The validation accuracy at iteration 2300  is               74.0%\n",
            "The validation accuracy at iteration 2300  is               74.0%\n",
            "The validation accuracy at iteration 1800  is               82.6%\n",
            "The validation accuracy at iteration 2300  is               74.0%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "The validation accuracy at iteration 2300  is               74.0%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 2300  is               74.0%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "The validation accuracy at iteration 2300  is               74.0%\n",
            "The validation accuracy at iteration 2300  is               77.5%\n",
            "The validation accuracy at iteration 2300  is               74.0%\n",
            "[<__main__.Solver object at 0x7f2ca1c8c210>, <__main__.Solver object at 0x7f2cad78fb50>, <__main__.Solver object at 0x7f2ca1fac6d0>, <__main__.Solver object at 0x7f2ca258c910>, <__main__.Solver object at 0x7f2ca258c3d0>]\n",
            "The validation accuracy at iteration 16  is               13.175%\n",
            "The validation accuracy at iteration 32  is               21.2%\n",
            "The validation accuracy at iteration 48  is               30.3%\n",
            "The validation accuracy at iteration 64  is               37.125%\n",
            "The validation accuracy at iteration 80  is               42.125%\n",
            "The validation accuracy at iteration 96  is               46.575%\n",
            "The validation accuracy at iteration 112  is               50.05%\n",
            "The validation accuracy at iteration 128  is               52.849999999999994%\n",
            "The validation accuracy at iteration 144  is               55.275%\n",
            "The validation accuracy at iteration 160  is               57.125%\n",
            "The validation accuracy at iteration 176  is               58.825%\n",
            "The validation accuracy at iteration 192  is               60.099999999999994%\n",
            "The validation accuracy at iteration 208  is               62.0%\n",
            "The validation accuracy at iteration 224  is               62.675000000000004%\n",
            "The validation accuracy at iteration 240  is               64.25%\n",
            "The validation accuracy at iteration 256  is               65.05%\n",
            "The validation accuracy at iteration 272  is               65.8%\n",
            "The validation accuracy at iteration 288  is               67.025%\n",
            "The validation accuracy at iteration 304  is               67.25%\n",
            "The validation accuracy at iteration 320  is               67.77499999999999%\n",
            "The validation accuracy at iteration 336  is               67.825%\n",
            "The validation accuracy at iteration 352  is               68.27499999999999%\n",
            "The validation accuracy at iteration 368  is               68.45%\n",
            "The validation accuracy at iteration 384  is               68.8%\n",
            "The validation accuracy at iteration 400  is               68.95%\n",
            "The validation accuracy at iteration 416  is               69.1%\n",
            "The validation accuracy at iteration 432  is               69.19999999999999%\n",
            "The validation accuracy at iteration 448  is               69.22500000000001%\n",
            "The validation accuracy at iteration 464  is               69.5%\n",
            "The validation accuracy at iteration 480  is               69.45%\n",
            "The validation accuracy at iteration 496  is               69.825%\n",
            "The validation accuracy at iteration 512  is               69.875%\n",
            "The validation accuracy at iteration 528  is               70.025%\n",
            "The validation accuracy at iteration 544  is               69.95%\n",
            "The validation accuracy at iteration 560  is               69.925%\n",
            "The validation accuracy at iteration 576  is               70.25%\n",
            "The validation accuracy at iteration 592  is               70.3%\n",
            "The validation accuracy at iteration 608  is               70.55%\n",
            "The validation accuracy at iteration 624  is               70.45%\n",
            "The validation accuracy at iteration 640  is               70.75%\n",
            "The validation accuracy at iteration 656  is               70.875%\n",
            "The validation accuracy at iteration 672  is               70.92500000000001%\n",
            "The validation accuracy at iteration 688  is               71.0%\n",
            "The validation accuracy at iteration 704  is               71.025%\n",
            "The validation accuracy at iteration 720  is               71.15%\n",
            "The validation accuracy at iteration 736  is               71.175%\n",
            "The validation accuracy at iteration 752  is               71.39999999999999%\n",
            "The validation accuracy at iteration 768  is               71.175%\n",
            "The validation accuracy at iteration 784  is               71.42500000000001%\n",
            "The validation accuracy at iteration 800  is               71.375%\n",
            "The validation accuracy at iteration 816  is               71.3%\n",
            "The validation accuracy at iteration 832  is               71.35000000000001%\n",
            "The validation accuracy at iteration 848  is               71.375%\n",
            "The validation accuracy at iteration 864  is               71.5%\n",
            "The validation accuracy at iteration 880  is               71.475%\n",
            "The validation accuracy at iteration 896  is               71.6%\n",
            "The validation accuracy at iteration 912  is               71.7%\n",
            "The validation accuracy at iteration 928  is               71.75%\n",
            "The validation accuracy at iteration 944  is               71.8%\n",
            "The validation accuracy at iteration 960  is               71.75%\n",
            "The validation accuracy at iteration 976  is               71.72500000000001%\n",
            "The validation accuracy at iteration 992  is               71.72500000000001%\n",
            "The validation accuracy at iteration 1008  is               71.6%\n",
            "The validation accuracy at iteration 1024  is               71.625%\n",
            "The validation accuracy at iteration 1040  is               71.5%\n",
            "The validation accuracy at iteration 1056  is               71.525%\n",
            "The validation accuracy at iteration 1072  is               71.5%\n",
            "The validation accuracy at iteration 1088  is               71.42500000000001%\n",
            "The validation accuracy at iteration 1104  is               71.55%\n",
            "The validation accuracy at iteration 1120  is               71.42500000000001%\n",
            "The validation accuracy at iteration 1136  is               71.275%\n",
            "The validation accuracy at iteration 1152  is               71.275%\n",
            "The validation accuracy at iteration 1168  is               71.275%\n",
            "The validation accuracy at iteration 1184  is               71.3%\n",
            "The validation accuracy at iteration 1200  is               71.3%\n",
            "The validation accuracy at iteration 1216  is               71.475%\n",
            "The validation accuracy at iteration 1232  is               71.5%\n",
            "The validation accuracy at iteration 1248  is               71.475%\n",
            "The validation accuracy at iteration 1264  is               71.55%\n",
            "The validation accuracy at iteration 1280  is               71.65%\n",
            "The validation accuracy at iteration 1296  is               71.72500000000001%\n",
            "The validation accuracy at iteration 1312  is               71.75%\n",
            "The validation accuracy at iteration 1328  is               71.775%\n",
            "The validation accuracy at iteration 1344  is               71.825%\n",
            "The validation accuracy at iteration 1360  is               71.89999999999999%\n",
            "The validation accuracy at iteration 1376  is               71.975%\n",
            "The validation accuracy at iteration 1392  is               72.1%\n",
            "The validation accuracy at iteration 1408  is               72.125%\n",
            "The validation accuracy at iteration 1424  is               72.15%\n",
            "The validation accuracy at iteration 1440  is               72.275%\n",
            "The validation accuracy at iteration 1456  is               72.32499999999999%\n",
            "The validation accuracy at iteration 1472  is               72.375%\n",
            "The validation accuracy at iteration 1488  is               72.35000000000001%\n",
            "The validation accuracy at iteration 1504  is               72.52499999999999%\n",
            "The validation accuracy at iteration 1520  is               72.575%\n",
            "The validation accuracy at iteration 1536  is               72.7%\n",
            "The validation accuracy at iteration 1552  is               72.7%\n",
            "The validation accuracy at iteration 1568  is               72.82499999999999%\n",
            "The validation accuracy at iteration 1584  is               72.89999999999999%\n",
            "The validation accuracy at iteration 1600  is               72.95%\n",
            "The validation accuracy at iteration 1616  is               72.89999999999999%\n",
            "The validation accuracy at iteration 1632  is               72.95%\n",
            "The validation accuracy at iteration 1648  is               73.0%\n",
            "The validation accuracy at iteration 1664  is               73.05%\n",
            "The validation accuracy at iteration 1680  is               73.15%\n",
            "The validation accuracy at iteration 1696  is               73.175%\n",
            "The validation accuracy at iteration 1712  is               73.175%\n",
            "The validation accuracy at iteration 1728  is               73.35000000000001%\n",
            "The validation accuracy at iteration 1744  is               73.3%\n",
            "The validation accuracy at iteration 1760  is               73.3%\n",
            "The validation accuracy at iteration 1776  is               73.4%\n",
            "The validation accuracy at iteration 1792  is               73.45%\n",
            "The validation accuracy at iteration 1800  is               73.425%\n",
            "The validation accuracy at iteration 1800  is               73.425%\n",
            "The validation accuracy at iteration 1800  is               82.6%\n",
            "The validation accuracy at iteration 1800  is               73.425%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "The validation accuracy at iteration 1800  is               73.425%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 1800  is               73.425%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "The validation accuracy at iteration 1800  is               73.425%\n",
            "The validation accuracy at iteration 2300  is               77.5%\n",
            "The validation accuracy at iteration 1800  is               73.425%\n",
            "[<__main__.Solver object at 0x7f2ca1c8c210>, <__main__.Solver object at 0x7f2cad78fb50>, <__main__.Solver object at 0x7f2ca1fac6d0>, <__main__.Solver object at 0x7f2ca258c910>, <__main__.Solver object at 0x7f2ca258c3d0>]\n",
            "The validation accuracy at iteration 16  is               13.55%\n",
            "The validation accuracy at iteration 32  is               13.55%\n",
            "The validation accuracy at iteration 48  is               13.55%\n",
            "The validation accuracy at iteration 64  is               13.55%\n",
            "The validation accuracy at iteration 80  is               13.55%\n",
            "The validation accuracy at iteration 96  is               13.55%\n",
            "The validation accuracy at iteration 112  is               13.600000000000001%\n",
            "The validation accuracy at iteration 128  is               13.600000000000001%\n",
            "The validation accuracy at iteration 144  is               13.600000000000001%\n",
            "The validation accuracy at iteration 160  is               13.600000000000001%\n",
            "The validation accuracy at iteration 176  is               13.600000000000001%\n",
            "The validation accuracy at iteration 192  is               13.625000000000002%\n",
            "The validation accuracy at iteration 208  is               13.675%\n",
            "The validation accuracy at iteration 224  is               13.675%\n",
            "The validation accuracy at iteration 240  is               13.675%\n",
            "The validation accuracy at iteration 256  is               13.700000000000001%\n",
            "The validation accuracy at iteration 272  is               13.700000000000001%\n",
            "The validation accuracy at iteration 288  is               13.700000000000001%\n",
            "The validation accuracy at iteration 304  is               13.725000000000001%\n",
            "The validation accuracy at iteration 320  is               13.725000000000001%\n",
            "The validation accuracy at iteration 336  is               13.725000000000001%\n",
            "The validation accuracy at iteration 352  is               13.775%\n",
            "The validation accuracy at iteration 368  is               13.8%\n",
            "The validation accuracy at iteration 384  is               13.8%\n",
            "The validation accuracy at iteration 400  is               13.8%\n",
            "The validation accuracy at iteration 416  is               13.8%\n",
            "The validation accuracy at iteration 432  is               13.8%\n",
            "The validation accuracy at iteration 448  is               13.8%\n",
            "The validation accuracy at iteration 464  is               13.8%\n",
            "The validation accuracy at iteration 480  is               13.8%\n",
            "The validation accuracy at iteration 496  is               13.8%\n",
            "The validation accuracy at iteration 512  is               13.825000000000001%\n",
            "The validation accuracy at iteration 528  is               13.825000000000001%\n",
            "The validation accuracy at iteration 544  is               13.825000000000001%\n",
            "The validation accuracy at iteration 560  is               13.825000000000001%\n",
            "The validation accuracy at iteration 576  is               13.825000000000001%\n",
            "The validation accuracy at iteration 592  is               13.825000000000001%\n",
            "The validation accuracy at iteration 608  is               13.825000000000001%\n",
            "The validation accuracy at iteration 624  is               13.850000000000001%\n",
            "The validation accuracy at iteration 640  is               13.875000000000002%\n",
            "The validation accuracy at iteration 656  is               13.875000000000002%\n",
            "The validation accuracy at iteration 672  is               13.925%\n",
            "The validation accuracy at iteration 688  is               13.925%\n",
            "The validation accuracy at iteration 704  is               13.925%\n",
            "The validation accuracy at iteration 720  is               13.925%\n",
            "The validation accuracy at iteration 736  is               13.925%\n",
            "The validation accuracy at iteration 752  is               13.925%\n",
            "The validation accuracy at iteration 768  is               13.925%\n",
            "The validation accuracy at iteration 784  is               13.950000000000001%\n",
            "The validation accuracy at iteration 800  is               13.975000000000001%\n",
            "The validation accuracy at iteration 816  is               13.975000000000001%\n",
            "The validation accuracy at iteration 832  is               13.975000000000001%\n",
            "The validation accuracy at iteration 848  is               13.975000000000001%\n",
            "The validation accuracy at iteration 864  is               13.975000000000001%\n",
            "The validation accuracy at iteration 880  is               13.975000000000001%\n",
            "The validation accuracy at iteration 896  is               13.975000000000001%\n",
            "The validation accuracy at iteration 912  is               14.000000000000002%\n",
            "The validation accuracy at iteration 928  is               14.000000000000002%\n",
            "The validation accuracy at iteration 944  is               14.000000000000002%\n",
            "The validation accuracy at iteration 960  is               14.000000000000002%\n",
            "The validation accuracy at iteration 976  is               14.05%\n",
            "The validation accuracy at iteration 992  is               14.05%\n",
            "The validation accuracy at iteration 1008  is               14.099999999999998%\n",
            "The validation accuracy at iteration 1024  is               14.099999999999998%\n",
            "The validation accuracy at iteration 1040  is               14.099999999999998%\n",
            "The validation accuracy at iteration 1056  is               14.124999999999998%\n",
            "The validation accuracy at iteration 1072  is               14.124999999999998%\n",
            "The validation accuracy at iteration 1088  is               14.124999999999998%\n",
            "The validation accuracy at iteration 1104  is               14.124999999999998%\n",
            "The validation accuracy at iteration 1120  is               14.124999999999998%\n",
            "The validation accuracy at iteration 1136  is               14.124999999999998%\n",
            "The validation accuracy at iteration 1152  is               14.149999999999999%\n",
            "The validation accuracy at iteration 1168  is               14.149999999999999%\n",
            "The validation accuracy at iteration 1184  is               14.149999999999999%\n",
            "The validation accuracy at iteration 1200  is               14.149999999999999%\n",
            "The validation accuracy at iteration 1216  is               14.149999999999999%\n",
            "The validation accuracy at iteration 1232  is               14.149999999999999%\n",
            "The validation accuracy at iteration 1248  is               14.149999999999999%\n",
            "The validation accuracy at iteration 1264  is               14.174999999999999%\n",
            "The validation accuracy at iteration 1280  is               14.2%\n",
            "The validation accuracy at iteration 1296  is               14.2%\n",
            "The validation accuracy at iteration 1312  is               14.2%\n",
            "The validation accuracy at iteration 1328  is               14.224999999999998%\n",
            "The validation accuracy at iteration 1344  is               14.224999999999998%\n",
            "The validation accuracy at iteration 1360  is               14.224999999999998%\n",
            "The validation accuracy at iteration 1376  is               14.249999999999998%\n",
            "The validation accuracy at iteration 1392  is               14.274999999999999%\n",
            "The validation accuracy at iteration 1408  is               14.274999999999999%\n",
            "The validation accuracy at iteration 1424  is               14.274999999999999%\n",
            "The validation accuracy at iteration 1440  is               14.274999999999999%\n",
            "The validation accuracy at iteration 1456  is               14.274999999999999%\n",
            "The validation accuracy at iteration 1472  is               14.299999999999999%\n",
            "The validation accuracy at iteration 1488  is               14.299999999999999%\n",
            "The validation accuracy at iteration 1504  is               14.299999999999999%\n",
            "The validation accuracy at iteration 1520  is               14.299999999999999%\n",
            "The validation accuracy at iteration 1536  is               14.325%\n",
            "The validation accuracy at iteration 1552  is               14.35%\n",
            "The validation accuracy at iteration 1568  is               14.374999999999998%\n",
            "The validation accuracy at iteration 1584  is               14.374999999999998%\n",
            "The validation accuracy at iteration 1600  is               14.374999999999998%\n",
            "The validation accuracy at iteration 1616  is               14.374999999999998%\n",
            "The validation accuracy at iteration 1632  is               14.374999999999998%\n",
            "The validation accuracy at iteration 1648  is               14.374999999999998%\n",
            "The validation accuracy at iteration 1664  is               14.374999999999998%\n",
            "The validation accuracy at iteration 1680  is               14.374999999999998%\n",
            "The validation accuracy at iteration 1696  is               14.399999999999999%\n",
            "The validation accuracy at iteration 1712  is               14.399999999999999%\n",
            "The validation accuracy at iteration 1728  is               14.424999999999999%\n",
            "The validation accuracy at iteration 1744  is               14.424999999999999%\n",
            "The validation accuracy at iteration 1760  is               14.424999999999999%\n",
            "The validation accuracy at iteration 1776  is               14.424999999999999%\n",
            "The validation accuracy at iteration 1792  is               14.424999999999999%\n",
            "The validation accuracy at iteration 1808  is               14.424999999999999%\n",
            "The validation accuracy at iteration 1824  is               14.399999999999999%\n",
            "The validation accuracy at iteration 1840  is               14.399999999999999%\n",
            "The validation accuracy at iteration 1856  is               14.424999999999999%\n",
            "The validation accuracy at iteration 1872  is               14.424999999999999%\n",
            "The validation accuracy at iteration 1888  is               14.424999999999999%\n",
            "The validation accuracy at iteration 1904  is               14.424999999999999%\n",
            "The validation accuracy at iteration 1920  is               14.424999999999999%\n",
            "The validation accuracy at iteration 1936  is               14.424999999999999%\n",
            "The validation accuracy at iteration 1952  is               14.424999999999999%\n",
            "The validation accuracy at iteration 1968  is               14.45%\n",
            "The validation accuracy at iteration 1984  is               14.475%\n",
            "The validation accuracy at iteration 2000  is               14.499999999999998%\n",
            "The validation accuracy at iteration 2016  is               14.499999999999998%\n",
            "The validation accuracy at iteration 2032  is               14.499999999999998%\n",
            "The validation accuracy at iteration 2048  is               14.499999999999998%\n",
            "The validation accuracy at iteration 2064  is               14.524999999999999%\n",
            "The validation accuracy at iteration 2080  is               14.524999999999999%\n",
            "The validation accuracy at iteration 2096  is               14.524999999999999%\n",
            "The validation accuracy at iteration 2112  is               14.524999999999999%\n",
            "The validation accuracy at iteration 2128  is               14.549999999999999%\n",
            "The validation accuracy at iteration 2144  is               14.575%\n",
            "The validation accuracy at iteration 2160  is               14.575%\n",
            "The validation accuracy at iteration 2176  is               14.6%\n",
            "The validation accuracy at iteration 2192  is               14.649999999999999%\n",
            "The validation accuracy at iteration 2208  is               14.649999999999999%\n",
            "The validation accuracy at iteration 2224  is               14.649999999999999%\n",
            "The validation accuracy at iteration 2240  is               14.649999999999999%\n",
            "The validation accuracy at iteration 2256  is               14.674999999999999%\n",
            "The validation accuracy at iteration 2272  is               14.674999999999999%\n",
            "The validation accuracy at iteration 2288  is               14.674999999999999%\n",
            "The validation accuracy at iteration 2304  is               14.674999999999999%\n",
            "The validation accuracy at iteration 2320  is               14.7%\n",
            "The validation accuracy at iteration 2336  is               14.7%\n",
            "The validation accuracy at iteration 2352  is               14.725%\n",
            "The validation accuracy at iteration 2368  is               14.75%\n",
            "The validation accuracy at iteration 2384  is               14.774999999999999%\n",
            "The validation accuracy at iteration 2400  is               14.774999999999999%\n",
            "The validation accuracy at iteration 2416  is               14.774999999999999%\n",
            "The validation accuracy at iteration 2432  is               14.774999999999999%\n",
            "The validation accuracy at iteration 2448  is               14.774999999999999%\n",
            "The validation accuracy at iteration 2464  is               14.799999999999999%\n",
            "The validation accuracy at iteration 2480  is               14.799999999999999%\n",
            "The validation accuracy at iteration 2496  is               14.825%\n",
            "The validation accuracy at iteration 2512  is               14.825%\n",
            "The validation accuracy at iteration 2528  is               14.825%\n",
            "The validation accuracy at iteration 2544  is               14.825%\n",
            "The validation accuracy at iteration 2560  is               14.825%\n",
            "The validation accuracy at iteration 2576  is               14.825%\n",
            "The validation accuracy at iteration 2592  is               14.85%\n",
            "The validation accuracy at iteration 2608  is               14.85%\n",
            "The validation accuracy at iteration 2624  is               14.85%\n",
            "The validation accuracy at iteration 2640  is               14.85%\n",
            "The validation accuracy at iteration 2656  is               14.875%\n",
            "The validation accuracy at iteration 2672  is               14.875%\n",
            "The validation accuracy at iteration 2688  is               14.875%\n",
            "The validation accuracy at iteration 2704  is               14.899999999999999%\n",
            "The validation accuracy at iteration 2720  is               14.924999999999999%\n",
            "The validation accuracy at iteration 2736  is               14.924999999999999%\n",
            "The validation accuracy at iteration 2752  is               14.924999999999999%\n",
            "The validation accuracy at iteration 2768  is               14.924999999999999%\n",
            "The validation accuracy at iteration 2784  is               14.95%\n",
            "The validation accuracy at iteration 2800  is               14.95%\n",
            "The validation accuracy at iteration 2816  is               14.95%\n",
            "The validation accuracy at iteration 2832  is               14.95%\n",
            "The validation accuracy at iteration 2848  is               14.975%\n",
            "The validation accuracy at iteration 2864  is               15.0%\n",
            "The validation accuracy at iteration 2880  is               15.0%\n",
            "The validation accuracy at iteration 2896  is               15.0%\n",
            "The validation accuracy at iteration 2912  is               15.0%\n",
            "The validation accuracy at iteration 2928  is               15.0%\n",
            "The validation accuracy at iteration 2944  is               15.049999999999999%\n",
            "The validation accuracy at iteration 2960  is               15.049999999999999%\n",
            "The validation accuracy at iteration 2976  is               15.049999999999999%\n",
            "The validation accuracy at iteration 2992  is               15.049999999999999%\n",
            "The validation accuracy at iteration 3008  is               15.049999999999999%\n",
            "The validation accuracy at iteration 3024  is               15.049999999999999%\n",
            "The validation accuracy at iteration 3040  is               15.075%\n",
            "The validation accuracy at iteration 3056  is               15.075%\n",
            "The validation accuracy at iteration 3072  is               15.075%\n",
            "The validation accuracy at iteration 3088  is               15.075%\n",
            "The validation accuracy at iteration 3104  is               15.1%\n",
            "The validation accuracy at iteration 3120  is               15.125%\n",
            "The validation accuracy at iteration 3136  is               15.125%\n",
            "The validation accuracy at iteration 3152  is               15.125%\n",
            "The validation accuracy at iteration 3168  is               15.125%\n",
            "The validation accuracy at iteration 3184  is               15.125%\n",
            "The validation accuracy at iteration 3200  is               15.125%\n",
            "The validation accuracy at iteration 3216  is               15.15%\n",
            "The validation accuracy at iteration 3232  is               15.174999999999999%\n",
            "The validation accuracy at iteration 3248  is               15.174999999999999%\n",
            "The validation accuracy at iteration 3264  is               15.174999999999999%\n",
            "The validation accuracy at iteration 3280  is               15.174999999999999%\n",
            "The validation accuracy at iteration 3296  is               15.174999999999999%\n",
            "The validation accuracy at iteration 3312  is               15.174999999999999%\n",
            "The validation accuracy at iteration 3328  is               15.174999999999999%\n",
            "The validation accuracy at iteration 3344  is               15.174999999999999%\n",
            "The validation accuracy at iteration 3360  is               15.174999999999999%\n",
            "The validation accuracy at iteration 3376  is               15.174999999999999%\n",
            "The validation accuracy at iteration 3392  is               15.2%\n",
            "The validation accuracy at iteration 3408  is               15.2%\n",
            "The validation accuracy at iteration 3424  is               15.2%\n",
            "The validation accuracy at iteration 3440  is               15.2%\n",
            "The validation accuracy at iteration 3456  is               15.2%\n",
            "The validation accuracy at iteration 3472  is               15.2%\n",
            "The validation accuracy at iteration 3488  is               15.225%\n",
            "The validation accuracy at iteration 3504  is               15.225%\n",
            "The validation accuracy at iteration 3520  is               15.225%\n",
            "The validation accuracy at iteration 3536  is               15.25%\n",
            "The validation accuracy at iteration 3552  is               15.25%\n",
            "The validation accuracy at iteration 3568  is               15.275%\n",
            "The validation accuracy at iteration 3584  is               15.299999999999999%\n",
            "The validation accuracy at iteration 3600  is               15.299999999999999%\n",
            "The validation accuracy at iteration 3616  is               15.299999999999999%\n",
            "The validation accuracy at iteration 3632  is               15.299999999999999%\n",
            "The validation accuracy at iteration 3648  is               15.299999999999999%\n",
            "The validation accuracy at iteration 3664  is               15.325%\n",
            "The validation accuracy at iteration 3680  is               15.325%\n",
            "The validation accuracy at iteration 3696  is               15.325%\n",
            "The validation accuracy at iteration 3712  is               15.325%\n",
            "The validation accuracy at iteration 3728  is               15.325%\n",
            "The validation accuracy at iteration 3744  is               15.325%\n",
            "The validation accuracy at iteration 3760  is               15.325%\n",
            "The validation accuracy at iteration 3776  is               15.325%\n",
            "The validation accuracy at iteration 3792  is               15.35%\n",
            "The validation accuracy at iteration 3808  is               15.375%\n",
            "The validation accuracy at iteration 3824  is               15.375%\n",
            "The validation accuracy at iteration 3840  is               15.35%\n",
            "The validation accuracy at iteration 3856  is               15.35%\n",
            "The validation accuracy at iteration 3872  is               15.35%\n",
            "The validation accuracy at iteration 3888  is               15.375%\n",
            "The validation accuracy at iteration 3904  is               15.375%\n",
            "The validation accuracy at iteration 3920  is               15.375%\n",
            "The validation accuracy at iteration 3936  is               15.375%\n",
            "The validation accuracy at iteration 3952  is               15.375%\n",
            "The validation accuracy at iteration 3968  is               15.375%\n",
            "The validation accuracy at iteration 3984  is               15.375%\n",
            "The validation accuracy at iteration 4000  is               15.375%\n",
            "The validation accuracy at iteration 4016  is               15.375%\n",
            "The validation accuracy at iteration 4032  is               15.375%\n",
            "The validation accuracy at iteration 4048  is               15.375%\n",
            "The validation accuracy at iteration 4064  is               15.375%\n",
            "The validation accuracy at iteration 4080  is               15.4%\n",
            "The validation accuracy at iteration 4096  is               15.425%\n",
            "The validation accuracy at iteration 4112  is               15.425%\n",
            "The validation accuracy at iteration 4128  is               15.425%\n",
            "The validation accuracy at iteration 4144  is               15.45%\n",
            "The validation accuracy at iteration 4160  is               15.45%\n",
            "The validation accuracy at iteration 4176  is               15.45%\n",
            "The validation accuracy at iteration 4192  is               15.475%\n",
            "The validation accuracy at iteration 4208  is               15.475%\n",
            "The validation accuracy at iteration 4224  is               15.5%\n",
            "The validation accuracy at iteration 4240  is               15.5%\n",
            "The validation accuracy at iteration 4256  is               15.525%\n",
            "The validation accuracy at iteration 4272  is               15.525%\n",
            "The validation accuracy at iteration 4288  is               15.525%\n",
            "The validation accuracy at iteration 4304  is               15.525%\n",
            "The validation accuracy at iteration 4320  is               15.525%\n",
            "The validation accuracy at iteration 4336  is               15.525%\n",
            "The validation accuracy at iteration 4352  is               15.525%\n",
            "The validation accuracy at iteration 4368  is               15.525%\n",
            "The validation accuracy at iteration 4384  is               15.525%\n",
            "The validation accuracy at iteration 4400  is               15.525%\n",
            "The validation accuracy at iteration 4416  is               15.525%\n",
            "The validation accuracy at iteration 4432  is               15.55%\n",
            "The validation accuracy at iteration 4448  is               15.55%\n",
            "The validation accuracy at iteration 4464  is               15.55%\n",
            "The validation accuracy at iteration 4480  is               15.55%\n",
            "The validation accuracy at iteration 4496  is               15.55%\n",
            "The validation accuracy at iteration 4512  is               15.55%\n",
            "The validation accuracy at iteration 4528  is               15.55%\n",
            "The validation accuracy at iteration 4544  is               15.55%\n",
            "The validation accuracy at iteration 4560  is               15.6%\n",
            "The validation accuracy at iteration 4576  is               15.6%\n",
            "The validation accuracy at iteration 4592  is               15.6%\n",
            "The validation accuracy at iteration 4608  is               15.6%\n",
            "The validation accuracy at iteration 4624  is               15.6%\n",
            "The validation accuracy at iteration 4640  is               15.6%\n",
            "The validation accuracy at iteration 4656  is               15.6%\n",
            "The validation accuracy at iteration 4672  is               15.6%\n",
            "The validation accuracy at iteration 4688  is               15.6%\n",
            "The validation accuracy at iteration 4704  is               15.6%\n",
            "The validation accuracy at iteration 4720  is               15.6%\n",
            "The validation accuracy at iteration 4736  is               15.6%\n",
            "The validation accuracy at iteration 4752  is               15.6%\n",
            "The validation accuracy at iteration 4768  is               15.6%\n",
            "The validation accuracy at iteration 4784  is               15.6%\n",
            "The validation accuracy at iteration 4800  is               15.6%\n",
            "The validation accuracy at iteration 4816  is               15.625%\n",
            "The validation accuracy at iteration 4832  is               15.625%\n",
            "The validation accuracy at iteration 4848  is               15.625%\n",
            "The validation accuracy at iteration 4864  is               15.625%\n",
            "The validation accuracy at iteration 4880  is               15.65%\n",
            "The validation accuracy at iteration 4896  is               15.65%\n",
            "The validation accuracy at iteration 4912  is               15.65%\n",
            "The validation accuracy at iteration 4928  is               15.65%\n",
            "The validation accuracy at iteration 4944  is               15.675%\n",
            "The validation accuracy at iteration 4960  is               15.675%\n",
            "The validation accuracy at iteration 4976  is               15.675%\n",
            "The validation accuracy at iteration 4992  is               15.675%\n",
            "The validation accuracy at iteration 5008  is               15.675%\n",
            "The validation accuracy at iteration 5024  is               15.675%\n",
            "The validation accuracy at iteration 5040  is               15.675%\n",
            "The validation accuracy at iteration 5056  is               15.7%\n",
            "The validation accuracy at iteration 5072  is               15.7%\n",
            "The validation accuracy at iteration 5088  is               15.7%\n",
            "The validation accuracy at iteration 5104  is               15.725%\n",
            "The validation accuracy at iteration 5120  is               15.725%\n",
            "The validation accuracy at iteration 5136  is               15.725%\n",
            "The validation accuracy at iteration 5152  is               15.725%\n",
            "The validation accuracy at iteration 5168  is               15.725%\n",
            "The validation accuracy at iteration 5184  is               15.725%\n",
            "The validation accuracy at iteration 5200  is               15.725%\n",
            "The validation accuracy at iteration 5216  is               15.725%\n",
            "The validation accuracy at iteration 5232  is               15.725%\n",
            "The validation accuracy at iteration 5248  is               15.725%\n",
            "The validation accuracy at iteration 5264  is               15.725%\n",
            "The validation accuracy at iteration 5280  is               15.775%\n",
            "The validation accuracy at iteration 5296  is               15.775%\n",
            "The validation accuracy at iteration 5312  is               15.775%\n",
            "The validation accuracy at iteration 5328  is               15.775%\n",
            "The validation accuracy at iteration 5344  is               15.775%\n",
            "The validation accuracy at iteration 5360  is               15.775%\n",
            "The validation accuracy at iteration 5376  is               15.775%\n",
            "The validation accuracy at iteration 5392  is               15.775%\n",
            "The validation accuracy at iteration 5408  is               15.775%\n",
            "The validation accuracy at iteration 5424  is               15.775%\n",
            "The validation accuracy at iteration 5440  is               15.8%\n",
            "The validation accuracy at iteration 5456  is               15.8%\n",
            "The validation accuracy at iteration 5472  is               15.8%\n",
            "The validation accuracy at iteration 5488  is               15.825%\n",
            "The validation accuracy at iteration 5504  is               15.825%\n",
            "The validation accuracy at iteration 5520  is               15.825%\n",
            "The validation accuracy at iteration 5536  is               15.825%\n",
            "The validation accuracy at iteration 5552  is               15.825%\n",
            "The validation accuracy at iteration 5568  is               15.825%\n",
            "The validation accuracy at iteration 5584  is               15.825%\n",
            "The validation accuracy at iteration 5600  is               15.9%\n",
            "The validation accuracy at iteration 5616  is               15.9%\n",
            "The validation accuracy at iteration 5632  is               15.925%\n",
            "The validation accuracy at iteration 5648  is               15.950000000000001%\n",
            "The validation accuracy at iteration 5664  is               15.975%\n",
            "The validation accuracy at iteration 5680  is               16.0%\n",
            "The validation accuracy at iteration 5696  is               16.0%\n",
            "The validation accuracy at iteration 5712  is               16.0%\n",
            "The validation accuracy at iteration 5728  is               16.025%\n",
            "The validation accuracy at iteration 5744  is               16.025%\n",
            "The validation accuracy at iteration 5760  is               16.075%\n",
            "The validation accuracy at iteration 5776  is               16.075%\n",
            "The validation accuracy at iteration 5792  is               16.075%\n",
            "The validation accuracy at iteration 5808  is               16.1%\n",
            "The validation accuracy at iteration 5824  is               16.125%\n",
            "The validation accuracy at iteration 5840  is               16.125%\n",
            "The validation accuracy at iteration 5856  is               16.125%\n",
            "The validation accuracy at iteration 5872  is               16.125%\n",
            "The validation accuracy at iteration 5888  is               16.150000000000002%\n",
            "The validation accuracy at iteration 5904  is               16.150000000000002%\n",
            "The validation accuracy at iteration 5920  is               16.150000000000002%\n",
            "The validation accuracy at iteration 5936  is               16.175%\n",
            "The validation accuracy at iteration 5952  is               16.175%\n",
            "The validation accuracy at iteration 5968  is               16.175%\n",
            "The validation accuracy at iteration 5984  is               16.225%\n",
            "The validation accuracy at iteration 6000  is               16.225%\n",
            "The validation accuracy at iteration 6016  is               16.225%\n",
            "The validation accuracy at iteration 6032  is               16.25%\n",
            "The validation accuracy at iteration 6048  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6064  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6080  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6096  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6112  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6128  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6144  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6160  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6176  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6192  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6208  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6224  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6240  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6256  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6272  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6288  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6304  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6320  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6336  is               16.275000000000002%\n",
            "The validation accuracy at iteration 6352  is               16.3%\n",
            "The validation accuracy at iteration 6368  is               16.3%\n",
            "The validation accuracy at iteration 6384  is               16.3%\n",
            "The validation accuracy at iteration 6400  is               16.3%\n",
            "The validation accuracy at iteration 6416  is               16.3%\n",
            "The validation accuracy at iteration 6432  is               16.35%\n",
            "The validation accuracy at iteration 6448  is               16.35%\n",
            "The validation accuracy at iteration 6464  is               16.35%\n",
            "The validation accuracy at iteration 6480  is               16.35%\n",
            "The validation accuracy at iteration 6496  is               16.35%\n",
            "The validation accuracy at iteration 6512  is               16.35%\n",
            "The validation accuracy at iteration 6528  is               16.400000000000002%\n",
            "The validation accuracy at iteration 6544  is               16.400000000000002%\n",
            "The validation accuracy at iteration 6560  is               16.400000000000002%\n",
            "The validation accuracy at iteration 6576  is               16.400000000000002%\n",
            "The validation accuracy at iteration 6592  is               16.400000000000002%\n",
            "The validation accuracy at iteration 6608  is               16.400000000000002%\n",
            "The validation accuracy at iteration 6624  is               16.400000000000002%\n",
            "The validation accuracy at iteration 6640  is               16.425%\n",
            "The validation accuracy at iteration 6656  is               16.45%\n",
            "The validation accuracy at iteration 6672  is               16.45%\n",
            "The validation accuracy at iteration 6688  is               16.45%\n",
            "The validation accuracy at iteration 6704  is               16.45%\n",
            "The validation accuracy at iteration 6720  is               16.475%\n",
            "The validation accuracy at iteration 6736  is               16.475%\n",
            "The validation accuracy at iteration 6752  is               16.475%\n",
            "The validation accuracy at iteration 6768  is               16.5%\n",
            "The validation accuracy at iteration 6784  is               16.5%\n",
            "The validation accuracy at iteration 6800  is               16.55%\n",
            "The validation accuracy at iteration 6816  is               16.575%\n",
            "The validation accuracy at iteration 6832  is               16.6%\n",
            "The validation accuracy at iteration 6848  is               16.6%\n",
            "The validation accuracy at iteration 6864  is               16.6%\n",
            "The validation accuracy at iteration 6880  is               16.625%\n",
            "The validation accuracy at iteration 6896  is               16.625%\n",
            "The validation accuracy at iteration 6912  is               16.675%\n",
            "The validation accuracy at iteration 6928  is               16.675%\n",
            "The validation accuracy at iteration 6944  is               16.675%\n",
            "The validation accuracy at iteration 6960  is               16.75%\n",
            "The validation accuracy at iteration 6976  is               16.75%\n",
            "The validation accuracy at iteration 6992  is               16.75%\n",
            "The validation accuracy at iteration 7008  is               16.8%\n",
            "The validation accuracy at iteration 7024  is               16.8%\n",
            "The validation accuracy at iteration 7040  is               16.8%\n",
            "The validation accuracy at iteration 7056  is               16.8%\n",
            "The validation accuracy at iteration 7072  is               16.8%\n",
            "The validation accuracy at iteration 7088  is               16.8%\n",
            "The validation accuracy at iteration 7104  is               16.8%\n",
            "The validation accuracy at iteration 7120  is               16.8%\n",
            "The validation accuracy at iteration 7136  is               16.8%\n",
            "The validation accuracy at iteration 7152  is               16.8%\n",
            "The validation accuracy at iteration 7168  is               16.8%\n",
            "The validation accuracy at iteration 7184  is               16.8%\n",
            "The validation accuracy at iteration 7200  is               16.825000000000003%\n",
            "The validation accuracy at iteration 7216  is               16.825000000000003%\n",
            "The validation accuracy at iteration 7232  is               16.825000000000003%\n",
            "The validation accuracy at iteration 7248  is               16.825000000000003%\n",
            "The validation accuracy at iteration 7264  is               16.825000000000003%\n",
            "The validation accuracy at iteration 7280  is               16.825000000000003%\n",
            "The validation accuracy at iteration 7296  is               16.825000000000003%\n",
            "The validation accuracy at iteration 7312  is               16.825000000000003%\n",
            "The validation accuracy at iteration 7328  is               16.825000000000003%\n",
            "The validation accuracy at iteration 7344  is               16.825000000000003%\n",
            "The validation accuracy at iteration 7360  is               16.825000000000003%\n",
            "The validation accuracy at iteration 7376  is               16.825000000000003%\n",
            "The validation accuracy at iteration 7392  is               16.825000000000003%\n",
            "The validation accuracy at iteration 7408  is               16.825000000000003%\n",
            "The validation accuracy at iteration 7424  is               16.85%\n",
            "The validation accuracy at iteration 7440  is               16.85%\n",
            "The validation accuracy at iteration 7456  is               16.85%\n",
            "The validation accuracy at iteration 7472  is               16.85%\n",
            "The validation accuracy at iteration 7488  is               16.85%\n",
            "The validation accuracy at iteration 7504  is               16.85%\n",
            "The validation accuracy at iteration 7520  is               16.85%\n",
            "The validation accuracy at iteration 7536  is               16.85%\n",
            "The validation accuracy at iteration 7552  is               16.85%\n",
            "The validation accuracy at iteration 7568  is               16.875%\n",
            "The validation accuracy at iteration 7584  is               16.875%\n",
            "The validation accuracy at iteration 7600  is               16.875%\n",
            "The validation accuracy at iteration 7616  is               16.875%\n",
            "The validation accuracy at iteration 7632  is               16.875%\n",
            "The validation accuracy at iteration 7648  is               16.875%\n",
            "The validation accuracy at iteration 7664  is               16.875%\n",
            "The validation accuracy at iteration 7680  is               16.875%\n",
            "The validation accuracy at iteration 7696  is               16.900000000000002%\n",
            "The validation accuracy at iteration 7712  is               16.900000000000002%\n",
            "The validation accuracy at iteration 7728  is               16.950000000000003%\n",
            "The validation accuracy at iteration 7744  is               16.975%\n",
            "The validation accuracy at iteration 7760  is               16.975%\n",
            "The validation accuracy at iteration 7776  is               16.950000000000003%\n",
            "The validation accuracy at iteration 7792  is               16.975%\n",
            "The validation accuracy at iteration 7808  is               16.975%\n",
            "The validation accuracy at iteration 7824  is               16.975%\n",
            "The validation accuracy at iteration 7840  is               16.975%\n",
            "The validation accuracy at iteration 7856  is               17.0%\n",
            "The validation accuracy at iteration 7872  is               17.0%\n",
            "The validation accuracy at iteration 7888  is               17.0%\n",
            "The validation accuracy at iteration 7904  is               17.0%\n",
            "The validation accuracy at iteration 7920  is               17.0%\n",
            "The validation accuracy at iteration 7936  is               17.0%\n",
            "The validation accuracy at iteration 7952  is               17.0%\n",
            "The validation accuracy at iteration 7968  is               17.025000000000002%\n",
            "The validation accuracy at iteration 7984  is               17.025000000000002%\n",
            "The validation accuracy at iteration 8000  is               17.025000000000002%\n",
            "The validation accuracy at iteration 8016  is               17.025000000000002%\n",
            "The validation accuracy at iteration 8032  is               17.05%\n",
            "The validation accuracy at iteration 8048  is               17.05%\n",
            "The validation accuracy at iteration 8064  is               17.05%\n",
            "The validation accuracy at iteration 8080  is               17.05%\n",
            "The validation accuracy at iteration 8096  is               17.05%\n",
            "The validation accuracy at iteration 8112  is               17.05%\n",
            "The validation accuracy at iteration 8128  is               17.05%\n",
            "The validation accuracy at iteration 8144  is               17.075000000000003%\n",
            "The validation accuracy at iteration 8160  is               17.075000000000003%\n",
            "The validation accuracy at iteration 8176  is               17.075000000000003%\n",
            "The validation accuracy at iteration 8192  is               17.075000000000003%\n",
            "The validation accuracy at iteration 8208  is               17.075000000000003%\n",
            "The validation accuracy at iteration 8224  is               17.05%\n",
            "The validation accuracy at iteration 8240  is               17.075000000000003%\n",
            "The validation accuracy at iteration 8256  is               17.1%\n",
            "The validation accuracy at iteration 8272  is               17.1%\n",
            "The validation accuracy at iteration 8288  is               17.1%\n",
            "The validation accuracy at iteration 8304  is               17.1%\n",
            "The validation accuracy at iteration 8320  is               17.1%\n",
            "The validation accuracy at iteration 8336  is               17.1%\n",
            "The validation accuracy at iteration 8352  is               17.1%\n",
            "The validation accuracy at iteration 8368  is               17.1%\n",
            "The validation accuracy at iteration 8384  is               17.1%\n",
            "The validation accuracy at iteration 8400  is               17.125%\n",
            "The validation accuracy at iteration 8416  is               17.125%\n",
            "The validation accuracy at iteration 8432  is               17.150000000000002%\n",
            "The validation accuracy at iteration 8448  is               17.150000000000002%\n",
            "The validation accuracy at iteration 8464  is               17.150000000000002%\n",
            "The validation accuracy at iteration 8480  is               17.175%\n",
            "The validation accuracy at iteration 8496  is               17.175%\n",
            "The validation accuracy at iteration 8512  is               17.175%\n",
            "The validation accuracy at iteration 8528  is               17.175%\n",
            "The validation accuracy at iteration 8544  is               17.175%\n",
            "The validation accuracy at iteration 8560  is               17.175%\n",
            "The validation accuracy at iteration 8576  is               17.224999999999998%\n",
            "The validation accuracy at iteration 8592  is               17.25%\n",
            "The validation accuracy at iteration 8608  is               17.275%\n",
            "The validation accuracy at iteration 8624  is               17.275%\n",
            "The validation accuracy at iteration 8640  is               17.275%\n",
            "The validation accuracy at iteration 8656  is               17.275%\n",
            "The validation accuracy at iteration 8672  is               17.275%\n",
            "The validation accuracy at iteration 8688  is               17.275%\n",
            "The validation accuracy at iteration 8704  is               17.275%\n",
            "The validation accuracy at iteration 8720  is               17.275%\n",
            "The validation accuracy at iteration 8736  is               17.275%\n",
            "The validation accuracy at iteration 8752  is               17.275%\n",
            "The validation accuracy at iteration 8768  is               17.299999999999997%\n",
            "The validation accuracy at iteration 8784  is               17.299999999999997%\n",
            "The validation accuracy at iteration 8800  is               17.299999999999997%\n",
            "The validation accuracy at iteration 8816  is               17.325%\n",
            "The validation accuracy at iteration 8832  is               17.325%\n",
            "The validation accuracy at iteration 8848  is               17.325%\n",
            "The validation accuracy at iteration 8864  is               17.325%\n",
            "The validation accuracy at iteration 8880  is               17.325%\n",
            "The validation accuracy at iteration 8896  is               17.325%\n",
            "The validation accuracy at iteration 8912  is               17.349999999999998%\n",
            "The validation accuracy at iteration 8928  is               17.45%\n",
            "The validation accuracy at iteration 8944  is               17.45%\n",
            "The validation accuracy at iteration 8960  is               17.5%\n",
            "The validation accuracy at iteration 8976  is               17.5%\n",
            "The validation accuracy at iteration 8992  is               17.525%\n",
            "The validation accuracy at iteration 9008  is               17.599999999999998%\n",
            "The validation accuracy at iteration 9024  is               17.625%\n",
            "The validation accuracy at iteration 9040  is               17.625%\n",
            "The validation accuracy at iteration 9056  is               17.625%\n",
            "The validation accuracy at iteration 9072  is               17.625%\n",
            "The validation accuracy at iteration 9088  is               17.625%\n",
            "The validation accuracy at iteration 9104  is               17.625%\n",
            "The validation accuracy at iteration 9120  is               17.625%\n",
            "The validation accuracy at iteration 9136  is               17.625%\n",
            "The validation accuracy at iteration 9152  is               17.625%\n",
            "The validation accuracy at iteration 9168  is               17.65%\n",
            "The validation accuracy at iteration 9184  is               17.625%\n",
            "The validation accuracy at iteration 9200  is               17.65%\n",
            "The validation accuracy at iteration 9216  is               17.65%\n",
            "The validation accuracy at iteration 9232  is               17.675%\n",
            "The validation accuracy at iteration 9248  is               17.675%\n",
            "The validation accuracy at iteration 9264  is               17.675%\n",
            "The validation accuracy at iteration 9280  is               17.675%\n",
            "The validation accuracy at iteration 9296  is               17.675%\n",
            "The validation accuracy at iteration 9312  is               17.7%\n",
            "The validation accuracy at iteration 9328  is               17.7%\n",
            "The validation accuracy at iteration 9344  is               17.724999999999998%\n",
            "The validation accuracy at iteration 9360  is               17.75%\n",
            "The validation accuracy at iteration 9376  is               17.75%\n",
            "The validation accuracy at iteration 9392  is               17.75%\n",
            "The validation accuracy at iteration 9408  is               17.75%\n",
            "The validation accuracy at iteration 9424  is               17.775%\n",
            "The validation accuracy at iteration 9440  is               17.775%\n",
            "The validation accuracy at iteration 9456  is               17.775%\n",
            "The validation accuracy at iteration 9472  is               17.775%\n",
            "The validation accuracy at iteration 9488  is               17.775%\n",
            "The validation accuracy at iteration 9504  is               17.8%\n",
            "The validation accuracy at iteration 9520  is               17.8%\n",
            "The validation accuracy at iteration 9536  is               17.8%\n",
            "The validation accuracy at iteration 9552  is               17.8%\n",
            "The validation accuracy at iteration 9568  is               17.8%\n",
            "The validation accuracy at iteration 9584  is               17.8%\n",
            "The validation accuracy at iteration 9600  is               17.8%\n",
            "The validation accuracy at iteration 9616  is               17.8%\n",
            "The validation accuracy at iteration 9632  is               17.825%\n",
            "The validation accuracy at iteration 9648  is               17.825%\n",
            "The validation accuracy at iteration 9664  is               17.849999999999998%\n",
            "The validation accuracy at iteration 9680  is               17.849999999999998%\n",
            "The validation accuracy at iteration 9696  is               17.849999999999998%\n",
            "The validation accuracy at iteration 9712  is               17.849999999999998%\n",
            "The validation accuracy at iteration 9728  is               17.849999999999998%\n",
            "The validation accuracy at iteration 9744  is               17.849999999999998%\n",
            "The validation accuracy at iteration 9760  is               17.849999999999998%\n",
            "The validation accuracy at iteration 9776  is               17.849999999999998%\n",
            "The validation accuracy at iteration 9792  is               17.849999999999998%\n",
            "The validation accuracy at iteration 9808  is               17.849999999999998%\n",
            "The validation accuracy at iteration 9824  is               17.849999999999998%\n",
            "The validation accuracy at iteration 9840  is               17.849999999999998%\n",
            "The validation accuracy at iteration 9856  is               17.875%\n",
            "The validation accuracy at iteration 9872  is               17.875%\n",
            "The validation accuracy at iteration 9888  is               17.875%\n",
            "The validation accuracy at iteration 9904  is               17.875%\n",
            "The validation accuracy at iteration 9920  is               17.875%\n",
            "The validation accuracy at iteration 9936  is               17.875%\n",
            "The validation accuracy at iteration 9952  is               17.875%\n",
            "The validation accuracy at iteration 9968  is               17.875%\n",
            "The validation accuracy at iteration 9984  is               17.875%\n",
            "The validation accuracy at iteration 10000  is               17.875%\n",
            "The validation accuracy at iteration 10016  is               17.925%\n",
            "The validation accuracy at iteration 10032  is               17.925%\n",
            "The validation accuracy at iteration 10048  is               17.925%\n",
            "The validation accuracy at iteration 10064  is               17.925%\n",
            "The validation accuracy at iteration 10080  is               17.974999999999998%\n",
            "The validation accuracy at iteration 10096  is               17.974999999999998%\n",
            "The validation accuracy at iteration 10112  is               17.974999999999998%\n",
            "The validation accuracy at iteration 10128  is               17.974999999999998%\n",
            "The validation accuracy at iteration 10144  is               17.974999999999998%\n",
            "The validation accuracy at iteration 10160  is               17.974999999999998%\n",
            "The validation accuracy at iteration 10176  is               18.0%\n",
            "The validation accuracy at iteration 10192  is               18.0%\n",
            "The validation accuracy at iteration 10208  is               18.0%\n",
            "The validation accuracy at iteration 10224  is               18.025%\n",
            "The validation accuracy at iteration 10240  is               18.025%\n",
            "The validation accuracy at iteration 10256  is               18.025%\n",
            "The validation accuracy at iteration 10272  is               18.025%\n",
            "The validation accuracy at iteration 10288  is               18.025%\n",
            "The validation accuracy at iteration 10304  is               18.05%\n",
            "The validation accuracy at iteration 10320  is               18.075%\n",
            "The validation accuracy at iteration 10336  is               18.099999999999998%\n",
            "The validation accuracy at iteration 10352  is               18.125%\n",
            "The validation accuracy at iteration 10368  is               18.125%\n",
            "The validation accuracy at iteration 10384  is               18.125%\n",
            "The validation accuracy at iteration 10400  is               18.125%\n",
            "The validation accuracy at iteration 10416  is               18.125%\n",
            "The validation accuracy at iteration 10432  is               18.175%\n",
            "The validation accuracy at iteration 10448  is               18.175%\n",
            "The validation accuracy at iteration 10464  is               18.175%\n",
            "The validation accuracy at iteration 10480  is               18.175%\n",
            "The validation accuracy at iteration 10496  is               18.175%\n",
            "The validation accuracy at iteration 10512  is               18.175%\n",
            "The validation accuracy at iteration 10528  is               18.175%\n",
            "The validation accuracy at iteration 10544  is               18.175%\n",
            "The validation accuracy at iteration 10560  is               18.2%\n",
            "The validation accuracy at iteration 10576  is               18.2%\n",
            "The validation accuracy at iteration 10592  is               18.224999999999998%\n",
            "The validation accuracy at iteration 10608  is               18.224999999999998%\n",
            "The validation accuracy at iteration 10624  is               18.224999999999998%\n",
            "The validation accuracy at iteration 10640  is               18.25%\n",
            "The validation accuracy at iteration 10656  is               18.25%\n",
            "The validation accuracy at iteration 10672  is               18.25%\n",
            "The validation accuracy at iteration 10688  is               18.275%\n",
            "The validation accuracy at iteration 10704  is               18.275%\n",
            "The validation accuracy at iteration 10720  is               18.275%\n",
            "The validation accuracy at iteration 10736  is               18.275%\n",
            "The validation accuracy at iteration 10752  is               18.275%\n",
            "The validation accuracy at iteration 10768  is               18.275%\n",
            "The validation accuracy at iteration 10784  is               18.275%\n",
            "The validation accuracy at iteration 10800  is               18.3%\n",
            "The validation accuracy at iteration 10816  is               18.3%\n",
            "The validation accuracy at iteration 10832  is               18.3%\n",
            "The validation accuracy at iteration 10848  is               18.325%\n",
            "The validation accuracy at iteration 10864  is               18.35%\n",
            "The validation accuracy at iteration 10880  is               18.375%\n",
            "The validation accuracy at iteration 10896  is               18.375%\n",
            "The validation accuracy at iteration 10912  is               18.4%\n",
            "The validation accuracy at iteration 10928  is               18.4%\n",
            "The validation accuracy at iteration 10944  is               18.4%\n",
            "The validation accuracy at iteration 10960  is               18.425%\n",
            "The validation accuracy at iteration 10976  is               18.425%\n",
            "The validation accuracy at iteration 10992  is               18.425%\n",
            "The validation accuracy at iteration 11008  is               18.425%\n",
            "The validation accuracy at iteration 11024  is               18.425%\n",
            "The validation accuracy at iteration 11040  is               18.425%\n",
            "The validation accuracy at iteration 11056  is               18.425%\n",
            "The validation accuracy at iteration 11072  is               18.425%\n",
            "The validation accuracy at iteration 11088  is               18.425%\n",
            "The validation accuracy at iteration 11104  is               18.425%\n",
            "The validation accuracy at iteration 11120  is               18.425%\n",
            "The validation accuracy at iteration 11136  is               18.425%\n",
            "The validation accuracy at iteration 11152  is               18.45%\n",
            "The validation accuracy at iteration 11168  is               18.45%\n",
            "The validation accuracy at iteration 11184  is               18.475%\n",
            "The validation accuracy at iteration 11200  is               18.475%\n",
            "The validation accuracy at iteration 11216  is               18.475%\n",
            "The validation accuracy at iteration 11232  is               18.475%\n",
            "The validation accuracy at iteration 11248  is               18.475%\n",
            "The validation accuracy at iteration 11264  is               18.5%\n",
            "The validation accuracy at iteration 11280  is               18.525%\n",
            "The validation accuracy at iteration 11296  is               18.525%\n",
            "The validation accuracy at iteration 11312  is               18.55%\n",
            "The validation accuracy at iteration 11328  is               18.55%\n",
            "The validation accuracy at iteration 11344  is               18.55%\n",
            "The validation accuracy at iteration 11360  is               18.55%\n",
            "The validation accuracy at iteration 11376  is               18.575%\n",
            "The validation accuracy at iteration 11392  is               18.575%\n",
            "The validation accuracy at iteration 11408  is               18.6%\n",
            "The validation accuracy at iteration 11424  is               18.6%\n",
            "The validation accuracy at iteration 11440  is               18.6%\n",
            "The validation accuracy at iteration 11456  is               18.65%\n",
            "The validation accuracy at iteration 11472  is               18.7%\n",
            "The validation accuracy at iteration 11488  is               18.7%\n",
            "The validation accuracy at iteration 11504  is               18.7%\n",
            "The validation accuracy at iteration 11520  is               18.7%\n",
            "The validation accuracy at iteration 11536  is               18.725%\n",
            "The validation accuracy at iteration 11552  is               18.725%\n",
            "The validation accuracy at iteration 11568  is               18.75%\n",
            "The validation accuracy at iteration 11584  is               18.75%\n",
            "The validation accuracy at iteration 11600  is               18.75%\n",
            "The validation accuracy at iteration 11616  is               18.775%\n",
            "The validation accuracy at iteration 11632  is               18.775%\n",
            "The validation accuracy at iteration 11648  is               18.8%\n",
            "The validation accuracy at iteration 11664  is               18.8%\n",
            "The validation accuracy at iteration 11680  is               18.8%\n",
            "The validation accuracy at iteration 11696  is               18.85%\n",
            "The validation accuracy at iteration 11712  is               18.85%\n",
            "The validation accuracy at iteration 11728  is               18.825%\n",
            "The validation accuracy at iteration 11744  is               18.825%\n",
            "The validation accuracy at iteration 11760  is               18.85%\n",
            "The validation accuracy at iteration 11776  is               18.85%\n",
            "The validation accuracy at iteration 11792  is               18.85%\n",
            "The validation accuracy at iteration 11808  is               18.85%\n",
            "The validation accuracy at iteration 11824  is               18.875%\n",
            "The validation accuracy at iteration 11840  is               18.875%\n",
            "The validation accuracy at iteration 11856  is               18.875%\n",
            "The validation accuracy at iteration 11872  is               18.875%\n",
            "The validation accuracy at iteration 11888  is               18.875%\n",
            "The validation accuracy at iteration 11904  is               18.875%\n",
            "The validation accuracy at iteration 11920  is               18.9%\n",
            "The validation accuracy at iteration 11936  is               18.925%\n",
            "The validation accuracy at iteration 11952  is               18.95%\n",
            "The validation accuracy at iteration 11968  is               18.95%\n",
            "The validation accuracy at iteration 11984  is               18.975%\n",
            "The validation accuracy at iteration 12000  is               19.0%\n",
            "The validation accuracy at iteration 12016  is               19.0%\n",
            "The validation accuracy at iteration 12032  is               19.0%\n",
            "The validation accuracy at iteration 12048  is               19.0%\n",
            "The validation accuracy at iteration 12064  is               19.025%\n",
            "The validation accuracy at iteration 12080  is               19.025%\n",
            "The validation accuracy at iteration 12096  is               19.025%\n",
            "The validation accuracy at iteration 12112  is               19.025%\n",
            "The validation accuracy at iteration 12128  is               19.025%\n",
            "The validation accuracy at iteration 12144  is               19.0%\n",
            "The validation accuracy at iteration 12160  is               19.0%\n",
            "The validation accuracy at iteration 12176  is               19.0%\n",
            "The validation accuracy at iteration 12192  is               19.025%\n",
            "The validation accuracy at iteration 12208  is               19.025%\n",
            "The validation accuracy at iteration 12224  is               19.025%\n",
            "The validation accuracy at iteration 12240  is               19.05%\n",
            "The validation accuracy at iteration 12256  is               19.05%\n",
            "The validation accuracy at iteration 12272  is               19.05%\n",
            "The validation accuracy at iteration 12288  is               19.075%\n",
            "The validation accuracy at iteration 12304  is               19.075%\n",
            "The validation accuracy at iteration 12320  is               19.075%\n",
            "The validation accuracy at iteration 12336  is               19.075%\n",
            "The validation accuracy at iteration 12352  is               19.075%\n",
            "The validation accuracy at iteration 12368  is               19.075%\n",
            "The validation accuracy at iteration 12384  is               19.075%\n",
            "The validation accuracy at iteration 12400  is               19.075%\n",
            "The validation accuracy at iteration 12416  is               19.075%\n",
            "The validation accuracy at iteration 12432  is               19.075%\n",
            "The validation accuracy at iteration 12448  is               19.075%\n",
            "The validation accuracy at iteration 12464  is               19.075%\n",
            "The validation accuracy at iteration 12480  is               19.1%\n",
            "The validation accuracy at iteration 12496  is               19.1%\n",
            "The validation accuracy at iteration 12512  is               19.125%\n",
            "The validation accuracy at iteration 12528  is               19.15%\n",
            "The validation accuracy at iteration 12544  is               19.15%\n",
            "The validation accuracy at iteration 12560  is               19.15%\n",
            "The validation accuracy at iteration 12576  is               19.15%\n",
            "The validation accuracy at iteration 12592  is               19.15%\n",
            "The validation accuracy at iteration 12608  is               19.175%\n",
            "The validation accuracy at iteration 12624  is               19.175%\n",
            "The validation accuracy at iteration 12640  is               19.175%\n",
            "The validation accuracy at iteration 12656  is               19.175%\n",
            "The validation accuracy at iteration 12672  is               19.175%\n",
            "The validation accuracy at iteration 12688  is               19.175%\n",
            "The validation accuracy at iteration 12704  is               19.175%\n",
            "The validation accuracy at iteration 12720  is               19.175%\n",
            "The validation accuracy at iteration 12736  is               19.175%\n",
            "The validation accuracy at iteration 12752  is               19.175%\n",
            "The validation accuracy at iteration 12768  is               19.175%\n",
            "The validation accuracy at iteration 12784  is               19.175%\n",
            "The validation accuracy at iteration 12800  is               19.175%\n",
            "The validation accuracy at iteration 12816  is               19.2%\n",
            "The validation accuracy at iteration 12832  is               19.2%\n",
            "The validation accuracy at iteration 12848  is               19.2%\n",
            "The validation accuracy at iteration 12864  is               19.2%\n",
            "The validation accuracy at iteration 12880  is               19.2%\n",
            "The validation accuracy at iteration 12896  is               19.2%\n",
            "The validation accuracy at iteration 12912  is               19.225%\n",
            "The validation accuracy at iteration 12928  is               19.225%\n",
            "The validation accuracy at iteration 12944  is               19.225%\n",
            "The validation accuracy at iteration 12960  is               19.225%\n",
            "The validation accuracy at iteration 12976  is               19.225%\n",
            "The validation accuracy at iteration 12992  is               19.225%\n",
            "The validation accuracy at iteration 13008  is               19.25%\n",
            "The validation accuracy at iteration 13024  is               19.25%\n",
            "The validation accuracy at iteration 13040  is               19.275000000000002%\n",
            "The validation accuracy at iteration 13056  is               19.275000000000002%\n",
            "The validation accuracy at iteration 13072  is               19.275000000000002%\n",
            "The validation accuracy at iteration 13088  is               19.3%\n",
            "The validation accuracy at iteration 13104  is               19.3%\n",
            "The validation accuracy at iteration 13120  is               19.3%\n",
            "The validation accuracy at iteration 13136  is               19.3%\n",
            "The validation accuracy at iteration 13152  is               19.3%\n",
            "The validation accuracy at iteration 13168  is               19.3%\n",
            "The validation accuracy at iteration 13184  is               19.3%\n",
            "The validation accuracy at iteration 13200  is               19.3%\n",
            "The validation accuracy at iteration 13216  is               19.3%\n",
            "The validation accuracy at iteration 13232  is               19.3%\n",
            "The validation accuracy at iteration 13248  is               19.3%\n",
            "The validation accuracy at iteration 13264  is               19.3%\n",
            "The validation accuracy at iteration 13280  is               19.3%\n",
            "The validation accuracy at iteration 13296  is               19.3%\n",
            "The validation accuracy at iteration 13312  is               19.3%\n",
            "The validation accuracy at iteration 13328  is               19.3%\n",
            "The validation accuracy at iteration 13344  is               19.3%\n",
            "The validation accuracy at iteration 13360  is               19.3%\n",
            "The validation accuracy at iteration 13376  is               19.3%\n",
            "The validation accuracy at iteration 13392  is               19.325%\n",
            "The validation accuracy at iteration 13408  is               19.325%\n",
            "The validation accuracy at iteration 13424  is               19.325%\n",
            "The validation accuracy at iteration 13440  is               19.325%\n",
            "The validation accuracy at iteration 13456  is               19.325%\n",
            "The validation accuracy at iteration 13472  is               19.35%\n",
            "The validation accuracy at iteration 13488  is               19.35%\n",
            "The validation accuracy at iteration 13504  is               19.35%\n",
            "The validation accuracy at iteration 13520  is               19.35%\n",
            "The validation accuracy at iteration 13536  is               19.35%\n",
            "The validation accuracy at iteration 13552  is               19.35%\n",
            "The validation accuracy at iteration 13568  is               19.35%\n",
            "The validation accuracy at iteration 13584  is               19.35%\n",
            "The validation accuracy at iteration 13600  is               19.35%\n",
            "The validation accuracy at iteration 13616  is               19.35%\n",
            "The validation accuracy at iteration 13632  is               19.35%\n",
            "The validation accuracy at iteration 13648  is               19.35%\n",
            "The validation accuracy at iteration 13664  is               19.35%\n",
            "The validation accuracy at iteration 13680  is               19.35%\n",
            "The validation accuracy at iteration 13696  is               19.35%\n",
            "The validation accuracy at iteration 13712  is               19.35%\n",
            "The validation accuracy at iteration 13728  is               19.35%\n",
            "The validation accuracy at iteration 13744  is               19.35%\n",
            "The validation accuracy at iteration 13760  is               19.375%\n",
            "The validation accuracy at iteration 13776  is               19.375%\n",
            "The validation accuracy at iteration 13792  is               19.375%\n",
            "The validation accuracy at iteration 13808  is               19.375%\n",
            "The validation accuracy at iteration 13824  is               19.375%\n",
            "The validation accuracy at iteration 13840  is               19.400000000000002%\n",
            "The validation accuracy at iteration 13856  is               19.400000000000002%\n",
            "The validation accuracy at iteration 13872  is               19.425%\n",
            "The validation accuracy at iteration 13888  is               19.475%\n",
            "The validation accuracy at iteration 13904  is               19.475%\n",
            "The validation accuracy at iteration 13920  is               19.475%\n",
            "The validation accuracy at iteration 13936  is               19.475%\n",
            "The validation accuracy at iteration 13952  is               19.5%\n",
            "The validation accuracy at iteration 13968  is               19.5%\n",
            "The validation accuracy at iteration 13984  is               19.5%\n",
            "The validation accuracy at iteration 14000  is               19.5%\n",
            "The validation accuracy at iteration 14016  is               19.5%\n",
            "The validation accuracy at iteration 14032  is               19.525000000000002%\n",
            "The validation accuracy at iteration 14048  is               19.55%\n",
            "The validation accuracy at iteration 14064  is               19.55%\n",
            "The validation accuracy at iteration 14080  is               19.55%\n",
            "The validation accuracy at iteration 14096  is               19.55%\n",
            "The validation accuracy at iteration 14112  is               19.55%\n",
            "The validation accuracy at iteration 14128  is               19.55%\n",
            "The validation accuracy at iteration 14144  is               19.55%\n",
            "The validation accuracy at iteration 14160  is               19.55%\n",
            "The validation accuracy at iteration 14176  is               19.575%\n",
            "The validation accuracy at iteration 14192  is               19.575%\n",
            "The validation accuracy at iteration 14208  is               19.575%\n",
            "The validation accuracy at iteration 14224  is               19.575%\n",
            "The validation accuracy at iteration 14240  is               19.575%\n",
            "The validation accuracy at iteration 14256  is               19.575%\n",
            "The validation accuracy at iteration 14272  is               19.575%\n",
            "The validation accuracy at iteration 14288  is               19.575%\n",
            "The validation accuracy at iteration 14304  is               19.575%\n",
            "The validation accuracy at iteration 14320  is               19.575%\n",
            "The validation accuracy at iteration 14336  is               19.6%\n",
            "The validation accuracy at iteration 14352  is               19.6%\n",
            "The validation accuracy at iteration 14368  is               19.625%\n",
            "The validation accuracy at iteration 14384  is               19.625%\n",
            "The validation accuracy at iteration 14400  is               19.625%\n",
            "The validation accuracy at iteration 14416  is               19.625%\n",
            "The validation accuracy at iteration 14432  is               19.650000000000002%\n",
            "The validation accuracy at iteration 14448  is               19.650000000000002%\n",
            "The validation accuracy at iteration 14464  is               19.650000000000002%\n",
            "The validation accuracy at iteration 14480  is               19.650000000000002%\n",
            "The validation accuracy at iteration 14496  is               19.650000000000002%\n",
            "The validation accuracy at iteration 14512  is               19.650000000000002%\n",
            "The validation accuracy at iteration 14528  is               19.650000000000002%\n",
            "The validation accuracy at iteration 14544  is               19.675%\n",
            "The validation accuracy at iteration 14560  is               19.7%\n",
            "The validation accuracy at iteration 14576  is               19.725%\n",
            "The validation accuracy at iteration 14592  is               19.725%\n",
            "The validation accuracy at iteration 14608  is               19.725%\n",
            "The validation accuracy at iteration 14624  is               19.725%\n",
            "The validation accuracy at iteration 14640  is               19.75%\n",
            "The validation accuracy at iteration 14656  is               19.75%\n",
            "The validation accuracy at iteration 14672  is               19.75%\n",
            "The validation accuracy at iteration 14688  is               19.75%\n",
            "The validation accuracy at iteration 14704  is               19.75%\n",
            "The validation accuracy at iteration 14720  is               19.775000000000002%\n",
            "The validation accuracy at iteration 14736  is               19.775000000000002%\n",
            "The validation accuracy at iteration 14752  is               19.775000000000002%\n",
            "The validation accuracy at iteration 14768  is               19.8%\n",
            "The validation accuracy at iteration 14784  is               19.8%\n",
            "The validation accuracy at iteration 14800  is               19.8%\n",
            "The validation accuracy at iteration 14816  is               19.8%\n",
            "The validation accuracy at iteration 14832  is               19.8%\n",
            "The validation accuracy at iteration 14848  is               19.825%\n",
            "The validation accuracy at iteration 14864  is               19.825%\n",
            "The validation accuracy at iteration 14880  is               19.85%\n",
            "The validation accuracy at iteration 14896  is               19.825%\n",
            "The validation accuracy at iteration 14912  is               19.85%\n",
            "The validation accuracy at iteration 14928  is               19.85%\n",
            "The validation accuracy at iteration 14944  is               19.85%\n",
            "The validation accuracy at iteration 14960  is               19.85%\n",
            "The validation accuracy at iteration 14976  is               19.85%\n",
            "The validation accuracy at iteration 14992  is               19.85%\n",
            "The validation accuracy at iteration 15008  is               19.85%\n",
            "The validation accuracy at iteration 15024  is               19.85%\n",
            "The validation accuracy at iteration 15040  is               19.875%\n",
            "The validation accuracy at iteration 15056  is               19.950000000000003%\n",
            "The validation accuracy at iteration 15072  is               19.950000000000003%\n",
            "The validation accuracy at iteration 15088  is               19.975%\n",
            "The validation accuracy at iteration 15104  is               20.0%\n",
            "The validation accuracy at iteration 15120  is               20.0%\n",
            "The validation accuracy at iteration 15136  is               20.0%\n",
            "The validation accuracy at iteration 15152  is               20.0%\n",
            "The validation accuracy at iteration 15168  is               20.05%\n",
            "The validation accuracy at iteration 15184  is               20.05%\n",
            "The validation accuracy at iteration 15200  is               20.05%\n",
            "The validation accuracy at iteration 15216  is               20.025000000000002%\n",
            "The validation accuracy at iteration 15232  is               20.05%\n",
            "The validation accuracy at iteration 15248  is               20.075000000000003%\n",
            "The validation accuracy at iteration 15264  is               20.1%\n",
            "The validation accuracy at iteration 15280  is               20.1%\n",
            "The validation accuracy at iteration 15296  is               20.1%\n",
            "The validation accuracy at iteration 15312  is               20.1%\n",
            "The validation accuracy at iteration 15328  is               20.1%\n",
            "The validation accuracy at iteration 15344  is               20.1%\n",
            "The validation accuracy at iteration 15360  is               20.1%\n",
            "The validation accuracy at iteration 15376  is               20.1%\n",
            "The validation accuracy at iteration 15392  is               20.150000000000002%\n",
            "The validation accuracy at iteration 15408  is               20.150000000000002%\n",
            "The validation accuracy at iteration 15424  is               20.150000000000002%\n",
            "The validation accuracy at iteration 15440  is               20.150000000000002%\n",
            "The validation accuracy at iteration 15456  is               20.150000000000002%\n",
            "The validation accuracy at iteration 15472  is               20.200000000000003%\n",
            "The validation accuracy at iteration 15488  is               20.200000000000003%\n",
            "The validation accuracy at iteration 15504  is               20.200000000000003%\n",
            "The validation accuracy at iteration 15520  is               20.200000000000003%\n",
            "The validation accuracy at iteration 15536  is               20.200000000000003%\n",
            "The validation accuracy at iteration 15552  is               20.200000000000003%\n",
            "The validation accuracy at iteration 15568  is               20.225%\n",
            "The validation accuracy at iteration 15584  is               20.25%\n",
            "The validation accuracy at iteration 15600  is               20.25%\n",
            "The validation accuracy at iteration 15616  is               20.25%\n",
            "The validation accuracy at iteration 15632  is               20.25%\n",
            "The validation accuracy at iteration 15648  is               20.25%\n",
            "The validation accuracy at iteration 15664  is               20.25%\n",
            "The validation accuracy at iteration 15680  is               20.25%\n",
            "The validation accuracy at iteration 15696  is               20.275000000000002%\n",
            "The validation accuracy at iteration 15712  is               20.275000000000002%\n",
            "The validation accuracy at iteration 15728  is               20.3%\n",
            "The validation accuracy at iteration 15744  is               20.325%\n",
            "The validation accuracy at iteration 15760  is               20.325%\n",
            "The validation accuracy at iteration 15776  is               20.325%\n",
            "The validation accuracy at iteration 15792  is               20.325%\n",
            "The validation accuracy at iteration 15808  is               20.325%\n",
            "The validation accuracy at iteration 15824  is               20.325%\n",
            "The validation accuracy at iteration 15840  is               20.325%\n",
            "The validation accuracy at iteration 15856  is               20.325%\n",
            "The validation accuracy at iteration 15872  is               20.325%\n",
            "The validation accuracy at iteration 15888  is               20.325%\n",
            "The validation accuracy at iteration 15904  is               20.325%\n",
            "The validation accuracy at iteration 15920  is               20.325%\n",
            "The validation accuracy at iteration 15936  is               20.325%\n",
            "The validation accuracy at iteration 15952  is               20.325%\n",
            "The validation accuracy at iteration 15968  is               20.325%\n",
            "The validation accuracy at iteration 15984  is               20.349999999999998%\n",
            "The validation accuracy at iteration 16000  is               20.375%\n",
            "The validation accuracy at iteration 16000  is               20.375%\n",
            "The validation accuracy at iteration 16000  is               20.375%\n",
            "The validation accuracy at iteration 1800  is               82.6%\n",
            "The validation accuracy at iteration 16000  is               20.375%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "The validation accuracy at iteration 16000  is               20.375%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 16000  is               20.375%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "The validation accuracy at iteration 16000  is               20.375%\n",
            "The validation accuracy at iteration 2300  is               77.5%\n",
            "The validation accuracy at iteration 16000  is               20.375%\n",
            "[<__main__.Solver object at 0x7f2ca1c8c210>, <__main__.Solver object at 0x7f2cad78fb50>, <__main__.Solver object at 0x7f2ca1fac6d0>, <__main__.Solver object at 0x7f2ca258c910>, <__main__.Solver object at 0x7f2ca258c3d0>]\n",
            "The validation accuracy at iteration 16  is               10.15%\n",
            "The validation accuracy at iteration 32  is               10.15%\n",
            "The validation accuracy at iteration 48  is               10.174999999999999%\n",
            "The validation accuracy at iteration 64  is               10.2%\n",
            "The validation accuracy at iteration 80  is               10.2%\n",
            "The validation accuracy at iteration 96  is               10.2%\n",
            "The validation accuracy at iteration 112  is               10.2%\n",
            "The validation accuracy at iteration 128  is               10.2%\n",
            "The validation accuracy at iteration 144  is               10.2%\n",
            "The validation accuracy at iteration 160  is               10.2%\n",
            "The validation accuracy at iteration 176  is               10.2%\n",
            "The validation accuracy at iteration 192  is               10.2%\n",
            "The validation accuracy at iteration 208  is               10.2%\n",
            "The validation accuracy at iteration 224  is               10.225%\n",
            "The validation accuracy at iteration 240  is               10.225%\n",
            "The validation accuracy at iteration 256  is               10.225%\n",
            "The validation accuracy at iteration 272  is               10.225%\n",
            "The validation accuracy at iteration 288  is               10.225%\n",
            "The validation accuracy at iteration 304  is               10.25%\n",
            "The validation accuracy at iteration 320  is               10.274999999999999%\n",
            "The validation accuracy at iteration 336  is               10.299999999999999%\n",
            "The validation accuracy at iteration 352  is               10.299999999999999%\n",
            "The validation accuracy at iteration 368  is               10.299999999999999%\n",
            "The validation accuracy at iteration 384  is               10.325%\n",
            "The validation accuracy at iteration 400  is               10.325%\n",
            "The validation accuracy at iteration 416  is               10.375%\n",
            "The validation accuracy at iteration 432  is               10.375%\n",
            "The validation accuracy at iteration 448  is               10.375%\n",
            "The validation accuracy at iteration 464  is               10.375%\n",
            "The validation accuracy at iteration 480  is               10.375%\n",
            "The validation accuracy at iteration 496  is               10.4%\n",
            "The validation accuracy at iteration 512  is               10.424999999999999%\n",
            "The validation accuracy at iteration 528  is               10.424999999999999%\n",
            "The validation accuracy at iteration 544  is               10.424999999999999%\n",
            "The validation accuracy at iteration 560  is               10.424999999999999%\n",
            "The validation accuracy at iteration 576  is               10.424999999999999%\n",
            "The validation accuracy at iteration 592  is               10.424999999999999%\n",
            "The validation accuracy at iteration 608  is               10.45%\n",
            "The validation accuracy at iteration 624  is               10.525%\n",
            "The validation accuracy at iteration 640  is               10.549999999999999%\n",
            "The validation accuracy at iteration 656  is               10.6%\n",
            "The validation accuracy at iteration 672  is               10.6%\n",
            "The validation accuracy at iteration 688  is               10.6%\n",
            "The validation accuracy at iteration 704  is               10.6%\n",
            "The validation accuracy at iteration 720  is               10.6%\n",
            "The validation accuracy at iteration 736  is               10.625%\n",
            "The validation accuracy at iteration 752  is               10.65%\n",
            "The validation accuracy at iteration 768  is               10.65%\n",
            "The validation accuracy at iteration 784  is               10.674999999999999%\n",
            "The validation accuracy at iteration 800  is               10.674999999999999%\n",
            "The validation accuracy at iteration 816  is               10.725%\n",
            "The validation accuracy at iteration 832  is               10.725%\n",
            "The validation accuracy at iteration 848  is               10.75%\n",
            "The validation accuracy at iteration 864  is               10.8%\n",
            "The validation accuracy at iteration 880  is               10.8%\n",
            "The validation accuracy at iteration 896  is               10.775%\n",
            "The validation accuracy at iteration 912  is               10.8%\n",
            "The validation accuracy at iteration 928  is               10.825%\n",
            "The validation accuracy at iteration 944  is               10.875%\n",
            "The validation accuracy at iteration 960  is               10.875%\n",
            "The validation accuracy at iteration 976  is               10.9%\n",
            "The validation accuracy at iteration 992  is               10.9%\n",
            "The validation accuracy at iteration 1008  is               10.875%\n",
            "The validation accuracy at iteration 1024  is               10.9%\n",
            "The validation accuracy at iteration 1040  is               10.9%\n",
            "The validation accuracy at iteration 1056  is               10.9%\n",
            "The validation accuracy at iteration 1072  is               10.925%\n",
            "The validation accuracy at iteration 1088  is               10.95%\n",
            "The validation accuracy at iteration 1104  is               10.95%\n",
            "The validation accuracy at iteration 1120  is               10.975%\n",
            "The validation accuracy at iteration 1136  is               11.025%\n",
            "The validation accuracy at iteration 1152  is               11.025%\n",
            "The validation accuracy at iteration 1168  is               11.05%\n",
            "The validation accuracy at iteration 1184  is               11.05%\n",
            "The validation accuracy at iteration 1200  is               11.1%\n",
            "The validation accuracy at iteration 1216  is               11.125%\n",
            "The validation accuracy at iteration 1232  is               11.15%\n",
            "The validation accuracy at iteration 1248  is               11.225%\n",
            "The validation accuracy at iteration 1264  is               11.25%\n",
            "The validation accuracy at iteration 1280  is               11.3%\n",
            "The validation accuracy at iteration 1296  is               11.275%\n",
            "The validation accuracy at iteration 1312  is               11.275%\n",
            "The validation accuracy at iteration 1328  is               11.275%\n",
            "The validation accuracy at iteration 1344  is               11.35%\n",
            "The validation accuracy at iteration 1360  is               11.375%\n",
            "The validation accuracy at iteration 1376  is               11.4%\n",
            "The validation accuracy at iteration 1392  is               11.4%\n",
            "The validation accuracy at iteration 1408  is               11.450000000000001%\n",
            "The validation accuracy at iteration 1424  is               11.450000000000001%\n",
            "The validation accuracy at iteration 1440  is               11.55%\n",
            "The validation accuracy at iteration 1456  is               11.575000000000001%\n",
            "The validation accuracy at iteration 1472  is               11.600000000000001%\n",
            "The validation accuracy at iteration 1488  is               11.625%\n",
            "The validation accuracy at iteration 1504  is               11.625%\n",
            "The validation accuracy at iteration 1520  is               11.625%\n",
            "The validation accuracy at iteration 1536  is               11.675%\n",
            "The validation accuracy at iteration 1552  is               11.675%\n",
            "The validation accuracy at iteration 1568  is               11.675%\n",
            "The validation accuracy at iteration 1584  is               11.75%\n",
            "The validation accuracy at iteration 1600  is               11.75%\n",
            "The validation accuracy at iteration 1616  is               11.774999999999999%\n",
            "The validation accuracy at iteration 1632  is               11.75%\n",
            "The validation accuracy at iteration 1648  is               11.75%\n",
            "The validation accuracy at iteration 1664  is               11.774999999999999%\n",
            "The validation accuracy at iteration 1680  is               11.825%\n",
            "The validation accuracy at iteration 1696  is               11.85%\n",
            "The validation accuracy at iteration 1712  is               11.875%\n",
            "The validation accuracy at iteration 1728  is               11.85%\n",
            "The validation accuracy at iteration 1744  is               11.85%\n",
            "The validation accuracy at iteration 1760  is               11.875%\n",
            "The validation accuracy at iteration 1776  is               11.95%\n",
            "The validation accuracy at iteration 1792  is               12.025%\n",
            "The validation accuracy at iteration 1808  is               12.025%\n",
            "The validation accuracy at iteration 1824  is               12.025%\n",
            "The validation accuracy at iteration 1840  is               12.049999999999999%\n",
            "The validation accuracy at iteration 1856  is               12.049999999999999%\n",
            "The validation accuracy at iteration 1872  is               12.1%\n",
            "The validation accuracy at iteration 1888  is               12.225%\n",
            "The validation accuracy at iteration 1904  is               12.25%\n",
            "The validation accuracy at iteration 1920  is               12.275%\n",
            "The validation accuracy at iteration 1936  is               12.275%\n",
            "The validation accuracy at iteration 1952  is               12.25%\n",
            "The validation accuracy at iteration 1968  is               12.25%\n",
            "The validation accuracy at iteration 1984  is               12.25%\n",
            "The validation accuracy at iteration 2000  is               12.275%\n",
            "The validation accuracy at iteration 2016  is               12.325%\n",
            "The validation accuracy at iteration 2032  is               12.325%\n",
            "The validation accuracy at iteration 2048  is               12.3%\n",
            "The validation accuracy at iteration 2064  is               12.425%\n",
            "The validation accuracy at iteration 2080  is               12.425%\n",
            "The validation accuracy at iteration 2096  is               12.425%\n",
            "The validation accuracy at iteration 2112  is               12.425%\n",
            "The validation accuracy at iteration 2128  is               12.475%\n",
            "The validation accuracy at iteration 2144  is               12.425%\n",
            "The validation accuracy at iteration 2160  is               12.425%\n",
            "The validation accuracy at iteration 2176  is               12.425%\n",
            "The validation accuracy at iteration 2192  is               12.425%\n",
            "The validation accuracy at iteration 2208  is               12.425%\n",
            "The validation accuracy at iteration 2224  is               12.425%\n",
            "The validation accuracy at iteration 2240  is               12.475%\n",
            "The validation accuracy at iteration 2256  is               12.525%\n",
            "The validation accuracy at iteration 2272  is               12.55%\n",
            "The validation accuracy at iteration 2288  is               12.575%\n",
            "The validation accuracy at iteration 2304  is               12.575%\n",
            "The validation accuracy at iteration 2320  is               12.625%\n",
            "The validation accuracy at iteration 2336  is               12.65%\n",
            "The validation accuracy at iteration 2352  is               12.65%\n",
            "The validation accuracy at iteration 2368  is               12.65%\n",
            "The validation accuracy at iteration 2384  is               12.65%\n",
            "The validation accuracy at iteration 2400  is               12.65%\n",
            "The validation accuracy at iteration 2416  is               12.675%\n",
            "The validation accuracy at iteration 2432  is               12.7%\n",
            "The validation accuracy at iteration 2448  is               12.725%\n",
            "The validation accuracy at iteration 2464  is               12.725%\n",
            "The validation accuracy at iteration 2480  is               12.725%\n",
            "The validation accuracy at iteration 2496  is               12.725%\n",
            "The validation accuracy at iteration 2512  is               12.725%\n",
            "The validation accuracy at iteration 2528  is               12.75%\n",
            "The validation accuracy at iteration 2544  is               12.775%\n",
            "The validation accuracy at iteration 2560  is               12.8%\n",
            "The validation accuracy at iteration 2576  is               12.825000000000001%\n",
            "The validation accuracy at iteration 2592  is               12.825000000000001%\n",
            "The validation accuracy at iteration 2608  is               12.875%\n",
            "The validation accuracy at iteration 2624  is               12.875%\n",
            "The validation accuracy at iteration 2640  is               12.875%\n",
            "The validation accuracy at iteration 2656  is               12.875%\n",
            "The validation accuracy at iteration 2672  is               12.9%\n",
            "The validation accuracy at iteration 2688  is               12.9%\n",
            "The validation accuracy at iteration 2704  is               12.925%\n",
            "The validation accuracy at iteration 2720  is               12.950000000000001%\n",
            "The validation accuracy at iteration 2736  is               12.950000000000001%\n",
            "The validation accuracy at iteration 2752  is               12.975%\n",
            "The validation accuracy at iteration 2768  is               13.0%\n",
            "The validation accuracy at iteration 2784  is               13.0%\n",
            "The validation accuracy at iteration 2800  is               13.025%\n",
            "The validation accuracy at iteration 2816  is               13.05%\n",
            "The validation accuracy at iteration 2832  is               13.05%\n",
            "The validation accuracy at iteration 2848  is               13.075000000000001%\n",
            "The validation accuracy at iteration 2864  is               13.075000000000001%\n",
            "The validation accuracy at iteration 2880  is               13.100000000000001%\n",
            "The validation accuracy at iteration 2896  is               13.15%\n",
            "The validation accuracy at iteration 2912  is               13.15%\n",
            "The validation accuracy at iteration 2928  is               13.15%\n",
            "The validation accuracy at iteration 2944  is               13.225000000000001%\n",
            "The validation accuracy at iteration 2960  is               13.25%\n",
            "The validation accuracy at iteration 2976  is               13.25%\n",
            "The validation accuracy at iteration 2992  is               13.25%\n",
            "The validation accuracy at iteration 3008  is               13.25%\n",
            "The validation accuracy at iteration 3024  is               13.275%\n",
            "The validation accuracy at iteration 3040  is               13.3%\n",
            "The validation accuracy at iteration 3056  is               13.325000000000001%\n",
            "The validation accuracy at iteration 3072  is               13.350000000000001%\n",
            "The validation accuracy at iteration 3088  is               13.350000000000001%\n",
            "The validation accuracy at iteration 3104  is               13.375%\n",
            "The validation accuracy at iteration 3120  is               13.375%\n",
            "The validation accuracy at iteration 3136  is               13.425%\n",
            "The validation accuracy at iteration 3152  is               13.4%\n",
            "The validation accuracy at iteration 3168  is               13.4%\n",
            "The validation accuracy at iteration 3184  is               13.4%\n",
            "The validation accuracy at iteration 3200  is               13.4%\n",
            "The validation accuracy at iteration 3216  is               13.4%\n",
            "The validation accuracy at iteration 3232  is               13.425%\n",
            "The validation accuracy at iteration 3248  is               13.475000000000001%\n",
            "The validation accuracy at iteration 3264  is               13.475000000000001%\n",
            "The validation accuracy at iteration 3280  is               13.475000000000001%\n",
            "The validation accuracy at iteration 3296  is               13.5%\n",
            "The validation accuracy at iteration 3312  is               13.55%\n",
            "The validation accuracy at iteration 3328  is               13.55%\n",
            "The validation accuracy at iteration 3344  is               13.575000000000001%\n",
            "The validation accuracy at iteration 3360  is               13.575000000000001%\n",
            "The validation accuracy at iteration 3376  is               13.55%\n",
            "The validation accuracy at iteration 3392  is               13.55%\n",
            "The validation accuracy at iteration 3408  is               13.575000000000001%\n",
            "The validation accuracy at iteration 3424  is               13.575000000000001%\n",
            "The validation accuracy at iteration 3440  is               13.600000000000001%\n",
            "The validation accuracy at iteration 3456  is               13.625000000000002%\n",
            "The validation accuracy at iteration 3472  is               13.65%\n",
            "The validation accuracy at iteration 3488  is               13.65%\n",
            "The validation accuracy at iteration 3504  is               13.65%\n",
            "The validation accuracy at iteration 3520  is               13.700000000000001%\n",
            "The validation accuracy at iteration 3536  is               13.700000000000001%\n",
            "The validation accuracy at iteration 3552  is               13.700000000000001%\n",
            "The validation accuracy at iteration 3568  is               13.700000000000001%\n",
            "The validation accuracy at iteration 3584  is               13.700000000000001%\n",
            "The validation accuracy at iteration 3600  is               13.725000000000001%\n",
            "The validation accuracy at iteration 3616  is               13.750000000000002%\n",
            "The validation accuracy at iteration 3632  is               13.8%\n",
            "The validation accuracy at iteration 3648  is               13.875000000000002%\n",
            "The validation accuracy at iteration 3664  is               13.875000000000002%\n",
            "The validation accuracy at iteration 3680  is               13.875000000000002%\n",
            "The validation accuracy at iteration 3696  is               13.875000000000002%\n",
            "The validation accuracy at iteration 3712  is               13.900000000000002%\n",
            "The validation accuracy at iteration 3728  is               13.900000000000002%\n",
            "The validation accuracy at iteration 3744  is               13.900000000000002%\n",
            "The validation accuracy at iteration 3760  is               13.925%\n",
            "The validation accuracy at iteration 3776  is               13.925%\n",
            "The validation accuracy at iteration 3792  is               13.950000000000001%\n",
            "The validation accuracy at iteration 3808  is               13.950000000000001%\n",
            "The validation accuracy at iteration 3824  is               13.975000000000001%\n",
            "The validation accuracy at iteration 3840  is               14.025000000000002%\n",
            "The validation accuracy at iteration 3856  is               14.025000000000002%\n",
            "The validation accuracy at iteration 3872  is               14.05%\n",
            "The validation accuracy at iteration 3888  is               14.075%\n",
            "The validation accuracy at iteration 3904  is               14.099999999999998%\n",
            "The validation accuracy at iteration 3920  is               14.174999999999999%\n",
            "The validation accuracy at iteration 3936  is               14.174999999999999%\n",
            "The validation accuracy at iteration 3952  is               14.224999999999998%\n",
            "The validation accuracy at iteration 3968  is               14.274999999999999%\n",
            "The validation accuracy at iteration 3984  is               14.274999999999999%\n",
            "The validation accuracy at iteration 4000  is               14.274999999999999%\n",
            "The validation accuracy at iteration 4016  is               14.274999999999999%\n",
            "The validation accuracy at iteration 4032  is               14.299999999999999%\n",
            "The validation accuracy at iteration 4048  is               14.325%\n",
            "The validation accuracy at iteration 4064  is               14.325%\n",
            "The validation accuracy at iteration 4080  is               14.325%\n",
            "The validation accuracy at iteration 4096  is               14.325%\n",
            "The validation accuracy at iteration 4112  is               14.325%\n",
            "The validation accuracy at iteration 4128  is               14.35%\n",
            "The validation accuracy at iteration 4144  is               14.35%\n",
            "The validation accuracy at iteration 4160  is               14.374999999999998%\n",
            "The validation accuracy at iteration 4176  is               14.45%\n",
            "The validation accuracy at iteration 4192  is               14.499999999999998%\n",
            "The validation accuracy at iteration 4208  is               14.499999999999998%\n",
            "The validation accuracy at iteration 4224  is               14.499999999999998%\n",
            "The validation accuracy at iteration 4240  is               14.499999999999998%\n",
            "The validation accuracy at iteration 4256  is               14.575%\n",
            "The validation accuracy at iteration 4272  is               14.625%\n",
            "The validation accuracy at iteration 4288  is               14.674999999999999%\n",
            "The validation accuracy at iteration 4304  is               14.674999999999999%\n",
            "The validation accuracy at iteration 4320  is               14.7%\n",
            "The validation accuracy at iteration 4336  is               14.725%\n",
            "The validation accuracy at iteration 4352  is               14.725%\n",
            "The validation accuracy at iteration 4368  is               14.725%\n",
            "The validation accuracy at iteration 4384  is               14.725%\n",
            "The validation accuracy at iteration 4400  is               14.725%\n",
            "The validation accuracy at iteration 4416  is               14.725%\n",
            "The validation accuracy at iteration 4432  is               14.725%\n",
            "The validation accuracy at iteration 4448  is               14.725%\n",
            "The validation accuracy at iteration 4464  is               14.75%\n",
            "The validation accuracy at iteration 4480  is               14.75%\n",
            "The validation accuracy at iteration 4496  is               14.774999999999999%\n",
            "The validation accuracy at iteration 4512  is               14.799999999999999%\n",
            "The validation accuracy at iteration 4528  is               14.799999999999999%\n",
            "The validation accuracy at iteration 4544  is               14.799999999999999%\n",
            "The validation accuracy at iteration 4560  is               14.825%\n",
            "The validation accuracy at iteration 4576  is               14.825%\n",
            "The validation accuracy at iteration 4592  is               14.825%\n",
            "The validation accuracy at iteration 4608  is               14.85%\n",
            "The validation accuracy at iteration 4624  is               14.825%\n",
            "The validation accuracy at iteration 4640  is               14.899999999999999%\n",
            "The validation accuracy at iteration 4656  is               14.975%\n",
            "The validation accuracy at iteration 4672  is               15.0%\n",
            "The validation accuracy at iteration 4688  is               15.024999999999999%\n",
            "The validation accuracy at iteration 4704  is               15.049999999999999%\n",
            "The validation accuracy at iteration 4720  is               15.049999999999999%\n",
            "The validation accuracy at iteration 4736  is               15.075%\n",
            "The validation accuracy at iteration 4752  is               15.125%\n",
            "The validation accuracy at iteration 4768  is               15.125%\n",
            "The validation accuracy at iteration 4784  is               15.174999999999999%\n",
            "The validation accuracy at iteration 4800  is               15.174999999999999%\n",
            "The validation accuracy at iteration 4816  is               15.2%\n",
            "The validation accuracy at iteration 4832  is               15.2%\n",
            "The validation accuracy at iteration 4848  is               15.225%\n",
            "The validation accuracy at iteration 4864  is               15.275%\n",
            "The validation accuracy at iteration 4880  is               15.275%\n",
            "The validation accuracy at iteration 4896  is               15.299999999999999%\n",
            "The validation accuracy at iteration 4912  is               15.325%\n",
            "The validation accuracy at iteration 4928  is               15.325%\n",
            "The validation accuracy at iteration 4944  is               15.35%\n",
            "The validation accuracy at iteration 4960  is               15.4%\n",
            "The validation accuracy at iteration 4976  is               15.425%\n",
            "The validation accuracy at iteration 4992  is               15.425%\n",
            "The validation accuracy at iteration 5008  is               15.425%\n",
            "The validation accuracy at iteration 5024  is               15.45%\n",
            "The validation accuracy at iteration 5040  is               15.5%\n",
            "The validation accuracy at iteration 5056  is               15.55%\n",
            "The validation accuracy at iteration 5072  is               15.55%\n",
            "The validation accuracy at iteration 5088  is               15.55%\n",
            "The validation accuracy at iteration 5104  is               15.575%\n",
            "The validation accuracy at iteration 5120  is               15.6%\n",
            "The validation accuracy at iteration 5136  is               15.6%\n",
            "The validation accuracy at iteration 5152  is               15.6%\n",
            "The validation accuracy at iteration 5168  is               15.625%\n",
            "The validation accuracy at iteration 5184  is               15.65%\n",
            "The validation accuracy at iteration 5200  is               15.675%\n",
            "The validation accuracy at iteration 5216  is               15.675%\n",
            "The validation accuracy at iteration 5232  is               15.7%\n",
            "The validation accuracy at iteration 5248  is               15.7%\n",
            "The validation accuracy at iteration 5264  is               15.725%\n",
            "The validation accuracy at iteration 5280  is               15.725%\n",
            "The validation accuracy at iteration 5296  is               15.75%\n",
            "The validation accuracy at iteration 5312  is               15.75%\n",
            "The validation accuracy at iteration 5328  is               15.8%\n",
            "The validation accuracy at iteration 5344  is               15.825%\n",
            "The validation accuracy at iteration 5350  is               15.85%\n",
            "The validation accuracy at iteration 5350  is               15.85%\n",
            "The validation accuracy at iteration 1800  is               82.6%\n",
            "The validation accuracy at iteration 5350  is               15.85%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "The validation accuracy at iteration 5350  is               15.85%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 5350  is               15.85%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "The validation accuracy at iteration 5350  is               15.85%\n",
            "The validation accuracy at iteration 2300  is               77.5%\n",
            "The validation accuracy at iteration 5350  is               15.85%\n",
            "[<__main__.Solver object at 0x7f2ca1c8c210>, <__main__.Solver object at 0x7f2cad78fb50>, <__main__.Solver object at 0x7f2ca1fac6d0>, <__main__.Solver object at 0x7f2ca258c910>, <__main__.Solver object at 0x7f2ca258c3d0>]\n",
            "The validation accuracy at iteration 16  is               6.950000000000001%\n",
            "The validation accuracy at iteration 32  is               6.9750000000000005%\n",
            "The validation accuracy at iteration 48  is               6.9750000000000005%\n",
            "The validation accuracy at iteration 64  is               7.000000000000001%\n",
            "The validation accuracy at iteration 80  is               7.025%\n",
            "The validation accuracy at iteration 96  is               7.049999999999999%\n",
            "The validation accuracy at iteration 112  is               7.124999999999999%\n",
            "The validation accuracy at iteration 128  is               7.124999999999999%\n",
            "The validation accuracy at iteration 144  is               7.1499999999999995%\n",
            "The validation accuracy at iteration 160  is               7.175%\n",
            "The validation accuracy at iteration 176  is               7.175%\n",
            "The validation accuracy at iteration 192  is               7.175%\n",
            "The validation accuracy at iteration 208  is               7.199999999999999%\n",
            "The validation accuracy at iteration 224  is               7.249999999999999%\n",
            "The validation accuracy at iteration 240  is               7.249999999999999%\n",
            "The validation accuracy at iteration 256  is               7.3%\n",
            "The validation accuracy at iteration 272  is               7.324999999999999%\n",
            "The validation accuracy at iteration 288  is               7.375%\n",
            "The validation accuracy at iteration 304  is               7.3999999999999995%\n",
            "The validation accuracy at iteration 320  is               7.449999999999999%\n",
            "The validation accuracy at iteration 336  is               7.5%\n",
            "The validation accuracy at iteration 352  is               7.55%\n",
            "The validation accuracy at iteration 368  is               7.6%\n",
            "The validation accuracy at iteration 384  is               7.6499999999999995%\n",
            "The validation accuracy at iteration 400  is               7.725%\n",
            "The validation accuracy at iteration 416  is               7.775%\n",
            "The validation accuracy at iteration 432  is               7.875%\n",
            "The validation accuracy at iteration 448  is               7.925%\n",
            "The validation accuracy at iteration 464  is               7.9750000000000005%\n",
            "The validation accuracy at iteration 480  is               8.025%\n",
            "The validation accuracy at iteration 496  is               8.125%\n",
            "The validation accuracy at iteration 512  is               8.200000000000001%\n",
            "The validation accuracy at iteration 528  is               8.275%\n",
            "The validation accuracy at iteration 544  is               8.3%\n",
            "The validation accuracy at iteration 560  is               8.35%\n",
            "The validation accuracy at iteration 576  is               8.4%\n",
            "The validation accuracy at iteration 592  is               8.475000000000001%\n",
            "The validation accuracy at iteration 608  is               8.55%\n",
            "The validation accuracy at iteration 624  is               8.6%\n",
            "The validation accuracy at iteration 640  is               8.649999999999999%\n",
            "The validation accuracy at iteration 656  is               8.649999999999999%\n",
            "The validation accuracy at iteration 672  is               8.674999999999999%\n",
            "The validation accuracy at iteration 688  is               8.7%\n",
            "The validation accuracy at iteration 704  is               8.7%\n",
            "The validation accuracy at iteration 720  is               8.799999999999999%\n",
            "The validation accuracy at iteration 736  is               8.85%\n",
            "The validation accuracy at iteration 752  is               8.975%\n",
            "The validation accuracy at iteration 768  is               8.975%\n",
            "The validation accuracy at iteration 784  is               9.075%\n",
            "The validation accuracy at iteration 800  is               9.1%\n",
            "The validation accuracy at iteration 816  is               9.125%\n",
            "The validation accuracy at iteration 832  is               9.125%\n",
            "The validation accuracy at iteration 848  is               9.225%\n",
            "The validation accuracy at iteration 864  is               9.275%\n",
            "The validation accuracy at iteration 880  is               9.325%\n",
            "The validation accuracy at iteration 896  is               9.4%\n",
            "The validation accuracy at iteration 912  is               9.475%\n",
            "The validation accuracy at iteration 928  is               9.525%\n",
            "The validation accuracy at iteration 944  is               9.625%\n",
            "The validation accuracy at iteration 960  is               9.725%\n",
            "The validation accuracy at iteration 976  is               9.725%\n",
            "The validation accuracy at iteration 992  is               9.775%\n",
            "The validation accuracy at iteration 1008  is               9.8%\n",
            "The validation accuracy at iteration 1024  is               9.85%\n",
            "The validation accuracy at iteration 1040  is               9.9%\n",
            "The validation accuracy at iteration 1056  is               9.9%\n",
            "The validation accuracy at iteration 1072  is               9.950000000000001%\n",
            "The validation accuracy at iteration 1088  is               10.025%\n",
            "The validation accuracy at iteration 1104  is               10.025%\n",
            "The validation accuracy at iteration 1120  is               10.05%\n",
            "The validation accuracy at iteration 1136  is               10.125%\n",
            "The validation accuracy at iteration 1152  is               10.125%\n",
            "The validation accuracy at iteration 1168  is               10.125%\n",
            "The validation accuracy at iteration 1184  is               10.174999999999999%\n",
            "The validation accuracy at iteration 1200  is               10.2%\n",
            "The validation accuracy at iteration 1216  is               10.225%\n",
            "The validation accuracy at iteration 1232  is               10.299999999999999%\n",
            "The validation accuracy at iteration 1248  is               10.325%\n",
            "The validation accuracy at iteration 1264  is               10.4%\n",
            "The validation accuracy at iteration 1280  is               10.424999999999999%\n",
            "The validation accuracy at iteration 1296  is               10.475%\n",
            "The validation accuracy at iteration 1312  is               10.525%\n",
            "The validation accuracy at iteration 1328  is               10.549999999999999%\n",
            "The validation accuracy at iteration 1344  is               10.575%\n",
            "The validation accuracy at iteration 1360  is               10.575%\n",
            "The validation accuracy at iteration 1376  is               10.65%\n",
            "The validation accuracy at iteration 1392  is               10.725%\n",
            "The validation accuracy at iteration 1408  is               10.85%\n",
            "The validation accuracy at iteration 1424  is               10.9%\n",
            "The validation accuracy at iteration 1440  is               11.025%\n",
            "The validation accuracy at iteration 1456  is               11.025%\n",
            "The validation accuracy at iteration 1472  is               11.1%\n",
            "The validation accuracy at iteration 1488  is               11.175%\n",
            "The validation accuracy at iteration 1504  is               11.25%\n",
            "The validation accuracy at iteration 1520  is               11.275%\n",
            "The validation accuracy at iteration 1536  is               11.325000000000001%\n",
            "The validation accuracy at iteration 1552  is               11.375%\n",
            "The validation accuracy at iteration 1568  is               11.425%\n",
            "The validation accuracy at iteration 1584  is               11.450000000000001%\n",
            "The validation accuracy at iteration 1600  is               11.525%\n",
            "The validation accuracy at iteration 1616  is               11.575000000000001%\n",
            "The validation accuracy at iteration 1632  is               11.625%\n",
            "The validation accuracy at iteration 1648  is               11.65%\n",
            "The validation accuracy at iteration 1664  is               11.675%\n",
            "The validation accuracy at iteration 1680  is               11.725%\n",
            "The validation accuracy at iteration 1696  is               11.725%\n",
            "The validation accuracy at iteration 1712  is               11.75%\n",
            "The validation accuracy at iteration 1728  is               11.799999999999999%\n",
            "The validation accuracy at iteration 1744  is               11.85%\n",
            "The validation accuracy at iteration 1760  is               11.899999999999999%\n",
            "The validation accuracy at iteration 1776  is               11.899999999999999%\n",
            "The validation accuracy at iteration 1792  is               11.899999999999999%\n",
            "The validation accuracy at iteration 1808  is               11.95%\n",
            "The validation accuracy at iteration 1824  is               11.975%\n",
            "The validation accuracy at iteration 1840  is               12.025%\n",
            "The validation accuracy at iteration 1856  is               12.0%\n",
            "The validation accuracy at iteration 1872  is               12.0%\n",
            "The validation accuracy at iteration 1888  is               12.125%\n",
            "The validation accuracy at iteration 1904  is               12.125%\n",
            "The validation accuracy at iteration 1920  is               12.2%\n",
            "The validation accuracy at iteration 1936  is               12.225%\n",
            "The validation accuracy at iteration 1952  is               12.3%\n",
            "The validation accuracy at iteration 1968  is               12.375%\n",
            "The validation accuracy at iteration 1984  is               12.475%\n",
            "The validation accuracy at iteration 2000  is               12.5%\n",
            "The validation accuracy at iteration 2016  is               12.525%\n",
            "The validation accuracy at iteration 2032  is               12.575%\n",
            "The validation accuracy at iteration 2048  is               12.6%\n",
            "The validation accuracy at iteration 2064  is               12.625%\n",
            "The validation accuracy at iteration 2080  is               12.65%\n",
            "The validation accuracy at iteration 2096  is               12.675%\n",
            "The validation accuracy at iteration 2112  is               12.725%\n",
            "The validation accuracy at iteration 2128  is               12.75%\n",
            "The validation accuracy at iteration 2144  is               12.775%\n",
            "The validation accuracy at iteration 2160  is               12.8%\n",
            "The validation accuracy at iteration 2176  is               12.8%\n",
            "The validation accuracy at iteration 2192  is               12.85%\n",
            "The validation accuracy at iteration 2208  is               12.875%\n",
            "The validation accuracy at iteration 2224  is               12.950000000000001%\n",
            "The validation accuracy at iteration 2240  is               13.100000000000001%\n",
            "The validation accuracy at iteration 2256  is               13.15%\n",
            "The validation accuracy at iteration 2272  is               13.15%\n",
            "The validation accuracy at iteration 2288  is               13.25%\n",
            "The validation accuracy at iteration 2304  is               13.275%\n",
            "The validation accuracy at iteration 2320  is               13.3%\n",
            "The validation accuracy at iteration 2336  is               13.3%\n",
            "The validation accuracy at iteration 2352  is               13.4%\n",
            "The validation accuracy at iteration 2368  is               13.425%\n",
            "The validation accuracy at iteration 2384  is               13.475000000000001%\n",
            "The validation accuracy at iteration 2400  is               13.475000000000001%\n",
            "The validation accuracy at iteration 2416  is               13.450000000000001%\n",
            "The validation accuracy at iteration 2432  is               13.475000000000001%\n",
            "The validation accuracy at iteration 2448  is               13.575000000000001%\n",
            "The validation accuracy at iteration 2464  is               13.600000000000001%\n",
            "The validation accuracy at iteration 2480  is               13.600000000000001%\n",
            "The validation accuracy at iteration 2496  is               13.675%\n",
            "The validation accuracy at iteration 2512  is               13.725000000000001%\n",
            "The validation accuracy at iteration 2528  is               13.750000000000002%\n",
            "The validation accuracy at iteration 2544  is               13.8%\n",
            "The validation accuracy at iteration 2560  is               13.850000000000001%\n",
            "The validation accuracy at iteration 2576  is               13.900000000000002%\n",
            "The validation accuracy at iteration 2592  is               13.900000000000002%\n",
            "The validation accuracy at iteration 2608  is               13.950000000000001%\n",
            "The validation accuracy at iteration 2624  is               14.000000000000002%\n",
            "The validation accuracy at iteration 2640  is               14.025000000000002%\n",
            "The validation accuracy at iteration 2656  is               14.05%\n",
            "The validation accuracy at iteration 2672  is               14.099999999999998%\n",
            "The validation accuracy at iteration 2688  is               14.174999999999999%\n",
            "The validation accuracy at iteration 2704  is               14.2%\n",
            "The validation accuracy at iteration 2720  is               14.249999999999998%\n",
            "The validation accuracy at iteration 2736  is               14.299999999999999%\n",
            "The validation accuracy at iteration 2752  is               14.399999999999999%\n",
            "The validation accuracy at iteration 2768  is               14.399999999999999%\n",
            "The validation accuracy at iteration 2784  is               14.499999999999998%\n",
            "The validation accuracy at iteration 2800  is               14.524999999999999%\n",
            "The validation accuracy at iteration 2816  is               14.6%\n",
            "The validation accuracy at iteration 2832  is               14.674999999999999%\n",
            "The validation accuracy at iteration 2848  is               14.725%\n",
            "The validation accuracy at iteration 2864  is               14.799999999999999%\n",
            "The validation accuracy at iteration 2880  is               14.975%\n",
            "The validation accuracy at iteration 2896  is               15.024999999999999%\n",
            "The validation accuracy at iteration 2912  is               15.075%\n",
            "The validation accuracy at iteration 2928  is               15.125%\n",
            "The validation accuracy at iteration 2944  is               15.174999999999999%\n",
            "The validation accuracy at iteration 2960  is               15.275%\n",
            "The validation accuracy at iteration 2976  is               15.4%\n",
            "The validation accuracy at iteration 2992  is               15.5%\n",
            "The validation accuracy at iteration 3008  is               15.55%\n",
            "The validation accuracy at iteration 3024  is               15.6%\n",
            "The validation accuracy at iteration 3040  is               15.6%\n",
            "The validation accuracy at iteration 3056  is               15.675%\n",
            "The validation accuracy at iteration 3072  is               15.675%\n",
            "The validation accuracy at iteration 3088  is               15.75%\n",
            "The validation accuracy at iteration 3104  is               15.875%\n",
            "The validation accuracy at iteration 3120  is               15.950000000000001%\n",
            "The validation accuracy at iteration 3136  is               16.025%\n",
            "The validation accuracy at iteration 3152  is               16.075%\n",
            "The validation accuracy at iteration 3168  is               16.150000000000002%\n",
            "The validation accuracy at iteration 3184  is               16.25%\n",
            "The validation accuracy at iteration 3200  is               16.275000000000002%\n",
            "The validation accuracy at iteration 3200  is               16.275000000000002%\n",
            "The validation accuracy at iteration 3200  is               16.275000000000002%\n",
            "The validation accuracy at iteration 1800  is               82.6%\n",
            "The validation accuracy at iteration 3200  is               16.275000000000002%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "The validation accuracy at iteration 3200  is               16.275000000000002%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 3200  is               16.275000000000002%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "The validation accuracy at iteration 3200  is               16.275000000000002%\n",
            "The validation accuracy at iteration 2300  is               77.5%\n",
            "The validation accuracy at iteration 3200  is               16.275000000000002%\n",
            "[<__main__.Solver object at 0x7f2ca1c8c210>, <__main__.Solver object at 0x7f2cad78fb50>, <__main__.Solver object at 0x7f2ca1fac6d0>, <__main__.Solver object at 0x7f2ca258c910>, <__main__.Solver object at 0x7f2ca258c3d0>]\n",
            "The validation accuracy at iteration 16  is               8.35%\n",
            "The validation accuracy at iteration 32  is               8.375%\n",
            "The validation accuracy at iteration 48  is               8.375%\n",
            "The validation accuracy at iteration 64  is               8.425%\n",
            "The validation accuracy at iteration 80  is               8.450000000000001%\n",
            "The validation accuracy at iteration 96  is               8.525%\n",
            "The validation accuracy at iteration 112  is               8.55%\n",
            "The validation accuracy at iteration 128  is               8.649999999999999%\n",
            "The validation accuracy at iteration 144  is               8.649999999999999%\n",
            "The validation accuracy at iteration 160  is               8.7%\n",
            "The validation accuracy at iteration 176  is               8.7%\n",
            "The validation accuracy at iteration 192  is               8.75%\n",
            "The validation accuracy at iteration 208  is               8.825%\n",
            "The validation accuracy at iteration 224  is               8.825%\n",
            "The validation accuracy at iteration 240  is               8.85%\n",
            "The validation accuracy at iteration 256  is               8.924999999999999%\n",
            "The validation accuracy at iteration 272  is               9.1%\n",
            "The validation accuracy at iteration 288  is               9.175%\n",
            "The validation accuracy at iteration 304  is               9.225%\n",
            "The validation accuracy at iteration 320  is               9.35%\n",
            "The validation accuracy at iteration 336  is               9.35%\n",
            "The validation accuracy at iteration 352  is               9.425%\n",
            "The validation accuracy at iteration 368  is               9.575%\n",
            "The validation accuracy at iteration 384  is               9.575%\n",
            "The validation accuracy at iteration 400  is               9.65%\n",
            "The validation accuracy at iteration 416  is               9.675%\n",
            "The validation accuracy at iteration 432  is               9.700000000000001%\n",
            "The validation accuracy at iteration 448  is               9.75%\n",
            "The validation accuracy at iteration 464  is               9.75%\n",
            "The validation accuracy at iteration 480  is               9.8%\n",
            "The validation accuracy at iteration 496  is               9.85%\n",
            "The validation accuracy at iteration 512  is               9.9%\n",
            "The validation accuracy at iteration 528  is               9.950000000000001%\n",
            "The validation accuracy at iteration 544  is               10.025%\n",
            "The validation accuracy at iteration 560  is               10.05%\n",
            "The validation accuracy at iteration 576  is               10.125%\n",
            "The validation accuracy at iteration 592  is               10.2%\n",
            "The validation accuracy at iteration 608  is               10.299999999999999%\n",
            "The validation accuracy at iteration 624  is               10.375%\n",
            "The validation accuracy at iteration 640  is               10.424999999999999%\n",
            "The validation accuracy at iteration 656  is               10.5%\n",
            "The validation accuracy at iteration 672  is               10.625%\n",
            "The validation accuracy at iteration 688  is               10.725%\n",
            "The validation accuracy at iteration 704  is               10.875%\n",
            "The validation accuracy at iteration 720  is               10.875%\n",
            "The validation accuracy at iteration 736  is               10.95%\n",
            "The validation accuracy at iteration 752  is               11.0%\n",
            "The validation accuracy at iteration 768  is               11.025%\n",
            "The validation accuracy at iteration 784  is               11.15%\n",
            "The validation accuracy at iteration 800  is               11.225%\n",
            "The validation accuracy at iteration 816  is               11.275%\n",
            "The validation accuracy at iteration 832  is               11.3%\n",
            "The validation accuracy at iteration 848  is               11.325000000000001%\n",
            "The validation accuracy at iteration 864  is               11.35%\n",
            "The validation accuracy at iteration 880  is               11.375%\n",
            "The validation accuracy at iteration 896  is               11.450000000000001%\n",
            "The validation accuracy at iteration 912  is               11.525%\n",
            "The validation accuracy at iteration 928  is               11.55%\n",
            "The validation accuracy at iteration 944  is               11.675%\n",
            "The validation accuracy at iteration 960  is               11.700000000000001%\n",
            "The validation accuracy at iteration 976  is               11.799999999999999%\n",
            "The validation accuracy at iteration 992  is               11.85%\n",
            "The validation accuracy at iteration 1008  is               11.85%\n",
            "The validation accuracy at iteration 1024  is               11.975%\n",
            "The validation accuracy at iteration 1040  is               12.025%\n",
            "The validation accuracy at iteration 1056  is               12.075%\n",
            "The validation accuracy at iteration 1072  is               12.125%\n",
            "The validation accuracy at iteration 1088  is               12.174999999999999%\n",
            "The validation accuracy at iteration 1104  is               12.25%\n",
            "The validation accuracy at iteration 1120  is               12.325%\n",
            "The validation accuracy at iteration 1136  is               12.35%\n",
            "The validation accuracy at iteration 1152  is               12.425%\n",
            "The validation accuracy at iteration 1168  is               12.5%\n",
            "The validation accuracy at iteration 1184  is               12.525%\n",
            "The validation accuracy at iteration 1200  is               12.575%\n",
            "The validation accuracy at iteration 1216  is               12.7%\n",
            "The validation accuracy at iteration 1232  is               12.8%\n",
            "The validation accuracy at iteration 1248  is               12.825000000000001%\n",
            "The validation accuracy at iteration 1264  is               12.8%\n",
            "The validation accuracy at iteration 1280  is               12.825000000000001%\n",
            "The validation accuracy at iteration 1296  is               12.925%\n",
            "The validation accuracy at iteration 1312  is               12.950000000000001%\n",
            "The validation accuracy at iteration 1328  is               13.025%\n",
            "The validation accuracy at iteration 1344  is               13.075000000000001%\n",
            "The validation accuracy at iteration 1360  is               13.100000000000001%\n",
            "The validation accuracy at iteration 1376  is               13.100000000000001%\n",
            "The validation accuracy at iteration 1392  is               13.100000000000001%\n",
            "The validation accuracy at iteration 1408  is               13.200000000000001%\n",
            "The validation accuracy at iteration 1424  is               13.3%\n",
            "The validation accuracy at iteration 1440  is               13.325000000000001%\n",
            "The validation accuracy at iteration 1456  is               13.425%\n",
            "The validation accuracy at iteration 1472  is               13.55%\n",
            "The validation accuracy at iteration 1488  is               13.625000000000002%\n",
            "The validation accuracy at iteration 1504  is               13.65%\n",
            "The validation accuracy at iteration 1520  is               13.725000000000001%\n",
            "The validation accuracy at iteration 1536  is               13.725000000000001%\n",
            "The validation accuracy at iteration 1552  is               13.775%\n",
            "The validation accuracy at iteration 1568  is               13.825000000000001%\n",
            "The validation accuracy at iteration 1584  is               13.900000000000002%\n",
            "The validation accuracy at iteration 1600  is               13.925%\n",
            "The validation accuracy at iteration 1616  is               14.025000000000002%\n",
            "The validation accuracy at iteration 1632  is               14.075%\n",
            "The validation accuracy at iteration 1648  is               14.124999999999998%\n",
            "The validation accuracy at iteration 1664  is               14.249999999999998%\n",
            "The validation accuracy at iteration 1680  is               14.299999999999999%\n",
            "The validation accuracy at iteration 1696  is               14.325%\n",
            "The validation accuracy at iteration 1712  is               14.35%\n",
            "The validation accuracy at iteration 1728  is               14.524999999999999%\n",
            "The validation accuracy at iteration 1744  is               14.575%\n",
            "The validation accuracy at iteration 1760  is               14.6%\n",
            "The validation accuracy at iteration 1776  is               14.674999999999999%\n",
            "The validation accuracy at iteration 1792  is               14.674999999999999%\n",
            "The validation accuracy at iteration 1808  is               14.725%\n",
            "The validation accuracy at iteration 1824  is               14.825%\n",
            "The validation accuracy at iteration 1840  is               14.924999999999999%\n",
            "The validation accuracy at iteration 1856  is               15.0%\n",
            "The validation accuracy at iteration 1872  is               15.075%\n",
            "The validation accuracy at iteration 1888  is               15.174999999999999%\n",
            "The validation accuracy at iteration 1904  is               15.2%\n",
            "The validation accuracy at iteration 1920  is               15.325%\n",
            "The validation accuracy at iteration 1936  is               15.35%\n",
            "The validation accuracy at iteration 1952  is               15.4%\n",
            "The validation accuracy at iteration 1968  is               15.5%\n",
            "The validation accuracy at iteration 1984  is               15.575%\n",
            "The validation accuracy at iteration 2000  is               15.65%\n",
            "The validation accuracy at iteration 2016  is               15.75%\n",
            "The validation accuracy at iteration 2032  is               15.8%\n",
            "The validation accuracy at iteration 2048  is               15.9%\n",
            "The validation accuracy at iteration 2064  is               15.975%\n",
            "The validation accuracy at iteration 2080  is               16.05%\n",
            "The validation accuracy at iteration 2096  is               16.1%\n",
            "The validation accuracy at iteration 2112  is               16.175%\n",
            "The validation accuracy at iteration 2128  is               16.275000000000002%\n",
            "The validation accuracy at iteration 2144  is               16.325%\n",
            "The validation accuracy at iteration 2160  is               16.3%\n",
            "The validation accuracy at iteration 2176  is               16.425%\n",
            "The validation accuracy at iteration 2192  is               16.5%\n",
            "The validation accuracy at iteration 2208  is               16.575%\n",
            "The validation accuracy at iteration 2224  is               16.650000000000002%\n",
            "The validation accuracy at iteration 2240  is               16.7%\n",
            "The validation accuracy at iteration 2256  is               16.75%\n",
            "The validation accuracy at iteration 2272  is               16.925%\n",
            "The validation accuracy at iteration 2288  is               16.975%\n",
            "The validation accuracy at iteration 2300  is               17.025000000000002%\n",
            "The validation accuracy at iteration 2300  is               17.025000000000002%\n",
            "The validation accuracy at iteration 1800  is               82.6%\n",
            "The validation accuracy at iteration 2300  is               17.025000000000002%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "The validation accuracy at iteration 2300  is               17.025000000000002%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 2300  is               17.025000000000002%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "The validation accuracy at iteration 2300  is               17.025000000000002%\n",
            "The validation accuracy at iteration 2300  is               77.5%\n",
            "The validation accuracy at iteration 2300  is               17.025000000000002%\n",
            "[<__main__.Solver object at 0x7f2ca1c8c210>, <__main__.Solver object at 0x7f2cad78fb50>, <__main__.Solver object at 0x7f2ca1fac6d0>, <__main__.Solver object at 0x7f2ca258c910>, <__main__.Solver object at 0x7f2ca258c3d0>]\n",
            "The validation accuracy at iteration 16  is               11.175%\n",
            "The validation accuracy at iteration 32  is               11.225%\n",
            "The validation accuracy at iteration 48  is               11.225%\n",
            "The validation accuracy at iteration 64  is               11.3%\n",
            "The validation accuracy at iteration 80  is               11.4%\n",
            "The validation accuracy at iteration 96  is               11.425%\n",
            "The validation accuracy at iteration 112  is               11.450000000000001%\n",
            "The validation accuracy at iteration 128  is               11.5%\n",
            "The validation accuracy at iteration 144  is               11.575000000000001%\n",
            "The validation accuracy at iteration 160  is               11.575000000000001%\n",
            "The validation accuracy at iteration 176  is               11.600000000000001%\n",
            "The validation accuracy at iteration 192  is               11.600000000000001%\n",
            "The validation accuracy at iteration 208  is               11.600000000000001%\n",
            "The validation accuracy at iteration 224  is               11.600000000000001%\n",
            "The validation accuracy at iteration 240  is               11.575000000000001%\n",
            "The validation accuracy at iteration 256  is               11.600000000000001%\n",
            "The validation accuracy at iteration 272  is               11.600000000000001%\n",
            "The validation accuracy at iteration 288  is               11.65%\n",
            "The validation accuracy at iteration 304  is               11.700000000000001%\n",
            "The validation accuracy at iteration 320  is               11.700000000000001%\n",
            "The validation accuracy at iteration 336  is               11.725%\n",
            "The validation accuracy at iteration 352  is               11.75%\n",
            "The validation accuracy at iteration 368  is               11.75%\n",
            "The validation accuracy at iteration 384  is               11.75%\n",
            "The validation accuracy at iteration 400  is               11.799999999999999%\n",
            "The validation accuracy at iteration 416  is               11.85%\n",
            "The validation accuracy at iteration 432  is               11.924999999999999%\n",
            "The validation accuracy at iteration 448  is               11.975%\n",
            "The validation accuracy at iteration 464  is               12.0%\n",
            "The validation accuracy at iteration 480  is               12.1%\n",
            "The validation accuracy at iteration 496  is               12.15%\n",
            "The validation accuracy at iteration 512  is               12.225%\n",
            "The validation accuracy at iteration 528  is               12.25%\n",
            "The validation accuracy at iteration 544  is               12.275%\n",
            "The validation accuracy at iteration 560  is               12.325%\n",
            "The validation accuracy at iteration 576  is               12.375%\n",
            "The validation accuracy at iteration 592  is               12.425%\n",
            "The validation accuracy at iteration 608  is               12.5%\n",
            "The validation accuracy at iteration 624  is               12.5%\n",
            "The validation accuracy at iteration 640  is               12.525%\n",
            "The validation accuracy at iteration 656  is               12.55%\n",
            "The validation accuracy at iteration 672  is               12.575%\n",
            "The validation accuracy at iteration 688  is               12.6%\n",
            "The validation accuracy at iteration 704  is               12.6%\n",
            "The validation accuracy at iteration 720  is               12.625%\n",
            "The validation accuracy at iteration 736  is               12.725%\n",
            "The validation accuracy at iteration 752  is               12.8%\n",
            "The validation accuracy at iteration 768  is               12.9%\n",
            "The validation accuracy at iteration 784  is               13.05%\n",
            "The validation accuracy at iteration 800  is               13.075000000000001%\n",
            "The validation accuracy at iteration 816  is               13.125%\n",
            "The validation accuracy at iteration 832  is               13.125%\n",
            "The validation accuracy at iteration 848  is               13.175%\n",
            "The validation accuracy at iteration 864  is               13.225000000000001%\n",
            "The validation accuracy at iteration 880  is               13.25%\n",
            "The validation accuracy at iteration 896  is               13.3%\n",
            "The validation accuracy at iteration 912  is               13.375%\n",
            "The validation accuracy at iteration 928  is               13.4%\n",
            "The validation accuracy at iteration 944  is               13.425%\n",
            "The validation accuracy at iteration 960  is               13.475000000000001%\n",
            "The validation accuracy at iteration 976  is               13.5%\n",
            "The validation accuracy at iteration 992  is               13.525%\n",
            "The validation accuracy at iteration 1008  is               13.625000000000002%\n",
            "The validation accuracy at iteration 1024  is               13.625000000000002%\n",
            "The validation accuracy at iteration 1040  is               13.65%\n",
            "The validation accuracy at iteration 1056  is               13.675%\n",
            "The validation accuracy at iteration 1072  is               13.675%\n",
            "The validation accuracy at iteration 1088  is               13.675%\n",
            "The validation accuracy at iteration 1104  is               13.775%\n",
            "The validation accuracy at iteration 1120  is               13.8%\n",
            "The validation accuracy at iteration 1136  is               13.825000000000001%\n",
            "The validation accuracy at iteration 1152  is               13.950000000000001%\n",
            "The validation accuracy at iteration 1168  is               13.950000000000001%\n",
            "The validation accuracy at iteration 1184  is               14.05%\n",
            "The validation accuracy at iteration 1200  is               14.124999999999998%\n",
            "The validation accuracy at iteration 1216  is               14.224999999999998%\n",
            "The validation accuracy at iteration 1232  is               14.299999999999999%\n",
            "The validation accuracy at iteration 1248  is               14.35%\n",
            "The validation accuracy at iteration 1264  is               14.399999999999999%\n",
            "The validation accuracy at iteration 1280  is               14.45%\n",
            "The validation accuracy at iteration 1296  is               14.499999999999998%\n",
            "The validation accuracy at iteration 1312  is               14.549999999999999%\n",
            "The validation accuracy at iteration 1328  is               14.575%\n",
            "The validation accuracy at iteration 1344  is               14.649999999999999%\n",
            "The validation accuracy at iteration 1360  is               14.774999999999999%\n",
            "The validation accuracy at iteration 1376  is               14.825%\n",
            "The validation accuracy at iteration 1392  is               14.875%\n",
            "The validation accuracy at iteration 1408  is               14.95%\n",
            "The validation accuracy at iteration 1424  is               15.0%\n",
            "The validation accuracy at iteration 1440  is               15.075%\n",
            "The validation accuracy at iteration 1456  is               15.15%\n",
            "The validation accuracy at iteration 1472  is               15.174999999999999%\n",
            "The validation accuracy at iteration 1488  is               15.25%\n",
            "The validation accuracy at iteration 1504  is               15.275%\n",
            "The validation accuracy at iteration 1520  is               15.375%\n",
            "The validation accuracy at iteration 1536  is               15.425%\n",
            "The validation accuracy at iteration 1552  is               15.45%\n",
            "The validation accuracy at iteration 1568  is               15.45%\n",
            "The validation accuracy at iteration 1584  is               15.475%\n",
            "The validation accuracy at iteration 1600  is               15.5%\n",
            "The validation accuracy at iteration 1616  is               15.5%\n",
            "The validation accuracy at iteration 1632  is               15.575%\n",
            "The validation accuracy at iteration 1648  is               15.6%\n",
            "The validation accuracy at iteration 1664  is               15.625%\n",
            "The validation accuracy at iteration 1680  is               15.7%\n",
            "The validation accuracy at iteration 1696  is               15.75%\n",
            "The validation accuracy at iteration 1712  is               15.75%\n",
            "The validation accuracy at iteration 1728  is               15.85%\n",
            "The validation accuracy at iteration 1744  is               15.875%\n",
            "The validation accuracy at iteration 1760  is               15.875%\n",
            "The validation accuracy at iteration 1776  is               15.975%\n",
            "The validation accuracy at iteration 1792  is               16.025%\n",
            "The validation accuracy at iteration 1800  is               16.1%\n",
            "The validation accuracy at iteration 1800  is               16.1%\n",
            "The validation accuracy at iteration 1800  is               82.6%\n",
            "The validation accuracy at iteration 1800  is               16.1%\n",
            "The validation accuracy at iteration 5350  is               82.525%\n",
            "The validation accuracy at iteration 1800  is               16.1%\n",
            "The validation accuracy at iteration 3200  is               82.5%\n",
            "The validation accuracy at iteration 1800  is               16.1%\n",
            "The validation accuracy at iteration 2300  is               82.425%\n",
            "The validation accuracy at iteration 1800  is               16.1%\n",
            "The validation accuracy at iteration 2300  is               77.5%\n",
            "The validation accuracy at iteration 1800  is               16.1%\n",
            "[<__main__.Solver object at 0x7f2ca1c8c210>, <__main__.Solver object at 0x7f2cad78fb50>, <__main__.Solver object at 0x7f2ca1fac6d0>, <__main__.Solver object at 0x7f2ca258c910>, <__main__.Solver object at 0x7f2ca258c3d0>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''svm = LinearSVM()\n",
        "solver = Solver(svm,DATA)\n",
        "solver.validate()'''\n",
        "#This is always about 10% which makes sense"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "R7YiQjDV2wCf",
        "outputId": "951bf480-0dd7-4ad9-ece5-0769dfad5566"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'svm = LinearSVM()\\nsolver = Solver(svm,DATA)\\nsolver.validate()'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## this is where we can use the val data to find which are our top preforming models \n",
        "\n",
        "## maybe call a training loop where model is replaced if it has better performance than the 5th best.\n",
        "\n",
        "#y_pred = svm.predict(x)"
      ],
      "metadata": {
        "id": "8rhE8gBKaARC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "214d4a91-d003-443c-a3a6-64239ff7243d"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-148-ce6251907878>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m## maybe call a training loop where model is replaced if it has better performance than the 5th best.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the testing performance of your top-5 performing models on the test set and print the results. "
      ],
      "metadata": {
        "id": "Dl4R1tyz4VpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_models1 = best_models.copy()"
      ],
      "metadata": {
        "id": "c6AbZQeqCvJ3"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "best_models = best_models1.copy()## reset"
      ],
      "metadata": {
        "id": "-dA_3Id8z27R"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## we need to find the test data... \n",
        "'''x_test, y_test'''\n",
        "\n",
        "## can we do solver.DATA = X_test? \n",
        "'''\n",
        "Solver has params: (these are used to return accuracy so that's all that needs to be changed)\n",
        "self.X_val = data[\"X_val\"]\n",
        "self.y_val = data[\"Y_val\"]\n",
        "'''\n",
        "for solvr in best_models: \n",
        "  solvr.X_val = x_test\n",
        "  solvr.y_val = y_test\n",
        "  acc = solvr.accuracy()\n",
        "  print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTsPEZde8yxo",
        "outputId": "41720677-535e-4491-96a8-e2d1fe07a51c"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The validation accuracy at iteration 2300  is               84.56%\n",
            "0.8456\n",
            "The validation accuracy at iteration 2300  is               84.56%\n",
            "0.8456\n",
            "The validation accuracy at iteration 2300  is               84.56%\n",
            "0.8456\n",
            "The validation accuracy at iteration 2300  is               84.56%\n",
            "0.8456\n",
            "The validation accuracy at iteration 2300  is               84.56%\n",
            "0.8456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the next cell to visualize the weights corresponding to each sample in the *best* performing SVM models. You should have ten 28x28 images.\n",
        "\n",
        "Make sure to rescale the  weights to be between 0 and 255.\n",
        "\n",
        "Depending on your learning rate and weights, it might not look so great. If all the images look the same but you have good accuracy, try subtracting the average of weights from weights of each class. \n",
        "\n",
        "You can add additional cells below."
      ],
      "metadata": {
        "id": "srNp8XPEbVAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([1,2,3])*np.array([4,5,6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obS-MPDpoTUf",
        "outputId": "597e3fac-42b4-45e3-b4be-c83fd4141ec7"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4, 10, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "solvr = best_models[0]\n",
        "print(solvr.model.params['W1'].shape) \n",
        "weights = solvr.model.params['W1'][:-1,:].copy()\n",
        "\n",
        "for i in range(10): \n",
        "  img = weights[:,i]\n",
        "  \n",
        "  img = img.reshape((28,28))\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bY8n8b2CzrQn",
        "outputId": "0b033ba3-029a-4c54-e4ba-749a5022f3b2"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(785, 10)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARjElEQVR4nO3dX4hc53kG8OeZ0a5GfyzZkm0hJNGkRmkx/eOURRRiWrchwfGNHAgmuggumCoXMSSQQo17EV+a0CTkogSUWkQpqdPQxLUuTBvVpJjcGK+Nakt2UzlCxlLXkuVNpJXXK83OvL3YI7G297zves7MnCO9zw+WnZ1vzsy3Z8+z8+c93/fRzCAiN75W3R0QkfFQ2EWSUNhFklDYRZJQ2EWSWDPOB9u0ZY3dvmNynA8pksq5M1dwcXaRK7VVCjvJewF8F0AbwD+a2ePe7W/fMYlv/tvvVXnI2rTQr7sLIqG/uf9EadvAL+NJtgH8A4DPAbgTwD6Sdw56fyIyWlXes+8B8LqZnTSzKwB+DGDvcLolIsNWJew7ALy57OfTxXXvQ3I/yWmS0xdmFys8nIhUMfJP483sgJlNmdnU5i1j/TxQRJapEvYzAHYt+3lncZ2INFCVsL8AYDfJj5OcBPBFAIeH0y0RGbaBX1eb2SLJhwH8B5ZKbwfN7Hi0nUpYw9em9qksIcpHsVZ6E21mzwB4psp9iMh46HRZkSQUdpEkFHaRJBR2kSQUdpEkFHaRJMZ6/iphqgmLAGg79fBR0TO7SBIKu0gSCrtIEgq7SBIKu0gSCrtIEmOfOqaOkoOI6JldJA2FXSQJhV0kCYVdJAmFXSQJhV0kCYVdJAkt0TIEdU+P3UW7tK1n/v/zrvmHQA8rrv57TT+4/5YzpDk65yIaDj1Bfzkx7/7r/puNivfX0jO7SBIKu0gSCrtIEgq7SBIKu0gSCrtIEgq7SBJjnkr6xq1vVtEP/udesfI6OgAs2ERp23x/rb9tv3xboHod3jPBntveYddvbwXtzvad1pVKj91cI1qymeQpAHMAegAWzWyqyv2JyOgM45n9L8zs/BDuR0RGSO/ZRZKoGnYD8HOSL5Lcv9INSO4nOU1y+sKsfy6ziIxO1Zfxd5vZGZK3AzhC8n/M7LnlNzCzAwAOAMAn/nCdZpsUqUmlZ3YzO1N8PwfgKQB7htEpERm+gcNOcgPJm65eBvBZAMeG1TERGa4qL+O3AXiK5NX7+Wcz+3d/k5xLNke1aq9ODgDvBrXyuV6ntC2qs8/3J932blDjj8bLe8I6e1BH39hecNtvbs+XtrUtGCsPv2/X43E8cNjN7CSAPx5iX0RkhFR6E0lCYRdJQmEXSUJhF0lCYRdJQlNJF6osJR0N84yGqFYprQHAXN8pvfWqld76NvgQ1mj7bsvfL/1gv0aluwWWlzSjaag79J8HJ4PSXF00lbSIKOwiWSjsIkko7CJJKOwiSSjsIkko7CJJjH0q6Sr17KaquixyNIw0GgJ72ZkOOrrvdjC190Sr2rLK3r6pWsMPh9/quex9tDdEklDYRZJQ2EWSUNhFklDYRZJQ2EWSUNhFkmjUePbWdTg9LwD0gzp4PN7d/zP0gzp+yzl3IZqOORoTHrVHfzPvHIBouehI9NjeOQTR+R7R0uKNPVadQ03P7CJJKOwiSSjsIkko7CJJKOwiSSjsIkko7CJJjLfOzgbXJ0coqpNXHdftjSnvBHXy9a3LbntUZ4/GjHu/e5f+ePRIVCv39ks0b/xk8HtH8wDUhc4+CZ/ZSR4keY7ksWXXbSF5hOSJ4vstQ+qriIzIal7G/wDAvR+47hEAz5rZbgDPFj+LSIOFYTez5wDMfuDqvQAOFZcPAbh/yP0SkSEb9AO6bWY2U1x+C8C2shuS3E9ymuT0hXeauT6WSAaVP403MwPKPxUwswNmNmVmU5u3VvtARkQGN2jYz5LcDgDF93PD65KIjMKgYT8M4MHi8oMAnh5Od0RkVMI6O8knAdwD4FaSpwF8A8DjAH5C8iEAbwB4YDUPRlhj65N1imrV0Xh4rxZedbx6NC98t++/NfPmdo/m248ee20wVr/D8vaojh7V4auqY/2EMOxmtq+k6dND7ouIjJBOlxVJQmEXSUJhF0lCYRdJQmEXSWLsU0nfiEs2R9MOVxkGuqrHd0pU0ZDiqG/RdM+Xeh23fS5o91QtG/olSb+0NurjdFRDvb0irZ7ZRZJQ2EWSUNhFklDYRZJQ2EWSUNhFklDYRZIYa52duH6nkq5aCx8ld7rmYFtvSWUAmO9P+u09v/1yv/wQW9OqdixEw6W9WnrVpairquN8k+YewSIyVAq7SBIKu0gSCrtIEgq7SBIKu0gSCrtIEhrPvloV6q5RPTiq6bbN32feVNMLvbXutpfNPwSq1NEB/xyAFq+420ZTSUftVYz6OB3V/VdasllEbgwKu0gSCrtIEgq7SBIKu0gSCrtIEgq7SBJjHs9u12+d3RHVe6M6ejS2ukt/WeSesyxyP1juOVpyuW/+9tE4f39Oe/9YaPLcBxMN7luZ8Jmd5EGS50geW3bdYyTPkDxafN032m6KSFWreRn/AwD3rnD9d8zsruLrmeF2S0SGLQy7mT0HYHYMfRGREaryAd3DJF8uXubfUnYjkvtJTpOc/s3s9fc+R+RGMWjYvwfgDgB3AZgB8K2yG5rZATObMrOpW7bow3+RugyUPjM7a2Y9M+sD+D6APcPtlogM20BhJ7l92Y+fB3Cs7LYi0gxhnZ3kkwDuAXArydMAvgHgHpJ3ATAApwB8ebUPGNVWG8vpdlQnnwzaO8G47uhfsjv3e7BtL6iTR+u3xzPTl4v2W3RORiuYJ8A7/yGaYyB67KaeL+KdFRGG3cz2rXD1E4N3R0TqoE/MRJJQ2EWSUNhFklDYRZJQ2EWSGPuSzV7JotXQcgYAdFn+f7FtfhmnQ7881Wv5/3OjqaS9MtKElS9bvLRtcN/BUM55+FNNezotf7+EpbmgjOv9btHvHQ1hbeoQV6/0pmd2kSQUdpEkFHaRJBR2kSQUdpEkFHaRJBR2kSTGXmevqz5ZdUiiN6Vy1aGYE/Rr4d6SzMUDlIrOAYiGsHadaaoBYKLl18I90XkV0X6J2r3zG6Iaflhnb+g5IVqyWUQUdpEsFHaRJBR2kSQUdpEkFHaRJBR2kSTGvmRzlfpkOyg3j9KVYEx5Ff3gf260LLInmio6uu+ozh7dv6fdipa69vd5NEW3V4fvhNN7R+dOjI6/x31ev/TMLpKEwi6ShMIukoTCLpKEwi6ShMIukoTCLpLEWOvsLQCdGmvlnjb9jnUrjMNfMGdJZQAXex23fb6/duD7n+/52873/XnfLwXbL/b9qvBaZ274aN74aFnleDx7efv6oM6+Pjge6tR25jeg0+/wmZ3kLpK/IPkqyeMkv1pcv4XkEZIniu+3DNJxERmP1byMXwTwdTO7E8CfAvgKyTsBPALgWTPbDeDZ4mcRaagw7GY2Y2YvFZfnALwGYAeAvQAOFTc7BOD+UXVSRKr7SB/QkfwYgE8CeB7ANjObKZreArCtZJv9JKdJTr8z28z1sUQyWHXYSW4E8FMAXzOzi8vbzMyAlUe4mNkBM5sys6mtW/Thv0hdVpU+khNYCvqPzOxnxdVnSW4v2rcDODeaLorIMISlNy59lv8EgNfM7NvLmg4DeBDA48X3p1dxX+g4Sx/XqRWUWq44pZpWUJaLSm/nFze57We7fvtvu+tK2+a6fllvoecfAovBENc1QQlr8+RCadvall86667xHzuawtsbxrqh5f+9J0Z8nHrlsyq8e11Nnf1TAL4E4BWSR4vrHsVSyH9C8iEAbwB4oFIvRWSkwrCb2S9R/g/j08PtjoiMSjNfU4vI0CnsIkko7CJJKOwiSSjsIkmMeYgrsZZjfchroiGsIW9Z5J5f753rldfBAeDUwla3/VcXVjwT+ZpzlzaWtr077w9R7ff9//etYLrnzrorbvu2my6Vtk0Gdfbtkxfc9ngp7PL2iaDOPVFpQuchHG+OlnMwtpzfS8/sIkko7CJJKOwiSSjsIkko7CJJKOwiSSjsIkmMeclmYIKD1y+9GuKobXT6vZ7lY7aBeDz7qXf9Ovuvz97qtvN0eR1/8rf+PotmyA5mucalrf4NLt9e/ruvbft19l2d37jt3Yq18CrqqqNXu18RSUFhF0lCYRdJQmEXSUJhF0lCYRdJQmEXSWLsg8tHVStv1zgf/a41/mPf3J532y8v+n+G/nl/TPqm0+X7dMNbfiG91fXH4l/eFIx3v+zXuufb5XX4mfU3udu+ud5fGHjn5Kzbflt7rrStw8vutkvrmZaLjuMq88K3gvnwPd6WemYXSUJhF0lCYRdJQmEXSUJhF0lCYRdJQmEXSWI167PvAvBDANuwVMY7YGbfJfkYgL8G8HZx00fN7BnvvgzAIvz1vD3eON+++fc7yrHw0Rj9djC/eYS9YEy686u3L/uP3V7w27sb/MduLfrta+bK982FixvcbV9fd5vbfttk+Zz0QHR+gz9WfqHlz4c/Ec5Z7za7I/GrjJXvOZX21ZxUswjg62b2EsmbALxI8kjR9h0z+/uBeyYiY7Oa9dlnAMwUl+dIvgZgx6g7JiLD9ZHes5P8GIBPAni+uOphki+TPEhyxXMbSe4nOU1y+vw7g7+EF5FqVh12khsB/BTA18zsIoDvAbgDwF1Yeub/1krbmdkBM5sys6lbt9Y3Z5hIdqsKO8kJLAX9R2b2MwAws7Nm1jOzPoDvA9gzum6KSFVh2EkSwBMAXjOzby+7fvuym30ewLHhd09EhmU1n8Z/CsCXALxC8mhx3aMA9pG8C0sVtVMAvhzdUR+Gub5f0vB4wwZbQbmiypDDiFfuAIA/X/em2/6vk/5U1Dbh3//W4+Xbt//rJXdbtPy3Vp07d7vtm076w2+5WF6ieuePypeaBoD/27nTbX/yDn8K7qO7yrffvu6iu+1tk+XDYwFg85r33PaNbf9v6una4G93Z3vPl7at5tP4XwIrJsWtqYtIs+gMOpEkFHaRJBR2kSQUdpEkFHaRJBR2kSTGOpX0bK+Df5n7/YG339CKpv8tt9D3l01u0a9lT7J8auEOuwP16aov3P6i3/4Zv/2dvyyvV0fDa7sWHQLn3db5/qS/dbe8bzMLm91t337Pr8Pv3vS2277JqYVHdfKT7/nLZK9t+VNNr235x8TMlZtL2z7Recvdtu2ss+39vfXMLpKEwi6ShMIukoTCLpKEwi6ShMIukoTCLpIEzQZfHvYjPxj5NoA3ll11K6JCbn2a2rem9gtQ3wY1zL79jpmtOAf3WMP+oQcnp81sqrYOOJrat6b2C1DfBjWuvullvEgSCrtIEnWH/UDNj+9pat+a2i9AfRvUWPpW63t2ERmfup/ZRWRMFHaRJGoJO8l7Sf6K5OskH6mjD2VIniL5CsmjJKdr7stBkudIHlt23RaSR0ieKL6vuMZeTX17jOSZYt8dJXlfTX3bRfIXJF8leZzkV4vra913Tr/Gst/G/p6dZBvA/wL4DIDTAF4AsM/MXh1rR0qQPAVgysxqPwGD5J8BuATgh2b2B8V13wQwa2aPF/8obzGzv21I3x4DcKnuZbyL1Yq2L19mHMD9AP4KNe47p18PYAz7rY5n9j0AXjezk2Z2BcCPAeytoR+NZ2bPAZj9wNV7ARwqLh/C0sEydiV9awQzmzGzl4rLcwCuLjNe675z+jUWdYR9B4Dl6yGdRrPWezcAPyf5Isn9dXdmBdvMbKa4/BaAbXV2ZgXhMt7j9IFlxhuz7wZZ/rwqfUD3YXeb2Z8A+ByArxQvVxvJlt6DNal2uqplvMdlhWXGr6lz3w26/HlVdYT9DIBdy37eWVzXCGZ2pvh+DsBTaN5S1GevrqBbfD9Xc3+uadIy3istM44G7Ls6lz+vI+wvANhN8uMkJwF8EcDhGvrxISQ3FB+cgOQGAJ9F85aiPgzgweLygwCerrEv79OUZbzLlhlHzfuu9uXPzWzsXwDuw9In8r8G8Hd19KGkX78L4L+Lr+N19w3Ak1h6WdfF0mcbDwHYCuBZACcA/CeALQ3q2z8BeAXAy1gK1vaa+nY3ll6ivwzgaPF1X937zunXWPabTpcVSUIf0IkkobCLJKGwiyShsIskobCLJKGwiyShsIsk8f/vMnB+wD/LEAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''solvr = best_models[2]\n",
        "print(solvr.model.params['W1'].shape) \n",
        "weights = solvr.model.params['W1'][:-1,:].copy()\n",
        "\n",
        "## we want an average for each feature (each row)\n",
        "## we want an average per pixel across all classes \n",
        "## we should have 784 averages, \n",
        "  ## then we should subtract each avg(for a pixel) from its respective pixel\n",
        "\n",
        "print(np.amax(weights, axis = 1).shape)## this is our average for each pixel\n",
        "#print(np.amax(weights, axis = 1)) \n",
        "avg = np.amax(weights, axis = 1)\n",
        "for i in range(784): \n",
        "  weights[i:] -= avg[i]## for each pixel(row) subtract the mean for that pixel\n",
        "\n",
        "weights *= int(255/weights.max())\n",
        "for i in range(10): \n",
        "  img = weights[:,i]\n",
        "  \n",
        "  img = img.reshape((28,28))\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "H3eiYJybyofX",
        "outputId": "07c97972-dc6d-4893-ae1c-1864bbe45d1b"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(785, 10)\n",
            "(784,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OverflowError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-225-c82f501585a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m## for each pixel(row) subtract the mean for that pixel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOverflowError\u001b[0m: cannot convert float infinity to integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "solvr = best_models[2]\n",
        "print(solvr.model.params['W1'].shape)## this should be a dictionary where we can get W1 \n",
        "weights = solvr.model.params['W1'][:-1,:].copy()## I think this should be the last row\n",
        "## is it the last column or row? \n",
        "print(weights.shape)\n",
        "print(np.amax(weights, axis = 0).shape)\n",
        "print(np.amax(weights, axis = 0))## the 10 means \n",
        "#print(np.amax(weights, axis = 1))\n",
        "\n",
        "## we want an average for each feature (each row)\n",
        "## we want an average per pixel across all classes \n",
        "for i in range(784):\n",
        "  weights[i,:]\n",
        "\n",
        "#weights *=(255.0/np.amax(weights, axis = 0))## this should be the average\n",
        "weights -= weights.mean(axis = 1)\n",
        "'''for i in range(784):\n",
        "  weights[i,:] *=(255.0/(weights[i:].max()))\n",
        "  weights[i,:] -=weights[i:].mean()'''\n",
        "#print(weights)\n",
        "for i in range(10): \n",
        "  img = weights[:,i]\n",
        "  '''img -= img.mean()\n",
        "  img*= 255.0/img.max()'''\n",
        "  \n",
        "  img = img.reshape((28,28))\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "SuDUTVI9n1EU",
        "outputId": "07204bdf-90d0-41d6-b98a-9d3063b0a372"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-211-291669241a39>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    weights -= weights.mean(axis = 1)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''for solvr in best_models:\n",
        "    print(solvr.model.params['W1'].shape)## this should be a dictionary where we can get W1 \n",
        "    weights = solvr.model.params['W1']\n",
        "    \n",
        "    weights*= 255.0/weights.max()\n",
        "    ## then get the weights\n",
        "    #image *= 255.0/image.max()\n",
        "    ## then look at weights to see how to rescale them\n",
        "    ## then rescale and consider setting them to integers\n",
        "    ## if it looks bad subtract the avg and then rescale... \n",
        "\n",
        "\n",
        "plt.imshow(weights)'''"
      ],
      "metadata": {
        "id": "hVDxnLZCbVQ8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "d96e6a67-3e8b-4c89-ad02-968b16aa077f"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(785, 10)\n",
            "(785, 10)\n",
            "(785, 10)\n",
            "(785, 10)\n",
            "(785, 10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2c91fd2d10>"
            ]
          },
          "metadata": {},
          "execution_count": 165
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (c) Cross-Entropy Loss\n",
        "\n",
        "The Softmax class defines the cross-entropy loss for training and prediction methods like the previous the linear classifiers.\n",
        "The cross-entropy loss is actually the composition of two distinct functions: the softmax function and the cross-entropy.\n",
        "However,\n",
        "we commonly refer to it just as the cross-entropy loss,\n",
        "with the implicit understanding that for deep learning,\n",
        "the cross-entropy is not computed on the raw scores,\n",
        "but rather the softmax of the raw scores.\n",
        "\n",
        "For a score vector $s$, the softmax activation of the $j$-th element is given by,\n",
        "\n",
        "$$\n",
        "\\sigma_j = \\frac{e^{s_{j}}}{\\sum^{C - 1}_{k=0}e^{s_k}}\n",
        "$$\n",
        "\n",
        "A simple implementation of the softmax function can be numerically unstable. Large scores can result in an overflow. Large scores are normalized to be not too big or too small. [Check here for more details.](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/#:~:text=Computing%20softmax%20and%20numerical%20stability)\n",
        "\n",
        "\n",
        "The cross-entropy is a measure of the difference between two probability distributions.\n",
        "In the general case,\n",
        "the cross-entropy $H$ between the true probability distribution $P$ and the estimated probability distribution $Q$ is given by:\n",
        "\n",
        "$$\n",
        "H(P, Q)=-\\sum_{x \\in \\mathcal{X}} P(x) \\log Q(x)\n",
        "$$\n",
        "\n",
        "where $\\mathcal{X}$ is the event space.\n",
        "It is a measure of how \"far off\" our estimated distribution $Q$ is from $P$.\n",
        "(Note that because $P$ and $Q$ are actually functions,\n",
        "$H$ in this case is a function operating on functions, also known as an *operator*.)\n",
        "\n",
        "In our case,\n",
        "$P$ is zero except for the correct label,\n",
        "and thus the cross-entropy reduces to simply the negative logarithm of the score corresponding to the correct class,\n",
        "which is just\n",
        "\n",
        "$$\n",
        "L_i = -\\log(\\sigma_{y_i}))\n",
        "$$\n",
        "\n",
        "where $y_i$ is the correct label of the $x_i$ input sample,\n",
        "and $\\sigma_{y_i}$ is the softmax output of the corresponding correct label. $L$ is then just the average over the $L_i$.\n",
        "\n",
        "The derivative of the softmax is given by, \n",
        "\n",
        "$$\n",
        "\\frac{\\partial\\sigma_i}{\\partial s_j} = \\left \\{\n",
        "\\begin{array}{ll}\n",
        "\\sigma_i(1 - \\sigma_{j}) & i = j     \\\\\n",
        "-\\sigma_i\\sigma_j & i \\neq j  \\\\\n",
        "\\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "Details on the derivation can be found [here](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/).\n",
        "\n",
        "The derivative of the negative logarithm is given by, \n",
        "\n",
        "$$\n",
        "\\frac{\\partial (-\\log)}{\\partial \\sigma_{y_i}} = -\\frac{1}{\\sigma_{y_i}}\n",
        "$$"
      ],
      "metadata": {
        "id": "nhA92akOczjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the `cross_entropy_loss` function in the following cell. The function returns a tuple of `(loss, dy)` where, `loss` is the cross-entropy loss based on the inputs, and `dy` is the gradient of the loss with respect to the `scores` input.This is the loss over multiple samples, therefor you should take the mean of the loss. "
      ],
      "metadata": {
        "id": "XJDqbXH4yxZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stablesoftmax(x):\n",
        "    \"\"\"Compute the softmax of vector x in a numerically stable way.\"\"\"\n",
        "    shiftx = x - np.max(x)\n",
        "    exps = np.exp(shiftx)\n",
        "    return exps / np.sum(exps)"
      ],
      "metadata": {
        "id": "g4_IQNSzFP6u"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(scores, y_batch):\n",
        "    \"\"\"\n",
        "    Computes the cross-entropy layer\n",
        "\n",
        "    Inputs:\n",
        "    - scores: A numpy array containing the scores, of shape (N, C)\n",
        "    - y_batch: A numpy array containing the labels, of shape (N, 1)\n",
        "\n",
        "    Returns: A tuple containing:\n",
        "    - loss as a single float\n",
        "    - gradient with respect to scores; an array of the same shape as scores\n",
        "    \"\"\"\n",
        "    N,C = scores.shape\n",
        "    loss = 0\n",
        "    dy = np.zeros(scores.shape)\n",
        "\n",
        "    # PUT YOUR CODE BELOW:                                                       \n",
        "    # Implement the cross-entropy loss, storing the  \n",
        "    # result in loss. Make sure to take the mean of the loss.\n",
        "    # Hint: The intermediate results maybe useful for the gradient calculation  \n",
        "    ## s is the vector for a samples score output \n",
        "    L = np.zeros((N))\n",
        "\n",
        "    for i in range(N): ## over all data points\n",
        "\n",
        "      yi = int(y_batch[i])## yi is our correct class\n",
        "      #print(\"yi\",yi)\n",
        "      syi = scores[i,yi]\n",
        "    \n",
        "      #sigma_yi = math.exp(syi)/ sum([math.exp(elem) for elem in scores[i,:] ])## scores[i,:] is the score vector s\n",
        "      sigma_yi = stablesoftmax(scores[i,:])[yi]\n",
        "      L[i] = -math.log(sigma_yi)\n",
        "    loss = L.mean()\n",
        "\n",
        "    \n",
        "    ## this dy has j be the column and i be the row of our score matrix \n",
        "    '''for i in range(N): \n",
        "      for j in range(C):\n",
        "        if (i==j):\n",
        "          dy[i,j] = sigma_i*(1-sigma_j)\n",
        "        else: \n",
        "          dy[i,j] = -sigma_i*sigma_j'''\n",
        "    for j in range(N):## rows\n",
        "      for i in range(C):## columns \n",
        "        pass\n",
        "\n",
        "    ## D_ijP_t = (S_t)(delta_ti-S_i)x_j\n",
        "    \n",
        "    ## for each data point: \n",
        "    ## calculate softmax(vector); vector = s = sample \n",
        "      ## sigma_i = soft_max[i]\n",
        "\n",
        "    ## for each row of scores\n",
        "    ##dy[r,c] = :\n",
        "      ## v = softmax([r,:])\n",
        "      ## if i = j then : \n",
        "        ## v[i]*(1-v[i])## is this dy[r,i] or dy\n",
        "      ## if i!=j then \n",
        "        ## -v[i]*v[j]\n",
        "\n",
        "    # PUT YOUR CODE BELOW:                                                                    \n",
        "    # Implement the gradient for the cross-entropy loss, storing the result    \n",
        "    # in dy.                                                                    \n",
        "    #                                                                          \n",
        "    # Hint: Instead of computing the gradient from scratch, it may be easier    \n",
        "    # to reuse some of the intermediate values that you used to compute the     \n",
        "    # loss. \n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "    return loss, dy"
      ],
      "metadata": {
        "id": "5hIEv5fl9llO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to define the `Softmax` classifier class."
      ],
      "metadata": {
        "id": "8h0EQF-yuu8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax(LinearClassifier):\n",
        "    \"\"\" A subclass that uses the Softmax + Cross-entropy loss function \"\"\"\n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        return cross_entropy_loss(scores, y_batch)"
      ],
      "metadata": {
        "id": "RKYgCIcHczy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Softmax Experiments\n",
        "\n",
        "In the next few cells run the `Solver` with Softmax models on the training and validation data you've defined previously, similar to the SVM experiements.  Use the `DATA` dictionary you defined previously as the data parameter.\n",
        "\n",
        "\n",
        "Keep the top-5 best performing models and the worst performing model on the validation set."
      ],
      "metadata": {
        "id": "Ug02WvIg5DT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** hyperparameter validation loop in the next cell to train multiple models with different hyperparameters. Keep the top-5 best performing models on the validation set. You can try different learning rates. You may change the num_epochs, but be wary of timeouts. "
      ],
      "metadata": {
        "id": "qRFvUnysFwvt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "05Od5fTg5Dqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the next cell to visualize the weights corresponding to each sample in the *best* performing Softmax models. You should have ten 28x28 images.\n",
        "\n",
        "\n",
        "You can add additional cells below.\n",
        "\n",
        "Depending on your learning rate and weights, it might not look so great. If all the images look the same but you have good accuracy, try subtracting the average of weights from weights of each class. "
      ],
      "metadata": {
        "id": "s8j9KoxfXgY5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0SEDP9m-EZNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the testing performance of your top-5 performing Softmax models on the test set and print the results. "
      ],
      "metadata": {
        "id": "4GdpbgYg5D8W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oxuJHeU45EVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Deeper Neural Networks (Very Slightly)\n",
        " "
      ],
      "metadata": {
        "id": "A7mX-suZStG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Up until now, we have been working with linear classification models. Linear classification models are very adept at modelling data that have nice linear boundaries. In practice, realy world data is rarely linear. Multilayer fully-connected neural networks with non-linear activation functions on the other hand can model non-linear data-label relationships. \n",
        "\n",
        "Such models are a powerful extension to linear models and are the building blocks of modern deep learning. \n",
        "\n",
        "In this section, you will be implementing a two-layer fully-connected neural network. Fully-connected neural networks perform the transformation that you've implemented above coupled with a non-linear activation function. You will also implement your own version of the rectified linear unit fuction (commonly reffered to as ReLU), a non-linear activation function."
      ],
      "metadata": {
        "id": "j60wKxwhXu2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (a) ReLU Function\n",
        "\n",
        "The ReLU function is given by:\n",
        "\n",
        "$$\n",
        "f(x) = x^{+} = max(0, x)\n",
        "$$\n",
        "\n",
        "**Implement** the following cell to complete the definition of the `ReLU_forward` function."
      ],
      "metadata": {
        "id": "gP_YgE1JWj1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reLU(x): \n",
        "  if x<0: \n",
        "    return 0 \n",
        "  else: \n",
        "    return x\n",
        "VreLU=np.vectorize(reLU)"
      ],
      "metadata": {
        "id": "rkUzCr9q2EXg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A = np.array([[1,-2,3],[-4,5,6]]); A\n",
        "#VreLU(A)\n",
        "#my_function = lambda x: if x<0 0 else: x"
      ],
      "metadata": {
        "id": "Tb6sIq_o2Or1",
        "outputId": "fca9c411-4c80-475b-ed74-252e8a6c87bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 3],\n",
              "       [0, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU_forward(x):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a ReLU actiivation.\n",
        "\n",
        "    The input x has shape (N, D) and contains a minibatch of N\n",
        "    examples, where each example x[i] has shape (D). We will \n",
        "    transform it to an output vector of dimension M.\n",
        "\n",
        "    Inputs:\n",
        "    - x: A numpy array containing input data, of shape (N, D)\n",
        "\n",
        "    \n",
        "    Returns a tuple of:\n",
        "    - out: output, of shape (N, D)\n",
        "    - cache: (x)\n",
        "    \"\"\"\n",
        "    out = None\n",
        "\n",
        "    out = VreLU(x)\n",
        "    \n",
        "    # PUT YOUR CODE BELOW: Implement the ReLU forward pass. Store the result in \n",
        "    # out. You will need to reshape the input into rows.\n",
        "    \n",
        "    \n",
        "    # The lines below do not need to be changed.\n",
        "\n",
        "    cache = (x,)\n",
        "    return out, cache"
      ],
      "metadata": {
        "id": "tQ-CcTqJStgz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ReLU derivative is given by: \n",
        "\n",
        "$$\n",
        "\\frac{\\partial f(x)}{\\partial x} = \\left\\{\n",
        "\\begin{array}{ll}\n",
        "      0 & x \\leq 0 \\\\\n",
        "      1 & x > 0 \\\\\n",
        "\\end{array}\n",
        "\\right. \n",
        "$$\n",
        "\n",
        "Where, $f(x)$ is the ReLU function of course.\n",
        "\n",
        "\n",
        "**Implement** the following cell to complete the definition of the `ReLU_backward` function."
      ],
      "metadata": {
        "id": "g3LU7V4Ib4xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def d_reLU(x): \n",
        "  if x<=0:\n",
        "    return 0 \n",
        "  else: \n",
        "    return 1 \n",
        "\n",
        "Vd_reLU=np.vectorize(d_reLU)"
      ],
      "metadata": {
        "id": "4SDvmFDl44EA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU_backward(d_upstream, cache):\n",
        "    \"\"\"\n",
        "    Computes the backward pass for an linear layer.\n",
        "\n",
        "    Inputs:\n",
        "    - d_upstream: Upstream derivative, of shape (N, D)\n",
        "    - cache: Tuple of:\n",
        "      - x: Input data, of shape (N, D)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - dx: Gradient with respect to x, of shape (N, D)\n",
        "    \"\"\"\n",
        "    N,D =  d_upstream.shape\n",
        "    ## dx = np.matmul(dy, w.T[:,:-1]) \n",
        "\n",
        "\n",
        "    x,  = cache\n",
        "    dx = Vd_reLU(x)## I wan't to multiply but then we get shape either D,D or N,N \n",
        "    ## this could be Vd_reLU(d_upstream)\n",
        "    ## we need dx be the shape of x\n",
        "\n",
        "    ## I think dx should be upstream*d_relu(x)\n",
        "\n",
        "    # PUT YOUR CODE BELOW: Implement the ReLU backward pass.                                 \n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "    assert(dx.shape == (N,D) )\n",
        "\n",
        "    return (dx, )"
      ],
      "metadata": {
        "id": "fTn6t0FaVBSs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (b) Two-layer Neural Network\n",
        "\n",
        "**Implement** the definition of the two-layer neural network below.\n",
        "\n",
        "Similar to the `LinearClassifier` class, you should write the `__init__`, `forward`, `backward`, and `predict` methods. We will be using the cross-entropy loss for this network. \n",
        "\n",
        "Complete the following:\n",
        "- The `__init__()` method initializes the class. You must generate two random weight matrices. We will be using the bias trick, so the bias should concatenated to the weight matrix. They are initialized differently. \n",
        "\n",
        "- The `forward()` method generates the scores for given an input sample, by applying a `linear_forward()` and `ReLU_forward()` with appropriate inputs. Make sure to store and return the cache for the intermediate steps. \n",
        "\n",
        "- The `backward()` method returns the gradients with respect to the inputs and weights, using the `linear_backward()` and `ReLU_backward()`. Make sure the keys for the returned dictionary `weights_gradient` matches the keys in the `self.params` dictionary.\n",
        "\n",
        "- The `predict()` method returns the labels predicted from the scores returned using the `self.forward()` method.\n"
      ],
      "metadata": {
        "id": "jYDMTehxYP75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoLayerNet(object):\n",
        "    \"\"\"\n",
        "    A two-layer fully-connected neural network with ReLU nonlinearity and\n",
        "    softmax loss that uses a modular layer design. We assume an input dimension\n",
        "    of D, a hidden dimension of H, and perform classification over C classes.\n",
        "\n",
        "    The architecure should be transform - relu - transform - softmax.\n",
        "\n",
        "    Note that this class does not implement gradient descent; instead, it\n",
        "    will interact with a separate Solver object that is responsible for running\n",
        "    optimization.\n",
        "\n",
        "    The learnable parameters of the model are stored in the dictionary\n",
        "    self.params that maps parameter names to numpy arrays.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 hidden_dim=100,\n",
        "                 num_classes=10,\n",
        "                 weight_scale=1e-3):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "\n",
        "        self.params = {}\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # PUT YOUR CODE BELOW: Initialize the weights of the two-layer net. Weights should be     \n",
        "        # initialized from a Gaussian centered at 0.0 with standard deviation      \n",
        "        # equal to weight_scale, and biases should be initialized to zero.         \n",
        "        # All weights should be stored in the dictionary self.params, with first   \n",
        "        # layer weights and using the keys 'W1' and second layer weights and using \n",
        "        # the keys 'W2'. Make sure to concatenate the weights and biases to make a \n",
        "        # a single matrix for the bias trick!      \n",
        "\n",
        "        ## W1 feeds into W2 so should be input by input and output hidden\n",
        "        ## W2 feeds into loss function so should be input by hidden and output num classes      \n",
        "        w1 = np.random.normal(0, weight_scale, size =(input_dim,hidden_dim)) ## we need an extra row for the 1s \n",
        "        bias = np.ones(hidden_dim).reshape(1,hidden_dim);bias\n",
        "        w1 = np.append(w1,bias, axis = 0).shape\n",
        "        self.params['W1'] = w1                                                 \n",
        "        \n",
        "        w2 = np.random.normal(0, weight_scale, size =(hidden_dim,num_classes)) ## we need an extra row for the 1s \n",
        "        bias = np.ones(num_classes).reshape(1,num_classes);bias\n",
        "        w2 = np.append(w2,bias, axis = 0).shape\n",
        "        #w2 = \n",
        "        self.params['W1'] = w1\n",
        "        self.params['W2'] = w2\n",
        "\n",
        "        # The lines below do not need to be changed in this method.\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Implement the forward pass of the neural network and return the scores\n",
        "\n",
        "        Inputs:\n",
        "        - x: A numpy array containing input data, of shape (N, self.input_dim)\n",
        "        \n",
        "\n",
        "        Returns a tuple of:\n",
        "        - out: output, of shape (N, D)\n",
        "        - Tuple of tuples:\n",
        "          - cache_lin_1: A tuple (x, w1) \n",
        "            - x: data, of shape (N, self.input_dim)\n",
        "            - w1: Weight of linear layer 1 of shape (self.input_dim+1, self.hidden_dim)\n",
        "          - cache_relu_1: A tuple (h, )\n",
        "            - h : data, of shape (N, self.hidden_dim)\n",
        "          - cache_lin_2:  A tuple (h, w2)\n",
        "            - h: data, of shape (N, self.hidden_dim)\n",
        "            - w2: weight of linear 2 of shape (self.hidden_dim+1, C)\n",
        "        \"\"\"\n",
        "        out = None\n",
        "        N, feature_dim = x.shape\n",
        "        #cache_lin_1, cache_relu_1, cache_lin_2 = None, None, None\n",
        "\n",
        "        if (feature_dim != self.input_dim):\n",
        "            raise Exception(f\"The input feature dimension of {feature_dim} does \\\n",
        "                            not match the expected feature dimension of \\\n",
        "                            {self.input_dim} \")\n",
        "\n",
        "        \n",
        "        # PUT YOUR CODE BELOW: Perform a forward pass of the two-layer net.\n",
        "        # The architecture is transform - relu - transform \n",
        "        # Make to store the appropriate cache in the appropriate variables                     \n",
        "\n",
        "        ## apply linear_forward() and ReLU_forward() with the approprate inputs \n",
        "        w1 = self.params['W1']\n",
        "        out, cache_lin_1 = linear_forward(x, w1)\n",
        "\n",
        "        out, cache_relu_1 = ReLU_forward(out)\n",
        "\n",
        "        w2 = self.params['W2']  \n",
        "        out, cache_lin_2 = linear_forward(out,w2)\n",
        "\n",
        "        # The lines below do not need to be changed in this method.\n",
        "\n",
        "        return out, (cache_lin_1, cache_relu_1, cache_lin_2)\n",
        "\n",
        "\n",
        "    def backward(self, dout, cache):\n",
        "        \"\"\"\n",
        "        Implement the backward pass of the neural network and return the\n",
        "        gradients w.r.t the input, and the weights\n",
        "\n",
        "        Inputs:\n",
        "        - dout: Upstream derivative, of shape (N, C)\n",
        "        - cache: Tuple of tuples:\n",
        "          - cache_lin_1: A tuple (x, w1) \n",
        "            - x: data, of shape (N, self.input_dim)\n",
        "            - w1: Weight of linear layer 1 of shape (self.input_dim+1, self.hidden_dim)\n",
        "          - cache_relu_1: A tuple (h, )\n",
        "            - h : data, of shape (N, self.hidden_dim)\n",
        "          - cache_lin_2:  A tuple (h, w2)\n",
        "            - h: data, of shape (N, self.hidden_dim)\n",
        "            - w2: weight of linear 2 of shape (self.hidden_dim+1, C)\n",
        "\n",
        "        Returns a tuple of:\n",
        "          - dx: A numpy array of the gradient with respect to x, of shape (N, D)\n",
        "          - weight_gradients: A dictionary of numpy arrays containing the\n",
        "              gradients with respect to the weights. \n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        weight_gradients = {}\n",
        "        #dx = None\n",
        "\n",
        "        N, classes = dout.shape\n",
        "        \n",
        "        cache_lin_1, cache_relu_1, cache_lin_2 = cache\n",
        "\n",
        "        if (classes != self.num_classes):\n",
        "            raise Exception(f\"The output class dimension of {classes} does \\\n",
        "                            not match the expected number of classes \\\n",
        "                            {self.num_classes} \")\n",
        "\n",
        "        # PUT YOUR CODE BELOW: Perform a backward pass of the two-layer net.                      \n",
        "        '''linear: \n",
        "                dx, dw = linear_backward(dout, cache)#dx, dw\n",
        "\n",
        "        weight_gradients = {}\n",
        "        weight_gradients['W1'] = dw\n",
        "        '''\n",
        "        ### what do we do? \n",
        "        ## linear backward\n",
        "        ## relu backward \n",
        "        ## linear backward \n",
        "\n",
        "        dx,dw = linear_backward(dout,cache_lin_2)## d_upstream = dout\n",
        "        weight_gradients['W2']## the backwards one goes first \n",
        "\n",
        "        dx = ReLU_backward(dx,cache_relu_1)## d_upstream = dx \n",
        "\n",
        "        \n",
        "        dx,dw = linear_backward(dx, cache_lin_1)## d_upstream = dx\n",
        "        weight_gradients['W1']## the first layer goes last \n",
        "\n",
        "        # The lines below do not need to be changed in this method.\n",
        "        return (dx, weight_gradients)\n",
        "    \n",
        "    def predict(self, x):\n",
        "\n",
        "        \"\"\"\n",
        "        Implement the predictions from the forward pass of the neural network and \n",
        "        returns it. \n",
        "\n",
        "        Inputs:\n",
        "        - x: Input data, of shape (N, self.input_dim)\n",
        "        \n",
        "        Returns a tuple of:\n",
        "          - predictions: A numpy array of shape (N, ) of the predicted class per sample \n",
        "          \n",
        "        \"\"\"\n",
        "\n",
        "        #y_pred = None\n",
        "\n",
        "\n",
        "        \n",
        "        # PUT YOUR CODE BELOW: Predict the classes of using the two-layer net.                    \n",
        "\n",
        "        scores, cache = self.forward(x)#forward(self, x)(x,self.params['W1'])## use the parameters to do a forward pass\n",
        "        \n",
        "        #y_pred = np.amax(scores, axis = 1)\n",
        "        y_pred = np.argmax(scores, axis = 1)\n",
        "        # The lines below do not need to be changed in this method.\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        # The lines below do not need to be changed in this method.\n",
        "        return cross_entropy_loss(scores, y_batch)"
      ],
      "metadata": {
        "id": "dSr_3dSiYQOf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (c) Experiments\n",
        "\n",
        "Similar to the linear classifiers, you also want to identify the best configuration of hyperparameters that perform the best for your dataset. Similar to the case of the linear models, you can vary the learning rate for your solver. You should use the `Solver` class for these models as well. Use the `DATA` dictionary you defined previously as the data parameter.\n",
        "\n",
        "Additionaly, the neural network provides another hyperparameter to vary, the the number of neurons in the hidden layer. \n",
        "\n",
        "Adding a large of number of neurons may cause a large degradation in performance, the linear transformation scales as $O(N^3)$ with the number of neurons. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yovrIeNablvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** a hyperparameter validation loop in the next cell to train multiple models with different hyperparameters. Keep the top-5 best performing models on the validation set. You may change learning rate, and hidden dims. You may change the num_epochs, but be wary of timeouts. "
      ],
      "metadata": {
        "id": "N8zQgNiK-I9g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qwZysCge-Js5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the testing performance of your top-5 performing NN models on the test set and print the results. You can add additional cells below."
      ],
      "metadata": {
        "id": "zi1hTKxU-Kap"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QL6IbrNo-PTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** visualization for the `W1` weights of the *best* performing NN models. There are `hidden_dim` many of them per model. You should visualize a subset of the weights. You can select the columns at random. \n",
        "\n",
        "You can add additional cells below."
      ],
      "metadata": {
        "id": "qC8IL-RNdCOY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R-CGHrOtdCb9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
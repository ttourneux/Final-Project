{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttourneux/Final-Project/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## questions: \n",
        "\n",
        "#---------\n",
        "4. why don't we have activation function in predict? Why do we just pick the best class? \n",
        "\n",
        "5. svm.loss takes : Inputs:\n",
        "    - scores: A numpy array of shape (N, C) containing a minibatch of N\n",
        "      data points; each point has dimension C, where C is the number of classes.\n",
        "\n",
        "    - but forward outputs: \n",
        "        A list containing the value of the loss function at each training iteration.\n",
        "\n",
        "  - How to get the correct scores to put into .loss? \n",
        "  - \" The forward() method generates the scores for given an input sample, by applying a linear_forward() transformation on the inputs x and weights matrix self.params['W1']\"\n",
        "\n",
        "6. how come I can print before and after .forward but if i print in forward nothing happens????\n",
        "\n",
        "#-------------\n",
        "1. how to get the pictures to print correctly? \n",
        "2. how to get dy for cross-entropy loss\n",
        "3. do we do vd_reLU on d_upstream or on x"
      ],
      "metadata": {
        "id": "d5-NVZyBvAXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Author Information\n",
        "Name: Theodore Tourneux\n",
        "\n",
        "B-Number: B00810586\n",
        "\n",
        "Email: ttourne1@binghamton.edu"
      ],
      "metadata": {
        "id": "tUheapJCOaxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Instructions \n",
        "### Due October 7th, 11:59 PM.\n",
        "\n",
        "In the following assignment, you will be implementing functions and their analytical derivatives to train linear classifiers and neural networks on the MNIST dataset. \n",
        "\n",
        "Functions and cells that need to be implemented are marked with a bold **implement** keyword or clearly marked in the experiments section. \n",
        "\n",
        "The experiments section for each classifier also need to be implemented. You should follow the instructions above the cell. You may also add additional cells. \n",
        "\n",
        "Cells marked **run** need to be run to set up the appropriate infrastructure, but do not need to be modified. Make sure you have run the previous cells before running the current cell, or you may get an error.\n",
        "\n",
        "Submission will be via GitHub Classroom. **You are required to have at least 10 commits for this assignment.**\n"
      ],
      "metadata": {
        "id": "jqLULe5pxwpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import statements\n",
        "\n",
        "**Run** the cell to import the packages needed for the code below. You may other packages but ask first. "
      ],
      "metadata": {
        "id": "Hnw_h7A1Orc9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "JLEavoS9O9g-"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Backpropagation\n"
      ],
      "metadata": {
        "id": "VIBNL5SMPMt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Transformation\n",
        "\n",
        "Linear transformations are vector-valued functions that take D-dimensional  vectors $x \\in \\mathbb{R}^{D}$ and transform them into M-dimensional vectors, $y \\in \\mathbb{R}^{M}$. We are going to use linear transformation with [\"bias trick\"](https://en.wikipedia.org/wiki/Affine_transformation#Augmented_matrix) to implement the transformation:\n",
        "\n",
        "$$\n",
        "y = xW + b\n",
        "$$\n",
        "\n",
        "\n",
        "In this assignment, you will use this transformation in the SVM, softmax, and neural network classifiers.\n",
        "\n",
        "You will need to implement both the forward and backward direction of this linear layer. Take a look here for more details on the [backpropagation of a linear layer.](https://web.eecs.umich.edu/~justincj/teaching/eecs442/notes/linear-backprop.html)"
      ],
      "metadata": {
        "id": "VhFZKNmUXzt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** linear_forward(X, W) that returns linear transformations on data X using the augmented parameter matrix, W. "
      ],
      "metadata": {
        "id": "KszunLwwRJqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_forward(x, w):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a linear transformation.\n",
        "\n",
        "    The input x has shape (N, D) and contains a minibatch of N\n",
        "    samples, where each sample x[i] has shape (D). We will \n",
        "    transform it to an output vector of dimension M.\n",
        "\n",
        "    Inputs:\n",
        "    - x: A numpy array containing input data, of shape (N, D)\n",
        "    - w: A numpy array of weights, of shape (D+1, M)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: output, of shape (N, M)\n",
        "    - cache: (x, w)\n",
        "\n",
        "    The returned (x, w) is redundant, but makes the constructing the entire layer\n",
        "    a little more concise.\n",
        "\n",
        "    \"\"\"\n",
        "    #print(\"w\", type(w),w)\n",
        "    N,D = x.shape\n",
        "    E,M = w.shape\n",
        "    assert(E == D+1)\n",
        "\n",
        "    out = None # Initialize the out variable.\n",
        "    bias = np.ones(N).reshape(N,1)\n",
        "    x_prime = np.append(x,bias, axis = 1)## axis1 should be columns \n",
        "    out = np.matmul( x_prime, w)\n",
        "\n",
        "    #\n",
        "    # PUT YOUR CODE BELOW: Below, implement the linear forward pass. Store the result in out.\n",
        "    # Make sure to do the bias trick! \n",
        "\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "    \n",
        "    cache = (x, w)\n",
        "    #print(\"cache in linear_forward\",cache)\n",
        "    assert(out.shape == (N,M) )\n",
        "    return out, cache"
      ],
      "metadata": {
        "id": "fsl6QHm_PJdi"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** linear_backward(dout, cache) that returns the analytical gradients with respect to X and W."
      ],
      "metadata": {
        "id": "VLnk9xwpRf2T"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3bDhhohYKtiW"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.matmul(\n",
        "    np.ones((3,4)),\n",
        "    np.ones( (4,5))\n",
        ").shape\n",
        "\n",
        "np.array([[1,2,3],[4,5,6],[7,8,9]])[:,:-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6uC5jYcRqz_",
        "outputId": "a1e7ac2c-5de0-4aea-aea5-d2401b179eb2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [4, 5],\n",
              "       [7, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_backward(d_upstream, cache):\n",
        "  #linear_backward(dout, cache)\n",
        "    \"\"\"\n",
        "    Computes the backward pass for an linear layer.\n",
        "\n",
        "    Inputs:\n",
        "    - d_upstream: Upstream derivative, of shape (N, M)\n",
        "    - cache: Tuple of:\n",
        "      - x: Input data, of shape (N, D)\n",
        "      - w: Weights, of shape (D+1, M)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - dx: Gradient of the output of this layer with respect to x, of shape (N, D).\n",
        "          This is the downstream gradient.\n",
        "          dL/dx\n",
        "    - dw: Gradient with respect to w, of shape (D+1, M)\n",
        "          dL/dw\n",
        "    \"\"\"\n",
        "    #print('cache',cache)\n",
        "    assert(len(cache)==2)\n",
        "    x, w = cache\n",
        "    N,D  = x.shape \n",
        "    #print('in x.shape',x.shape)\n",
        "    #print('in w.shape',w.shape)\n",
        "    E,M = w.shape\n",
        "    assert( E == D+1)\n",
        "    bias = np.ones(N).reshape(N,1)\n",
        "    x_prime = np.append(x,bias, axis = 1)\n",
        "    #dx, dw = None, None\n",
        "\n",
        "    # PUT YOUR CODE BELOW: Implement the linear backward pass by calculating the\n",
        "    # gradient with respect to the cached inputs x and w. Store them in the \n",
        "    # variables dx and dw.\n",
        "\n",
        "    dy = d_upstream \n",
        "    dx = np.matmul(dy, w.T[:,:-1]).reshape((N,D))## (NxM)X (M,D+1)\n",
        "\n",
        "    dw = np.matmul(x_prime.T, dy).reshape((D+1,M))## this is better once we use the correct x_prime\n",
        "    ## the reshape fixed the assertion errors\n",
        "\n",
        "   \n",
        "    #dy is 2x3 and w is 2x3\n",
        "    # The lines below do not need to be changed.\n",
        "    #dx.shape (16, 5)\n",
        "    #dw.shape (4, 3)\n",
        "    #print(\"dx.shape\",dx.shape)\n",
        "    #print('dw.shape',dw.shape)\n",
        "    #print(x)\n",
        "    assert(dw.shape == (D+1,M))\n",
        "    assert(dx.shape == (N,D))\n",
        "    \n",
        "    return dx, dw"
      ],
      "metadata": {
        "id": "41ac6dd5TSEX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finite difference is the discrete analog of derivatives, used to implement gradients numerically. While analytical derivates are faster to compute, they tend to be difficult to implement and error prone. It is standard practice to perform a gradient check by comparing the analytical gradient implementation with a numerical gradient. \n",
        "\n",
        "The multi-variate central difference for a function $f(x,y)$ is given by:\n",
        "$$\n",
        "\\frac{\\partial  f}{\\partial x} = \\frac{f(x+h, y)-f(x-h, y)}{2h}\n",
        "$$\n",
        "and \n",
        "$$\n",
        "\\frac{\\partial  f}{\\partial y} = \\frac{f(x, y+h)-f(x, y-h)}{2h}\n",
        "$$\n",
        "\n",
        "The pattern holds for functions with higher number of variables. For central finite difference, generally $h=10^{-6}$. \n",
        "\n",
        "The multi-variate chain can be written as: \n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial x_i} = \\sum^{m}_{\\mathcal{l}=1} \\frac{\\partial L}{\\partial y_l}\\frac{\\partial y_l}{\\partial x_i}\n",
        "$$\n",
        "\n",
        "This simplifies nicely as the gradient for each variable in the matrix the sum of the products of the upstream gradient. `d_upstream` and the finite difference matrix. \n"
      ],
      "metadata": {
        "id": "lk1XRA9LSKml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement**  the `finite_difference_linear` function the next cell to test your implementation of the linear_forward and linear_backward functions. "
      ],
      "metadata": {
        "id": "Je8LC4OnT-rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def finite_difference_linear(d_upstream, cache):\n",
        "    '''\n",
        "    Computes the numerical gradient for a linear layer\n",
        "\n",
        "    Inputs:\n",
        "    - d_upstream: Upstream derivative, of shape (N, M)\n",
        "    - cache: Tuple of:\n",
        "      - x: Input data, of shape (N, D)\n",
        "      - w: Weights, of shape (D+1, M)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - dx: Gradient with respect to x, of shape (N, D).  This is the downstream\n",
        "          gradient.\n",
        "    - dw: Gradient with respect to w, of shape (D+1, M)\n",
        "    '''\n",
        "\n",
        "    ## let Y = XW ## this is the forward pass calculation\n",
        "    ## then finite difference is \n",
        "    #N,M = d_upstream.shape \n",
        "\n",
        "    (x,w) = cache\n",
        "    (N,D) = x.shape\n",
        "    (E,M) = w.shape\n",
        "    assert(E == D+1)\n",
        "\n",
        "\n",
        "    #out = None # Initialize the out variable.\n",
        "    bias = np.ones(N).reshape(N,1)\n",
        "    #print(\"x,bias\", x.shape,bias.shape)\n",
        "    x_prime = np.append(x,bias, axis = 1)\n",
        "    #print(\"x_prime\", x_prime.shape)\n",
        "    #print(\"w.shape\",w.shape)\n",
        "\n",
        "    #h_x = np.ones(x.shape)/(10**10)\n",
        "    #h_w = np.ones(w.shape)/(10**10)\n",
        "    h = (1/(10**10))\n",
        "\n",
        "    dl_dx = np.zeros((N,D))\n",
        "    for i in range(N):\n",
        "      for j in range(D):\n",
        "        x_diff = x_prime.copy()\n",
        "        x_diff[i,j] = x_diff[i,j]+h#(1/(10**10))\n",
        "        dy_dxij=((np.matmul(x_diff,w))-(np.matmul(x_prime, w)))/h#/(10**10)\n",
        "\n",
        "        acc = 0\n",
        "        for a in range(N):\n",
        "          for b in range(M):\n",
        "            acc+=d_upstream[a,b]*dy_dxij[a,b]\n",
        "        dl_dx[i,j] = acc\n",
        "\n",
        "\n",
        "    dl_dw = np.zeros((D+1,M))\n",
        "    for i in range(D+1):\n",
        "      for j in range(M):\n",
        "        w_diff = w.copy()\n",
        "        w_diff[i,j] = w_diff[i,j]+h#(1/(10**10))\n",
        "        dy_dwij=((np.matmul(x_prime,w_diff))-(np.matmul(x_prime, w)))/h#/(1/(10**10))\n",
        "        # (np.matmul(x,w+h_w))-(np.matmul(x, w))/(10**10)\n",
        "        \n",
        "        acc = 0\n",
        "        for a in range(N):\n",
        "          for b in range(M):\n",
        "            acc+=d_upstream[a,b]*dy_dwij[a,b]\n",
        "        dl_dw[i,j] = acc\n",
        "\n",
        "\n",
        "\n",
        "    dx = dl_dx\n",
        "    dw = dl_dw\n",
        "    # The lines below do not need to be changed.\n",
        "    #print(x.type)\n",
        "    #print(\"dx shape\", dx.shape)\n",
        "    #print(\"should be\" ,(N,D))## this is the same \n",
        "    assert((dx.shape) == (N,D))## this throws the error\n",
        "    assert((dw.shape) == (D+1,M))## this also throws an error \n",
        "    return dx, dw"
      ],
      "metadata": {
        "id": "HvUDtyAWUx7u"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5e3IbOzNO5qB"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finite_difference_linear()\n"
      ],
      "metadata": {
        "id": "OP7bm5h989HV"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** this cell to do a gradient check to test the analytical gradients from the `linear_backward` function with `finite_difference_linear`.  "
      ],
      "metadata": {
        "id": "iTNHRnDDvCMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_check_linear():\n",
        "    N = 16\n",
        "    D = 4\n",
        "    C = 3\n",
        "\n",
        "    test_weight = np.random.random((D+1, C))\n",
        "    test_input = np.random.random((N, D))\n",
        "    dout = np.random.random((N, C))\n",
        "\n",
        "    cache = (test_input, test_weight)\n",
        "    \n",
        "    grad_x_numerical, grad_w_numerical = finite_difference_linear(dout, cache)\n",
        "    grad_x_analytical, grad_w_analytical = linear_backward(dout, cache)\n",
        "\n",
        "    '''print('grad_w_numerical, grad_w_analytical',grad_w_numerical, grad_w_analytical)\n",
        "    print('space')\n",
        "    print('grad_x_numerical, grad_x_analytical',grad_x_numerical, grad_x_analytical)'''\n",
        "\n",
        "    check_input_gradient = np.allclose(grad_x_numerical, grad_x_analytical)\n",
        "    check_weight_gradient = np.allclose(grad_w_numerical, grad_w_analytical)\n",
        "\n",
        "    if not check_input_gradient:\n",
        "        print(\"The gradient with respect to x failed\")\n",
        "\n",
        "    if not check_weight_gradient:\n",
        "        print(\"The gradient respect to w failed\")\n",
        "    \n",
        "    print(\"gradient check for linear passed!\")\n",
        "\n",
        "gradient_check_linear()"
      ],
      "metadata": {
        "id": "jvmbfkfRPSZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77cb6e32-ac51-4d65-8766-a76dc42ee22d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The gradient with respect to x failed\n",
            "gradient check for linear passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Linear Classifiers\n"
      ],
      "metadata": {
        "id": "i1DiweHpU-_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MNIST Dataset\n",
        "\n",
        "MNIST is a dataset images of handwritten digits compiled by the National Institute of Standards and Technology (NIST). The dataset is widely used as a testing ground for machine learning algorithms for image classification.  \n",
        "\n",
        "The images are 28x28 pixels with only a single grayscale channel. You will be using 20,000 samples from the original training dataset for our next set of experiments. \n",
        "\n",
        "You will perform tests on the 10,000 sample test set.\n",
        "\n",
        "In this section, we will implement the linear classifiers with the MNIST dataset"
      ],
      "metadata": {
        "id": "38HrO_eBXjrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to define some helper functions to load the MNIST data."
      ],
      "metadata": {
        "id": "dU3af5u3vY2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist_data_parser_helper(csv_file_name):\n",
        "    X = []\n",
        "    Y = []\n",
        "    with open(csv_file_name,'r') as _file:\n",
        "        csv_reader = csv.reader(_file, delimiter=\",\")\n",
        "        for row in csv_reader:\n",
        "            Y.append(float(row[0]))\n",
        "            X.append([float(i) for i in row[1:]])\n",
        "    return (np.array(X), np.array(Y))\n",
        "\n",
        "def get_mnist_train_data():\n",
        "    X_train, Y_train = mnist_data_parser_helper(\"sample_data/mnist_train_small.csv\")\n",
        "    return X_train, Y_train\n",
        "\n",
        "def get_mnist_test_data():\n",
        "    X_test, Y_test = mnist_data_parser_helper(\"sample_data/mnist_test.csv\")\n",
        "    return X_test, Y_test"
      ],
      "metadata": {
        "id": "y6p9vHGhfBzg"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to visualize some of the samples from the MNIST dataset."
      ],
      "metadata": {
        "id": "nsEncnA3vh9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = get_mnist_train_data()\n",
        "\n",
        "# Visualize some examples from the dataset.\n",
        "# We show a few examples of training images from each class.\n",
        "classes = list(range(10))\n",
        "\n",
        "num_classes = len(classes)\n",
        "samples_per_class = 7\n",
        "for y, cls in enumerate(classes):\n",
        "    idxs = np.flatnonzero(y_train.astype('uint8') == y)\n",
        "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
        "    for i, idx in enumerate(idxs):\n",
        "        plt_idx = i * num_classes + y + 1\n",
        "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
        "        plt.imshow(x_train[idx].astype('uint8').reshape(28,28), cmap='gray')\n",
        "        plt.axis('off')\n",
        "        if i == 0:\n",
        "            plt.title(cls)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "21II-zCpe-ER",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "1b705e70-eeb1-4517-e4b3-c8b04cba61d8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 70 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to gather the training dataset.\n"
      ],
      "metadata": {
        "id": "SLbwp3V-vxg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = get_mnist_train_data()  # Get the training dataset"
      ],
      "metadata": {
        "id": "ZY8RrHx4Fegk"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following gather the testing dataset. "
      ],
      "metadata": {
        "id": "RHijm2aiv0cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = get_mnist_test_data()     # Get the test dataset"
      ],
      "metadata": {
        "id": "84cjF778Ag9O"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following normalize the input dataset to have a mean of 0 and standard deviation of 1. "
      ],
      "metadata": {
        "id": "d4cTK2RDv5wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_mean = x_train.mean()\n",
        "x_std = x_train.std()\n",
        "\n",
        "x_train = (x_train - x_mean)/(x_std)\n",
        "x_test = (x_test - x_mean)/(x_std)"
      ],
      "metadata": {
        "id": "n7RKsVNmfTx7"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to check the dimensions of the data."
      ],
      "metadata": {
        "id": "LfRlRMS9PTZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N, dim = x_train.shape\n",
        "N_test, _ = x_test.shape\n",
        "print(f\"Number of training sample {N} with {dim} pixels per image\")\n",
        "print(f\"Number of training sample {N_test} with {dim} pixels per image\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59jB-sjwQNVL",
        "outputId": "786270ce-eb52-4a8d-89dd-8b6087135cbe"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sample 20000 with 784 pixels per image\n",
            "Number of training sample 10000 with 784 pixels per image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implement and Evaluate ML Models\n",
        "\n",
        "In this problem we are optimizing parametric ML models on high-dimensional real world data. As we've seen before in our optimization tasks, even simple polynomial functions can have many local minima that our optimizers can get stuck on.\n",
        "\n",
        "\n",
        "Therefore, we need to be able to evaluate how well our model was optimized on the data, especially on the with different hyperparameters. Hyperparameters are parameters that control the learning process that are not updated during the training process, such learning rate or model size.\n",
        "\n",
        "\n",
        "For large enough datasets, a common strategy is to use [validation sets](https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets) to evaluate the [best model](https://en.wikipedia.org/wiki/Model_selection). In the next cell, split the training dataset into training and validation set with an 80-20 split ratio. "
      ],
      "metadata": {
        "id": "TDV7xaD_BkEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the following cell to split the `x_train` and `y_train` arrays to training and validations sets with an 80-20 split ratio. Place the split arrays in to the `DATA` dictionary. This dictionary will be used to feed data into the `Solver`."
      ],
      "metadata": {
        "id": "wi9rQwaUWBHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform training and validation dataset splits\n",
        "\n",
        "# PUT YOUR CODE BELOW\n",
        "number_of_rows = x_train.shape[0]\n",
        "random_indices = np.random.choice(number_of_rows, size=(int(.8*number_of_rows)), replace=False)\n",
        "\n",
        "random_rows = x_train[random_indices, :]\n",
        "rows_left = np.delete(x_train, random_indices, axis=0)##x_train[-random_indices,:]\n",
        "\n",
        "DATA = {\"X_train\": x_train[random_indices, :],      # Replace with the value here\n",
        "        \"X_val\" : np.delete(x_train, random_indices, axis=0),       # Replace with the value here\n",
        "        \"Y_train\" : y_train[random_indices],     # Replace with the value here\n",
        "        \"Y_val\" : np.delete(y_train, random_indices)}       # Replace with the value here\n"
      ],
      "metadata": {
        "id": "e0gRbRkAEO5C"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(DATA['X_train'].shape)\n",
        "DATA['X_val'].shape\n",
        "## the shapes are correct even if the first couple of rows are the same... this is probably because the first entries are 1s \n"
      ],
      "metadata": {
        "id": "KMdfJF2b3vKX",
        "outputId": "1dfc7fbf-52b3-4a84-923f-d15144d05be7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16000, 784)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA"
      ],
      "metadata": {
        "id": "vtlNuEEP6bvb",
        "outputId": "c1ffd1b6-6034-43f8-d7ea-d1a7fc9fb392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'X_train': array([[-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        ...,\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694]]),\n",
              " 'X_val': array([[-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        ...,\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694],\n",
              "        [-0.42401694, -0.42401694, -0.42401694, ..., -0.42401694,\n",
              "         -0.42401694, -0.42401694]]),\n",
              " 'Y_train': array([8., 3., 1., ..., 9., 4., 7.]),\n",
              " 'Y_val': array([5., 6., 5., ..., 0., 1., 2.])}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimizing Algorithm\n",
        "\n",
        "**Run** the following cell to define the stochastic gradient descent algorithm that we will use to optimize our models. "
      ],
      "metadata": {
        "id": "xXdYUcfTa78v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd(w, dw, lr=1e-2):\n",
        "    \"\"\"\n",
        "    Performs vanilla stochastic gradient descent.\n",
        "\n",
        "    config format:\n",
        "    - learning_rate: Scalar learning rate.\n",
        "    \"\"\"\n",
        "\n",
        "    w -= lr * dw\n",
        "    return w"
      ],
      "metadata": {
        "id": "elsI_qFOa8HB"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Solver\n",
        "\n",
        "\n",
        "The following solver class optimizes a given model using mini-batch gradient optimizations. \n",
        "\n",
        "**Run** the following cell to define the `Solver` class. "
      ],
      "metadata": {
        "id": "haKibBipbrmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Solver(object):\n",
        "    \"\"\"\n",
        "    Solver class for the learnable models using \n",
        "    mini-batch gradient descent.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 data,\n",
        "                 learning_rate=1e-3,\n",
        "                 num_epochs=50,\n",
        "                 batch_size=200,\n",
        "                 validation_frequency=16):\n",
        "        \"\"\"\n",
        "        Construct a new Solver instance.\n",
        "\n",
        "        Inputs:\n",
        "          model: Python class equiped with forward, backward, predict methods and a params dictionary\n",
        "          data: Dictionary with X_train, X_val,  Y_train, Y_val keys\n",
        "          learning_rate: Float, step size of the optimizer\n",
        "          num_epochs: Int, Number of times to completely traverse X_train\n",
        "          batch_size: Int, The number of samples in update\n",
        "          validation_frequency: Int, Solver performs validation loop every validation_frequency batches.\n",
        "                               Set this to a high number if num_epochs is large\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        \n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.validation_frequency = validation_frequency\n",
        "\n",
        "        self.num_training = data[\"X_train\"].shape[0]\n",
        "        self.input_dim = data[\"X_train\"].shape[1]\n",
        "        \n",
        "        intervals = list(range(0, self.num_training, batch_size))[1:]\n",
        "        \n",
        "        self.X_train = np.array_split(data[\"X_train\"], intervals, axis=0)\n",
        "        self.y_train = np.array_split(data[\"Y_train\"], intervals)\n",
        "\n",
        "        self.num_batches_in_training = len(self.X_train)\n",
        "\n",
        "        self.X_val = data[\"X_val\"]\n",
        "        self.y_val = data[\"Y_val\"]\n",
        "\n",
        "        self.update_rule = sgd\n",
        "        self.loss_history = []\n",
        "        self.validation_history = []\n",
        "\n",
        "        self.iteration_num = 0\n",
        "\n",
        "\n",
        "    def _step(self, batch_id):\n",
        "        \"\"\"\n",
        "        Make a single gradient update. This is called by train() and should not\n",
        "        be called manually.\n",
        "        \"\"\"\n",
        "        # Make a minibatch of training data\n",
        "        X_batch = self.X_train[batch_id]\n",
        "        y_batch = self.y_train[batch_id]\n",
        "        #print('X_batch.shape,y_batch.shape',X_batch.shape,y_batch.shape)\n",
        "\n",
        "        # Compute loss and gradient\n",
        "        score, cache = self.model.forward(X_batch)\n",
        "        #print(\"score in step\", score)\n",
        "        loss, dL = self.model.loss(score, y_batch)\n",
        "        #print(\"cache in step\",cache)\n",
        "        _, grads = self.model.backward(dL, cache)\n",
        "\n",
        "        self.loss_history.append(loss)\n",
        "\n",
        "        # Perform a parameter update\n",
        "        for p, w in self.model.params.items():\n",
        "            dw = grads[p]\n",
        "            #print('dw',dw)\n",
        "            next_w = self.update_rule(w, dw, self.learning_rate)#svm.params['W1']-= step_size*weight_gradients['W1']\n",
        "            self.model.params[p] = next_w\n",
        "    \n",
        "    \n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Optimization to train the model\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            for batch_id in range(self.num_batches_in_training):\n",
        "                #print(\"batch_id.shape\",batch_id.shape)\n",
        "                \n",
        "                self._step(batch_id)\n",
        "\n",
        "                self.iteration_num += 1\n",
        "\n",
        "                if (self.iteration_num % self.validation_frequency == 0):\n",
        "                    self.validate()\n",
        "\n",
        "        self.validate()\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"\n",
        "        Checks the validation error of the model at the time it is being called.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        N = self.y_val.shape[0]\n",
        "        predictions = self.model.predict(self.X_val)\n",
        " \n",
        "        accuracy = np.count_nonzero(predictions == self.y_val.astype(int))\n",
        "\n",
        "        print(f\"The validation accuracy at iteration {self.iteration_num}  is \\\n",
        "              {(float(accuracy)/N)*100}%\")\n",
        "    \n",
        "\n",
        "    def accuracy(self):\n",
        "        \"\"\"\n",
        "        Checks the validation error of the model at the time it is being called.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        N = self.y_val.shape[0]\n",
        "        predictions = self.model.predict(self.X_val)\n",
        " \n",
        "        accuracy = np.count_nonzero(predictions == self.y_val.astype(int))\n",
        "        print(f\"The validation accuracy at iteration {self.iteration_num}  is \\\n",
        "              {(float(accuracy)/N)*100}%\")\n",
        "        return (float(accuracy)/N)#*100"
      ],
      "metadata": {
        "id": "kQP6qra2bpOL"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (a) Linear Classifier\n",
        "\n",
        "We will be using two linear classifiers on the (MNIST) dataset. Using the linear transform you’ve implemented before, you will use SGD to train a multiclass support vector machine (SVM) and softmax classifiers to predict the handwritten digits.\n",
        "\n",
        "The linear classifier base class implements training and prediction methods shared by the linear classifiers. \n",
        "\n",
        "**Implement** the following cell to complete the definition of the following `LinearClassifier` class."
      ],
      "metadata": {
        "id": "vZfssCcKavEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the `__init__`, `forward`, `backward`, and `predict` methods. \n",
        "\n",
        "Complete the following:\n",
        "- The `__init__()` method initializes the class. You must generate a random weight matrix of shape `(input_dim+1,num_classes)`  \n",
        "- The `forward()` method generates the scores for given an input sample, by applying a `linear_forward()` transformation on the inputs `x` and weights matrix `self.params['W1']`\n",
        "- The `backward()` method returns the gradients with respect to the inputs and weights, using the `linear_backward()` method. Make sure the key for the returned dictionary `weights_gradient` matches the paramts dictionary.\n",
        "- The `predict()` method returns the labels predicted from the scores returned using the `self.forward()` method. "
      ],
      "metadata": {
        "id": "VbsDBRjmYeUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''input_dim, num_classes = 3,4 \n",
        "\n",
        "\n",
        "w1 = np.random.normal(0, 1e-3, size =(input_dim,num_classes)) ## we need an extra row for the 1s \n",
        "bias = np.ones(num_classes).reshape(1,num_classes);bias\n",
        "w1 = np.append(w1,bias, axis = 0).shape'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "rsEfwmwZ8xi6",
        "outputId": "d8aff013-2d4c-48c9-bddf-b4852123fbbd"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'input_dim, num_classes = 3,4 \\n\\n\\nw1 = np.random.normal(0, 1e-3, size =(input_dim,num_classes)) ## we need an extra row for the 1s \\nbias = np.ones(num_classes).reshape(1,num_classes);bias\\nw1 = np.append(w1,bias, axis = 0).shape'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearClassifier(object):\n",
        "    \"\"\"\n",
        "    The base class for the linear classifier. \n",
        "\n",
        "    Note that this class does not implement gradient descent; instead, it\n",
        "    will interact with a separate Solver object that is responsible for running\n",
        "    optimization.\n",
        "\n",
        "    The learnable parameters of the model are stored in the dictionary\n",
        "    self.params that maps parameter names to numpy arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_dim=784,\n",
        "                 num_classes=10):\n",
        "        self.params = {}## these should be our weights \n",
        "        self.input_features = input_dim\n",
        "        self.num_classes = 10\n",
        "\n",
        "        # PUT YOUR CODE BELOW:                                                    \n",
        "        # Initialize the weights of the linear classifier. Weights should be      \n",
        "        # initialized from a Gaussian centered at 0.0 with standard deviation     \n",
        "        # equal to 1e-3, and biases should be initialized to zero.                   \n",
        "        # Store in the self.W dictionary with key name 'W1'                       \n",
        "\n",
        "        ## one layer NN\n",
        "          ## weights in f\n",
        "          ## 1 input (one row) features*edges-> (activation)\n",
        "          ## n inputs (n rows) \n",
        "          ## rows is the sample dimesnion \n",
        "            ## for each minibatch, the same model is used for all the samples in the same batch \n",
        "          \n",
        "        w1 = np.random.normal(0, 1e-3, size =(input_dim,num_classes)) ## we need an extra row for the 1s \n",
        "        bias = np.ones(num_classes).reshape(1,num_classes);bias\n",
        "        w1 = np.append(w1,bias, axis = 0)\n",
        "        self.params['W1'] = w1 #np.random.normal(0, 1e-3, size =(input_dim+1,num_classes)) ## these are our weights\n",
        "        #self.params['W1'] = np.random.normal(0, 1e-3, size =(input_dim+1,num_classes))\n",
        "        \n",
        "        ##############################################NN works before this change^^\n",
        "        \n",
        "        ## make sure we have the bias term \n",
        "\n",
        "        ## we should have every \n",
        "\n",
        "        # The lines below do not need to be changed in the method\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        #print('start of forward')\n",
        "        \"\"\"\n",
        "        Train this linear classifier using stochastic gradient descent.\n",
        "\n",
        "        Inputs:\n",
        "        - x: A numpy array of shape (N, D) containing training data; there are N\n",
        "          training samples each of dimension D.\n",
        "\n",
        "        Outputs:\n",
        "        A list containing the value of the loss function at each training iteration.\n",
        "        \"\"\"\n",
        "        num_train, dim = x.shape\n",
        "        num_classes = self.num_classes\n",
        "\n",
        "\n",
        "        #out = None\n",
        "        #cache = None\n",
        "        \n",
        "        # PUT YOUR CODE BELOW:                                                    \n",
        "        # Implement this method. Generate the scores in out and store the old      \n",
        "        # values into the cache.                                                  \n",
        "\n",
        "        w = self.params['W1']\n",
        "        #out, cache\n",
        "        out, cache = linear_forward(x, w)#np.matmul(x,W)\n",
        "        #print('cache in model.forward', cache)\n",
        "        ##cache = (x, w)\n",
        "\n",
        "\n",
        "        #print()\n",
        "        #print(\"in .forward\", out)\n",
        "        #print()\n",
        "        ##############cache = x    changed\n",
        "        # The lines below do not need to be changed\n",
        "\n",
        "        '''- d_upstream: Upstream derivative, of shape (N, M)\n",
        "        - cache: Tuple of:\n",
        "          - x: Input data, of shape (N, D)\n",
        "          - w: Weights, of shape (D+1, M)'''\n",
        "        \n",
        "\n",
        "        out = np.array(out)\n",
        "        #return out, (cache, )\n",
        "        return out, cache\n",
        "    def backward(self, dout, cache):\n",
        "        '''The backward() method returns the gradients with respect to the inputs and weights, \n",
        "        using the linear_backward() method. Make sure the key for the returned dictionary \n",
        "        weights_gradient matches the paramts dictionary.'''\n",
        "        '''- dout: Upstream derivative, of shape (N, C)'''\n",
        "        #d_upstream = dout \n",
        "        #print(\"in .backward cache\",cache)\n",
        "        dx, dw = linear_backward(dout, cache)#dx, dw\n",
        "\n",
        "        weight_gradients = {}\n",
        "        weight_gradients['W1'] = dw\n",
        "        \n",
        "        \n",
        "        # PUT YOUR CODE BELOW:                                                                   \n",
        "        # Implement this method. Generate the gradients with respect to x from \n",
        "        # cache and set it dx, the upstream error signal.\n",
        "        # Store the gradient with respect to the weights in the weights_gradients\n",
        "        # dictionary. Make sure the key matches the ket of the params dictionary    \n",
        "\n",
        "        # The lines below do not need to be changed \n",
        "\n",
        "        return (dx, weight_gradients)\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"\n",
        "        Use the trained weights of this linear classifier to predict labels for\n",
        "        data points.\n",
        "\n",
        "        Inputs:\n",
        "        - x: A numpy array of shape (N, D) containing training data; there are N\n",
        "          training samples each of dimension D.\n",
        "\n",
        "        Returns:\n",
        "        - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional\n",
        "          array of length N, and each element is an integer giving the predicted\n",
        "          class.\n",
        "        \"\"\"\n",
        "        #y_pred = np.zeros(x.shape[0])\n",
        "        #out, cache = linear_forward(x, w)## there are two outputs\n",
        "        scores, cache = linear_forward(x,self.params['W1'])## use the parameters to do a forward pass\n",
        "        \n",
        "        #y_pred = np.amax(scores, axis = 1)\n",
        "        y_pred = np.argmax(scores, axis = 1)\n",
        "        #print(\"shape of y_pred\", )\n",
        "        #print('scores.shape',scores.shape)\n",
        "        #print(\"y_pred in predict\", y_pred.shape)\n",
        "        # PUT YOUR CODE BELOW:                                                                   \n",
        "        # Implement this method. Store the predicted labels in y_pred.            \n",
        "\n",
        "\n",
        "        # The lines below do not need to be changed\n",
        "\n",
        "        return y_pred\n",
        "    \n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        \"\"\"\n",
        "        Compute the loss function and its derivative.\n",
        "        Subclasses will override this.\n",
        "\n",
        "        Inputs:\n",
        "        - scores: A numpy array of shape (N, C) containing a minibatch of N\n",
        "          data points; each point has dimension C, where C is the number of classes.\n",
        "        - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
        "        - reg: (float) regularization strength.\n",
        "\n",
        "        Returns: A tuple containing:\n",
        "        - loss as a single float\n",
        "        - gradient with respect to scores; an array of the same shape as scores\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        \n",
        "        # The lines below do not need to be changed\n",
        "        # Do not implement anything here. The subclasses will override this method\n",
        "        pass"
      ],
      "metadata": {
        "id": "oLgT_g66T71G"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (b) Support Vector Machine\n",
        "\n",
        "\n",
        "The LinearSVM class defines an SVM-based linear classifier. The classifier uses the hinge loss to optimize the model parameters. \n",
        "\n",
        "The Hinge loss for an input sample $x_i$ (a vector) is given by: \n",
        "\n",
        "$$\n",
        "L_i = \\sum_{j \\neq y_i} \\text{max}(0, s_j-s_{y_i}+1)\n",
        "$$\n",
        "\n",
        "\n",
        "Where, $y_i$ is the label of the $i$-th sample.  The label is the correct class label where $0 \\leq y_i \\lt C$, where C is the number of classes.   The scalar $s_{y_i}$ is the $y_i$-th element of the score vector. \n",
        "\n",
        "The average loss over N samples is therefore:\n",
        "\n",
        "$$\n",
        "L = \\frac{1}{N}\\sum^{N}_{i=1}L_i\n",
        "$$\n",
        "\n",
        "The per-sample gradient of the loss w.r.t. the score $s_j$ is given by:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial  L_i}{\\partial s_j} = \\left \\{\n",
        "\\begin{array}{ll}\n",
        "0 & j = s_{y_i} \\text{ or } s_j-s_{y_i}+1 \\leq 0    \\\\\n",
        "1 & j \\neq s_{y_i} \\text{ and } s_j-s_{y_i}+1 > 0 \\\\\n",
        "\\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "**Implement** the `svm_loss` function in the following cell. Store the average loss the `loss` variable and the gradient w.r.t `scores` in the `dy` variable. This is the loss over multiple samples, therefore you should take the mean of the loss. \n"
      ],
      "metadata": {
        "id": "rS6qcaqUcyqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_loss(scores, y_batch):\n",
        "    \"\"\"\n",
        "    Returns hinge loss of the scores and y_batch. \n",
        "\n",
        "    Inputs:\n",
        "    - scores: A numpy array of shape (N, C) containing a minibatch of N\n",
        "      data points; each point has dimension C, where C is the number of classes.\n",
        "    - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
        "    - reg: (float) regularization strength.\n",
        "\n",
        "    Returns: A tuple containing:\n",
        "    - loss as a single float\n",
        "    - gradient with respect to scores; an array of the same shape as scores\n",
        "    \"\"\"\n",
        "\n",
        "    #assert(scores.shape = N,C)\n",
        "\n",
        "    ## the score of each class[without the correct class] - the score of the correct class\n",
        "    loss = 0\n",
        "    dy = np.zeros(scores.shape)  \n",
        "    # PUT YOUR CODE BELOW:                                                       \n",
        "    # Implement the structured SVM loss, storing the  \n",
        "    # result in loss. Make sure to take the mean of the loss.\n",
        "    # Hint: The intermediate results maybe useful for the gradient calculation                                                        \n",
        "\n",
        "    N,C = scores.shape\n",
        "\n",
        "    L = np.zeros((N))\n",
        "    for i in range(N):\n",
        "      yi = int(y_batch[i])## yi is our correct class\n",
        "      #print(\"yi\",yi)\n",
        "      syi = scores[i,yi]## this is the score for our correct class \n",
        "\n",
        "      #sj = scores[i,j!=yi]\n",
        "\n",
        "      acc = 0\n",
        "      for j in range(C): ## across the scores for one sample: \n",
        "        \n",
        "        ## part1 \n",
        "        if j==yi: \n",
        "          #dy[i,j] = 0## this is by default\n",
        "          continue \n",
        "        sj = scores[i,j]\n",
        "        acc+=max(0,\n",
        "                sj-syi+1)\n",
        "        #### part2 \n",
        "        if sj-syi+1>0:## if this is greater than 0 and j!=yi then it should be 1 else 0 which it already is\n",
        "          dy[i,j] = 1\n",
        "        \n",
        "        \n",
        "      \n",
        "    L[i] = acc\n",
        "    #print(L)\n",
        "\n",
        "    loss = np.mean(L)\n",
        "    #print('loss',loss)\n",
        "  \n",
        "    # PUT YOUR CODE BELOW:                                                                    \n",
        "    # Implement the gradient for the SVM loss, storing the result    \n",
        "    # in dy.                                                                    \n",
        "    #                                                                           \n",
        "    # Hint: Instead of computing the gradient from scratch, it may be easier    \n",
        "    # to reuse some of the intermediate values that you used to compute the     \n",
        "    # loss.                                                                     \n",
        "\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "    return loss, dy"
      ],
      "metadata": {
        "id": "S-_mC08N89UC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to define the `LinearSVM` class with your implementation of the `svm_loss`"
      ],
      "metadata": {
        "id": "MMaObHBhamT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearSVM(LinearClassifier):\n",
        "    \"\"\" A subclass that uses the Multiclass SVM loss function \"\"\"\n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        return svm_loss(scores, y_batch)"
      ],
      "metadata": {
        "id": "VD43ltPTcw-B"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SVM Experiments\n",
        "\n",
        "In the next few cells run the `Solver` with SVM models on the training and validation data you've defined previously. Use the `DATA` dictionary you defined previously as the data parameter.\n",
        "\n",
        "As you have seen with previous assignments, optimizations can be highly dependent on the hyperparameters of the model. You should try multiple models with different learning rates. You may also increase the amount of time you train by increasing the number of epochs. \n",
        "\n",
        "Keep the top-5 best performing models and the worst performing model on the validation set.\n"
      ],
      "metadata": {
        "id": "DNPZ7RoU2Oyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** hyperparameter validation loop in the next cell to train multiple models with different hyperparameters. Keep the top-5 best performing models on the validation set. You can try different learning rates. You may change the num_epochs, but be wary of timeouts. "
      ],
      "metadata": {
        "id": "DD7et1xEF9h6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''## this is just training... no validation \n",
        "\n",
        "#The forward() method generates the scores for given an input sample\n",
        "#The predict() method returns the labels predicted from the scores returned using the self.forward()\n",
        "\n",
        "X_train = DATA['X_train']\n",
        "\n",
        "svm = LinearSVM()## this shouldn't need to be passed any paramters\n",
        "step_size = .01\n",
        "batch_size = 8\n",
        "#for epoch in range(epochs)\n",
        "#for minibatch in samples\n",
        "not_end = True\n",
        "i = 0\n",
        "while (not_end) :\n",
        "  X_batch = X_train[i*batch_size:(i+1)*batch_size,:]\n",
        "  y_batch = y_train[i*batch_size: (i+1)*batch_size]\n",
        "  \n",
        "  if ((i*batch_size) > X_train.shape[0]) :\n",
        "    not_end = False\n",
        "  print(\"before forward\")\n",
        "  scores,cache = svm.forward(X_batch)\n",
        "  print(\"after forward\")\n",
        "  #print(type(scores),scores, \"scores\")## scores should be one matrix....\n",
        "  #print(len(scores))\n",
        "  loss,dy = svm.loss(scores,y_batch)\n",
        "  (dx,weight_gradients) = svm.backward(dy,cache)\n",
        "  svm.params['W1']-= step_size*weight_gradients['W1']\n",
        "  #print(batch)\n",
        "  #print()\n",
        "  i+=1\n",
        "  print('end of batch')\n",
        "'''\n",
        "'''\n",
        "## scores was dout \n",
        "scores, (cache, ) =svm.forward(x)## we need to do this to get answers for th back prop\n",
        "##.forward : A list containing the value of the loss function at each training iteration.\n",
        "\n",
        "loss, dy = svm.loss(scores, y_batch)## this is our dL/dy\n",
        "\n",
        "## dy was dout \n",
        "(dx, weight_gradients) = svm.backward(dy, cache)## this uses our dL/dy to update the weights\n",
        "svm.params['W1'] -= step_size*weight_gradients['W1']\n",
        "DATA'''\n"
      ],
      "metadata": {
        "id": "US364cOjGC5p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9534d57d-529f-4485-d230-0a580457610e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n## scores was dout \\nscores, (cache, ) =svm.forward(x)## we need to do this to get answers for th back prop\\n##.forward : A list containing the value of the loss function at each training iteration.\\n\\nloss, dy = svm.loss(scores, y_batch)## this is our dL/dy\\n\\n## dy was dout \\n(dx, weight_gradients) = svm.backward(dy, cache)## this uses our dL/dy to update the weights\\nsvm.params['W1'] -= step_size*weight_gradients['W1']\\nDATA\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "10*10*10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kH6-e9H5NRL",
        "outputId": "b4b729e6-d4d7-41bd-d62d-001c36cdb202"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = [None]\n",
        "\n",
        "LR = [.1**x for x in range(1,11,2)]\n",
        "BS =[x for x in range(50,550,100)]\n",
        "print(\"itters\", len(LR)*len(BS))\n",
        "#E = [x for x in range(10,110,20)]\n",
        "#print(E)\n",
        "#print(LR)\n",
        "\n",
        "for lr in LR: \n",
        "  for bs in BS: \n",
        "    svm = LinearSVM()\n",
        "    solver = Solver(svm,DATA, learning_rate=lr, batch_size=bs)\n",
        "    solver.train()\n",
        "\n",
        "    acc = solver.accuracy()\n",
        "    for i in range(len(best_models)): \n",
        "      if (best_models[i] == None):\n",
        "        best_models[i] = solver\n",
        "      elif len(best_models)<5:\n",
        "        best_models.append( solver)\n",
        "      elif(best_models[i].accuracy()<solver.accuracy()):\n",
        "        best_models[i] = solver\n",
        "        break\n",
        "    print(best_models)\n",
        "    \n",
        "\n",
        "svm_best_models = best_models \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dtdEjmlE3ox8",
        "outputId": "75433734-9ebb-4fe2-d787-86ec6b72062f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itters 25\n",
            "The validation accuracy at iteration 16  is               38.05%\n",
            "The validation accuracy at iteration 32  is               50.925%\n",
            "The validation accuracy at iteration 48  is               64.4%\n",
            "The validation accuracy at iteration 64  is               51.475%\n",
            "The validation accuracy at iteration 80  is               50.775000000000006%\n",
            "The validation accuracy at iteration 96  is               69.575%\n",
            "The validation accuracy at iteration 112  is               46.675%\n",
            "The validation accuracy at iteration 128  is               54.7%\n",
            "The validation accuracy at iteration 144  is               40.35%\n",
            "The validation accuracy at iteration 160  is               44.975%\n",
            "The validation accuracy at iteration 176  is               51.025%\n",
            "The validation accuracy at iteration 192  is               27.6%\n",
            "The validation accuracy at iteration 208  is               46.675%\n",
            "The validation accuracy at iteration 224  is               38.45%\n",
            "The validation accuracy at iteration 240  is               37.45%\n",
            "The validation accuracy at iteration 256  is               59.95%\n",
            "The validation accuracy at iteration 272  is               65.4%\n",
            "The validation accuracy at iteration 288  is               54.25%\n",
            "The validation accuracy at iteration 304  is               61.175000000000004%\n",
            "The validation accuracy at iteration 320  is               44.875%\n",
            "The validation accuracy at iteration 336  is               41.925000000000004%\n",
            "The validation accuracy at iteration 352  is               42.75%\n",
            "The validation accuracy at iteration 368  is               45.574999999999996%\n",
            "The validation accuracy at iteration 384  is               45.2%\n",
            "The validation accuracy at iteration 400  is               66.55%\n",
            "The validation accuracy at iteration 416  is               48.475%\n",
            "The validation accuracy at iteration 432  is               52.0%\n",
            "The validation accuracy at iteration 448  is               46.975%\n",
            "The validation accuracy at iteration 464  is               47.15%\n",
            "The validation accuracy at iteration 480  is               52.1%\n",
            "The validation accuracy at iteration 496  is               70.275%\n",
            "The validation accuracy at iteration 512  is               51.800000000000004%\n",
            "The validation accuracy at iteration 528  is               62.849999999999994%\n",
            "The validation accuracy at iteration 544  is               45.375%\n",
            "The validation accuracy at iteration 560  is               54.800000000000004%\n",
            "The validation accuracy at iteration 576  is               49.225%\n",
            "The validation accuracy at iteration 592  is               56.125%\n",
            "The validation accuracy at iteration 608  is               50.74999999999999%\n",
            "The validation accuracy at iteration 624  is               46.300000000000004%\n",
            "The validation accuracy at iteration 640  is               59.62499999999999%\n",
            "The validation accuracy at iteration 656  is               38.725%\n",
            "The validation accuracy at iteration 672  is               63.849999999999994%\n",
            "The validation accuracy at iteration 688  is               40.2%\n",
            "The validation accuracy at iteration 704  is               53.175%\n",
            "The validation accuracy at iteration 720  is               50.575%\n",
            "The validation accuracy at iteration 736  is               57.49999999999999%\n",
            "The validation accuracy at iteration 752  is               53.65%\n",
            "The validation accuracy at iteration 768  is               46.75%\n",
            "The validation accuracy at iteration 784  is               57.199999999999996%\n",
            "The validation accuracy at iteration 800  is               46.475%\n",
            "The validation accuracy at iteration 816  is               60.02499999999999%\n",
            "The validation accuracy at iteration 832  is               64.64999999999999%\n",
            "The validation accuracy at iteration 848  is               62.425%\n",
            "The validation accuracy at iteration 864  is               59.45%\n",
            "The validation accuracy at iteration 880  is               39.275%\n",
            "The validation accuracy at iteration 896  is               65.275%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-e5d7fb65ae4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-45e301fcf144>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;31m#print(\"batch_id.shape\",batch_id.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-45e301fcf144>\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, batch_id)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Compute loss and gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;31m#print(\"score in step\", score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-6cf6e98dbd36>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m#out, cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#np.matmul(x,W)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;31m#print('cache in model.forward', cache)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m##cache = (x, w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-926fd6119e39>\u001b[0m in \u001b[0;36mlinear_forward\u001b[0;34m(x, w)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mx_prime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m## axis1 should be columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''svm = LinearSVM()\n",
        "solver = Solver(svm,DATA)\n",
        "solver.validate()'''\n",
        "#This is always about 10% which makes sense"
      ],
      "metadata": {
        "id": "R7YiQjDV2wCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## this is where we can use the val data to find which are our top preforming models \n",
        "\n",
        "## maybe call a training loop where model is replaced if it has better performance than the 5th best.\n",
        "\n",
        "#y_pred = svm.predict(x)"
      ],
      "metadata": {
        "id": "8rhE8gBKaARC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the testing performance of your top-5 performing models on the test set and print the results. "
      ],
      "metadata": {
        "id": "Dl4R1tyz4VpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_models1 = best_models.copy()"
      ],
      "metadata": {
        "id": "c6AbZQeqCvJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "best_models = best_models1.copy()## reset"
      ],
      "metadata": {
        "id": "-dA_3Id8z27R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models"
      ],
      "metadata": {
        "id": "f58SoUsyyrz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## we need to find the test data... \n",
        "'''x_test, y_test'''\n",
        "\n",
        "## can we do solver.DATA = X_test? \n",
        "'''\n",
        "Solver has params: (these are used to return accuracy so that's all that needs to be changed)\n",
        "self.X_val = data[\"X_val\"]\n",
        "self.y_val = data[\"Y_val\"]\n",
        "'''\n",
        "for solvr in svm_best_models: \n",
        "  solvr.X_val = x_test\n",
        "  solvr.y_val = y_test\n",
        "  acc = solvr.accuracy()\n",
        "  print(acc)"
      ],
      "metadata": {
        "id": "PTsPEZde8yxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the next cell to visualize the weights corresponding to each sample in the *best* performing SVM models. You should have ten 28x28 images.\n",
        "\n",
        "Make sure to rescale the  weights to be between 0 and 255.\n",
        "\n",
        "Depending on your learning rate and weights, it might not look so great. If all the images look the same but you have good accuracy, try subtracting the average of weights from weights of each class. \n",
        "\n",
        "You can add additional cells below."
      ],
      "metadata": {
        "id": "srNp8XPEbVAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([1,2,3])*np.array([4,5,6])"
      ],
      "metadata": {
        "id": "obS-MPDpoTUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solvr = best_models[0]\n",
        "def weights_to_img(solver):\n",
        "  print(solvr.model.params['W1'].shape) \n",
        "  weights = solvr.model.params['W1'][:-1,:].copy()\n",
        "\n",
        "  ## first we want to normalize over all pixels \n",
        "  weights *=(255.0/weights.max())\n",
        "  ## then for each pixel subtract the average for that class\n",
        "  for i in range(784):\n",
        "    weights[i,:]= weights[i,:]-weights[i,:].mean()\n",
        "\n",
        "\n",
        "  for i in range(10): \n",
        "    img = weights[:,i]\n",
        "    \n",
        "    img = img.reshape((28,28))\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bY8n8b2CzrQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for solver in svm_best_models: \n",
        "  weights_to_img(solver)\n"
      ],
      "metadata": {
        "id": "QEjjMojCR6G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (c) Cross-Entropy Loss\n",
        "\n",
        "The Softmax class defines the cross-entropy loss for training and prediction methods like the previous the linear classifiers.\n",
        "The cross-entropy loss is actually the composition of two distinct functions: the softmax function and the cross-entropy.\n",
        "However,\n",
        "we commonly refer to it just as the cross-entropy loss,\n",
        "with the implicit understanding that for deep learning,\n",
        "the cross-entropy is not computed on the raw scores,\n",
        "but rather the softmax of the raw scores.\n",
        "\n",
        "For a score vector $s$, the softmax activation of the $j$-th element is given by,\n",
        "\n",
        "$$\n",
        "\\sigma_j = \\frac{e^{s_{j}}}{\\sum^{C - 1}_{k=0}e^{s_k}}\n",
        "$$\n",
        "\n",
        "A simple implementation of the softmax function can be numerically unstable. Large scores can result in an overflow. Large scores are normalized to be not too big or too small. [Check here for more details.](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/#:~:text=Computing%20softmax%20and%20numerical%20stability)\n",
        "\n",
        "\n",
        "The cross-entropy is a measure of the difference between two probability distributions.\n",
        "In the general case,\n",
        "the cross-entropy $H$ between the true probability distribution $P$ and the estimated probability distribution $Q$ is given by:\n",
        "\n",
        "$$\n",
        "H(P, Q)=-\\sum_{x \\in \\mathcal{X}} P(x) \\log Q(x)\n",
        "$$\n",
        "\n",
        "where $\\mathcal{X}$ is the event space.\n",
        "It is a measure of how \"far off\" our estimated distribution $Q$ is from $P$.\n",
        "(Note that because $P$ and $Q$ are actually functions,\n",
        "$H$ in this case is a function operating on functions, also known as an *operator*.)\n",
        "\n",
        "In our case,\n",
        "$P$ is zero except for the correct label,\n",
        "and thus the cross-entropy reduces to simply the negative logarithm of the score corresponding to the correct class,\n",
        "which is just\n",
        "\n",
        "$$\n",
        "L_i = -\\log(\\sigma_{y_i}))\n",
        "$$\n",
        "\n",
        "where $y_i$ is the correct label of the $x_i$ input sample,\n",
        "and $\\sigma_{y_i}$ is the softmax output of the corresponding correct label. $L$ is then just the average over the $L_i$.\n",
        "\n",
        "The derivative of the softmax is given by, \n",
        "\n",
        "$$\n",
        "\\frac{\\partial\\sigma_i}{\\partial s_j} = \\left \\{\n",
        "\\begin{array}{ll}\n",
        "\\sigma_i(1 - \\sigma_{j}) & i = j     \\\\\n",
        "-\\sigma_i\\sigma_j & i \\neq j  \\\\\n",
        "\\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "Details on the derivation can be found [here](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/).\n",
        "\n",
        "The derivative of the negative logarithm is given by, \n",
        "\n",
        "$$\n",
        "\\frac{\\partial (-\\log)}{\\partial \\sigma_{y_i}} = -\\frac{1}{\\sigma_{y_i}}\n",
        "$$"
      ],
      "metadata": {
        "id": "nhA92akOczjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the `cross_entropy_loss` function in the following cell. The function returns a tuple of `(loss, dy)` where, `loss` is the cross-entropy loss based on the inputs, and `dy` is the gradient of the loss with respect to the `scores` input.This is the loss over multiple samples, therefor you should take the mean of the loss. "
      ],
      "metadata": {
        "id": "XJDqbXH4yxZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stablesoftmax(x):\n",
        "    \"\"\"Compute the softmax of vector x in a numerically stable way.\"\"\"\n",
        "    shiftx = x - np.max(x)\n",
        "    exps = np.exp(shiftx)\n",
        "    return exps / np.sum(exps)"
      ],
      "metadata": {
        "id": "g4_IQNSzFP6u"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## dy = dL/ds_i\n",
        "## s_i = the ith classifier in the sample \n",
        "## we are working with the correct class\n",
        "\n",
        "## i is the correct class in the formula above \n",
        "## j is the index into the softmax vector \n",
        "\n",
        "def cross_entropy_loss(scores, y_batch):\n",
        "    \"\"\"\n",
        "    Computes the cross-entropy layer\n",
        "\n",
        "    Inputs:\n",
        "    - scores: A numpy array containing the scores, of shape (N, C)\n",
        "    - y_batch: A numpy array containing the labels, of shape (N, 1)\n",
        "\n",
        "    Returns: A tuple containing:\n",
        "    - loss as a single float\n",
        "    - gradient with respect to scores; an array of the same shape as scores\n",
        "    \"\"\"\n",
        "    N,C = scores.shape\n",
        "    loss = 0\n",
        "    dy = np.zeros(scores.shape)\n",
        "\n",
        "    # PUT YOUR CODE BELOW:                                                       \n",
        "    # Implement the cross-entropy loss, storing the  \n",
        "    # result in loss. Make sure to take the mean of the loss.\n",
        "    # Hint: The intermediate results maybe useful for the gradient calculation  \n",
        "    ## s is the vector for a samples score output \n",
        "    L = np.zeros((N))\n",
        "\n",
        "    for i in range(N): ## over all data points\n",
        "\n",
        "      yi = int(y_batch[i])## yi is our correct class\n",
        "      ## yi is between 0 and 9 \n",
        "      sigma = stablesoftmax(scores[i,:])\n",
        "      '''for j in range(C):\n",
        "        ## yi is the correct class \n",
        "\n",
        "        if yi ==j: \n",
        "          dy[i,j] = sigma[yi]*(1-sigma[j])\n",
        "        else: \n",
        "          #print('i,j',i,j)\n",
        "          dy[i,j] = -sigma[yi]*sigma[j]\n",
        "\n",
        "        sigma = stablesoftmax(scores[i,:])'''\n",
        "      dy[i,yi] = sigma[yi] -1 ## idk why this works\n",
        "\n",
        "      #print(\"yi\",yi)\n",
        "      syi = scores[i,yi]\n",
        "    \n",
        "      #sigma_yi = math.exp(syi)/ sum([math.exp(elem) for elem in scores[i,:] ])## scores[i,:] is the score vector s\n",
        "      sigma_yi = stablesoftmax(scores[i,:])[yi]\n",
        "      #print('sigma_yi',sigma_yi)\n",
        "      if sigma_yi>0:## this is just to avoid the 0's that might happen when float is extremely small\n",
        "              L[i] = -math.log(sigma_yi)\n",
        "      else: \n",
        "        L[i] = -math.log(10*1000000000)\n",
        "    loss = L.mean()\n",
        "\n",
        "    \n",
        "    ## this dy has j be the column and i be the row of our score matrix \n",
        "\n",
        "\n",
        "    ## D_ijP_t = (S_t)(delta_ti-S_i)x_j\n",
        "    \n",
        "    ## for each data point: \n",
        "    ## calculate softmax(vector); vector = s = sample \n",
        "      ## sigma_i = soft_max[i]\n",
        "\n",
        "    ## for each row of scores\n",
        "    ##dy[r,c] = :\n",
        "      ## v = softmax([r,:])\n",
        "      ## if i = j then : \n",
        "        ## v[i]*(1-v[i])## is this dy[r,i] or dy\n",
        "      ## if i!=j then \n",
        "        ## -v[i]*v[j]\n",
        "\n",
        "    # PUT YOUR CODE BELOW:                                                                    \n",
        "    # Implement the gradient for the cross-entropy loss, storing the result    \n",
        "    # in dy.                                                                    \n",
        "    #                                                                          \n",
        "    # Hint: Instead of computing the gradient from scratch, it may be easier    \n",
        "    # to reuse some of the intermediate values that you used to compute the     \n",
        "    # loss. \n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "    return loss, dy"
      ],
      "metadata": {
        "id": "5hIEv5fl9llO"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to define the `Softmax` classifier class."
      ],
      "metadata": {
        "id": "8h0EQF-yuu8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax(LinearClassifier):\n",
        "    \"\"\" A subclass that uses the Softmax + Cross-entropy loss function \"\"\"\n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        return cross_entropy_loss(scores, y_batch)"
      ],
      "metadata": {
        "id": "RKYgCIcHczy1"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Softmax Experiments\n",
        "\n",
        "In the next few cells run the `Solver` with Softmax models on the training and validation data you've defined previously, similar to the SVM experiements.  Use the `DATA` dictionary you defined previously as the data parameter.\n",
        "\n",
        "\n",
        "Keep the top-5 best performing models and the worst performing model on the validation set."
      ],
      "metadata": {
        "id": "Ug02WvIg5DT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** hyperparameter validation loop in the next cell to train multiple models with different hyperparameters. Keep the top-5 best performing models on the validation set. You can try different learning rates. You may change the num_epochs, but be wary of timeouts. "
      ],
      "metadata": {
        "id": "qRFvUnysFwvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = [None]\n",
        "\n",
        "LR = [.1**x for x in range(1,11,2)]\n",
        "BS =[x for x in range(50,550,100)]\n",
        "print(\"itters\", len(LR)*len(BS))\n",
        "#E = [x for x in range(10,110,20)]\n",
        "#print(E)\n",
        "#print(LR)\n",
        "\n",
        "for lr in LR: \n",
        "  for bs in BS: \n",
        "    #svm = LinearSVM()\n",
        "    softmax = Softmax()\n",
        "    solver = Solver(softmax,DATA, learning_rate=lr, batch_size=bs)\n",
        "    solver.train()\n",
        "\n",
        "    acc = solver.accuracy()\n",
        "    for i in range(len(best_models)): \n",
        "      if (best_models[i] == None):\n",
        "        best_models[i] = solver\n",
        "      elif len(best_models)<5:\n",
        "        best_models.append( solver)\n",
        "      elif(best_models[i].accuracy()<solver.accuracy()):\n",
        "        best_models[i] = solver\n",
        "        break\n",
        "    print(best_models)\n",
        "\n",
        "sm_best_models = best_models"
      ],
      "metadata": {
        "id": "05Od5fTg5Dqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the next cell to visualize the weights corresponding to each sample in the *best* performing Softmax models. You should have ten 28x28 images.\n",
        "\n",
        "\n",
        "You can add additional cells below.\n",
        "\n",
        "Depending on your learning rate and weights, it might not look so great. If all the images look the same but you have good accuracy, try subtracting the average of weights from weights of each class. "
      ],
      "metadata": {
        "id": "s8j9KoxfXgY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for solver in sm_best_models: \n",
        "  weights_to_img(solver)\n"
      ],
      "metadata": {
        "id": "0SEDP9m-EZNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the testing performance of your top-5 performing Softmax models on the test set and print the results. "
      ],
      "metadata": {
        "id": "4GdpbgYg5D8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for solvr in sm_best_models: \n",
        "  solvr.X_val = x_test\n",
        "  solvr.y_val = y_test\n",
        "  acc = solvr.accuracy()\n",
        "  print(acc)"
      ],
      "metadata": {
        "id": "oxuJHeU45EVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Deeper Neural Networks (Very Slightly)\n",
        " "
      ],
      "metadata": {
        "id": "A7mX-suZStG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Up until now, we have been working with linear classification models. Linear classification models are very adept at modelling data that have nice linear boundaries. In practice, realy world data is rarely linear. Multilayer fully-connected neural networks with non-linear activation functions on the other hand can model non-linear data-label relationships. \n",
        "\n",
        "Such models are a powerful extension to linear models and are the building blocks of modern deep learning. \n",
        "\n",
        "In this section, you will be implementing a two-layer fully-connected neural network. Fully-connected neural networks perform the transformation that you've implemented above coupled with a non-linear activation function. You will also implement your own version of the rectified linear unit fuction (commonly reffered to as ReLU), a non-linear activation function."
      ],
      "metadata": {
        "id": "j60wKxwhXu2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (a) ReLU Function\n",
        "\n",
        "The ReLU function is given by:\n",
        "\n",
        "$$\n",
        "f(x) = x^{+} = max(0, x)\n",
        "$$\n",
        "\n",
        "**Implement** the following cell to complete the definition of the `ReLU_forward` function."
      ],
      "metadata": {
        "id": "gP_YgE1JWj1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reLU(x): \n",
        "  if x<0: \n",
        "    return 0 \n",
        "  else: \n",
        "    return x\n",
        "VreLU=np.vectorize(reLU)"
      ],
      "metadata": {
        "id": "rkUzCr9q2EXg"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A = np.array([[1,-2,3],[-4,5,6]]); A\n",
        "#VreLU(A)\n",
        "#my_function = lambda x: if x<0 0 else: x"
      ],
      "metadata": {
        "id": "Tb6sIq_o2Or1"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU_forward(x):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a ReLU actiivation.\n",
        "\n",
        "    The input x has shape (N, D) and contains a minibatch of N\n",
        "    examples, where each example x[i] has shape (D). We will \n",
        "    transform it to an output vector of dimension M.\n",
        "\n",
        "    Inputs:\n",
        "    - x: A numpy array containing input data, of shape (N, D)\n",
        "\n",
        "    \n",
        "    Returns a tuple of:\n",
        "    - out: output, of shape (N, D)\n",
        "    - cache: (x)\n",
        "    \"\"\"\n",
        "    N,D = x.shape \n",
        "    out = None\n",
        "\n",
        "    out = VreLU(x)\n",
        "    \n",
        "    # PUT YOUR CODE BELOW: Implement the ReLU forward pass. Store the result in \n",
        "    # out. You will need to reshape the input into rows.\n",
        "    \n",
        "    \n",
        "    # The lines below do not need to be changed.\n",
        "\n",
        "    cache = (x,)\n",
        "    \n",
        "    assert(out.shape == (N,D))\n",
        "    return out, cache"
      ],
      "metadata": {
        "id": "tQ-CcTqJStgz"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ReLU derivative is given by: \n",
        "\n",
        "$$\n",
        "\\frac{\\partial f(x)}{\\partial x} = \\left\\{\n",
        "\\begin{array}{ll}\n",
        "      0 & x \\leq 0 \\\\\n",
        "      1 & x > 0 \\\\\n",
        "\\end{array}\n",
        "\\right. \n",
        "$$\n",
        "\n",
        "Where, $f(x)$ is the ReLU function of course.\n",
        "\n",
        "\n",
        "**Implement** the following cell to complete the definition of the `ReLU_backward` function."
      ],
      "metadata": {
        "id": "g3LU7V4Ib4xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def d_reLU(x): \n",
        "  if x<=0:\n",
        "    return 0 \n",
        "  else: \n",
        "    return 1 \n",
        "\n",
        "Vd_reLU=np.vectorize(d_reLU)"
      ],
      "metadata": {
        "id": "4SDvmFDl44EA"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vd_reLU(np.array([[1,2,3],[4,-5,-6]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z65xD-Ljj9DV",
        "outputId": "fb3e83b6-b7d9-48ad-bfd3-552bd179f4d3"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1],\n",
              "       [1, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU_backward(d_upstream, cache):\n",
        "    \"\"\"\n",
        "    Computes the backward pass for an linear layer.\n",
        "\n",
        "    Inputs:\n",
        "    - d_upstream: Upstream derivative, of shape (N, D)\n",
        "    - cache: Tuple of:\n",
        "      - x: Input data, of shape (N, D)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - dx: Gradient with respect to x, of shape (N, D)\n",
        "    \"\"\"\n",
        "    N,D =  d_upstream.shape\n",
        "    ## dx = np.matmul(dy, w.T[:,:-1]) \n",
        "\n",
        "\n",
        "    x,  = cache\n",
        "    \n",
        "    #dx = Vd_reLU(x)## I wan't to multiply but then we get shape either D,D or N,N \n",
        "    dx = Vd_reLU(d_upstream)#############################################changed from above\n",
        "    ## this could be Vd_reLU(d_upstream)\n",
        "    ## we need dx be the shape of x\n",
        "\n",
        "    ## I think dx should be upstream*d_relu(x)\n",
        "\n",
        "    # PUT YOUR CODE BELOW: Implement the ReLU backward pass.                                 \n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "    assert(dx.shape == (N,D) )\n",
        "\n",
        "    return (dx, )"
      ],
      "metadata": {
        "id": "fTn6t0FaVBSs"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (b) Two-layer Neural Network\n",
        "\n",
        "**Implement** the definition of the two-layer neural network below.\n",
        "\n",
        "Similar to the `LinearClassifier` class, you should write the `__init__`, `forward`, `backward`, and `predict` methods. We will be using the cross-entropy loss for this network. \n",
        "\n",
        "Complete the following:\n",
        "- The `__init__()` method initializes the class. You must generate two random weight matrices. We will be using the bias trick, so the bias should concatenated to the weight matrix. They are initialized differently. \n",
        "\n",
        "- The `forward()` method generates the scores for given an input sample, by applying a `linear_forward()` and `ReLU_forward()` with appropriate inputs. Make sure to store and return the cache for the intermediate steps. \n",
        "\n",
        "- The `backward()` method returns the gradients with respect to the inputs and weights, using the `linear_backward()` and `ReLU_backward()`. Make sure the keys for the returned dictionary `weights_gradient` matches the keys in the `self.params` dictionary.\n",
        "\n",
        "- The `predict()` method returns the labels predicted from the scores returned using the `self.forward()` method.\n"
      ],
      "metadata": {
        "id": "jYDMTehxYP75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoLayerNet(object):\n",
        "    \"\"\"\n",
        "    A two-layer fully-connected neural network with ReLU nonlinearity and\n",
        "    softmax loss that uses a modular layer design. We assume an input dimension\n",
        "    of D, a hidden dimension of H, and perform classification over C classes.\n",
        "\n",
        "    The architecure should be transform - relu - transform - softmax.\n",
        "\n",
        "    Note that this class does not implement gradient descent; instead, it\n",
        "    will interact with a separate Solver object that is responsible for running\n",
        "    optimization.\n",
        "\n",
        "    The learnable parameters of the model are stored in the dictionary\n",
        "    self.params that maps parameter names to numpy arrays.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 hidden_dim=100,\n",
        "                 num_classes=10,\n",
        "                 weight_scale=1e-3):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "\n",
        "        self.params = {}\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # PUT YOUR CODE BELOW: Initialize the weights of the two-layer net. Weights should be     \n",
        "        # initialized from a Gaussian centered at 0.0 with standard deviation      \n",
        "        # equal to weight_scale, and biases should be initialized to zero.         \n",
        "        # All weights should be stored in the dictionary self.params, with first   \n",
        "        # layer weights and using the keys 'W1' and second layer weights and using \n",
        "        # the keys 'W2'. Make sure to concatenate the weights and biases to make a \n",
        "        # a single matrix for the bias trick!      \n",
        "\n",
        "        ## W1 feeds into W2 so should be input by input and output hidden\n",
        "        ## W2 feeds into loss function so should be input by hidden and output num classes      \n",
        "        w1 = np.random.normal(0, weight_scale, size =(input_dim,hidden_dim)) ## we need an extra row for the 1s \n",
        "        bias = np.ones(hidden_dim).reshape(1,hidden_dim);bias\n",
        "        w1 = np.append(w1,bias, axis = 0)\n",
        "        self.params['W1'] = w1                                                 \n",
        "        \n",
        "        w2 = np.random.normal(0, weight_scale, size =(hidden_dim,num_classes)) ## we need an extra row for the 1s \n",
        "        bias = np.ones(num_classes).reshape(1,num_classes);bias\n",
        "        w2 = np.append(w2,bias, axis = 0)\n",
        "        #w2 = \n",
        "        self.params['W1'] = w1\n",
        "        self.params['W2'] = w2\n",
        "\n",
        "        # The lines below do not need to be changed in this method.\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Implement the forward pass of the neural network and return the scores\n",
        "\n",
        "        Inputs:\n",
        "        - x: A numpy array containing input data, of shape (N, self.input_dim)\n",
        "        \n",
        "\n",
        "        Returns a tuple of:\n",
        "        - out: output, of shape (N, D)\n",
        "        - Tuple of tuples:\n",
        "          - cache_lin_1: A tuple (x, w1) \n",
        "            - x: data, of shape (N, self.input_dim)\n",
        "            - w1: Weight of linear layer 1 of shape (self.input_dim+1, self.hidden_dim)\n",
        "          - cache_relu_1: A tuple (h, )\n",
        "            - h : data, of shape (N, self.hidden_dim)\n",
        "          - cache_lin_2:  A tuple (h, w2)\n",
        "            - h: data, of shape (N, self.hidden_dim)\n",
        "            - w2: weight of linear 2 of shape (self.hidden_dim+1, C)\n",
        "        \"\"\"\n",
        "        out = None\n",
        "        N, feature_dim = x.shape\n",
        "        #cache_lin_1, cache_relu_1, cache_lin_2 = None, None, None\n",
        "\n",
        "        if (feature_dim != self.input_dim):\n",
        "            raise Exception(f\"The input feature dimension of {feature_dim} does \\\n",
        "                            not match the expected feature dimension of \\\n",
        "                            {self.input_dim} \")\n",
        "\n",
        "        \n",
        "        # PUT YOUR CODE BELOW: Perform a forward pass of the two-layer net.\n",
        "        # The architecture is transform - relu - transform \n",
        "        # Make to store the appropriate cache in the appropriate variables                     \n",
        "\n",
        "        ## apply linear_forward() and ReLU_forward() with the approprate inputs \n",
        "        w1 = self.params['W1']\n",
        "        out, cache_lin_1 = linear_forward(x, w1)\n",
        "\n",
        "        out, cache_relu_1 = ReLU_forward(out)\n",
        "\n",
        "        w2 = self.params['W2']  \n",
        "        out, cache_lin_2 = linear_forward(out,w2)\n",
        "\n",
        "        # The lines below do not need to be changed in this method.\n",
        "\n",
        "        return out, (cache_lin_1, cache_relu_1, cache_lin_2)\n",
        "\n",
        "\n",
        "    def backward(self, dout, cache):\n",
        "        \"\"\"\n",
        "        Implement the backward pass of the neural network and return the\n",
        "        gradients w.r.t the input, and the weights\n",
        "\n",
        "        Inputs:\n",
        "        - dout: Upstream derivative, of shape (N, C)\n",
        "        - cache: Tuple of tuples:\n",
        "          - cache_lin_1: A tuple (x, w1) \n",
        "            - x: data, of shape (N, self.input_dim)\n",
        "            - w1: Weight of linear layer 1 of shape (self.input_dim+1, self.hidden_dim)\n",
        "          - cache_relu_1: A tuple (h, )\n",
        "            - h : data, of shape (N, self.hidden_dim)\n",
        "          - cache_lin_2:  A tuple (h, w2)\n",
        "            - h: data, of shape (N, self.hidden_dim)\n",
        "            - w2: weight of linear 2 of shape (self.hidden_dim+1, C)\n",
        "\n",
        "        Returns a tuple of:\n",
        "          - dx: A numpy array of the gradient with respect to x, of shape (N, D)\n",
        "          - weight_gradients: A dictionary of numpy arrays containing the\n",
        "              gradients with respect to the weights. \n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        weight_gradients = {}\n",
        "        #dx = None\n",
        "\n",
        "        N, classes = dout.shape\n",
        "        \n",
        "        cache_lin_1, cache_relu_1, cache_lin_2 = cache\n",
        "\n",
        "        if (classes != self.num_classes):\n",
        "            raise Exception(f\"The output class dimension of {classes} does \\\n",
        "                            not match the expected number of classes \\\n",
        "                            {self.num_classes} \")\n",
        "\n",
        "        # PUT YOUR CODE BELOW: Perform a backward pass of the two-layer net.                      \n",
        "        '''linear: \n",
        "                dx, dw = linear_backward(dout, cache)#dx, dw\n",
        "\n",
        "        weight_gradients = {}\n",
        "        weight_gradients['W1'] = dw\n",
        "        '''\n",
        "        ### what do we do? \n",
        "        ## linear backward\n",
        "        ## relu backward \n",
        "        ## linear backward \n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "        dx,dw = linear_backward(dout, cache_lin_1)## d_upstream = dx\n",
        "        weight_gradients['W1'] = dw\n",
        "\n",
        "        dx = ReLU_backward(dx,cache_relu_1)## d_upstream = dx \n",
        "\n",
        "        dx,dw = linear_backward(dout,cache_lin_2)## d_upstream = dout\n",
        "        weight_gradients['W2'] = dw## the backwards one goes first \n",
        "        #weight_gradients['W1']  = dw ## doesn't work\n",
        "        dx = ReLU_backward(dx,cache_relu_1)## d_upstream = dx \n",
        "\n",
        "        \n",
        "        '''dx,dw = linear_backward(dx, cache_lin_1)## d_upstream = dx\n",
        "        weight_gradients['W1'] = dw## the first layer goes last \n",
        "        #weight_gradients['W2'] = dw\n",
        "        # The lines below do not need to be changed in this method.'''\n",
        "        return (dx, weight_gradients)\n",
        "    \n",
        "    def predict(self, x):\n",
        "\n",
        "        \"\"\"\n",
        "        Implement the predictions from the forward pass of the neural network and \n",
        "        returns it. \n",
        "\n",
        "        Inputs:\n",
        "        - x: Input data, of shape (N, self.input_dim)\n",
        "        \n",
        "        Returns a tuple of:\n",
        "          - predictions: A numpy array of shape (N, ) of the predicted class per sample \n",
        "          \n",
        "        \"\"\"\n",
        "\n",
        "        #y_pred = None\n",
        "\n",
        "\n",
        "        \n",
        "        # PUT YOUR CODE BELOW: Predict the classes of using the two-layer net.                    \n",
        "\n",
        "        scores, cache = self.forward(x)#forward(self, x)(x,self.params['W1'])## use the parameters to do a forward pass\n",
        "        \n",
        "        #y_pred = np.amax(scores, axis = 1)\n",
        "        y_pred = np.argmax(scores, axis = 1)\n",
        "        # The lines below do not need to be changed in this method.\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        # The lines below do not need to be changed in this method.\n",
        "        return cross_entropy_loss(scores, y_batch)"
      ],
      "metadata": {
        "id": "dSr_3dSiYQOf"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (c) Experiments\n",
        "\n",
        "Similar to the linear classifiers, you also want to identify the best configuration of hyperparameters that perform the best for your dataset. Similar to the case of the linear models, you can vary the learning rate for your solver. You should use the `Solver` class for these models as well. Use the `DATA` dictionary you defined previously as the data parameter.\n",
        "\n",
        "Additionaly, the neural network provides another hyperparameter to vary, the the number of neurons in the hidden layer. \n",
        "\n",
        "Adding a large of number of neurons may cause a large degradation in performance, the linear transformation scales as $O(N^3)$ with the number of neurons. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yovrIeNablvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** a hyperparameter validation loop in the next cell to train multiple models with different hyperparameters. Keep the top-5 best performing models on the validation set. You may change learning rate, and hidden dims. You may change the num_epochs, but be wary of timeouts. "
      ],
      "metadata": {
        "id": "N8zQgNiK-I9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "28*28\n"
      ],
      "metadata": {
        "id": "J8HJMpvFUGv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''NN = TwoLayerNet(input_dim  = 784, hidden_dim=10)\n",
        "#print(NN.params)\n",
        "solver = Solver(NN,DATA, learning_rate=.001, batch_size=bs)\n",
        "solver.train()\n",
        "#solver.train()'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nXH_5iZmXuUN",
        "outputId": "c691544a-b565-4d67-9258-196009f7004f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NN = TwoLayerNet(input_dim  = 784, hidden_dim=10)\\n#print(NN.params)\\nsolver = Solver(NN,DATA, learning_rate=.001, batch_size=bs)\\nsolver.train()\\n#solver.train()'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = [None]\n",
        "\n",
        "LR = [.1**x for x in range(1,11,2)]\n",
        "BS =[x for x in range(50,550,100)]\n",
        "print(\"itters\", len(LR)*len(BS))\n",
        "#E = [x for x in range(10,110,20)]\n",
        "#print(E)\n",
        "#print(LR)\n",
        "\n",
        "for lr in LR: \n",
        "  for bs in BS: \n",
        "    #svm = LinearSVM()\n",
        "    #softmax = Softmax()## this needs to be changed \n",
        "    NN = TwoLayerNet(input_dim  = 784, hidden_dim=10)\n",
        "    solver = Solver(NN,DATA, learning_rate=lr, batch_size=bs)\n",
        "    solver.train()\n",
        "\n",
        "    acc = solver.accuracy()\n",
        "    for i in range(len(best_models)): \n",
        "      if (best_models[i] == None):\n",
        "        best_models[i] = solver\n",
        "      elif len(best_models)<5:\n",
        "        best_models.append( solver)\n",
        "      elif(best_models[i].accuracy()<solver.accuracy()):\n",
        "        best_models[i] = solver\n",
        "        break\n",
        "    print(best_models)"
      ],
      "metadata": {
        "id": "qwZysCge-Js5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ab4bb9-26b0-42fd-8140-fe3bee0f3c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "The validation accuracy at iteration 5456  is               81.675%\n",
            "The validation accuracy at iteration 5472  is               81.27499999999999%\n",
            "The validation accuracy at iteration 5488  is               82.15%\n",
            "The validation accuracy at iteration 5504  is               76.7%\n",
            "The validation accuracy at iteration 5520  is               79.80000000000001%\n",
            "The validation accuracy at iteration 5536  is               82.27499999999999%\n",
            "The validation accuracy at iteration 5552  is               81.69999999999999%\n",
            "The validation accuracy at iteration 5568  is               77.5%\n",
            "The validation accuracy at iteration 5584  is               78.4%\n",
            "The validation accuracy at iteration 5600  is               79.125%\n",
            "The validation accuracy at iteration 5616  is               78.55%\n",
            "The validation accuracy at iteration 5632  is               80.325%\n",
            "The validation accuracy at iteration 5648  is               79.3%\n",
            "The validation accuracy at iteration 5664  is               79.07499999999999%\n",
            "The validation accuracy at iteration 5680  is               78.55%\n",
            "The validation accuracy at iteration 5696  is               81.39999999999999%\n",
            "The validation accuracy at iteration 5712  is               77.85%\n",
            "The validation accuracy at iteration 5728  is               80.22500000000001%\n",
            "The validation accuracy at iteration 5744  is               80.60000000000001%\n",
            "The validation accuracy at iteration 5760  is               81.55%\n",
            "The validation accuracy at iteration 5776  is               81.27499999999999%\n",
            "The validation accuracy at iteration 5792  is               81.325%\n",
            "The validation accuracy at iteration 5808  is               81.925%\n",
            "The validation accuracy at iteration 5824  is               78.8%\n",
            "The validation accuracy at iteration 5840  is               79.85%\n",
            "The validation accuracy at iteration 5856  is               81.89999999999999%\n",
            "The validation accuracy at iteration 5872  is               82.15%\n",
            "The validation accuracy at iteration 5888  is               80.2%\n",
            "The validation accuracy at iteration 5904  is               78.675%\n",
            "The validation accuracy at iteration 5920  is               80.0%\n",
            "The validation accuracy at iteration 5936  is               78.4%\n",
            "The validation accuracy at iteration 5952  is               80.05%\n",
            "The validation accuracy at iteration 5968  is               79.7%\n",
            "The validation accuracy at iteration 5984  is               79.675%\n",
            "The validation accuracy at iteration 6000  is               81.525%\n",
            "The validation accuracy at iteration 6016  is               81.425%\n",
            "The validation accuracy at iteration 6032  is               78.9%\n",
            "The validation accuracy at iteration 6048  is               81.3%\n",
            "The validation accuracy at iteration 6064  is               80.175%\n",
            "The validation accuracy at iteration 6080  is               81.27499999999999%\n",
            "The validation accuracy at iteration 6096  is               81.25%\n",
            "The validation accuracy at iteration 6112  is               81.875%\n",
            "The validation accuracy at iteration 6128  is               82.8%\n",
            "The validation accuracy at iteration 6144  is               76.95%\n",
            "The validation accuracy at iteration 6160  is               80.05%\n",
            "The validation accuracy at iteration 6176  is               82.775%\n",
            "The validation accuracy at iteration 6192  is               81.975%\n",
            "The validation accuracy at iteration 6208  is               80.7%\n",
            "The validation accuracy at iteration 6224  is               80.925%\n",
            "The validation accuracy at iteration 6240  is               80.45%\n",
            "The validation accuracy at iteration 6256  is               79.75%\n",
            "The validation accuracy at iteration 6272  is               81.65%\n",
            "The validation accuracy at iteration 6288  is               79.825%\n",
            "The validation accuracy at iteration 6304  is               80.475%\n",
            "The validation accuracy at iteration 6320  is               82.22500000000001%\n",
            "The validation accuracy at iteration 6336  is               82.22500000000001%\n",
            "The validation accuracy at iteration 6352  is               80.2%\n",
            "The validation accuracy at iteration 6368  is               78.8%\n",
            "The validation accuracy at iteration 6384  is               80.875%\n",
            "The validation accuracy at iteration 6400  is               81.55%\n",
            "The validation accuracy at iteration 6416  is               82.05%\n",
            "The validation accuracy at iteration 6432  is               82.475%\n",
            "The validation accuracy at iteration 6448  is               83.5%\n",
            "The validation accuracy at iteration 6464  is               81.25%\n",
            "The validation accuracy at iteration 6480  is               80.35%\n",
            "The validation accuracy at iteration 6496  is               80.075%\n",
            "The validation accuracy at iteration 6512  is               82.0%\n",
            "The validation accuracy at iteration 6528  is               79.875%\n",
            "The validation accuracy at iteration 6544  is               80.72500000000001%\n",
            "The validation accuracy at iteration 6560  is               80.72500000000001%\n",
            "The validation accuracy at iteration 6576  is               79.27499999999999%\n",
            "The validation accuracy at iteration 6592  is               81.875%\n",
            "The validation accuracy at iteration 6608  is               79.425%\n",
            "The validation accuracy at iteration 6624  is               80.125%\n",
            "The validation accuracy at iteration 6640  is               81.69999999999999%\n",
            "The validation accuracy at iteration 6656  is               81.89999999999999%\n",
            "The validation accuracy at iteration 6672  is               78.675%\n",
            "The validation accuracy at iteration 6688  is               80.375%\n",
            "The validation accuracy at iteration 6704  is               81.22500000000001%\n",
            "The validation accuracy at iteration 6720  is               80.475%\n",
            "The validation accuracy at iteration 6736  is               81.65%\n",
            "The validation accuracy at iteration 6752  is               82.6%\n",
            "The validation accuracy at iteration 6768  is               82.75%\n",
            "The validation accuracy at iteration 6784  is               81.69999999999999%\n",
            "The validation accuracy at iteration 6800  is               80.425%\n",
            "The validation accuracy at iteration 6816  is               82.95%\n",
            "The validation accuracy at iteration 6832  is               82.55%\n",
            "The validation accuracy at iteration 6848  is               79.375%\n",
            "The validation accuracy at iteration 6864  is               80.475%\n",
            "The validation accuracy at iteration 6880  is               81.0%\n",
            "The validation accuracy at iteration 6896  is               80.15%\n",
            "The validation accuracy at iteration 6912  is               81.75%\n",
            "The validation accuracy at iteration 6928  is               78.75%\n",
            "The validation accuracy at iteration 6944  is               79.325%\n",
            "The validation accuracy at iteration 6960  is               80.875%\n",
            "The validation accuracy at iteration 6976  is               81.89999999999999%\n",
            "The validation accuracy at iteration 6992  is               79.35%\n",
            "The validation accuracy at iteration 7008  is               80.75%\n",
            "The validation accuracy at iteration 7024  is               80.65%\n",
            "The validation accuracy at iteration 7040  is               80.9%\n",
            "The validation accuracy at iteration 7056  is               82.05%\n",
            "The validation accuracy at iteration 7072  is               82.425%\n",
            "The validation accuracy at iteration 7088  is               81.425%\n",
            "The validation accuracy at iteration 7104  is               81.3%\n",
            "The validation accuracy at iteration 7120  is               80.27499999999999%\n",
            "The validation accuracy at iteration 7136  is               82.69999999999999%\n",
            "The validation accuracy at iteration 7152  is               82.075%\n",
            "The validation accuracy at iteration 7168  is               80.475%\n",
            "The validation accuracy at iteration 7184  is               78.525%\n",
            "The validation accuracy at iteration 7200  is               79.975%\n",
            "The validation accuracy at iteration 7216  is               79.625%\n",
            "The validation accuracy at iteration 7232  is               80.675%\n",
            "The validation accuracy at iteration 7248  is               78.7%\n",
            "The validation accuracy at iteration 7264  is               80.35%\n",
            "The validation accuracy at iteration 7280  is               81.475%\n",
            "The validation accuracy at iteration 7296  is               82.15%\n",
            "The validation accuracy at iteration 7312  is               80.075%\n",
            "The validation accuracy at iteration 7328  is               79.325%\n",
            "The validation accuracy at iteration 7344  is               80.925%\n",
            "The validation accuracy at iteration 7360  is               81.375%\n",
            "The validation accuracy at iteration 7376  is               81.85%\n",
            "The validation accuracy at iteration 7392  is               82.825%\n",
            "The validation accuracy at iteration 7408  is               82.575%\n",
            "The validation accuracy at iteration 7424  is               82.625%\n",
            "The validation accuracy at iteration 7440  is               80.55%\n",
            "The validation accuracy at iteration 7456  is               82.975%\n",
            "The validation accuracy at iteration 7472  is               82.5%\n",
            "The validation accuracy at iteration 7488  is               78.95%\n",
            "The validation accuracy at iteration 7504  is               80.525%\n",
            "The validation accuracy at iteration 7520  is               79.95%\n",
            "The validation accuracy at iteration 7536  is               79.55%\n",
            "The validation accuracy at iteration 7552  is               81.77499999999999%\n",
            "The validation accuracy at iteration 7568  is               79.925%\n",
            "The validation accuracy at iteration 7584  is               80.25%\n",
            "The validation accuracy at iteration 7600  is               81.77499999999999%\n",
            "The validation accuracy at iteration 7616  is               81.65%\n",
            "The validation accuracy at iteration 7632  is               79.75%\n",
            "The validation accuracy at iteration 7648  is               80.95%\n",
            "The validation accuracy at iteration 7664  is               81.025%\n",
            "The validation accuracy at iteration 7680  is               81.8%\n",
            "The validation accuracy at iteration 7696  is               82.075%\n",
            "The validation accuracy at iteration 7712  is               82.95%\n",
            "The validation accuracy at iteration 7728  is               83.55%\n",
            "The validation accuracy at iteration 7744  is               81.77499999999999%\n",
            "The validation accuracy at iteration 7760  is               80.425%\n",
            "The validation accuracy at iteration 7776  is               82.675%\n",
            "The validation accuracy at iteration 7792  is               82.325%\n",
            "The validation accuracy at iteration 7808  is               79.725%\n",
            "The validation accuracy at iteration 7824  is               80.30000000000001%\n",
            "The validation accuracy at iteration 7840  is               81.05%\n",
            "The validation accuracy at iteration 7856  is               79.35%\n",
            "The validation accuracy at iteration 7872  is               82.3%\n",
            "The validation accuracy at iteration 7888  is               80.075%\n",
            "The validation accuracy at iteration 7904  is               81.27499999999999%\n",
            "The validation accuracy at iteration 7920  is               82.22500000000001%\n",
            "The validation accuracy at iteration 7936  is               81.875%\n",
            "The validation accuracy at iteration 7952  is               79.9%\n",
            "The validation accuracy at iteration 7968  is               80.625%\n",
            "The validation accuracy at iteration 7984  is               82.425%\n",
            "The validation accuracy at iteration 8000  is               82.39999999999999%\n",
            "The validation accuracy at iteration 8016  is               82.15%\n",
            "The validation accuracy at iteration 8032  is               82.72500000000001%\n",
            "The validation accuracy at iteration 8048  is               82.05%\n",
            "The validation accuracy at iteration 8064  is               79.14999999999999%\n",
            "The validation accuracy at iteration 8080  is               80.0%\n",
            "The validation accuracy at iteration 8096  is               81.65%\n",
            "The validation accuracy at iteration 8112  is               82.5%\n",
            "The validation accuracy at iteration 8128  is               81.55%\n",
            "The validation accuracy at iteration 8144  is               80.35%\n",
            "The validation accuracy at iteration 8160  is               80.55%\n",
            "The validation accuracy at iteration 8176  is               80.22500000000001%\n",
            "The validation accuracy at iteration 8192  is               81.39999999999999%\n",
            "The validation accuracy at iteration 8208  is               79.35%\n",
            "The validation accuracy at iteration 8224  is               81.75%\n",
            "The validation accuracy at iteration 8240  is               82.425%\n",
            "The validation accuracy at iteration 8256  is               82.8%\n",
            "The validation accuracy at iteration 8272  is               81.175%\n",
            "The validation accuracy at iteration 8288  is               81.925%\n",
            "The validation accuracy at iteration 8304  is               82.625%\n",
            "The validation accuracy at iteration 8320  is               82.425%\n",
            "The validation accuracy at iteration 8336  is               81.975%\n",
            "The validation accuracy at iteration 8352  is               82.525%\n",
            "The validation accuracy at iteration 8368  is               83.42500000000001%\n",
            "The validation accuracy at iteration 8384  is               82.425%\n",
            "The validation accuracy at iteration 8400  is               80.75%\n",
            "The validation accuracy at iteration 8416  is               82.22500000000001%\n",
            "The validation accuracy at iteration 8432  is               81.75%\n",
            "The validation accuracy at iteration 8448  is               80.80000000000001%\n",
            "The validation accuracy at iteration 8464  is               80.95%\n",
            "The validation accuracy at iteration 8480  is               80.9%\n",
            "The validation accuracy at iteration 8496  is               80.825%\n",
            "The validation accuracy at iteration 8512  is               81.175%\n",
            "The validation accuracy at iteration 8528  is               80.77499999999999%\n",
            "The validation accuracy at iteration 8544  is               80.675%\n",
            "The validation accuracy at iteration 8560  is               82.35%\n",
            "The validation accuracy at iteration 8576  is               82.675%\n",
            "The validation accuracy at iteration 8592  is               81.075%\n",
            "The validation accuracy at iteration 8608  is               82.075%\n",
            "The validation accuracy at iteration 8624  is               82.25%\n",
            "The validation accuracy at iteration 8640  is               81.77499999999999%\n",
            "The validation accuracy at iteration 8656  is               82.075%\n",
            "The validation accuracy at iteration 8672  is               82.825%\n",
            "The validation accuracy at iteration 8688  is               83.2%\n",
            "The validation accuracy at iteration 8704  is               83.3%\n",
            "The validation accuracy at iteration 8720  is               81.0%\n",
            "The validation accuracy at iteration 8736  is               82.6%\n",
            "The validation accuracy at iteration 8752  is               82.72500000000001%\n",
            "The validation accuracy at iteration 8768  is               81.45%\n",
            "The validation accuracy at iteration 8784  is               80.625%\n",
            "The validation accuracy at iteration 8800  is               80.55%\n",
            "The validation accuracy at iteration 8816  is               80.175%\n",
            "The validation accuracy at iteration 8832  is               82.15%\n",
            "The validation accuracy at iteration 8848  is               80.35%\n",
            "The validation accuracy at iteration 8864  is               80.9%\n",
            "The validation accuracy at iteration 8880  is               82.69999999999999%\n",
            "The validation accuracy at iteration 8896  is               82.425%\n",
            "The validation accuracy at iteration 8912  is               79.57499999999999%\n",
            "The validation accuracy at iteration 8928  is               81.25%\n",
            "The validation accuracy at iteration 8944  is               81.25%\n",
            "The validation accuracy at iteration 8960  is               81.89999999999999%\n",
            "The validation accuracy at iteration 8976  is               82.625%\n",
            "The validation accuracy at iteration 8992  is               83.125%\n",
            "The validation accuracy at iteration 9008  is               84.0%\n",
            "The validation accuracy at iteration 9024  is               83.475%\n",
            "The validation accuracy at iteration 9040  is               81.45%\n",
            "The validation accuracy at iteration 9056  is               82.22500000000001%\n",
            "The validation accuracy at iteration 9072  is               82.375%\n",
            "The validation accuracy at iteration 9088  is               79.95%\n",
            "The validation accuracy at iteration 9104  is               81.05%\n",
            "The validation accuracy at iteration 9120  is               82.175%\n",
            "The validation accuracy at iteration 9136  is               80.175%\n",
            "The validation accuracy at iteration 9152  is               80.9%\n",
            "The validation accuracy at iteration 9168  is               80.375%\n",
            "The validation accuracy at iteration 9184  is               81.575%\n",
            "The validation accuracy at iteration 9200  is               82.72500000000001%\n",
            "The validation accuracy at iteration 9216  is               83.075%\n",
            "The validation accuracy at iteration 9232  is               81.325%\n",
            "The validation accuracy at iteration 9248  is               81.625%\n",
            "The validation accuracy at iteration 9264  is               82.19999999999999%\n",
            "The validation accuracy at iteration 9280  is               82.825%\n",
            "The validation accuracy at iteration 9296  is               82.15%\n",
            "The validation accuracy at iteration 9312  is               82.625%\n",
            "The validation accuracy at iteration 9328  is               83.25%\n",
            "The validation accuracy at iteration 9344  is               83.39999999999999%\n",
            "The validation accuracy at iteration 9360  is               80.55%\n",
            "The validation accuracy at iteration 9376  is               82.69999999999999%\n",
            "The validation accuracy at iteration 9392  is               82.325%\n",
            "The validation accuracy at iteration 9408  is               81.525%\n",
            "The validation accuracy at iteration 9424  is               80.525%\n",
            "The validation accuracy at iteration 9440  is               80.60000000000001%\n",
            "The validation accuracy at iteration 9456  is               79.675%\n",
            "The validation accuracy at iteration 9472  is               82.19999999999999%\n",
            "The validation accuracy at iteration 9488  is               80.825%\n",
            "The validation accuracy at iteration 9504  is               81.0%\n",
            "The validation accuracy at iteration 9520  is               83.125%\n",
            "The validation accuracy at iteration 9536  is               82.0%\n",
            "The validation accuracy at iteration 9552  is               80.22500000000001%\n",
            "The validation accuracy at iteration 9568  is               81.175%\n",
            "The validation accuracy at iteration 9584  is               80.975%\n",
            "The validation accuracy at iteration 9600  is               81.675%\n",
            "The validation accuracy at iteration 9616  is               82.39999999999999%\n",
            "The validation accuracy at iteration 9632  is               83.075%\n",
            "The validation accuracy at iteration 9648  is               83.325%\n",
            "The validation accuracy at iteration 9664  is               83.025%\n",
            "The validation accuracy at iteration 9680  is               80.80000000000001%\n",
            "The validation accuracy at iteration 9696  is               82.575%\n",
            "The validation accuracy at iteration 9712  is               82.025%\n",
            "The validation accuracy at iteration 9728  is               81.89999999999999%\n",
            "The validation accuracy at iteration 9744  is               81.85%\n",
            "The validation accuracy at iteration 9760  is               81.025%\n",
            "The validation accuracy at iteration 9776  is               80.30000000000001%\n",
            "The validation accuracy at iteration 9792  is               82.89999999999999%\n",
            "The validation accuracy at iteration 9808  is               80.525%\n",
            "The validation accuracy at iteration 9824  is               80.825%\n",
            "The validation accuracy at iteration 9840  is               82.375%\n",
            "The validation accuracy at iteration 9856  is               83.05%\n",
            "The validation accuracy at iteration 9872  is               80.80000000000001%\n",
            "The validation accuracy at iteration 9888  is               81.77499999999999%\n",
            "The validation accuracy at iteration 9904  is               81.575%\n",
            "The validation accuracy at iteration 9920  is               82.325%\n",
            "The validation accuracy at iteration 9936  is               82.175%\n",
            "The validation accuracy at iteration 9952  is               82.85%\n",
            "The validation accuracy at iteration 9968  is               83.45%\n",
            "The validation accuracy at iteration 9984  is               83.775%\n",
            "The validation accuracy at iteration 10000  is               81.2%\n",
            "The validation accuracy at iteration 10016  is               82.525%\n",
            "The validation accuracy at iteration 10032  is               82.92500000000001%\n",
            "The validation accuracy at iteration 10048  is               81.39999999999999%\n",
            "The validation accuracy at iteration 10064  is               80.85%\n",
            "The validation accuracy at iteration 10080  is               80.925%\n",
            "The validation accuracy at iteration 10096  is               80.65%\n",
            "The validation accuracy at iteration 10112  is               82.5%\n",
            "The validation accuracy at iteration 10128  is               80.7%\n",
            "The validation accuracy at iteration 10144  is               82.25%\n",
            "The validation accuracy at iteration 10160  is               82.15%\n",
            "The validation accuracy at iteration 10176  is               82.875%\n",
            "The validation accuracy at iteration 10192  is               81.325%\n",
            "The validation accuracy at iteration 10208  is               82.19999999999999%\n",
            "The validation accuracy at iteration 10224  is               81.75%\n",
            "The validation accuracy at iteration 10240  is               82.375%\n",
            "The validation accuracy at iteration 10256  is               82.525%\n",
            "The validation accuracy at iteration 10272  is               83.05%\n",
            "The validation accuracy at iteration 10288  is               83.0%\n",
            "The validation accuracy at iteration 10304  is               83.025%\n",
            "The validation accuracy at iteration 10320  is               80.5%\n",
            "The validation accuracy at iteration 10336  is               82.69999999999999%\n",
            "The validation accuracy at iteration 10352  is               83.0%\n",
            "The validation accuracy at iteration 10368  is               81.72500000000001%\n",
            "The validation accuracy at iteration 10384  is               80.525%\n",
            "The validation accuracy at iteration 10400  is               81.5%\n",
            "The validation accuracy at iteration 10416  is               80.35%\n",
            "The validation accuracy at iteration 10432  is               82.175%\n",
            "The validation accuracy at iteration 10448  is               80.9%\n",
            "The validation accuracy at iteration 10464  is               82.19999999999999%\n",
            "The validation accuracy at iteration 10480  is               81.45%\n",
            "The validation accuracy at iteration 10496  is               82.025%\n",
            "The validation accuracy at iteration 10512  is               80.4%\n",
            "The validation accuracy at iteration 10528  is               80.9%\n",
            "The validation accuracy at iteration 10544  is               81.3%\n",
            "The validation accuracy at iteration 10560  is               82.025%\n",
            "The validation accuracy at iteration 10576  is               82.125%\n",
            "The validation accuracy at iteration 10592  is               83.325%\n",
            "The validation accuracy at iteration 10608  is               83.325%\n",
            "The validation accuracy at iteration 10624  is               83.25%\n",
            "The validation accuracy at iteration 10640  is               80.7%\n",
            "The validation accuracy at iteration 10656  is               82.89999999999999%\n",
            "The validation accuracy at iteration 10672  is               81.95%\n",
            "The validation accuracy at iteration 10688  is               81.375%\n",
            "The validation accuracy at iteration 10704  is               80.60000000000001%\n",
            "The validation accuracy at iteration 10720  is               81.825%\n",
            "The validation accuracy at iteration 10736  is               80.22500000000001%\n",
            "The validation accuracy at iteration 10752  is               82.05%\n",
            "The validation accuracy at iteration 10768  is               80.60000000000001%\n",
            "The validation accuracy at iteration 10784  is               80.9%\n",
            "The validation accuracy at iteration 10800  is               82.25%\n",
            "The validation accuracy at iteration 10816  is               82.55%\n",
            "The validation accuracy at iteration 10832  is               80.475%\n",
            "The validation accuracy at iteration 10848  is               81.55%\n",
            "The validation accuracy at iteration 10864  is               82.27499999999999%\n",
            "The validation accuracy at iteration 10880  is               82.69999999999999%\n",
            "The validation accuracy at iteration 10896  is               82.675%\n",
            "The validation accuracy at iteration 10912  is               83.075%\n",
            "The validation accuracy at iteration 10928  is               83.575%\n",
            "The validation accuracy at iteration 10944  is               83.15%\n",
            "The validation accuracy at iteration 10960  is               80.95%\n",
            "The validation accuracy at iteration 10976  is               82.92500000000001%\n",
            "The validation accuracy at iteration 10992  is               82.575%\n",
            "The validation accuracy at iteration 11008  is               81.325%\n",
            "The validation accuracy at iteration 11024  is               81.15%\n",
            "The validation accuracy at iteration 11040  is               81.5%\n",
            "The validation accuracy at iteration 11056  is               80.175%\n",
            "The validation accuracy at iteration 11072  is               81.45%\n",
            "The validation accuracy at iteration 11088  is               81.675%\n",
            "The validation accuracy at iteration 11104  is               82.025%\n",
            "The validation accuracy at iteration 11120  is               83.0%\n",
            "The validation accuracy at iteration 11136  is               82.65%\n",
            "The validation accuracy at iteration 11152  is               80.77499999999999%\n",
            "The validation accuracy at iteration 11168  is               81.35%\n",
            "The validation accuracy at iteration 11184  is               80.80000000000001%\n",
            "The validation accuracy at iteration 11200  is               82.5%\n",
            "The validation accuracy at iteration 11216  is               81.975%\n",
            "The validation accuracy at iteration 11232  is               82.92500000000001%\n",
            "The validation accuracy at iteration 11248  is               83.2%\n",
            "The validation accuracy at iteration 11264  is               83.2%\n",
            "The validation accuracy at iteration 11280  is               81.0%\n",
            "The validation accuracy at iteration 11296  is               82.825%\n",
            "The validation accuracy at iteration 11312  is               82.025%\n",
            "The validation accuracy at iteration 11328  is               82.3%\n",
            "The validation accuracy at iteration 11344  is               81.025%\n",
            "The validation accuracy at iteration 11360  is               81.45%\n",
            "The validation accuracy at iteration 11376  is               80.60000000000001%\n",
            "The validation accuracy at iteration 11392  is               82.22500000000001%\n",
            "The validation accuracy at iteration 11408  is               81.10000000000001%\n",
            "The validation accuracy at iteration 11424  is               82.35%\n",
            "The validation accuracy at iteration 11440  is               83.075%\n",
            "The validation accuracy at iteration 11456  is               82.69999999999999%\n",
            "The validation accuracy at iteration 11472  is               81.625%\n",
            "The validation accuracy at iteration 11488  is               81.45%\n",
            "The validation accuracy at iteration 11504  is               82.22500000000001%\n",
            "The validation accuracy at iteration 11520  is               82.5%\n",
            "The validation accuracy at iteration 11536  is               82.75%\n",
            "The validation accuracy at iteration 11552  is               83.075%\n",
            "The validation accuracy at iteration 11568  is               83.675%\n",
            "The validation accuracy at iteration 11584  is               83.275%\n",
            "The validation accuracy at iteration 11600  is               81.375%\n",
            "The validation accuracy at iteration 11616  is               82.675%\n",
            "The validation accuracy at iteration 11632  is               82.325%\n",
            "The validation accuracy at iteration 11648  is               81.575%\n",
            "The validation accuracy at iteration 11664  is               80.825%\n",
            "The validation accuracy at iteration 11680  is               82.075%\n",
            "The validation accuracy at iteration 11696  is               80.175%\n",
            "The validation accuracy at iteration 11712  is               82.1%\n",
            "The validation accuracy at iteration 11728  is               81.375%\n",
            "The validation accuracy at iteration 11744  is               81.75%\n",
            "The validation accuracy at iteration 11760  is               82.92500000000001%\n",
            "The validation accuracy at iteration 11776  is               82.0%\n",
            "The validation accuracy at iteration 11792  is               80.575%\n",
            "The validation accuracy at iteration 11808  is               80.75%\n",
            "The validation accuracy at iteration 11824  is               81.69999999999999%\n",
            "The validation accuracy at iteration 11840  is               82.425%\n",
            "The validation accuracy at iteration 11856  is               82.425%\n",
            "The validation accuracy at iteration 11872  is               83.15%\n",
            "The validation accuracy at iteration 11888  is               83.125%\n",
            "The validation accuracy at iteration 11904  is               83.45%\n",
            "The validation accuracy at iteration 11920  is               81.175%\n",
            "The validation accuracy at iteration 11936  is               82.6%\n",
            "The validation accuracy at iteration 11952  is               82.625%\n",
            "The validation accuracy at iteration 11968  is               81.575%\n",
            "The validation accuracy at iteration 11984  is               81.075%\n",
            "The validation accuracy at iteration 12000  is               81.675%\n",
            "The validation accuracy at iteration 12016  is               80.375%\n",
            "The validation accuracy at iteration 12032  is               82.125%\n",
            "The validation accuracy at iteration 12048  is               81.75%\n",
            "The validation accuracy at iteration 12064  is               81.89999999999999%\n",
            "The validation accuracy at iteration 12080  is               83.22500000000001%\n",
            "The validation accuracy at iteration 12096  is               82.825%\n",
            "The validation accuracy at iteration 12112  is               81.72500000000001%\n",
            "The validation accuracy at iteration 12128  is               82.025%\n",
            "The validation accuracy at iteration 12144  is               82.0%\n",
            "The validation accuracy at iteration 12160  is               82.825%\n",
            "The validation accuracy at iteration 12176  is               82.75%\n",
            "The validation accuracy at iteration 12192  is               82.975%\n",
            "The validation accuracy at iteration 12208  is               83.89999999999999%\n",
            "The validation accuracy at iteration 12224  is               83.35000000000001%\n",
            "The validation accuracy at iteration 12240  is               81.39999999999999%\n",
            "The validation accuracy at iteration 12256  is               82.89999999999999%\n",
            "The validation accuracy at iteration 12272  is               82.92500000000001%\n",
            "The validation accuracy at iteration 12288  is               81.72500000000001%\n",
            "The validation accuracy at iteration 12304  is               81.025%\n",
            "The validation accuracy at iteration 12320  is               81.85%\n",
            "The validation accuracy at iteration 12336  is               80.35%\n",
            "The validation accuracy at iteration 12352  is               83.35000000000001%\n",
            "The validation accuracy at iteration 12368  is               81.55%\n",
            "The validation accuracy at iteration 12384  is               81.69999999999999%\n",
            "The validation accuracy at iteration 12400  is               83.8%\n",
            "The validation accuracy at iteration 12416  is               82.5%\n",
            "The validation accuracy at iteration 12432  is               81.39999999999999%\n",
            "The validation accuracy at iteration 12448  is               81.525%\n",
            "The validation accuracy at iteration 12464  is               82.1%\n",
            "The validation accuracy at iteration 12480  is               82.475%\n",
            "The validation accuracy at iteration 12496  is               82.475%\n",
            "The validation accuracy at iteration 12512  is               83.175%\n",
            "The validation accuracy at iteration 12528  is               83.15%\n",
            "The validation accuracy at iteration 12544  is               83.15%\n",
            "The validation accuracy at iteration 12560  is               80.875%\n",
            "The validation accuracy at iteration 12576  is               82.3%\n",
            "The validation accuracy at iteration 12592  is               82.075%\n",
            "The validation accuracy at iteration 12608  is               81.525%\n",
            "The validation accuracy at iteration 12624  is               81.025%\n",
            "The validation accuracy at iteration 12640  is               81.05%\n",
            "The validation accuracy at iteration 12656  is               80.95%\n",
            "The validation accuracy at iteration 12672  is               82.65%\n",
            "The validation accuracy at iteration 12688  is               81.05%\n",
            "The validation accuracy at iteration 12704  is               81.5%\n",
            "The validation accuracy at iteration 12720  is               82.95%\n",
            "The validation accuracy at iteration 12736  is               82.5%\n",
            "The validation accuracy at iteration 12752  is               81.175%\n",
            "The validation accuracy at iteration 12768  is               82.325%\n",
            "The validation accuracy at iteration 12784  is               81.77499999999999%\n",
            "The validation accuracy at iteration 12800  is               82.39999999999999%\n",
            "The validation accuracy at iteration 12816  is               82.69999999999999%\n",
            "The validation accuracy at iteration 12832  is               83.075%\n",
            "The validation accuracy at iteration 12848  is               82.95%\n",
            "The validation accuracy at iteration 12864  is               83.22500000000001%\n",
            "The validation accuracy at iteration 12880  is               81.27499999999999%\n",
            "The validation accuracy at iteration 12896  is               82.475%\n",
            "The validation accuracy at iteration 12912  is               82.89999999999999%\n",
            "The validation accuracy at iteration 12928  is               81.69999999999999%\n",
            "The validation accuracy at iteration 12944  is               81.27499999999999%\n",
            "The validation accuracy at iteration 12960  is               82.475%\n",
            "The validation accuracy at iteration 12976  is               80.425%\n",
            "The validation accuracy at iteration 12992  is               82.95%\n",
            "The validation accuracy at iteration 13008  is               81.125%\n",
            "The validation accuracy at iteration 13024  is               82.125%\n",
            "The validation accuracy at iteration 13040  is               83.325%\n",
            "The validation accuracy at iteration 13056  is               82.85%\n",
            "The validation accuracy at iteration 13072  is               81.72500000000001%\n",
            "The validation accuracy at iteration 13088  is               81.77499999999999%\n",
            "The validation accuracy at iteration 13104  is               82.35%\n",
            "The validation accuracy at iteration 13120  is               82.72500000000001%\n",
            "The validation accuracy at iteration 13136  is               82.675%\n",
            "The validation accuracy at iteration 13152  is               83.0%\n",
            "The validation accuracy at iteration 13168  is               82.675%\n",
            "The validation accuracy at iteration 13184  is               82.89999999999999%\n",
            "The validation accuracy at iteration 13200  is               81.025%\n",
            "The validation accuracy at iteration 13216  is               82.39999999999999%\n",
            "The validation accuracy at iteration 13232  is               81.925%\n",
            "The validation accuracy at iteration 13248  is               81.525%\n",
            "The validation accuracy at iteration 13264  is               81.27499999999999%\n",
            "The validation accuracy at iteration 13280  is               81.55%\n",
            "The validation accuracy at iteration 13296  is               80.75%\n",
            "The validation accuracy at iteration 13312  is               82.89999999999999%\n",
            "The validation accuracy at iteration 13328  is               81.72500000000001%\n",
            "The validation accuracy at iteration 13344  is               81.975%\n",
            "The validation accuracy at iteration 13360  is               83.025%\n",
            "The validation accuracy at iteration 13376  is               82.625%\n",
            "The validation accuracy at iteration 13392  is               82.19999999999999%\n",
            "The validation accuracy at iteration 13408  is               81.95%\n",
            "The validation accuracy at iteration 13424  is               81.975%\n",
            "The validation accuracy at iteration 13440  is               82.6%\n",
            "The validation accuracy at iteration 13456  is               82.575%\n",
            "The validation accuracy at iteration 13472  is               83.025%\n",
            "The validation accuracy at iteration 13488  is               83.2%\n",
            "The validation accuracy at iteration 13504  is               82.22500000000001%\n",
            "The validation accuracy at iteration 13520  is               81.075%\n",
            "The validation accuracy at iteration 13536  is               81.525%\n",
            "The validation accuracy at iteration 13552  is               82.8%\n",
            "The validation accuracy at iteration 13568  is               82.025%\n",
            "The validation accuracy at iteration 13584  is               81.525%\n",
            "The validation accuracy at iteration 13600  is               81.075%\n",
            "The validation accuracy at iteration 13616  is               80.5%\n",
            "The validation accuracy at iteration 13632  is               82.475%\n",
            "The validation accuracy at iteration 13648  is               81.475%\n",
            "The validation accuracy at iteration 13664  is               81.65%\n",
            "The validation accuracy at iteration 13680  is               83.2%\n",
            "The validation accuracy at iteration 13696  is               82.69999999999999%\n",
            "The validation accuracy at iteration 13712  is               82.0%\n",
            "The validation accuracy at iteration 13728  is               82.175%\n",
            "The validation accuracy at iteration 13744  is               81.825%\n",
            "The validation accuracy at iteration 13760  is               82.425%\n",
            "The validation accuracy at iteration 13776  is               82.92500000000001%\n",
            "The validation accuracy at iteration 13792  is               83.375%\n",
            "The validation accuracy at iteration 13808  is               83.025%\n",
            "The validation accuracy at iteration 13824  is               82.19999999999999%\n",
            "The validation accuracy at iteration 13840  is               81.27499999999999%\n",
            "The validation accuracy at iteration 13856  is               82.69999999999999%\n",
            "The validation accuracy at iteration 13872  is               82.35%\n",
            "The validation accuracy at iteration 13888  is               81.975%\n",
            "The validation accuracy at iteration 13904  is               81.025%\n",
            "The validation accuracy at iteration 13920  is               81.625%\n",
            "The validation accuracy at iteration 13936  is               80.525%\n",
            "The validation accuracy at iteration 13952  is               82.325%\n",
            "The validation accuracy at iteration 13968  is               81.55%\n",
            "The validation accuracy at iteration 13984  is               81.5%\n",
            "The validation accuracy at iteration 14000  is               83.325%\n",
            "The validation accuracy at iteration 14016  is               82.825%\n",
            "The validation accuracy at iteration 14032  is               81.72500000000001%\n",
            "The validation accuracy at iteration 14048  is               82.475%\n",
            "The validation accuracy at iteration 14064  is               82.39999999999999%\n",
            "The validation accuracy at iteration 14080  is               82.775%\n",
            "The validation accuracy at iteration 14096  is               82.75%\n",
            "The validation accuracy at iteration 14112  is               83.125%\n",
            "The validation accuracy at iteration 14128  is               83.025%\n",
            "The validation accuracy at iteration 14144  is               83.15%\n",
            "The validation accuracy at iteration 14160  is               81.625%\n",
            "The validation accuracy at iteration 14176  is               82.175%\n",
            "The validation accuracy at iteration 14192  is               82.075%\n",
            "The validation accuracy at iteration 14208  is               81.8%\n",
            "The validation accuracy at iteration 14224  is               81.375%\n",
            "The validation accuracy at iteration 14240  is               82.075%\n",
            "The validation accuracy at iteration 14256  is               79.85%\n",
            "The validation accuracy at iteration 14272  is               83.15%\n",
            "The validation accuracy at iteration 14288  is               81.475%\n",
            "The validation accuracy at iteration 14304  is               82.05%\n",
            "The validation accuracy at iteration 14320  is               83.39999999999999%\n",
            "The validation accuracy at iteration 14336  is               82.625%\n",
            "The validation accuracy at iteration 14352  is               82.175%\n",
            "The validation accuracy at iteration 14368  is               82.1%\n",
            "The validation accuracy at iteration 14384  is               81.325%\n",
            "The validation accuracy at iteration 14400  is               82.675%\n",
            "The validation accuracy at iteration 14416  is               82.675%\n",
            "The validation accuracy at iteration 14432  is               83.275%\n",
            "The validation accuracy at iteration 14448  is               83.6%\n",
            "The validation accuracy at iteration 14464  is               83.6%\n",
            "The validation accuracy at iteration 14480  is               80.77499999999999%\n",
            "The validation accuracy at iteration 14496  is               82.525%\n",
            "The validation accuracy at iteration 14512  is               81.89999999999999%\n",
            "The validation accuracy at iteration 14528  is               82.075%\n",
            "The validation accuracy at iteration 14544  is               81.675%\n",
            "The validation accuracy at iteration 14560  is               82.25%\n",
            "The validation accuracy at iteration 14576  is               80.625%\n",
            "The validation accuracy at iteration 14592  is               81.89999999999999%\n",
            "The validation accuracy at iteration 14608  is               81.475%\n",
            "The validation accuracy at iteration 14624  is               81.975%\n",
            "The validation accuracy at iteration 14640  is               83.45%\n",
            "The validation accuracy at iteration 14656  is               82.85%\n",
            "The validation accuracy at iteration 14672  is               82.1%\n",
            "The validation accuracy at iteration 14688  is               82.1%\n",
            "The validation accuracy at iteration 14704  is               82.45%\n",
            "The validation accuracy at iteration 14720  is               82.75%\n",
            "The validation accuracy at iteration 14736  is               82.675%\n",
            "The validation accuracy at iteration 14752  is               83.25%\n",
            "The validation accuracy at iteration 14768  is               83.125%\n",
            "The validation accuracy at iteration 14784  is               84.05%\n",
            "The validation accuracy at iteration 14800  is               81.475%\n",
            "The validation accuracy at iteration 14816  is               82.5%\n",
            "The validation accuracy at iteration 14832  is               82.575%\n",
            "The validation accuracy at iteration 14848  is               82.025%\n",
            "The validation accuracy at iteration 14864  is               80.80000000000001%\n",
            "The validation accuracy at iteration 14880  is               82.19999999999999%\n",
            "The validation accuracy at iteration 14896  is               80.60000000000001%\n",
            "The validation accuracy at iteration 14912  is               82.75%\n",
            "The validation accuracy at iteration 14928  is               81.575%\n",
            "The validation accuracy at iteration 14944  is               81.65%\n",
            "The validation accuracy at iteration 14960  is               83.625%\n",
            "The validation accuracy at iteration 14976  is               82.775%\n",
            "The validation accuracy at iteration 14992  is               82.25%\n",
            "The validation accuracy at iteration 15008  is               81.975%\n",
            "The validation accuracy at iteration 15024  is               82.625%\n",
            "The validation accuracy at iteration 15040  is               82.825%\n",
            "The validation accuracy at iteration 15056  is               82.85%\n",
            "The validation accuracy at iteration 15072  is               83.39999999999999%\n",
            "The validation accuracy at iteration 15088  is               82.8%\n",
            "The validation accuracy at iteration 15104  is               82.775%\n",
            "The validation accuracy at iteration 15120  is               81.3%\n",
            "The validation accuracy at iteration 15136  is               82.22500000000001%\n",
            "The validation accuracy at iteration 15152  is               82.27499999999999%\n",
            "The validation accuracy at iteration 15168  is               82.675%\n",
            "The validation accuracy at iteration 15184  is               81.075%\n",
            "The validation accuracy at iteration 15200  is               81.125%\n",
            "The validation accuracy at iteration 15216  is               80.65%\n",
            "The validation accuracy at iteration 15232  is               83.25%\n",
            "The validation accuracy at iteration 15248  is               81.72500000000001%\n",
            "The validation accuracy at iteration 15264  is               81.72500000000001%\n",
            "The validation accuracy at iteration 15280  is               83.575%\n",
            "The validation accuracy at iteration 15296  is               82.95%\n",
            "The validation accuracy at iteration 15312  is               81.325%\n",
            "The validation accuracy at iteration 15328  is               82.375%\n",
            "The validation accuracy at iteration 15344  is               82.25%\n",
            "The validation accuracy at iteration 15360  is               82.85%\n",
            "The validation accuracy at iteration 15376  is               83.0%\n",
            "The validation accuracy at iteration 15392  is               83.55%\n",
            "The validation accuracy at iteration 15408  is               83.85000000000001%\n",
            "The validation accuracy at iteration 15424  is               83.625%\n",
            "The validation accuracy at iteration 15440  is               81.3%\n",
            "The validation accuracy at iteration 15456  is               82.85%\n",
            "The validation accuracy at iteration 15472  is               83.15%\n",
            "The validation accuracy at iteration 15488  is               82.0%\n",
            "The validation accuracy at iteration 15504  is               81.45%\n",
            "The validation accuracy at iteration 15520  is               82.025%\n",
            "The validation accuracy at iteration 15536  is               80.375%\n",
            "The validation accuracy at iteration 15552  is               83.6%\n",
            "The validation accuracy at iteration 15568  is               81.825%\n",
            "The validation accuracy at iteration 15584  is               81.525%\n",
            "The validation accuracy at iteration 15600  is               83.3%\n",
            "The validation accuracy at iteration 15616  is               82.875%\n",
            "The validation accuracy at iteration 15632  is               81.825%\n",
            "The validation accuracy at iteration 15648  is               81.875%\n",
            "The validation accuracy at iteration 15664  is               82.825%\n",
            "The validation accuracy at iteration 15680  is               82.6%\n",
            "The validation accuracy at iteration 15696  is               82.8%\n",
            "The validation accuracy at iteration 15712  is               83.3%\n",
            "The validation accuracy at iteration 15728  is               83.25%\n",
            "The validation accuracy at iteration 15744  is               82.3%\n",
            "The validation accuracy at iteration 15760  is               81.3%\n",
            "The validation accuracy at iteration 15776  is               82.75%\n",
            "The validation accuracy at iteration 15792  is               82.35%\n",
            "The validation accuracy at iteration 15808  is               82.025%\n",
            "The validation accuracy at iteration 15824  is               81.15%\n",
            "The validation accuracy at iteration 15840  is               81.925%\n",
            "The validation accuracy at iteration 15856  is               80.425%\n",
            "The validation accuracy at iteration 15872  is               83.175%\n",
            "The validation accuracy at iteration 15888  is               81.575%\n",
            "The validation accuracy at iteration 15904  is               82.65%\n",
            "The validation accuracy at iteration 15920  is               83.375%\n",
            "The validation accuracy at iteration 15936  is               83.22500000000001%\n",
            "The validation accuracy at iteration 15952  is               81.27499999999999%\n",
            "The validation accuracy at iteration 15968  is               82.125%\n",
            "The validation accuracy at iteration 15984  is               82.475%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 16000  is               82.875%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 2300  is               81.575%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "[<__main__.Solver object at 0x7f6e25755490>, <__main__.Solver object at 0x7f6e457874d0>, <__main__.Solver object at 0x7f6e4c519d10>, <__main__.Solver object at 0x7f6e4c519d10>, <__main__.Solver object at 0x7f6e4c79e350>]\n",
            "The validation accuracy at iteration 16  is               44.25%\n",
            "The validation accuracy at iteration 32  is               30.725%\n",
            "The validation accuracy at iteration 48  is               45.300000000000004%\n",
            "The validation accuracy at iteration 64  is               24.65%\n",
            "The validation accuracy at iteration 80  is               55.55%\n",
            "The validation accuracy at iteration 96  is               58.575%\n",
            "The validation accuracy at iteration 112  is               52.775000000000006%\n",
            "The validation accuracy at iteration 128  is               49.5%\n",
            "The validation accuracy at iteration 144  is               62.74999999999999%\n",
            "The validation accuracy at iteration 160  is               62.9%\n",
            "The validation accuracy at iteration 176  is               53.1%\n",
            "The validation accuracy at iteration 192  is               73.475%\n",
            "The validation accuracy at iteration 208  is               62.625%\n",
            "The validation accuracy at iteration 224  is               67.77499999999999%\n",
            "The validation accuracy at iteration 240  is               46.375%\n",
            "The validation accuracy at iteration 256  is               67.525%\n",
            "The validation accuracy at iteration 272  is               55.50000000000001%\n",
            "The validation accuracy at iteration 288  is               59.45%\n",
            "The validation accuracy at iteration 304  is               52.1%\n",
            "The validation accuracy at iteration 320  is               66.55%\n",
            "The validation accuracy at iteration 336  is               64.60000000000001%\n",
            "The validation accuracy at iteration 352  is               68.925%\n",
            "The validation accuracy at iteration 368  is               70.1%\n",
            "The validation accuracy at iteration 384  is               67.9%\n",
            "The validation accuracy at iteration 400  is               62.45%\n",
            "The validation accuracy at iteration 416  is               68.375%\n",
            "The validation accuracy at iteration 432  is               67.825%\n",
            "The validation accuracy at iteration 448  is               60.0%\n",
            "The validation accuracy at iteration 464  is               68.4%\n",
            "The validation accuracy at iteration 480  is               73.85000000000001%\n",
            "The validation accuracy at iteration 496  is               74.625%\n",
            "The validation accuracy at iteration 512  is               66.57499999999999%\n",
            "The validation accuracy at iteration 528  is               73.3%\n",
            "The validation accuracy at iteration 544  is               75.85%\n",
            "The validation accuracy at iteration 560  is               74.775%\n",
            "The validation accuracy at iteration 576  is               70.125%\n",
            "The validation accuracy at iteration 592  is               74.1%\n",
            "The validation accuracy at iteration 608  is               63.275000000000006%\n",
            "The validation accuracy at iteration 624  is               75.6%\n",
            "The validation accuracy at iteration 640  is               69.325%\n",
            "The validation accuracy at iteration 656  is               74.02499999999999%\n",
            "The validation accuracy at iteration 672  is               77.9%\n",
            "The validation accuracy at iteration 688  is               73.4%\n",
            "The validation accuracy at iteration 704  is               70.975%\n",
            "The validation accuracy at iteration 720  is               71.7%\n",
            "The validation accuracy at iteration 736  is               62.74999999999999%\n",
            "The validation accuracy at iteration 752  is               69.5%\n",
            "The validation accuracy at iteration 768  is               64.14999999999999%\n",
            "The validation accuracy at iteration 784  is               73.15%\n",
            "The validation accuracy at iteration 800  is               75.97500000000001%\n",
            "The validation accuracy at iteration 816  is               78.55%\n",
            "The validation accuracy at iteration 832  is               76.9%\n",
            "The validation accuracy at iteration 848  is               76.7%\n",
            "The validation accuracy at iteration 864  is               75.25%\n",
            "The validation accuracy at iteration 880  is               75.175%\n",
            "The validation accuracy at iteration 896  is               76.425%\n",
            "The validation accuracy at iteration 912  is               78.77499999999999%\n",
            "The validation accuracy at iteration 928  is               79.27499999999999%\n",
            "The validation accuracy at iteration 944  is               79.0%\n",
            "The validation accuracy at iteration 960  is               67.05%\n",
            "The validation accuracy at iteration 976  is               78.2%\n",
            "The validation accuracy at iteration 992  is               79.0%\n",
            "The validation accuracy at iteration 1008  is               73.45%\n",
            "The validation accuracy at iteration 1024  is               73.225%\n",
            "The validation accuracy at iteration 1040  is               64.0%\n",
            "The validation accuracy at iteration 1056  is               70.55%\n",
            "The validation accuracy at iteration 1072  is               77.825%\n",
            "The validation accuracy at iteration 1088  is               73.95%\n",
            "The validation accuracy at iteration 1104  is               68.475%\n",
            "The validation accuracy at iteration 1120  is               73.25%\n",
            "The validation accuracy at iteration 1136  is               74.6%\n",
            "The validation accuracy at iteration 1152  is               75.875%\n",
            "The validation accuracy at iteration 1168  is               78.64999999999999%\n",
            "The validation accuracy at iteration 1184  is               78.875%\n",
            "The validation accuracy at iteration 1200  is               75.2%\n",
            "The validation accuracy at iteration 1216  is               67.95%\n",
            "The validation accuracy at iteration 1232  is               79.05%\n",
            "The validation accuracy at iteration 1248  is               76.825%\n",
            "The validation accuracy at iteration 1264  is               71.65%\n",
            "The validation accuracy at iteration 1280  is               66.7%\n",
            "The validation accuracy at iteration 1296  is               77.97500000000001%\n",
            "The validation accuracy at iteration 1312  is               75.175%\n",
            "The validation accuracy at iteration 1328  is               74.1%\n",
            "The validation accuracy at iteration 1344  is               77.97500000000001%\n",
            "The validation accuracy at iteration 1360  is               78.375%\n",
            "The validation accuracy at iteration 1376  is               69.8%\n",
            "The validation accuracy at iteration 1392  is               75.225%\n",
            "The validation accuracy at iteration 1408  is               75.0%\n",
            "The validation accuracy at iteration 1424  is               75.0%\n",
            "The validation accuracy at iteration 1440  is               77.10000000000001%\n",
            "The validation accuracy at iteration 1456  is               79.10000000000001%\n",
            "The validation accuracy at iteration 1472  is               77.125%\n",
            "The validation accuracy at iteration 1488  is               79.4%\n",
            "The validation accuracy at iteration 1504  is               81.925%\n",
            "The validation accuracy at iteration 1520  is               79.3%\n",
            "The validation accuracy at iteration 1536  is               79.675%\n",
            "The validation accuracy at iteration 1552  is               81.10000000000001%\n",
            "The validation accuracy at iteration 1568  is               81.27499999999999%\n",
            "The validation accuracy at iteration 1584  is               79.225%\n",
            "The validation accuracy at iteration 1600  is               76.2%\n",
            "The validation accuracy at iteration 1616  is               79.875%\n",
            "The validation accuracy at iteration 1632  is               78.625%\n",
            "The validation accuracy at iteration 1648  is               76.925%\n",
            "The validation accuracy at iteration 1664  is               78.64999999999999%\n",
            "The validation accuracy at iteration 1680  is               80.675%\n",
            "The validation accuracy at iteration 1696  is               78.10000000000001%\n",
            "The validation accuracy at iteration 1712  is               79.65%\n",
            "The validation accuracy at iteration 1728  is               81.375%\n",
            "The validation accuracy at iteration 1744  is               78.85%\n",
            "The validation accuracy at iteration 1760  is               78.0%\n",
            "The validation accuracy at iteration 1776  is               81.05%\n",
            "The validation accuracy at iteration 1792  is               80.85%\n",
            "The validation accuracy at iteration 1808  is               78.9%\n",
            "The validation accuracy at iteration 1824  is               80.60000000000001%\n",
            "The validation accuracy at iteration 1840  is               79.07499999999999%\n",
            "The validation accuracy at iteration 1856  is               81.025%\n",
            "The validation accuracy at iteration 1872  is               80.55%\n",
            "The validation accuracy at iteration 1888  is               79.95%\n",
            "The validation accuracy at iteration 1904  is               76.75%\n",
            "The validation accuracy at iteration 1920  is               80.10000000000001%\n",
            "The validation accuracy at iteration 1936  is               81.27499999999999%\n",
            "The validation accuracy at iteration 1952  is               78.57499999999999%\n",
            "The validation accuracy at iteration 1968  is               77.575%\n",
            "The validation accuracy at iteration 1984  is               81.025%\n",
            "The validation accuracy at iteration 2000  is               80.425%\n",
            "The validation accuracy at iteration 2016  is               77.0%\n",
            "The validation accuracy at iteration 2032  is               78.7%\n",
            "The validation accuracy at iteration 2048  is               80.5%\n",
            "The validation accuracy at iteration 2064  is               80.125%\n",
            "The validation accuracy at iteration 2080  is               78.14999999999999%\n",
            "The validation accuracy at iteration 2096  is               81.2%\n",
            "The validation accuracy at iteration 2112  is               78.675%\n",
            "The validation accuracy at iteration 2128  is               79.65%\n",
            "The validation accuracy at iteration 2144  is               77.575%\n",
            "The validation accuracy at iteration 2160  is               80.5%\n",
            "The validation accuracy at iteration 2176  is               78.57499999999999%\n",
            "The validation accuracy at iteration 2192  is               79.80000000000001%\n",
            "The validation accuracy at iteration 2208  is               80.675%\n",
            "The validation accuracy at iteration 2224  is               77.60000000000001%\n",
            "The validation accuracy at iteration 2240  is               76.725%\n",
            "The validation accuracy at iteration 2256  is               80.9%\n",
            "The validation accuracy at iteration 2272  is               78.425%\n",
            "The validation accuracy at iteration 2288  is               78.35%\n",
            "The validation accuracy at iteration 2304  is               79.225%\n",
            "The validation accuracy at iteration 2320  is               82.175%\n",
            "The validation accuracy at iteration 2336  is               78.75%\n",
            "The validation accuracy at iteration 2352  is               76.25%\n",
            "The validation accuracy at iteration 2368  is               82.075%\n",
            "The validation accuracy at iteration 2384  is               81.3%\n",
            "The validation accuracy at iteration 2400  is               81.22500000000001%\n",
            "The validation accuracy at iteration 2416  is               81.0%\n",
            "The validation accuracy at iteration 2432  is               77.725%\n",
            "The validation accuracy at iteration 2448  is               76.725%\n",
            "The validation accuracy at iteration 2464  is               80.925%\n",
            "The validation accuracy at iteration 2480  is               78.675%\n",
            "The validation accuracy at iteration 2496  is               80.475%\n",
            "The validation accuracy at iteration 2512  is               82.35%\n",
            "The validation accuracy at iteration 2528  is               81.525%\n",
            "The validation accuracy at iteration 2544  is               79.925%\n",
            "The validation accuracy at iteration 2560  is               79.25%\n",
            "The validation accuracy at iteration 2576  is               82.6%\n",
            "The validation accuracy at iteration 2592  is               80.2%\n",
            "The validation accuracy at iteration 2608  is               69.72500000000001%\n",
            "The validation accuracy at iteration 2624  is               80.75%\n",
            "The validation accuracy at iteration 2640  is               80.9%\n",
            "The validation accuracy at iteration 2656  is               80.45%\n",
            "The validation accuracy at iteration 2672  is               79.10000000000001%\n",
            "The validation accuracy at iteration 2688  is               81.27499999999999%\n",
            "The validation accuracy at iteration 2704  is               81.325%\n",
            "The validation accuracy at iteration 2720  is               78.225%\n",
            "The validation accuracy at iteration 2736  is               80.80000000000001%\n",
            "The validation accuracy at iteration 2752  is               76.175%\n",
            "The validation accuracy at iteration 2768  is               80.025%\n",
            "The validation accuracy at iteration 2784  is               79.925%\n",
            "The validation accuracy at iteration 2800  is               82.475%\n",
            "The validation accuracy at iteration 2816  is               80.27499999999999%\n",
            "The validation accuracy at iteration 2832  is               77.825%\n",
            "The validation accuracy at iteration 2848  is               81.675%\n",
            "The validation accuracy at iteration 2864  is               81.875%\n",
            "The validation accuracy at iteration 2880  is               79.375%\n",
            "The validation accuracy at iteration 2896  is               82.35%\n",
            "The validation accuracy at iteration 2912  is               81.325%\n",
            "The validation accuracy at iteration 2928  is               77.25%\n",
            "The validation accuracy at iteration 2944  is               81.525%\n",
            "The validation accuracy at iteration 2960  is               81.39999999999999%\n",
            "The validation accuracy at iteration 2976  is               81.675%\n",
            "The validation accuracy at iteration 2992  is               77.8%\n",
            "The validation accuracy at iteration 3008  is               81.2%\n",
            "The validation accuracy at iteration 3024  is               80.60000000000001%\n",
            "The validation accuracy at iteration 3040  is               81.35%\n",
            "The validation accuracy at iteration 3056  is               81.975%\n",
            "The validation accuracy at iteration 3072  is               80.675%\n",
            "The validation accuracy at iteration 3088  is               75.875%\n",
            "The validation accuracy at iteration 3104  is               77.85%\n",
            "The validation accuracy at iteration 3120  is               81.875%\n",
            "The validation accuracy at iteration 3136  is               81.3%\n",
            "The validation accuracy at iteration 3152  is               79.45%\n",
            "The validation accuracy at iteration 3168  is               81.525%\n",
            "The validation accuracy at iteration 3184  is               81.875%\n",
            "The validation accuracy at iteration 3200  is               81.95%\n",
            "The validation accuracy at iteration 3216  is               82.27499999999999%\n",
            "The validation accuracy at iteration 3232  is               78.60000000000001%\n",
            "The validation accuracy at iteration 3248  is               82.075%\n",
            "The validation accuracy at iteration 3264  is               81.39999999999999%\n",
            "The validation accuracy at iteration 3280  is               81.6%\n",
            "The validation accuracy at iteration 3296  is               81.2%\n",
            "The validation accuracy at iteration 3312  is               78.5%\n",
            "The validation accuracy at iteration 3328  is               81.77499999999999%\n",
            "The validation accuracy at iteration 3344  is               79.4%\n",
            "The validation accuracy at iteration 3360  is               80.77499999999999%\n",
            "The validation accuracy at iteration 3376  is               80.05%\n",
            "The validation accuracy at iteration 3392  is               82.35%\n",
            "The validation accuracy at iteration 3408  is               81.375%\n",
            "The validation accuracy at iteration 3424  is               81.0%\n",
            "The validation accuracy at iteration 3440  is               82.875%\n",
            "The validation accuracy at iteration 3456  is               78.225%\n",
            "The validation accuracy at iteration 3472  is               81.27499999999999%\n",
            "The validation accuracy at iteration 3488  is               80.425%\n",
            "The validation accuracy at iteration 3504  is               81.625%\n",
            "The validation accuracy at iteration 3520  is               80.75%\n",
            "The validation accuracy at iteration 3536  is               80.15%\n",
            "The validation accuracy at iteration 3552  is               83.22500000000001%\n",
            "The validation accuracy at iteration 3568  is               81.925%\n",
            "The validation accuracy at iteration 3584  is               80.85%\n",
            "The validation accuracy at iteration 3600  is               81.875%\n",
            "The validation accuracy at iteration 3616  is               77.925%\n",
            "The validation accuracy at iteration 3632  is               80.77499999999999%\n",
            "The validation accuracy at iteration 3648  is               82.39999999999999%\n",
            "The validation accuracy at iteration 3664  is               76.325%\n",
            "The validation accuracy at iteration 3680  is               78.77499999999999%\n",
            "The validation accuracy at iteration 3696  is               80.60000000000001%\n",
            "The validation accuracy at iteration 3712  is               81.45%\n",
            "The validation accuracy at iteration 3728  is               80.525%\n",
            "The validation accuracy at iteration 3744  is               79.525%\n",
            "The validation accuracy at iteration 3760  is               83.075%\n",
            "The validation accuracy at iteration 3776  is               82.675%\n",
            "The validation accuracy at iteration 3792  is               78.875%\n",
            "The validation accuracy at iteration 3808  is               81.875%\n",
            "The validation accuracy at iteration 3824  is               80.825%\n",
            "The validation accuracy at iteration 3840  is               80.675%\n",
            "The validation accuracy at iteration 3856  is               80.72500000000001%\n",
            "The validation accuracy at iteration 3872  is               81.875%\n",
            "The validation accuracy at iteration 3888  is               80.55%\n",
            "The validation accuracy at iteration 3904  is               82.575%\n",
            "The validation accuracy at iteration 3920  is               81.525%\n",
            "The validation accuracy at iteration 3936  is               77.925%\n",
            "The validation accuracy at iteration 3952  is               79.95%\n",
            "The validation accuracy at iteration 3968  is               82.55%\n",
            "The validation accuracy at iteration 3984  is               81.125%\n",
            "The validation accuracy at iteration 4000  is               79.0%\n",
            "The validation accuracy at iteration 4016  is               81.075%\n",
            "The validation accuracy at iteration 4032  is               82.175%\n",
            "The validation accuracy at iteration 4048  is               80.175%\n",
            "The validation accuracy at iteration 4064  is               78.175%\n",
            "The validation accuracy at iteration 4080  is               82.525%\n",
            "The validation accuracy at iteration 4096  is               82.075%\n",
            "The validation accuracy at iteration 4112  is               80.375%\n",
            "The validation accuracy at iteration 4128  is               81.85%\n",
            "The validation accuracy at iteration 4144  is               79.925%\n",
            "The validation accuracy at iteration 4160  is               78.025%\n",
            "The validation accuracy at iteration 4176  is               81.675%\n",
            "The validation accuracy at iteration 4192  is               80.25%\n",
            "The validation accuracy at iteration 4208  is               81.475%\n",
            "The validation accuracy at iteration 4224  is               83.025%\n",
            "The validation accuracy at iteration 4240  is               82.15%\n",
            "The validation accuracy at iteration 4256  is               80.72500000000001%\n",
            "The validation accuracy at iteration 4272  is               81.475%\n",
            "The validation accuracy at iteration 4288  is               83.22500000000001%\n",
            "The validation accuracy at iteration 4304  is               81.55%\n",
            "The validation accuracy at iteration 4320  is               74.725%\n",
            "The validation accuracy at iteration 4336  is               82.3%\n",
            "The validation accuracy at iteration 4352  is               81.6%\n",
            "The validation accuracy at iteration 4368  is               81.3%\n",
            "The validation accuracy at iteration 4384  is               80.25%\n",
            "The validation accuracy at iteration 4400  is               82.075%\n",
            "The validation accuracy at iteration 4416  is               83.0%\n",
            "The validation accuracy at iteration 4432  is               79.65%\n",
            "The validation accuracy at iteration 4448  is               82.75%\n",
            "The validation accuracy at iteration 4464  is               79.625%\n",
            "The validation accuracy at iteration 4480  is               80.875%\n",
            "The validation accuracy at iteration 4496  is               81.825%\n",
            "The validation accuracy at iteration 4512  is               83.025%\n",
            "The validation accuracy at iteration 4528  is               81.05%\n",
            "The validation accuracy at iteration 4544  is               80.475%\n",
            "The validation accuracy at iteration 4560  is               81.675%\n",
            "The validation accuracy at iteration 4576  is               82.575%\n",
            "The validation accuracy at iteration 4592  is               81.35%\n",
            "The validation accuracy at iteration 4608  is               82.5%\n",
            "The validation accuracy at iteration 4624  is               81.575%\n",
            "The validation accuracy at iteration 4640  is               78.64999999999999%\n",
            "The validation accuracy at iteration 4656  is               81.95%\n",
            "The validation accuracy at iteration 4672  is               82.35%\n",
            "The validation accuracy at iteration 4688  is               82.6%\n",
            "The validation accuracy at iteration 4704  is               80.125%\n",
            "The validation accuracy at iteration 4720  is               82.475%\n",
            "The validation accuracy at iteration 4736  is               82.55%\n",
            "The validation accuracy at iteration 4752  is               82.39999999999999%\n",
            "The validation accuracy at iteration 4768  is               82.875%\n",
            "The validation accuracy at iteration 4784  is               80.675%\n",
            "The validation accuracy at iteration 4800  is               79.45%\n",
            "The validation accuracy at iteration 4816  is               80.30000000000001%\n",
            "The validation accuracy at iteration 4832  is               82.575%\n",
            "The validation accuracy at iteration 4848  is               82.075%\n",
            "The validation accuracy at iteration 4864  is               80.60000000000001%\n",
            "The validation accuracy at iteration 4880  is               82.8%\n",
            "The validation accuracy at iteration 4896  is               82.72500000000001%\n",
            "The validation accuracy at iteration 4912  is               81.575%\n",
            "The validation accuracy at iteration 4928  is               81.925%\n",
            "The validation accuracy at iteration 4944  is               81.27499999999999%\n",
            "The validation accuracy at iteration 4960  is               82.475%\n",
            "The validation accuracy at iteration 4976  is               81.95%\n",
            "The validation accuracy at iteration 4992  is               81.8%\n",
            "The validation accuracy at iteration 5008  is               83.025%\n",
            "The validation accuracy at iteration 5024  is               80.025%\n",
            "The validation accuracy at iteration 5040  is               82.025%\n",
            "The validation accuracy at iteration 5056  is               82.1%\n",
            "The validation accuracy at iteration 5072  is               82.025%\n",
            "The validation accuracy at iteration 5088  is               81.15%\n",
            "The validation accuracy at iteration 5104  is               82.025%\n",
            "The validation accuracy at iteration 5120  is               82.27499999999999%\n",
            "The validation accuracy at iteration 5136  is               82.3%\n",
            "The validation accuracy at iteration 5152  is               83.025%\n",
            "The validation accuracy at iteration 5168  is               81.325%\n",
            "The validation accuracy at iteration 5184  is               79.925%\n",
            "The validation accuracy at iteration 5200  is               82.425%\n",
            "The validation accuracy at iteration 5216  is               82.625%\n",
            "The validation accuracy at iteration 5232  is               81.35%\n",
            "The validation accuracy at iteration 5248  is               80.575%\n",
            "The validation accuracy at iteration 5264  is               83.075%\n",
            "The validation accuracy at iteration 5280  is               83.325%\n",
            "The validation accuracy at iteration 5296  is               80.60000000000001%\n",
            "The validation accuracy at iteration 5312  is               81.65%\n",
            "The validation accuracy at iteration 5328  is               80.45%\n",
            "The validation accuracy at iteration 5344  is               81.95%\n",
            "The validation accuracy at iteration 5350  is               81.8%\n",
            "The validation accuracy at iteration 5350  is               81.8%\n",
            "The validation accuracy at iteration 16000  is               82.875%\n",
            "The validation accuracy at iteration 5350  is               81.8%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 5350  is               81.8%\n",
            "The validation accuracy at iteration 3200  is               81.375%\n",
            "The validation accuracy at iteration 5350  is               81.8%\n",
            "[<__main__.Solver object at 0x7f6e25755490>, <__main__.Solver object at 0x7f6e457874d0>, <__main__.Solver object at 0x7f6e3ac62710>, <__main__.Solver object at 0x7f6e4c519d10>, <__main__.Solver object at 0x7f6e4c79e350>]\n",
            "The validation accuracy at iteration 16  is               27.075%\n",
            "The validation accuracy at iteration 32  is               25.974999999999998%\n",
            "The validation accuracy at iteration 48  is               45.324999999999996%\n",
            "The validation accuracy at iteration 64  is               19.725%\n",
            "The validation accuracy at iteration 80  is               47.349999999999994%\n",
            "The validation accuracy at iteration 96  is               29.95%\n",
            "The validation accuracy at iteration 112  is               46.85%\n",
            "The validation accuracy at iteration 128  is               35.775%\n",
            "The validation accuracy at iteration 144  is               59.9%\n",
            "The validation accuracy at iteration 160  is               68.4%\n",
            "The validation accuracy at iteration 176  is               35.699999999999996%\n",
            "The validation accuracy at iteration 192  is               75.175%\n",
            "The validation accuracy at iteration 208  is               53.7%\n",
            "The validation accuracy at iteration 224  is               55.35%\n",
            "The validation accuracy at iteration 240  is               39.275%\n",
            "The validation accuracy at iteration 256  is               73.2%\n",
            "The validation accuracy at iteration 272  is               55.65%\n",
            "The validation accuracy at iteration 288  is               55.574999999999996%\n",
            "The validation accuracy at iteration 304  is               39.6%\n",
            "The validation accuracy at iteration 320  is               75.275%\n",
            "The validation accuracy at iteration 336  is               60.925%\n",
            "The validation accuracy at iteration 352  is               60.224999999999994%\n",
            "The validation accuracy at iteration 368  is               43.025000000000006%\n",
            "The validation accuracy at iteration 384  is               75.375%\n",
            "The validation accuracy at iteration 400  is               73.875%\n",
            "The validation accuracy at iteration 416  is               60.724999999999994%\n",
            "The validation accuracy at iteration 432  is               50.575%\n",
            "The validation accuracy at iteration 448  is               75.825%\n",
            "The validation accuracy at iteration 464  is               67.5%\n",
            "The validation accuracy at iteration 480  is               72.175%\n",
            "The validation accuracy at iteration 496  is               55.775%\n",
            "The validation accuracy at iteration 512  is               77.47500000000001%\n",
            "The validation accuracy at iteration 528  is               69.675%\n",
            "The validation accuracy at iteration 544  is               76.875%\n",
            "The validation accuracy at iteration 560  is               58.975%\n",
            "The validation accuracy at iteration 576  is               78.64999999999999%\n",
            "The validation accuracy at iteration 592  is               73.75%\n",
            "The validation accuracy at iteration 608  is               76.4%\n",
            "The validation accuracy at iteration 624  is               63.6%\n",
            "The validation accuracy at iteration 640  is               77.925%\n",
            "The validation accuracy at iteration 656  is               75.625%\n",
            "The validation accuracy at iteration 672  is               76.875%\n",
            "The validation accuracy at iteration 688  is               64.225%\n",
            "The validation accuracy at iteration 704  is               77.10000000000001%\n",
            "The validation accuracy at iteration 720  is               69.025%\n",
            "The validation accuracy at iteration 736  is               76.875%\n",
            "The validation accuracy at iteration 752  is               70.19999999999999%\n",
            "The validation accuracy at iteration 768  is               78.975%\n",
            "The validation accuracy at iteration 784  is               74.175%\n",
            "The validation accuracy at iteration 800  is               78.7%\n",
            "The validation accuracy at iteration 816  is               71.325%\n",
            "The validation accuracy at iteration 832  is               79.75%\n",
            "The validation accuracy at iteration 848  is               69.575%\n",
            "The validation accuracy at iteration 864  is               77.3%\n",
            "The validation accuracy at iteration 880  is               73.275%\n",
            "The validation accuracy at iteration 896  is               79.475%\n",
            "The validation accuracy at iteration 912  is               69.22500000000001%\n",
            "The validation accuracy at iteration 928  is               79.27499999999999%\n",
            "The validation accuracy at iteration 944  is               76.47500000000001%\n",
            "The validation accuracy at iteration 960  is               79.80000000000001%\n",
            "The validation accuracy at iteration 976  is               71.2%\n",
            "The validation accuracy at iteration 992  is               79.525%\n",
            "The validation accuracy at iteration 1008  is               76.525%\n",
            "The validation accuracy at iteration 1024  is               80.7%\n",
            "The validation accuracy at iteration 1040  is               75.3%\n",
            "The validation accuracy at iteration 1056  is               78.975%\n",
            "The validation accuracy at iteration 1072  is               75.52499999999999%\n",
            "The validation accuracy at iteration 1088  is               80.55%\n",
            "The validation accuracy at iteration 1104  is               75.2%\n",
            "The validation accuracy at iteration 1120  is               78.2%\n",
            "The validation accuracy at iteration 1136  is               76.14999999999999%\n",
            "The validation accuracy at iteration 1152  is               80.35%\n",
            "The validation accuracy at iteration 1168  is               72.45%\n",
            "The validation accuracy at iteration 1184  is               78.25%\n",
            "The validation accuracy at iteration 1200  is               74.95%\n",
            "The validation accuracy at iteration 1216  is               80.72500000000001%\n",
            "The validation accuracy at iteration 1232  is               78.825%\n",
            "The validation accuracy at iteration 1248  is               79.4%\n",
            "The validation accuracy at iteration 1264  is               74.2%\n",
            "The validation accuracy at iteration 1280  is               80.825%\n",
            "The validation accuracy at iteration 1296  is               79.625%\n",
            "The validation accuracy at iteration 1312  is               79.875%\n",
            "The validation accuracy at iteration 1328  is               75.925%\n",
            "The validation accuracy at iteration 1344  is               80.65%\n",
            "The validation accuracy at iteration 1360  is               78.625%\n",
            "The validation accuracy at iteration 1376  is               79.75%\n",
            "The validation accuracy at iteration 1392  is               77.60000000000001%\n",
            "The validation accuracy at iteration 1408  is               80.80000000000001%\n",
            "The validation accuracy at iteration 1424  is               80.475%\n",
            "The validation accuracy at iteration 1440  is               80.375%\n",
            "The validation accuracy at iteration 1456  is               75.6%\n",
            "The validation accuracy at iteration 1472  is               80.575%\n",
            "The validation accuracy at iteration 1488  is               77.5%\n",
            "The validation accuracy at iteration 1504  is               80.075%\n",
            "The validation accuracy at iteration 1520  is               75.3%\n",
            "The validation accuracy at iteration 1536  is               80.375%\n",
            "The validation accuracy at iteration 1552  is               78.825%\n",
            "The validation accuracy at iteration 1568  is               80.72500000000001%\n",
            "The validation accuracy at iteration 1584  is               74.75%\n",
            "The validation accuracy at iteration 1600  is               81.10000000000001%\n",
            "The validation accuracy at iteration 1616  is               79.725%\n",
            "The validation accuracy at iteration 1632  is               80.075%\n",
            "The validation accuracy at iteration 1648  is               72.02499999999999%\n",
            "The validation accuracy at iteration 1664  is               81.25%\n",
            "The validation accuracy at iteration 1680  is               80.85%\n",
            "The validation accuracy at iteration 1696  is               81.22500000000001%\n",
            "The validation accuracy at iteration 1712  is               77.875%\n",
            "The validation accuracy at iteration 1728  is               81.025%\n",
            "The validation accuracy at iteration 1744  is               79.425%\n",
            "The validation accuracy at iteration 1760  is               81.25%\n",
            "The validation accuracy at iteration 1776  is               79.125%\n",
            "The validation accuracy at iteration 1792  is               81.3%\n",
            "The validation accuracy at iteration 1808  is               79.0%\n",
            "The validation accuracy at iteration 1824  is               80.575%\n",
            "The validation accuracy at iteration 1840  is               73.2%\n",
            "The validation accuracy at iteration 1856  is               81.175%\n",
            "The validation accuracy at iteration 1872  is               80.325%\n",
            "The validation accuracy at iteration 1888  is               80.5%\n",
            "The validation accuracy at iteration 1904  is               73.825%\n",
            "The validation accuracy at iteration 1920  is               80.60000000000001%\n",
            "The validation accuracy at iteration 1936  is               80.575%\n",
            "The validation accuracy at iteration 1952  is               81.425%\n",
            "The validation accuracy at iteration 1968  is               76.85%\n",
            "The validation accuracy at iteration 1984  is               80.95%\n",
            "The validation accuracy at iteration 2000  is               79.25%\n",
            "The validation accuracy at iteration 2016  is               80.575%\n",
            "The validation accuracy at iteration 2032  is               80.575%\n",
            "The validation accuracy at iteration 2048  is               81.22500000000001%\n",
            "The validation accuracy at iteration 2064  is               80.5%\n",
            "The validation accuracy at iteration 2080  is               80.85%\n",
            "The validation accuracy at iteration 2096  is               80.05%\n",
            "The validation accuracy at iteration 2112  is               80.9%\n",
            "The validation accuracy at iteration 2128  is               80.65%\n",
            "The validation accuracy at iteration 2144  is               81.27499999999999%\n",
            "The validation accuracy at iteration 2160  is               80.22500000000001%\n",
            "The validation accuracy at iteration 2176  is               80.975%\n",
            "The validation accuracy at iteration 2192  is               80.7%\n",
            "The validation accuracy at iteration 2208  is               81.325%\n",
            "The validation accuracy at iteration 2224  is               79.975%\n",
            "The validation accuracy at iteration 2240  is               81.5%\n",
            "The validation accuracy at iteration 2256  is               80.9%\n",
            "The validation accuracy at iteration 2272  is               81.39999999999999%\n",
            "The validation accuracy at iteration 2288  is               81.15%\n",
            "The validation accuracy at iteration 2304  is               81.75%\n",
            "The validation accuracy at iteration 2320  is               80.975%\n",
            "The validation accuracy at iteration 2336  is               81.025%\n",
            "The validation accuracy at iteration 2352  is               81.925%\n",
            "The validation accuracy at iteration 2368  is               80.72500000000001%\n",
            "The validation accuracy at iteration 2384  is               80.9%\n",
            "The validation accuracy at iteration 2400  is               81.575%\n",
            "The validation accuracy at iteration 2416  is               76.725%\n",
            "The validation accuracy at iteration 2432  is               81.2%\n",
            "The validation accuracy at iteration 2448  is               81.05%\n",
            "The validation accuracy at iteration 2464  is               80.875%\n",
            "The validation accuracy at iteration 2480  is               80.925%\n",
            "The validation accuracy at iteration 2496  is               81.25%\n",
            "The validation accuracy at iteration 2512  is               80.9%\n",
            "The validation accuracy at iteration 2528  is               81.10000000000001%\n",
            "The validation accuracy at iteration 2544  is               81.77499999999999%\n",
            "The validation accuracy at iteration 2560  is               80.925%\n",
            "The validation accuracy at iteration 2576  is               81.05%\n",
            "The validation accuracy at iteration 2592  is               81.22500000000001%\n",
            "The validation accuracy at iteration 2608  is               77.45%\n",
            "The validation accuracy at iteration 2624  is               81.45%\n",
            "The validation accuracy at iteration 2640  is               80.95%\n",
            "The validation accuracy at iteration 2656  is               80.925%\n",
            "The validation accuracy at iteration 2672  is               82.0%\n",
            "The validation accuracy at iteration 2688  is               81.69999999999999%\n",
            "The validation accuracy at iteration 2704  is               80.95%\n",
            "The validation accuracy at iteration 2720  is               81.39999999999999%\n",
            "The validation accuracy at iteration 2736  is               80.825%\n",
            "The validation accuracy at iteration 2752  is               81.025%\n",
            "The validation accuracy at iteration 2768  is               80.975%\n",
            "The validation accuracy at iteration 2784  is               81.2%\n",
            "The validation accuracy at iteration 2800  is               81.3%\n",
            "The validation accuracy at iteration 2816  is               80.75%\n",
            "The validation accuracy at iteration 2832  is               80.75%\n",
            "The validation accuracy at iteration 2848  is               81.10000000000001%\n",
            "The validation accuracy at iteration 2864  is               81.875%\n",
            "The validation accuracy at iteration 2880  is               81.425%\n",
            "The validation accuracy at iteration 2896  is               81.3%\n",
            "The validation accuracy at iteration 2912  is               81.3%\n",
            "The validation accuracy at iteration 2928  is               81.15%\n",
            "The validation accuracy at iteration 2944  is               81.575%\n",
            "The validation accuracy at iteration 2960  is               81.175%\n",
            "The validation accuracy at iteration 2976  is               81.375%\n",
            "The validation accuracy at iteration 2992  is               80.875%\n",
            "The validation accuracy at iteration 3008  is               81.35%\n",
            "The validation accuracy at iteration 3024  is               81.25%\n",
            "The validation accuracy at iteration 3040  is               81.5%\n",
            "The validation accuracy at iteration 3056  is               79.80000000000001%\n",
            "The validation accuracy at iteration 3072  is               81.5%\n",
            "The validation accuracy at iteration 3088  is               80.55%\n",
            "The validation accuracy at iteration 3104  is               81.5%\n",
            "The validation accuracy at iteration 3120  is               81.525%\n",
            "The validation accuracy at iteration 3136  is               81.95%\n",
            "The validation accuracy at iteration 3152  is               81.45%\n",
            "The validation accuracy at iteration 3168  is               81.65%\n",
            "The validation accuracy at iteration 3184  is               81.22500000000001%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "The validation accuracy at iteration 16000  is               82.875%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "The validation accuracy at iteration 5350  is               81.8%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "[<__main__.Solver object at 0x7f6e25755490>, <__main__.Solver object at 0x7f6e457874d0>, <__main__.Solver object at 0x7f6e5b0b1490>, <__main__.Solver object at 0x7f6e4c519d10>, <__main__.Solver object at 0x7f6e4c79e350>]\n",
            "The validation accuracy at iteration 16  is               24.825%\n",
            "The validation accuracy at iteration 32  is               39.074999999999996%\n",
            "The validation accuracy at iteration 48  is               21.675%\n",
            "The validation accuracy at iteration 64  is               52.900000000000006%\n",
            "The validation accuracy at iteration 80  is               39.125%\n",
            "The validation accuracy at iteration 96  is               51.475%\n",
            "The validation accuracy at iteration 112  is               47.875%\n",
            "The validation accuracy at iteration 128  is               38.625%\n",
            "The validation accuracy at iteration 144  is               40.775%\n",
            "The validation accuracy at iteration 160  is               37.25%\n",
            "The validation accuracy at iteration 176  is               54.974999999999994%\n",
            "The validation accuracy at iteration 192  is               60.3%\n",
            "The validation accuracy at iteration 208  is               66.60000000000001%\n",
            "The validation accuracy at iteration 224  is               60.525%\n",
            "The validation accuracy at iteration 240  is               60.150000000000006%\n",
            "The validation accuracy at iteration 256  is               63.775000000000006%\n",
            "The validation accuracy at iteration 272  is               65.05%\n",
            "The validation accuracy at iteration 288  is               60.975%\n",
            "The validation accuracy at iteration 304  is               59.45%\n",
            "The validation accuracy at iteration 320  is               65.2%\n",
            "The validation accuracy at iteration 336  is               53.849999999999994%\n",
            "The validation accuracy at iteration 352  is               77.05%\n",
            "The validation accuracy at iteration 368  is               75.725%\n",
            "The validation accuracy at iteration 384  is               76.5%\n",
            "The validation accuracy at iteration 400  is               72.125%\n",
            "The validation accuracy at iteration 416  is               71.125%\n",
            "The validation accuracy at iteration 432  is               68.975%\n",
            "The validation accuracy at iteration 448  is               75.55%\n",
            "The validation accuracy at iteration 464  is               71.2%\n",
            "The validation accuracy at iteration 480  is               69.875%\n",
            "The validation accuracy at iteration 496  is               71.95%\n",
            "The validation accuracy at iteration 512  is               73.375%\n",
            "The validation accuracy at iteration 528  is               77.75%\n",
            "The validation accuracy at iteration 544  is               77.525%\n",
            "The validation accuracy at iteration 560  is               70.72500000000001%\n",
            "The validation accuracy at iteration 576  is               78.8%\n",
            "The validation accuracy at iteration 592  is               65.14999999999999%\n",
            "The validation accuracy at iteration 608  is               57.85%\n",
            "The validation accuracy at iteration 624  is               78.925%\n",
            "The validation accuracy at iteration 640  is               79.125%\n",
            "The validation accuracy at iteration 656  is               78.0%\n",
            "The validation accuracy at iteration 672  is               79.325%\n",
            "The validation accuracy at iteration 688  is               78.675%\n",
            "The validation accuracy at iteration 704  is               79.875%\n",
            "The validation accuracy at iteration 720  is               80.0%\n",
            "The validation accuracy at iteration 736  is               79.325%\n",
            "The validation accuracy at iteration 752  is               79.725%\n",
            "The validation accuracy at iteration 768  is               79.35%\n",
            "The validation accuracy at iteration 784  is               76.55%\n",
            "The validation accuracy at iteration 800  is               72.35000000000001%\n",
            "The validation accuracy at iteration 816  is               76.7%\n",
            "The validation accuracy at iteration 832  is               76.2%\n",
            "The validation accuracy at iteration 848  is               75.3%\n",
            "The validation accuracy at iteration 864  is               78.14999999999999%\n",
            "The validation accuracy at iteration 880  is               79.60000000000001%\n",
            "The validation accuracy at iteration 896  is               80.2%\n",
            "The validation accuracy at iteration 912  is               80.45%\n",
            "The validation accuracy at iteration 928  is               75.9%\n",
            "The validation accuracy at iteration 944  is               78.525%\n",
            "The validation accuracy at iteration 960  is               72.3%\n",
            "The validation accuracy at iteration 976  is               75.05%\n",
            "The validation accuracy at iteration 992  is               81.39999999999999%\n",
            "The validation accuracy at iteration 1008  is               79.75%\n",
            "The validation accuracy at iteration 1024  is               78.525%\n",
            "The validation accuracy at iteration 1040  is               79.55%\n",
            "The validation accuracy at iteration 1056  is               78.64999999999999%\n",
            "The validation accuracy at iteration 1072  is               80.75%\n",
            "The validation accuracy at iteration 1088  is               79.975%\n",
            "The validation accuracy at iteration 1104  is               80.22500000000001%\n",
            "The validation accuracy at iteration 1120  is               81.0%\n",
            "The validation accuracy at iteration 1136  is               81.89999999999999%\n",
            "The validation accuracy at iteration 1152  is               81.65%\n",
            "The validation accuracy at iteration 1168  is               74.625%\n",
            "The validation accuracy at iteration 1184  is               79.2%\n",
            "The validation accuracy at iteration 1200  is               82.125%\n",
            "The validation accuracy at iteration 1216  is               74.6%\n",
            "The validation accuracy at iteration 1232  is               80.825%\n",
            "The validation accuracy at iteration 1248  is               80.65%\n",
            "The validation accuracy at iteration 1264  is               74.8%\n",
            "The validation accuracy at iteration 1280  is               81.10000000000001%\n",
            "The validation accuracy at iteration 1296  is               78.325%\n",
            "The validation accuracy at iteration 1312  is               79.45%\n",
            "The validation accuracy at iteration 1328  is               74.125%\n",
            "The validation accuracy at iteration 1344  is               79.45%\n",
            "The validation accuracy at iteration 1360  is               81.675%\n",
            "The validation accuracy at iteration 1376  is               80.525%\n",
            "The validation accuracy at iteration 1392  is               79.65%\n",
            "The validation accuracy at iteration 1408  is               78.675%\n",
            "The validation accuracy at iteration 1424  is               80.075%\n",
            "The validation accuracy at iteration 1440  is               80.72500000000001%\n",
            "The validation accuracy at iteration 1456  is               80.22500000000001%\n",
            "The validation accuracy at iteration 1472  is               81.15%\n",
            "The validation accuracy at iteration 1488  is               81.8%\n",
            "The validation accuracy at iteration 1504  is               79.975%\n",
            "The validation accuracy at iteration 1520  is               82.05%\n",
            "The validation accuracy at iteration 1536  is               76.75%\n",
            "The validation accuracy at iteration 1552  is               78.64999999999999%\n",
            "The validation accuracy at iteration 1568  is               82.525%\n",
            "The validation accuracy at iteration 1584  is               75.85%\n",
            "The validation accuracy at iteration 1600  is               80.30000000000001%\n",
            "The validation accuracy at iteration 1616  is               82.625%\n",
            "The validation accuracy at iteration 1632  is               80.525%\n",
            "The validation accuracy at iteration 1648  is               82.375%\n",
            "The validation accuracy at iteration 1664  is               78.875%\n",
            "The validation accuracy at iteration 1680  is               79.45%\n",
            "The validation accuracy at iteration 1696  is               74.75%\n",
            "The validation accuracy at iteration 1712  is               78.05%\n",
            "The validation accuracy at iteration 1728  is               80.325%\n",
            "The validation accuracy at iteration 1744  is               80.45%\n",
            "The validation accuracy at iteration 1760  is               79.25%\n",
            "The validation accuracy at iteration 1776  is               79.625%\n",
            "The validation accuracy at iteration 1792  is               80.875%\n",
            "The validation accuracy at iteration 1808  is               59.775%\n",
            "The validation accuracy at iteration 1824  is               80.575%\n",
            "The validation accuracy at iteration 1840  is               81.15%\n",
            "The validation accuracy at iteration 1856  is               82.175%\n",
            "The validation accuracy at iteration 1872  is               81.975%\n",
            "The validation accuracy at iteration 1888  is               81.825%\n",
            "The validation accuracy at iteration 1904  is               79.425%\n",
            "The validation accuracy at iteration 1920  is               80.625%\n",
            "The validation accuracy at iteration 1936  is               82.39999999999999%\n",
            "The validation accuracy at iteration 1952  is               76.625%\n",
            "The validation accuracy at iteration 1968  is               80.10000000000001%\n",
            "The validation accuracy at iteration 1984  is               82.19999999999999%\n",
            "The validation accuracy at iteration 2000  is               80.60000000000001%\n",
            "The validation accuracy at iteration 2016  is               81.8%\n",
            "The validation accuracy at iteration 2032  is               80.25%\n",
            "The validation accuracy at iteration 2048  is               80.525%\n",
            "The validation accuracy at iteration 2064  is               76.175%\n",
            "The validation accuracy at iteration 2080  is               79.625%\n",
            "The validation accuracy at iteration 2096  is               82.575%\n",
            "The validation accuracy at iteration 2112  is               81.825%\n",
            "The validation accuracy at iteration 2128  is               81.15%\n",
            "The validation accuracy at iteration 2144  is               81.675%\n",
            "The validation accuracy at iteration 2160  is               81.35%\n",
            "The validation accuracy at iteration 2176  is               81.55%\n",
            "The validation accuracy at iteration 2192  is               82.25%\n",
            "The validation accuracy at iteration 2208  is               81.825%\n",
            "The validation accuracy at iteration 2224  is               81.325%\n",
            "The validation accuracy at iteration 2240  is               82.075%\n",
            "The validation accuracy at iteration 2256  is               81.65%\n",
            "The validation accuracy at iteration 2272  is               69.075%\n",
            "The validation accuracy at iteration 2288  is               79.025%\n",
            "The validation accuracy at iteration 2300  is               81.75%\n",
            "The validation accuracy at iteration 2300  is               81.75%\n",
            "The validation accuracy at iteration 16000  is               82.875%\n",
            "The validation accuracy at iteration 2300  is               81.75%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 2300  is               81.75%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "The validation accuracy at iteration 2300  is               81.75%\n",
            "The validation accuracy at iteration 3200  is               81.375%\n",
            "The validation accuracy at iteration 2300  is               81.75%\n",
            "[<__main__.Solver object at 0x7f6e25755490>, <__main__.Solver object at 0x7f6e457874d0>, <__main__.Solver object at 0x7f6e5b0b1490>, <__main__.Solver object at 0x7f6e4c6b5710>, <__main__.Solver object at 0x7f6e4c79e350>]\n",
            "The validation accuracy at iteration 16  is               25.174999999999997%\n",
            "The validation accuracy at iteration 32  is               33.875%\n",
            "The validation accuracy at iteration 48  is               36.95%\n",
            "The validation accuracy at iteration 64  is               43.575%\n",
            "The validation accuracy at iteration 80  is               50.125%\n",
            "The validation accuracy at iteration 96  is               59.050000000000004%\n",
            "The validation accuracy at iteration 112  is               44.75%\n",
            "The validation accuracy at iteration 128  is               59.975%\n",
            "The validation accuracy at iteration 144  is               56.00000000000001%\n",
            "The validation accuracy at iteration 160  is               61.575%\n",
            "The validation accuracy at iteration 176  is               48.425000000000004%\n",
            "The validation accuracy at iteration 192  is               59.95%\n",
            "The validation accuracy at iteration 208  is               72.0%\n",
            "The validation accuracy at iteration 224  is               73.225%\n",
            "The validation accuracy at iteration 240  is               60.6%\n",
            "The validation accuracy at iteration 256  is               73.425%\n",
            "The validation accuracy at iteration 272  is               70.65%\n",
            "The validation accuracy at iteration 288  is               62.125%\n",
            "The validation accuracy at iteration 304  is               71.3%\n",
            "The validation accuracy at iteration 320  is               44.275%\n",
            "The validation accuracy at iteration 336  is               55.35%\n",
            "The validation accuracy at iteration 352  is               57.975%\n",
            "The validation accuracy at iteration 368  is               74.275%\n",
            "The validation accuracy at iteration 384  is               66.8%\n",
            "The validation accuracy at iteration 400  is               56.39999999999999%\n",
            "The validation accuracy at iteration 416  is               68.625%\n",
            "The validation accuracy at iteration 432  is               62.425%\n",
            "The validation accuracy at iteration 448  is               66.64999999999999%\n",
            "The validation accuracy at iteration 464  is               47.099999999999994%\n",
            "The validation accuracy at iteration 480  is               68.10000000000001%\n",
            "The validation accuracy at iteration 496  is               57.825%\n",
            "The validation accuracy at iteration 512  is               74.95%\n",
            "The validation accuracy at iteration 528  is               71.55%\n",
            "The validation accuracy at iteration 544  is               64.925%\n",
            "The validation accuracy at iteration 560  is               76.64999999999999%\n",
            "The validation accuracy at iteration 576  is               77.25%\n",
            "The validation accuracy at iteration 592  is               75.44999999999999%\n",
            "The validation accuracy at iteration 608  is               61.3%\n",
            "The validation accuracy at iteration 624  is               76.6%\n",
            "The validation accuracy at iteration 640  is               74.925%\n",
            "The validation accuracy at iteration 656  is               78.375%\n",
            "The validation accuracy at iteration 672  is               79.525%\n",
            "The validation accuracy at iteration 688  is               77.025%\n",
            "The validation accuracy at iteration 704  is               80.175%\n",
            "The validation accuracy at iteration 720  is               78.125%\n",
            "The validation accuracy at iteration 736  is               78.625%\n",
            "The validation accuracy at iteration 752  is               79.425%\n",
            "The validation accuracy at iteration 768  is               77.3%\n",
            "The validation accuracy at iteration 784  is               75.7%\n",
            "The validation accuracy at iteration 800  is               76.95%\n",
            "The validation accuracy at iteration 816  is               80.27499999999999%\n",
            "The validation accuracy at iteration 832  is               78.45%\n",
            "The validation accuracy at iteration 848  is               80.80000000000001%\n",
            "The validation accuracy at iteration 864  is               79.525%\n",
            "The validation accuracy at iteration 880  is               78.125%\n",
            "The validation accuracy at iteration 896  is               79.07499999999999%\n",
            "The validation accuracy at iteration 912  is               78.14999999999999%\n",
            "The validation accuracy at iteration 928  is               77.525%\n",
            "The validation accuracy at iteration 944  is               78.2%\n",
            "The validation accuracy at iteration 960  is               79.25%\n",
            "The validation accuracy at iteration 976  is               80.75%\n",
            "The validation accuracy at iteration 992  is               81.125%\n",
            "The validation accuracy at iteration 1008  is               79.9%\n",
            "The validation accuracy at iteration 1024  is               77.525%\n",
            "The validation accuracy at iteration 1040  is               79.85%\n",
            "The validation accuracy at iteration 1056  is               79.5%\n",
            "The validation accuracy at iteration 1072  is               77.125%\n",
            "The validation accuracy at iteration 1088  is               80.72500000000001%\n",
            "The validation accuracy at iteration 1104  is               78.55%\n",
            "The validation accuracy at iteration 1120  is               81.425%\n",
            "The validation accuracy at iteration 1136  is               80.95%\n",
            "The validation accuracy at iteration 1152  is               81.075%\n",
            "The validation accuracy at iteration 1168  is               78.925%\n",
            "The validation accuracy at iteration 1184  is               80.60000000000001%\n",
            "The validation accuracy at iteration 1200  is               80.2%\n",
            "The validation accuracy at iteration 1216  is               79.9%\n",
            "The validation accuracy at iteration 1232  is               80.75%\n",
            "The validation accuracy at iteration 1248  is               81.175%\n",
            "The validation accuracy at iteration 1264  is               81.15%\n",
            "The validation accuracy at iteration 1280  is               81.85%\n",
            "The validation accuracy at iteration 1296  is               81.175%\n",
            "The validation accuracy at iteration 1312  is               77.775%\n",
            "The validation accuracy at iteration 1328  is               80.55%\n",
            "The validation accuracy at iteration 1344  is               79.125%\n",
            "The validation accuracy at iteration 1360  is               79.45%\n",
            "The validation accuracy at iteration 1376  is               80.7%\n",
            "The validation accuracy at iteration 1392  is               80.325%\n",
            "The validation accuracy at iteration 1408  is               82.325%\n",
            "The validation accuracy at iteration 1424  is               77.9%\n",
            "The validation accuracy at iteration 1440  is               81.55%\n",
            "The validation accuracy at iteration 1456  is               78.025%\n",
            "The validation accuracy at iteration 1472  is               81.525%\n",
            "The validation accuracy at iteration 1488  is               80.25%\n",
            "The validation accuracy at iteration 1504  is               78.375%\n",
            "The validation accuracy at iteration 1520  is               81.075%\n",
            "The validation accuracy at iteration 1536  is               80.45%\n",
            "The validation accuracy at iteration 1552  is               81.0%\n",
            "The validation accuracy at iteration 1568  is               81.075%\n",
            "The validation accuracy at iteration 1584  is               81.975%\n",
            "The validation accuracy at iteration 1600  is               81.825%\n",
            "The validation accuracy at iteration 1616  is               80.525%\n",
            "The validation accuracy at iteration 1632  is               80.175%\n",
            "The validation accuracy at iteration 1648  is               80.85%\n",
            "The validation accuracy at iteration 1664  is               81.875%\n",
            "The validation accuracy at iteration 1680  is               79.975%\n",
            "The validation accuracy at iteration 1696  is               82.25%\n",
            "The validation accuracy at iteration 1712  is               80.72500000000001%\n",
            "The validation accuracy at iteration 1728  is               81.6%\n",
            "The validation accuracy at iteration 1744  is               81.5%\n",
            "The validation accuracy at iteration 1760  is               81.05%\n",
            "The validation accuracy at iteration 1776  is               79.95%\n",
            "The validation accuracy at iteration 1792  is               81.325%\n",
            "The validation accuracy at iteration 1800  is               81.55%\n",
            "The validation accuracy at iteration 1800  is               81.55%\n",
            "The validation accuracy at iteration 16000  is               82.875%\n",
            "The validation accuracy at iteration 1800  is               81.55%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 1800  is               81.55%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "The validation accuracy at iteration 1800  is               81.55%\n",
            "The validation accuracy at iteration 2300  is               81.75%\n",
            "The validation accuracy at iteration 1800  is               81.55%\n",
            "The validation accuracy at iteration 2300  is               81.575%\n",
            "The validation accuracy at iteration 1800  is               81.55%\n",
            "[<__main__.Solver object at 0x7f6e25755490>, <__main__.Solver object at 0x7f6e457874d0>, <__main__.Solver object at 0x7f6e5b0b1490>, <__main__.Solver object at 0x7f6e4c6b5710>, <__main__.Solver object at 0x7f6e4c79e350>]\n",
            "The validation accuracy at iteration 16  is               10.825%\n",
            "The validation accuracy at iteration 32  is               10.825%\n",
            "The validation accuracy at iteration 48  is               10.825%\n",
            "The validation accuracy at iteration 64  is               11.899999999999999%\n",
            "The validation accuracy at iteration 80  is               18.825%\n",
            "The validation accuracy at iteration 96  is               17.849999999999998%\n",
            "The validation accuracy at iteration 112  is               22.5%\n",
            "The validation accuracy at iteration 128  is               9.575%\n",
            "The validation accuracy at iteration 144  is               17.875%\n",
            "The validation accuracy at iteration 160  is               9.85%\n",
            "The validation accuracy at iteration 176  is               14.774999999999999%\n",
            "The validation accuracy at iteration 192  is               17.2%\n",
            "The validation accuracy at iteration 208  is               10.274999999999999%\n",
            "The validation accuracy at iteration 224  is               9.175%\n",
            "The validation accuracy at iteration 240  is               15.475%\n",
            "The validation accuracy at iteration 256  is               9.625%\n",
            "The validation accuracy at iteration 272  is               17.05%\n",
            "The validation accuracy at iteration 288  is               17.95%\n",
            "The validation accuracy at iteration 304  is               19.675%\n",
            "The validation accuracy at iteration 320  is               17.25%\n",
            "The validation accuracy at iteration 336  is               10.2%\n",
            "The validation accuracy at iteration 352  is               9.425%\n",
            "The validation accuracy at iteration 368  is               9.0%\n",
            "The validation accuracy at iteration 384  is               9.725%\n",
            "The validation accuracy at iteration 400  is               9.4%\n",
            "The validation accuracy at iteration 416  is               10.6%\n",
            "The validation accuracy at iteration 432  is               12.3%\n",
            "The validation accuracy at iteration 448  is               12.575%\n",
            "The validation accuracy at iteration 464  is               12.5%\n",
            "The validation accuracy at iteration 480  is               12.35%\n",
            "The validation accuracy at iteration 496  is               16.0%\n",
            "The validation accuracy at iteration 512  is               14.499999999999998%\n",
            "The validation accuracy at iteration 528  is               14.524999999999999%\n",
            "The validation accuracy at iteration 544  is               14.475%\n",
            "The validation accuracy at iteration 560  is               16.375%\n",
            "The validation accuracy at iteration 576  is               14.75%\n",
            "The validation accuracy at iteration 592  is               17.925%\n",
            "The validation accuracy at iteration 608  is               19.45%\n",
            "The validation accuracy at iteration 624  is               23.275000000000002%\n",
            "The validation accuracy at iteration 640  is               20.775%\n",
            "The validation accuracy at iteration 656  is               18.3%\n",
            "The validation accuracy at iteration 672  is               16.425%\n",
            "The validation accuracy at iteration 688  is               15.85%\n",
            "The validation accuracy at iteration 704  is               19.15%\n",
            "The validation accuracy at iteration 720  is               23.05%\n",
            "The validation accuracy at iteration 736  is               23.925%\n",
            "The validation accuracy at iteration 752  is               24.825%\n",
            "The validation accuracy at iteration 768  is               27.1%\n",
            "The validation accuracy at iteration 784  is               31.924999999999997%\n",
            "The validation accuracy at iteration 800  is               29.9%\n",
            "The validation accuracy at iteration 816  is               35.35%\n",
            "The validation accuracy at iteration 832  is               30.7%\n",
            "The validation accuracy at iteration 848  is               32.074999999999996%\n",
            "The validation accuracy at iteration 864  is               30.025000000000002%\n",
            "The validation accuracy at iteration 880  is               35.025%\n",
            "The validation accuracy at iteration 896  is               31.1%\n",
            "The validation accuracy at iteration 912  is               39.65%\n",
            "The validation accuracy at iteration 928  is               38.475%\n",
            "The validation accuracy at iteration 944  is               42.35%\n",
            "The validation accuracy at iteration 960  is               37.125%\n",
            "The validation accuracy at iteration 976  is               32.550000000000004%\n",
            "The validation accuracy at iteration 992  is               35.875%\n",
            "The validation accuracy at iteration 1008  is               38.574999999999996%\n",
            "The validation accuracy at iteration 1024  is               40.2%\n",
            "The validation accuracy at iteration 1040  is               40.949999999999996%\n",
            "The validation accuracy at iteration 1056  is               43.325%\n",
            "The validation accuracy at iteration 1072  is               46.400000000000006%\n",
            "The validation accuracy at iteration 1088  is               46.775%\n",
            "The validation accuracy at iteration 1104  is               50.55%\n",
            "The validation accuracy at iteration 1120  is               48.3%\n",
            "The validation accuracy at iteration 1136  is               53.425%\n",
            "The validation accuracy at iteration 1152  is               52.55%\n",
            "The validation accuracy at iteration 1168  is               54.949999999999996%\n",
            "The validation accuracy at iteration 1184  is               51.275000000000006%\n",
            "The validation accuracy at iteration 1200  is               53.77499999999999%\n",
            "The validation accuracy at iteration 1216  is               54.50000000000001%\n",
            "The validation accuracy at iteration 1232  is               57.375%\n",
            "The validation accuracy at iteration 1248  is               55.825%\n",
            "The validation accuracy at iteration 1264  is               55.55%\n",
            "The validation accuracy at iteration 1280  is               53.87499999999999%\n",
            "The validation accuracy at iteration 1296  is               54.50000000000001%\n",
            "The validation accuracy at iteration 1312  is               58.45%\n",
            "The validation accuracy at iteration 1328  is               58.8%\n",
            "The validation accuracy at iteration 1344  is               57.375%\n",
            "The validation accuracy at iteration 1360  is               55.800000000000004%\n",
            "The validation accuracy at iteration 1376  is               56.95%\n",
            "The validation accuracy at iteration 1392  is               59.550000000000004%\n",
            "The validation accuracy at iteration 1408  is               56.85%\n",
            "The validation accuracy at iteration 1424  is               60.375%\n",
            "The validation accuracy at iteration 1440  is               59.550000000000004%\n",
            "The validation accuracy at iteration 1456  is               63.349999999999994%\n",
            "The validation accuracy at iteration 1472  is               62.0%\n",
            "The validation accuracy at iteration 1488  is               62.7%\n",
            "The validation accuracy at iteration 1504  is               60.550000000000004%\n",
            "The validation accuracy at iteration 1520  is               62.9%\n",
            "The validation accuracy at iteration 1536  is               61.95%\n",
            "The validation accuracy at iteration 1552  is               64.5%\n",
            "The validation accuracy at iteration 1568  is               62.9%\n",
            "The validation accuracy at iteration 1584  is               63.575%\n",
            "The validation accuracy at iteration 1600  is               61.375%\n",
            "The validation accuracy at iteration 1616  is               61.35%\n",
            "The validation accuracy at iteration 1632  is               63.6%\n",
            "The validation accuracy at iteration 1648  is               65.925%\n",
            "The validation accuracy at iteration 1664  is               64.875%\n",
            "The validation accuracy at iteration 1680  is               63.849999999999994%\n",
            "The validation accuracy at iteration 1696  is               63.075%\n",
            "The validation accuracy at iteration 1712  is               65.05%\n",
            "The validation accuracy at iteration 1728  is               63.224999999999994%\n",
            "The validation accuracy at iteration 1744  is               65.05%\n",
            "The validation accuracy at iteration 1760  is               64.875%\n",
            "The validation accuracy at iteration 1776  is               68.125%\n",
            "The validation accuracy at iteration 1792  is               66.425%\n",
            "The validation accuracy at iteration 1808  is               67.07499999999999%\n",
            "The validation accuracy at iteration 1824  is               65.75%\n",
            "The validation accuracy at iteration 1840  is               66.25%\n",
            "The validation accuracy at iteration 1856  is               65.725%\n",
            "The validation accuracy at iteration 1872  is               66.725%\n",
            "The validation accuracy at iteration 1888  is               66.45%\n",
            "The validation accuracy at iteration 1904  is               66.125%\n",
            "The validation accuracy at iteration 1920  is               64.725%\n",
            "The validation accuracy at iteration 1936  is               65.275%\n",
            "The validation accuracy at iteration 1952  is               67.025%\n",
            "The validation accuracy at iteration 1968  is               68.55%\n",
            "The validation accuracy at iteration 1984  is               67.2%\n",
            "The validation accuracy at iteration 2000  is               66.925%\n",
            "The validation accuracy at iteration 2016  is               66.57499999999999%\n",
            "The validation accuracy at iteration 2032  is               67.80000000000001%\n",
            "The validation accuracy at iteration 2048  is               66.625%\n",
            "The validation accuracy at iteration 2064  is               67.875%\n",
            "The validation accuracy at iteration 2080  is               67.95%\n",
            "The validation accuracy at iteration 2096  is               70.55%\n",
            "The validation accuracy at iteration 2112  is               68.60000000000001%\n",
            "The validation accuracy at iteration 2128  is               69.175%\n",
            "The validation accuracy at iteration 2144  is               68.0%\n",
            "The validation accuracy at iteration 2160  is               68.35%\n",
            "The validation accuracy at iteration 2176  is               67.95%\n",
            "The validation accuracy at iteration 2192  is               68.77499999999999%\n",
            "The validation accuracy at iteration 2208  is               67.975%\n",
            "The validation accuracy at iteration 2224  is               68.475%\n",
            "The validation accuracy at iteration 2240  is               67.225%\n",
            "The validation accuracy at iteration 2256  is               67.65%\n",
            "The validation accuracy at iteration 2272  is               68.875%\n",
            "The validation accuracy at iteration 2288  is               70.22500000000001%\n",
            "The validation accuracy at iteration 2304  is               68.925%\n",
            "The validation accuracy at iteration 2320  is               68.825%\n",
            "The validation accuracy at iteration 2336  is               68.0%\n",
            "The validation accuracy at iteration 2352  is               69.19999999999999%\n",
            "The validation accuracy at iteration 2368  is               68.575%\n",
            "The validation accuracy at iteration 2384  is               69.72500000000001%\n",
            "The validation accuracy at iteration 2400  is               69.425%\n",
            "The validation accuracy at iteration 2416  is               71.775%\n",
            "The validation accuracy at iteration 2432  is               70.325%\n",
            "The validation accuracy at iteration 2448  is               70.5%\n",
            "The validation accuracy at iteration 2464  is               69.65%\n",
            "The validation accuracy at iteration 2480  is               69.475%\n",
            "The validation accuracy at iteration 2496  is               68.925%\n",
            "The validation accuracy at iteration 2512  is               70.125%\n",
            "The validation accuracy at iteration 2528  is               69.3%\n",
            "The validation accuracy at iteration 2544  is               69.825%\n",
            "The validation accuracy at iteration 2560  is               68.89999999999999%\n",
            "The validation accuracy at iteration 2576  is               69.55%\n",
            "The validation accuracy at iteration 2592  is               70.05%\n",
            "The validation accuracy at iteration 2608  is               71.39999999999999%\n",
            "The validation accuracy at iteration 2624  is               70.55%\n",
            "The validation accuracy at iteration 2640  is               70.325%\n",
            "The validation accuracy at iteration 2656  is               69.625%\n",
            "The validation accuracy at iteration 2672  is               70.5%\n",
            "The validation accuracy at iteration 2688  is               69.95%\n",
            "The validation accuracy at iteration 2704  is               70.875%\n",
            "The validation accuracy at iteration 2720  is               71.0%\n",
            "The validation accuracy at iteration 2736  is               72.6%\n",
            "The validation accuracy at iteration 2752  is               71.375%\n",
            "The validation accuracy at iteration 2768  is               71.85000000000001%\n",
            "The validation accuracy at iteration 2784  is               71.3%\n",
            "The validation accuracy at iteration 2800  is               70.775%\n",
            "The validation accuracy at iteration 2816  is               70.15%\n",
            "The validation accuracy at iteration 2832  is               71.25%\n",
            "The validation accuracy at iteration 2848  is               70.72500000000001%\n",
            "The validation accuracy at iteration 2864  is               70.825%\n",
            "The validation accuracy at iteration 2880  is               70.1%\n",
            "The validation accuracy at iteration 2896  is               70.7%\n",
            "The validation accuracy at iteration 2912  is               71.45%\n",
            "The validation accuracy at iteration 2928  is               72.6%\n",
            "The validation accuracy at iteration 2944  is               71.575%\n",
            "The validation accuracy at iteration 2960  is               71.525%\n",
            "The validation accuracy at iteration 2976  is               71.05%\n",
            "The validation accuracy at iteration 2992  is               71.89999999999999%\n",
            "The validation accuracy at iteration 3008  is               71.22500000000001%\n",
            "The validation accuracy at iteration 3024  is               71.775%\n",
            "The validation accuracy at iteration 3040  is               72.425%\n",
            "The validation accuracy at iteration 3056  is               73.375%\n",
            "The validation accuracy at iteration 3072  is               72.375%\n",
            "The validation accuracy at iteration 3088  is               72.35000000000001%\n",
            "The validation accuracy at iteration 3104  is               72.625%\n",
            "The validation accuracy at iteration 3120  is               71.775%\n",
            "The validation accuracy at iteration 3136  is               71.5%\n",
            "The validation accuracy at iteration 3152  is               72.2%\n",
            "The validation accuracy at iteration 3168  is               71.575%\n",
            "The validation accuracy at iteration 3184  is               71.89999999999999%\n",
            "The validation accuracy at iteration 3200  is               71.1%\n",
            "The validation accuracy at iteration 3216  is               72.075%\n",
            "The validation accuracy at iteration 3232  is               72.55%\n",
            "The validation accuracy at iteration 3248  is               73.32499999999999%\n",
            "The validation accuracy at iteration 3264  is               72.575%\n",
            "The validation accuracy at iteration 3280  is               72.575%\n",
            "The validation accuracy at iteration 3296  is               72.39999999999999%\n",
            "The validation accuracy at iteration 3312  is               73.02499999999999%\n",
            "The validation accuracy at iteration 3328  is               72.475%\n",
            "The validation accuracy at iteration 3344  is               72.975%\n",
            "The validation accuracy at iteration 3360  is               73.425%\n",
            "The validation accuracy at iteration 3376  is               74.3%\n",
            "The validation accuracy at iteration 3392  is               73.52499999999999%\n",
            "The validation accuracy at iteration 3408  is               73.6%\n",
            "The validation accuracy at iteration 3424  is               74.0%\n",
            "The validation accuracy at iteration 3440  is               72.725%\n",
            "The validation accuracy at iteration 3456  is               72.425%\n",
            "The validation accuracy at iteration 3472  is               72.95%\n",
            "The validation accuracy at iteration 3488  is               72.5%\n",
            "The validation accuracy at iteration 3504  is               72.875%\n",
            "The validation accuracy at iteration 3520  is               72.125%\n",
            "The validation accuracy at iteration 3536  is               73.05%\n",
            "The validation accuracy at iteration 3552  is               73.32499999999999%\n",
            "The validation accuracy at iteration 3568  is               74.325%\n",
            "The validation accuracy at iteration 3584  is               73.575%\n",
            "The validation accuracy at iteration 3600  is               73.425%\n",
            "The validation accuracy at iteration 3616  is               73.575%\n",
            "The validation accuracy at iteration 3632  is               74.075%\n",
            "The validation accuracy at iteration 3648  is               73.425%\n",
            "The validation accuracy at iteration 3664  is               73.95%\n",
            "The validation accuracy at iteration 3680  is               74.3%\n",
            "The validation accuracy at iteration 3696  is               75.275%\n",
            "The validation accuracy at iteration 3712  is               74.575%\n",
            "The validation accuracy at iteration 3728  is               74.35000000000001%\n",
            "The validation accuracy at iteration 3744  is               74.775%\n",
            "The validation accuracy at iteration 3760  is               73.675%\n",
            "The validation accuracy at iteration 3776  is               73.6%\n",
            "The validation accuracy at iteration 3792  is               73.825%\n",
            "The validation accuracy at iteration 3808  is               73.45%\n",
            "The validation accuracy at iteration 3824  is               73.675%\n",
            "The validation accuracy at iteration 3840  is               73.3%\n",
            "The validation accuracy at iteration 3856  is               73.75%\n",
            "The validation accuracy at iteration 3872  is               74.4%\n",
            "The validation accuracy at iteration 3888  is               75.125%\n",
            "The validation accuracy at iteration 3904  is               74.275%\n",
            "The validation accuracy at iteration 3920  is               74.2%\n",
            "The validation accuracy at iteration 3936  is               74.275%\n",
            "The validation accuracy at iteration 3952  is               74.875%\n",
            "The validation accuracy at iteration 3968  is               74.4%\n",
            "The validation accuracy at iteration 3984  is               74.625%\n",
            "The validation accuracy at iteration 4000  is               75.125%\n",
            "The validation accuracy at iteration 4016  is               75.8%\n",
            "The validation accuracy at iteration 4032  is               75.35%\n",
            "The validation accuracy at iteration 4048  is               75.05%\n",
            "The validation accuracy at iteration 4064  is               75.325%\n",
            "The validation accuracy at iteration 4080  is               74.625%\n",
            "The validation accuracy at iteration 4096  is               74.375%\n",
            "The validation accuracy at iteration 4112  is               74.47500000000001%\n",
            "The validation accuracy at iteration 4128  is               74.125%\n",
            "The validation accuracy at iteration 4144  is               74.4%\n",
            "The validation accuracy at iteration 4160  is               74.1%\n",
            "The validation accuracy at iteration 4176  is               74.925%\n",
            "The validation accuracy at iteration 4192  is               74.9%\n",
            "The validation accuracy at iteration 4208  is               75.725%\n",
            "The validation accuracy at iteration 4224  is               75.125%\n",
            "The validation accuracy at iteration 4240  is               74.95%\n",
            "The validation accuracy at iteration 4256  is               75.05%\n",
            "The validation accuracy at iteration 4272  is               75.675%\n",
            "The validation accuracy at iteration 4288  is               75.02499999999999%\n",
            "The validation accuracy at iteration 4304  is               75.3%\n",
            "The validation accuracy at iteration 4320  is               75.775%\n",
            "The validation accuracy at iteration 4336  is               76.525%\n",
            "The validation accuracy at iteration 4352  is               76.2%\n",
            "The validation accuracy at iteration 4368  is               75.625%\n",
            "The validation accuracy at iteration 4384  is               76.0%\n",
            "The validation accuracy at iteration 4400  is               75.14999999999999%\n",
            "The validation accuracy at iteration 4416  is               74.95%\n",
            "The validation accuracy at iteration 4432  is               75.02499999999999%\n",
            "The validation accuracy at iteration 4448  is               74.6%\n",
            "The validation accuracy at iteration 4464  is               75.0%\n",
            "The validation accuracy at iteration 4480  is               74.775%\n",
            "The validation accuracy at iteration 4496  is               75.64999999999999%\n",
            "The validation accuracy at iteration 4512  is               75.775%\n",
            "The validation accuracy at iteration 4528  is               76.325%\n",
            "The validation accuracy at iteration 4544  is               75.44999999999999%\n",
            "The validation accuracy at iteration 4560  is               75.6%\n",
            "The validation accuracy at iteration 4576  is               75.64999999999999%\n",
            "The validation accuracy at iteration 4592  is               76.3%\n",
            "The validation accuracy at iteration 4608  is               75.7%\n",
            "The validation accuracy at iteration 4624  is               75.925%\n",
            "The validation accuracy at iteration 4640  is               76.02499999999999%\n",
            "The validation accuracy at iteration 4656  is               77.3%\n",
            "The validation accuracy at iteration 4672  is               76.775%\n",
            "The validation accuracy at iteration 4688  is               76.225%\n",
            "The validation accuracy at iteration 4704  is               76.6%\n",
            "The validation accuracy at iteration 4720  is               75.775%\n",
            "The validation accuracy at iteration 4736  is               75.6%\n",
            "The validation accuracy at iteration 4752  is               75.775%\n",
            "The validation accuracy at iteration 4768  is               75.225%\n",
            "The validation accuracy at iteration 4784  is               75.325%\n",
            "The validation accuracy at iteration 4800  is               75.225%\n",
            "The validation accuracy at iteration 4816  is               76.1%\n",
            "The validation accuracy at iteration 4832  is               76.25%\n",
            "The validation accuracy at iteration 4848  is               76.6%\n",
            "The validation accuracy at iteration 4864  is               75.875%\n",
            "The validation accuracy at iteration 4880  is               76.1%\n",
            "The validation accuracy at iteration 4896  is               76.125%\n",
            "The validation accuracy at iteration 4912  is               76.8%\n",
            "The validation accuracy at iteration 4928  is               76.1%\n",
            "The validation accuracy at iteration 4944  is               76.5%\n",
            "The validation accuracy at iteration 4960  is               76.47500000000001%\n",
            "The validation accuracy at iteration 4976  is               77.625%\n",
            "The validation accuracy at iteration 4992  is               77.0%\n",
            "The validation accuracy at iteration 5008  is               76.725%\n",
            "The validation accuracy at iteration 5024  is               77.0%\n",
            "The validation accuracy at iteration 5040  is               76.075%\n",
            "The validation accuracy at iteration 5056  is               76.0%\n",
            "The validation accuracy at iteration 5072  is               76.2%\n",
            "The validation accuracy at iteration 5088  is               75.675%\n",
            "The validation accuracy at iteration 5104  is               75.85%\n",
            "The validation accuracy at iteration 5120  is               75.625%\n",
            "The validation accuracy at iteration 5136  is               76.725%\n",
            "The validation accuracy at iteration 5152  is               76.8%\n",
            "The validation accuracy at iteration 5168  is               77.2%\n",
            "The validation accuracy at iteration 5184  is               76.6%\n",
            "The validation accuracy at iteration 5200  is               76.575%\n",
            "The validation accuracy at iteration 5216  is               76.575%\n",
            "The validation accuracy at iteration 5232  is               77.10000000000001%\n",
            "The validation accuracy at iteration 5248  is               76.525%\n",
            "The validation accuracy at iteration 5264  is               76.825%\n",
            "The validation accuracy at iteration 5280  is               77.35%\n",
            "The validation accuracy at iteration 5296  is               77.825%\n",
            "The validation accuracy at iteration 5312  is               77.64999999999999%\n",
            "The validation accuracy at iteration 5328  is               77.225%\n",
            "The validation accuracy at iteration 5344  is               77.325%\n",
            "The validation accuracy at iteration 5360  is               76.64999999999999%\n",
            "The validation accuracy at iteration 5376  is               76.7%\n",
            "The validation accuracy at iteration 5392  is               76.85%\n",
            "The validation accuracy at iteration 5408  is               76.3%\n",
            "The validation accuracy at iteration 5424  is               76.425%\n",
            "The validation accuracy at iteration 5440  is               76.1%\n",
            "The validation accuracy at iteration 5456  is               77.025%\n",
            "The validation accuracy at iteration 5472  is               77.35%\n",
            "The validation accuracy at iteration 5488  is               77.85%\n",
            "The validation accuracy at iteration 5504  is               76.97500000000001%\n",
            "The validation accuracy at iteration 5520  is               76.97500000000001%\n",
            "The validation accuracy at iteration 5536  is               76.925%\n",
            "The validation accuracy at iteration 5552  is               77.60000000000001%\n",
            "The validation accuracy at iteration 5568  is               77.075%\n",
            "The validation accuracy at iteration 5584  is               77.375%\n",
            "The validation accuracy at iteration 5600  is               77.625%\n",
            "The validation accuracy at iteration 5616  is               78.14999999999999%\n",
            "The validation accuracy at iteration 5632  is               77.97500000000001%\n",
            "The validation accuracy at iteration 5648  is               77.625%\n",
            "The validation accuracy at iteration 5664  is               77.625%\n",
            "The validation accuracy at iteration 5680  is               76.875%\n",
            "The validation accuracy at iteration 5696  is               77.025%\n",
            "The validation accuracy at iteration 5712  is               77.35%\n",
            "The validation accuracy at iteration 5728  is               76.75%\n",
            "The validation accuracy at iteration 5744  is               76.925%\n",
            "The validation accuracy at iteration 5760  is               76.325%\n",
            "The validation accuracy at iteration 5776  is               77.325%\n",
            "The validation accuracy at iteration 5792  is               77.67500000000001%\n",
            "The validation accuracy at iteration 5808  is               78.375%\n",
            "The validation accuracy at iteration 5824  is               77.525%\n",
            "The validation accuracy at iteration 5840  is               77.3%\n",
            "The validation accuracy at iteration 5856  is               77.225%\n",
            "The validation accuracy at iteration 5872  is               77.97500000000001%\n",
            "The validation accuracy at iteration 5888  is               77.55%\n",
            "The validation accuracy at iteration 5904  is               77.825%\n",
            "The validation accuracy at iteration 5920  is               78.10000000000001%\n",
            "The validation accuracy at iteration 5936  is               78.375%\n",
            "The validation accuracy at iteration 5952  is               78.3%\n",
            "The validation accuracy at iteration 5968  is               77.9%\n",
            "The validation accuracy at iteration 5984  is               77.825%\n",
            "The validation accuracy at iteration 6000  is               77.17500000000001%\n",
            "The validation accuracy at iteration 6016  is               77.3%\n",
            "The validation accuracy at iteration 6032  is               77.64999999999999%\n",
            "The validation accuracy at iteration 6048  is               76.97500000000001%\n",
            "The validation accuracy at iteration 6064  is               77.325%\n",
            "The validation accuracy at iteration 6080  is               76.85%\n",
            "The validation accuracy at iteration 6096  is               77.85%\n",
            "The validation accuracy at iteration 6112  is               78.175%\n",
            "The validation accuracy at iteration 6128  is               78.64999999999999%\n",
            "The validation accuracy at iteration 6144  is               77.825%\n",
            "The validation accuracy at iteration 6160  is               77.5%\n",
            "The validation accuracy at iteration 6176  is               77.525%\n",
            "The validation accuracy at iteration 6192  is               78.27499999999999%\n",
            "The validation accuracy at iteration 6208  is               77.8%\n",
            "The validation accuracy at iteration 6224  is               78.10000000000001%\n",
            "The validation accuracy at iteration 6240  is               78.35%\n",
            "The validation accuracy at iteration 6256  is               78.55%\n",
            "The validation accuracy at iteration 6272  is               78.525%\n",
            "The validation accuracy at iteration 6288  is               78.25%\n",
            "The validation accuracy at iteration 6304  is               78.25%\n",
            "The validation accuracy at iteration 6320  is               77.5%\n",
            "The validation accuracy at iteration 6336  is               77.55%\n",
            "The validation accuracy at iteration 6352  is               78.075%\n",
            "The validation accuracy at iteration 6368  is               77.125%\n",
            "The validation accuracy at iteration 6384  is               77.575%\n",
            "The validation accuracy at iteration 6400  is               77.25%\n",
            "The validation accuracy at iteration 6416  is               78.3%\n",
            "The validation accuracy at iteration 6432  is               78.55%\n",
            "The validation accuracy at iteration 6448  is               78.77499999999999%\n",
            "The validation accuracy at iteration 6464  is               78.175%\n",
            "The validation accuracy at iteration 6480  is               77.9%\n",
            "The validation accuracy at iteration 6496  is               77.8%\n",
            "The validation accuracy at iteration 6512  is               78.5%\n",
            "The validation accuracy at iteration 6528  is               78.225%\n",
            "The validation accuracy at iteration 6544  is               78.425%\n",
            "The validation accuracy at iteration 6560  is               78.625%\n",
            "The validation accuracy at iteration 6576  is               78.8%\n",
            "The validation accuracy at iteration 6592  is               78.85%\n",
            "The validation accuracy at iteration 6608  is               78.475%\n",
            "The validation accuracy at iteration 6624  is               78.60000000000001%\n",
            "The validation accuracy at iteration 6640  is               77.875%\n",
            "The validation accuracy at iteration 6656  is               77.75%\n",
            "The validation accuracy at iteration 6672  is               78.27499999999999%\n",
            "The validation accuracy at iteration 6688  is               77.4%\n",
            "The validation accuracy at iteration 6704  is               77.725%\n",
            "The validation accuracy at iteration 6720  is               77.55%\n",
            "The validation accuracy at iteration 6736  is               78.7%\n",
            "The validation accuracy at iteration 6752  is               78.825%\n",
            "The validation accuracy at iteration 6768  is               78.9%\n",
            "The validation accuracy at iteration 6784  is               78.325%\n",
            "The validation accuracy at iteration 6800  is               78.025%\n",
            "The validation accuracy at iteration 6816  is               78.125%\n",
            "The validation accuracy at iteration 6832  is               78.85%\n",
            "The validation accuracy at iteration 6848  is               78.5%\n",
            "The validation accuracy at iteration 6864  is               78.825%\n",
            "The validation accuracy at iteration 6880  is               78.8%\n",
            "The validation accuracy at iteration 6896  is               78.925%\n",
            "The validation accuracy at iteration 6912  is               79.325%\n",
            "The validation accuracy at iteration 6928  is               78.625%\n",
            "The validation accuracy at iteration 6944  is               78.75%\n",
            "The validation accuracy at iteration 6960  is               78.2%\n",
            "The validation accuracy at iteration 6976  is               77.875%\n",
            "The validation accuracy at iteration 6992  is               78.60000000000001%\n",
            "The validation accuracy at iteration 7008  is               77.7%\n",
            "The validation accuracy at iteration 7024  is               78.075%\n",
            "The validation accuracy at iteration 7040  is               77.8%\n",
            "The validation accuracy at iteration 7056  is               79.025%\n",
            "The validation accuracy at iteration 7072  is               79.025%\n",
            "The validation accuracy at iteration 7088  is               79.025%\n",
            "The validation accuracy at iteration 7104  is               78.4%\n",
            "The validation accuracy at iteration 7120  is               78.325%\n",
            "The validation accuracy at iteration 7136  is               78.35%\n",
            "The validation accuracy at iteration 7152  is               79.0%\n",
            "The validation accuracy at iteration 7168  is               78.625%\n",
            "The validation accuracy at iteration 7184  is               79.05%\n",
            "The validation accuracy at iteration 7200  is               78.975%\n",
            "The validation accuracy at iteration 7216  is               79.07499999999999%\n",
            "The validation accuracy at iteration 7232  is               79.60000000000001%\n",
            "The validation accuracy at iteration 7248  is               78.7%\n",
            "The validation accuracy at iteration 7264  is               78.975%\n",
            "The validation accuracy at iteration 7280  is               78.45%\n",
            "The validation accuracy at iteration 7296  is               78.25%\n",
            "The validation accuracy at iteration 7312  is               78.77499999999999%\n",
            "The validation accuracy at iteration 7328  is               77.825%\n",
            "The validation accuracy at iteration 7344  is               78.3%\n",
            "The validation accuracy at iteration 7360  is               78.075%\n",
            "The validation accuracy at iteration 7376  is               79.25%\n",
            "The validation accuracy at iteration 7392  is               79.225%\n",
            "The validation accuracy at iteration 7408  is               79.10000000000001%\n",
            "The validation accuracy at iteration 7424  is               78.60000000000001%\n",
            "The validation accuracy at iteration 7440  is               78.5%\n",
            "The validation accuracy at iteration 7456  is               78.725%\n",
            "The validation accuracy at iteration 7472  is               79.14999999999999%\n",
            "The validation accuracy at iteration 7488  is               78.825%\n",
            "The validation accuracy at iteration 7504  is               79.27499999999999%\n",
            "The validation accuracy at iteration 7520  is               79.25%\n",
            "The validation accuracy at iteration 7536  is               79.2%\n",
            "The validation accuracy at iteration 7552  is               79.75%\n",
            "The validation accuracy at iteration 7568  is               78.825%\n",
            "The validation accuracy at iteration 7584  is               79.0%\n",
            "The validation accuracy at iteration 7600  is               78.64999999999999%\n",
            "The validation accuracy at iteration 7616  is               78.5%\n",
            "The validation accuracy at iteration 7632  is               78.85%\n",
            "The validation accuracy at iteration 7648  is               77.97500000000001%\n",
            "The validation accuracy at iteration 7664  is               78.64999999999999%\n",
            "The validation accuracy at iteration 7680  is               78.27499999999999%\n",
            "The validation accuracy at iteration 7696  is               79.4%\n",
            "The validation accuracy at iteration 7712  is               79.475%\n",
            "The validation accuracy at iteration 7728  is               79.225%\n",
            "The validation accuracy at iteration 7744  is               78.825%\n",
            "The validation accuracy at iteration 7760  is               78.77499999999999%\n",
            "The validation accuracy at iteration 7776  is               78.975%\n",
            "The validation accuracy at iteration 7792  is               79.325%\n",
            "The validation accuracy at iteration 7808  is               78.975%\n",
            "The validation accuracy at iteration 7824  is               79.3%\n",
            "The validation accuracy at iteration 7840  is               79.475%\n",
            "The validation accuracy at iteration 7856  is               79.35%\n",
            "The validation accuracy at iteration 7872  is               80.05%\n",
            "The validation accuracy at iteration 7888  is               79.07499999999999%\n",
            "The validation accuracy at iteration 7904  is               79.10000000000001%\n",
            "The validation accuracy at iteration 7920  is               79.025%\n",
            "The validation accuracy at iteration 7936  is               78.725%\n",
            "The validation accuracy at iteration 7952  is               78.95%\n",
            "The validation accuracy at iteration 7968  is               78.125%\n",
            "The validation accuracy at iteration 7984  is               78.825%\n",
            "The validation accuracy at iteration 8000  is               78.525%\n",
            "The validation accuracy at iteration 8016  is               79.65%\n",
            "The validation accuracy at iteration 8032  is               79.675%\n",
            "The validation accuracy at iteration 8048  is               79.60000000000001%\n",
            "The validation accuracy at iteration 8064  is               78.975%\n",
            "The validation accuracy at iteration 8080  is               79.05%\n",
            "The validation accuracy at iteration 8096  is               79.225%\n",
            "The validation accuracy at iteration 8112  is               79.5%\n",
            "The validation accuracy at iteration 8128  is               79.175%\n",
            "The validation accuracy at iteration 8144  is               79.57499999999999%\n",
            "The validation accuracy at iteration 8160  is               79.65%\n",
            "The validation accuracy at iteration 8176  is               79.45%\n",
            "The validation accuracy at iteration 8192  is               80.15%\n",
            "The validation accuracy at iteration 8208  is               79.325%\n",
            "The validation accuracy at iteration 8224  is               79.425%\n",
            "The validation accuracy at iteration 8240  is               79.225%\n",
            "The validation accuracy at iteration 8256  is               78.85%\n",
            "The validation accuracy at iteration 8272  is               79.10000000000001%\n",
            "The validation accuracy at iteration 8288  is               78.35%\n",
            "The validation accuracy at iteration 8304  is               79.025%\n",
            "The validation accuracy at iteration 8320  is               78.60000000000001%\n",
            "The validation accuracy at iteration 8336  is               79.825%\n",
            "The validation accuracy at iteration 8352  is               79.7%\n",
            "The validation accuracy at iteration 8368  is               79.825%\n",
            "The validation accuracy at iteration 8384  is               79.325%\n",
            "The validation accuracy at iteration 8400  is               79.125%\n",
            "The validation accuracy at iteration 8416  is               79.45%\n",
            "The validation accuracy at iteration 8432  is               79.60000000000001%\n",
            "The validation accuracy at iteration 8448  is               79.625%\n",
            "The validation accuracy at iteration 8464  is               79.825%\n",
            "The validation accuracy at iteration 8480  is               79.925%\n",
            "The validation accuracy at iteration 8496  is               79.5%\n",
            "The validation accuracy at iteration 8512  is               80.375%\n",
            "The validation accuracy at iteration 8528  is               79.475%\n",
            "The validation accuracy at iteration 8544  is               79.625%\n",
            "The validation accuracy at iteration 8560  is               79.35%\n",
            "The validation accuracy at iteration 8576  is               79.2%\n",
            "The validation accuracy at iteration 8592  is               79.4%\n",
            "The validation accuracy at iteration 8608  is               78.425%\n",
            "The validation accuracy at iteration 8624  is               79.175%\n",
            "The validation accuracy at iteration 8640  is               78.77499999999999%\n",
            "The validation accuracy at iteration 8656  is               79.95%\n",
            "The validation accuracy at iteration 8672  is               79.975%\n",
            "The validation accuracy at iteration 8688  is               80.175%\n",
            "The validation accuracy at iteration 8704  is               79.57499999999999%\n",
            "The validation accuracy at iteration 8720  is               79.3%\n",
            "The validation accuracy at iteration 8736  is               79.625%\n",
            "The validation accuracy at iteration 8752  is               79.75%\n",
            "The validation accuracy at iteration 8768  is               79.77499999999999%\n",
            "The validation accuracy at iteration 8784  is               79.975%\n",
            "The validation accuracy at iteration 8800  is               80.025%\n",
            "The validation accuracy at iteration 8816  is               79.7%\n",
            "The validation accuracy at iteration 8832  is               80.5%\n",
            "The validation accuracy at iteration 8848  is               79.625%\n",
            "The validation accuracy at iteration 8864  is               79.65%\n",
            "The validation accuracy at iteration 8880  is               79.475%\n",
            "The validation accuracy at iteration 8896  is               79.475%\n",
            "The validation accuracy at iteration 8912  is               79.57499999999999%\n",
            "The validation accuracy at iteration 8928  is               78.7%\n",
            "The validation accuracy at iteration 8944  is               79.425%\n",
            "The validation accuracy at iteration 8960  is               79.0%\n",
            "The validation accuracy at iteration 8976  is               80.15%\n",
            "The validation accuracy at iteration 8992  is               79.975%\n",
            "The validation accuracy at iteration 9008  is               80.325%\n",
            "The validation accuracy at iteration 9024  is               79.75%\n",
            "The validation accuracy at iteration 9040  is               79.5%\n",
            "The validation accuracy at iteration 9056  is               79.7%\n",
            "The validation accuracy at iteration 9072  is               79.875%\n",
            "The validation accuracy at iteration 9088  is               79.95%\n",
            "The validation accuracy at iteration 9104  is               80.05%\n",
            "The validation accuracy at iteration 9120  is               80.125%\n",
            "The validation accuracy at iteration 9136  is               79.875%\n",
            "The validation accuracy at iteration 9152  is               80.7%\n",
            "The validation accuracy at iteration 9168  is               79.77499999999999%\n",
            "The validation accuracy at iteration 9184  is               79.975%\n",
            "The validation accuracy at iteration 9200  is               79.625%\n",
            "The validation accuracy at iteration 9216  is               79.60000000000001%\n",
            "The validation accuracy at iteration 9232  is               79.675%\n",
            "The validation accuracy at iteration 9248  is               78.85%\n",
            "The validation accuracy at iteration 9264  is               79.60000000000001%\n",
            "The validation accuracy at iteration 9280  is               79.175%\n",
            "The validation accuracy at iteration 9296  is               80.27499999999999%\n",
            "The validation accuracy at iteration 9312  is               80.125%\n",
            "The validation accuracy at iteration 9328  is               80.525%\n",
            "The validation accuracy at iteration 9344  is               79.975%\n",
            "The validation accuracy at iteration 9360  is               79.525%\n",
            "The validation accuracy at iteration 9376  is               79.9%\n",
            "The validation accuracy at iteration 9392  is               79.925%\n",
            "The validation accuracy at iteration 9408  is               80.15%\n",
            "The validation accuracy at iteration 9424  is               80.175%\n",
            "The validation accuracy at iteration 9440  is               80.35%\n",
            "The validation accuracy at iteration 9456  is               80.075%\n",
            "The validation accuracy at iteration 9472  is               80.80000000000001%\n",
            "The validation accuracy at iteration 9488  is               79.95%\n",
            "The validation accuracy at iteration 9504  is               80.05%\n",
            "The validation accuracy at iteration 9520  is               79.75%\n",
            "The validation accuracy at iteration 9536  is               79.80000000000001%\n",
            "The validation accuracy at iteration 9552  is               79.825%\n",
            "The validation accuracy at iteration 9568  is               79.10000000000001%\n",
            "The validation accuracy at iteration 9584  is               79.75%\n",
            "The validation accuracy at iteration 9600  is               79.375%\n",
            "The validation accuracy at iteration 9616  is               80.45%\n",
            "The validation accuracy at iteration 9632  is               80.4%\n",
            "The validation accuracy at iteration 9648  is               80.7%\n",
            "The validation accuracy at iteration 9664  is               80.25%\n",
            "The validation accuracy at iteration 9680  is               79.7%\n",
            "The validation accuracy at iteration 9696  is               80.025%\n",
            "The validation accuracy at iteration 9712  is               80.125%\n",
            "The validation accuracy at iteration 9728  is               80.25%\n",
            "The validation accuracy at iteration 9744  is               80.4%\n",
            "The validation accuracy at iteration 9760  is               80.475%\n",
            "The validation accuracy at iteration 9776  is               80.22500000000001%\n",
            "The validation accuracy at iteration 9792  is               81.025%\n",
            "The validation accuracy at iteration 9808  is               80.025%\n",
            "The validation accuracy at iteration 9824  is               80.27499999999999%\n",
            "The validation accuracy at iteration 9840  is               79.975%\n",
            "The validation accuracy at iteration 9856  is               79.9%\n",
            "The validation accuracy at iteration 9872  is               80.025%\n",
            "The validation accuracy at iteration 9888  is               79.35%\n",
            "The validation accuracy at iteration 9904  is               79.875%\n",
            "The validation accuracy at iteration 9920  is               79.45%\n",
            "The validation accuracy at iteration 9936  is               80.5%\n",
            "The validation accuracy at iteration 9952  is               80.525%\n",
            "The validation accuracy at iteration 9968  is               80.875%\n",
            "The validation accuracy at iteration 9984  is               80.35%\n",
            "The validation accuracy at iteration 10000  is               79.825%\n",
            "The validation accuracy at iteration 10016  is               80.10000000000001%\n",
            "The validation accuracy at iteration 10032  is               80.25%\n",
            "The validation accuracy at iteration 10048  is               80.35%\n",
            "The validation accuracy at iteration 10064  is               80.475%\n",
            "The validation accuracy at iteration 10080  is               80.675%\n",
            "The validation accuracy at iteration 10096  is               80.375%\n",
            "The validation accuracy at iteration 10112  is               81.15%\n",
            "The validation accuracy at iteration 10128  is               80.2%\n",
            "The validation accuracy at iteration 10144  is               80.4%\n",
            "The validation accuracy at iteration 10160  is               80.15%\n",
            "The validation accuracy at iteration 10176  is               79.95%\n",
            "The validation accuracy at iteration 10192  is               80.175%\n",
            "The validation accuracy at iteration 10208  is               79.5%\n",
            "The validation accuracy at iteration 10224  is               80.0%\n",
            "The validation accuracy at iteration 10240  is               79.65%\n",
            "The validation accuracy at iteration 10256  is               80.65%\n",
            "The validation accuracy at iteration 10272  is               80.65%\n",
            "The validation accuracy at iteration 10288  is               81.025%\n",
            "The validation accuracy at iteration 10304  is               80.525%\n",
            "The validation accuracy at iteration 10320  is               79.925%\n",
            "The validation accuracy at iteration 10336  is               80.2%\n",
            "The validation accuracy at iteration 10352  is               80.45%\n",
            "The validation accuracy at iteration 10368  is               80.425%\n",
            "The validation accuracy at iteration 10384  is               80.575%\n",
            "The validation accuracy at iteration 10400  is               80.72500000000001%\n",
            "The validation accuracy at iteration 10416  is               80.475%\n",
            "The validation accuracy at iteration 10432  is               81.25%\n",
            "The validation accuracy at iteration 10448  is               80.27499999999999%\n",
            "The validation accuracy at iteration 10464  is               80.45%\n",
            "The validation accuracy at iteration 10480  is               80.27499999999999%\n",
            "The validation accuracy at iteration 10496  is               80.175%\n",
            "The validation accuracy at iteration 10512  is               80.175%\n",
            "The validation accuracy at iteration 10528  is               79.57499999999999%\n",
            "The validation accuracy at iteration 10544  is               80.27499999999999%\n",
            "The validation accuracy at iteration 10560  is               79.725%\n",
            "The validation accuracy at iteration 10576  is               80.825%\n",
            "The validation accuracy at iteration 10592  is               80.85%\n",
            "The validation accuracy at iteration 10608  is               81.10000000000001%\n",
            "The validation accuracy at iteration 10624  is               80.65%\n",
            "The validation accuracy at iteration 10640  is               79.975%\n",
            "The validation accuracy at iteration 10656  is               80.35%\n",
            "The validation accuracy at iteration 10672  is               80.575%\n",
            "The validation accuracy at iteration 10688  is               80.525%\n",
            "The validation accuracy at iteration 10704  is               80.625%\n",
            "The validation accuracy at iteration 10720  is               80.875%\n",
            "The validation accuracy at iteration 10736  is               80.675%\n",
            "The validation accuracy at iteration 10752  is               81.5%\n",
            "The validation accuracy at iteration 10768  is               80.4%\n",
            "The validation accuracy at iteration 10784  is               80.525%\n",
            "The validation accuracy at iteration 10800  is               80.4%\n",
            "The validation accuracy at iteration 10816  is               80.4%\n",
            "The validation accuracy at iteration 10832  is               80.2%\n",
            "The validation accuracy at iteration 10848  is               79.725%\n",
            "The validation accuracy at iteration 10864  is               80.425%\n",
            "The validation accuracy at iteration 10880  is               79.875%\n",
            "The validation accuracy at iteration 10896  is               80.925%\n",
            "The validation accuracy at iteration 10912  is               80.975%\n",
            "The validation accuracy at iteration 10928  is               81.2%\n",
            "The validation accuracy at iteration 10944  is               80.9%\n",
            "The validation accuracy at iteration 10960  is               80.10000000000001%\n",
            "The validation accuracy at iteration 10976  is               80.5%\n",
            "The validation accuracy at iteration 10992  is               80.7%\n",
            "The validation accuracy at iteration 11008  is               80.675%\n",
            "The validation accuracy at iteration 11024  is               80.875%\n",
            "The validation accuracy at iteration 11040  is               81.025%\n",
            "The validation accuracy at iteration 11056  is               80.72500000000001%\n",
            "The validation accuracy at iteration 11072  is               81.625%\n",
            "The validation accuracy at iteration 11088  is               80.625%\n",
            "The validation accuracy at iteration 11104  is               80.625%\n",
            "The validation accuracy at iteration 11120  is               80.5%\n",
            "The validation accuracy at iteration 11136  is               80.575%\n",
            "The validation accuracy at iteration 11152  is               80.35%\n",
            "The validation accuracy at iteration 11168  is               79.85%\n",
            "The validation accuracy at iteration 11184  is               80.525%\n",
            "The validation accuracy at iteration 11200  is               79.925%\n",
            "The validation accuracy at iteration 11216  is               81.075%\n",
            "The validation accuracy at iteration 11232  is               81.10000000000001%\n",
            "The validation accuracy at iteration 11248  is               81.3%\n",
            "The validation accuracy at iteration 11264  is               81.075%\n",
            "The validation accuracy at iteration 11280  is               80.22500000000001%\n",
            "The validation accuracy at iteration 11296  is               80.60000000000001%\n",
            "The validation accuracy at iteration 11312  is               80.77499999999999%\n",
            "The validation accuracy at iteration 11328  is               80.77499999999999%\n",
            "The validation accuracy at iteration 11344  is               81.0%\n",
            "The validation accuracy at iteration 11360  is               81.10000000000001%\n",
            "The validation accuracy at iteration 11376  is               80.85%\n",
            "The validation accuracy at iteration 11392  is               81.72500000000001%\n",
            "The validation accuracy at iteration 11408  is               80.77499999999999%\n",
            "The validation accuracy at iteration 11424  is               80.75%\n",
            "The validation accuracy at iteration 11440  is               80.55%\n",
            "The validation accuracy at iteration 11456  is               80.625%\n",
            "The validation accuracy at iteration 11472  is               80.525%\n",
            "The validation accuracy at iteration 11488  is               80.0%\n",
            "The validation accuracy at iteration 11504  is               80.75%\n",
            "The validation accuracy at iteration 11520  is               80.125%\n",
            "The validation accuracy at iteration 11536  is               81.22500000000001%\n",
            "The validation accuracy at iteration 11552  is               81.3%\n",
            "The validation accuracy at iteration 11568  is               81.325%\n",
            "The validation accuracy at iteration 11584  is               81.15%\n",
            "The validation accuracy at iteration 11600  is               80.325%\n",
            "The validation accuracy at iteration 11616  is               80.7%\n",
            "The validation accuracy at iteration 11632  is               80.9%\n",
            "The validation accuracy at iteration 11648  is               80.95%\n",
            "The validation accuracy at iteration 11664  is               81.10000000000001%\n",
            "The validation accuracy at iteration 11680  is               81.22500000000001%\n",
            "The validation accuracy at iteration 11696  is               80.925%\n",
            "The validation accuracy at iteration 11712  is               81.825%\n",
            "The validation accuracy at iteration 11728  is               80.875%\n",
            "The validation accuracy at iteration 11744  is               80.9%\n",
            "The validation accuracy at iteration 11760  is               80.625%\n",
            "The validation accuracy at iteration 11776  is               80.675%\n",
            "The validation accuracy at iteration 11792  is               80.7%\n",
            "The validation accuracy at iteration 11808  is               80.10000000000001%\n",
            "The validation accuracy at iteration 11824  is               80.825%\n",
            "The validation accuracy at iteration 11840  is               80.22500000000001%\n",
            "The validation accuracy at iteration 11856  is               81.35%\n",
            "The validation accuracy at iteration 11872  is               81.325%\n",
            "The validation accuracy at iteration 11888  is               81.45%\n",
            "The validation accuracy at iteration 11904  is               81.325%\n",
            "The validation accuracy at iteration 11920  is               80.425%\n",
            "The validation accuracy at iteration 11936  is               80.77499999999999%\n",
            "The validation accuracy at iteration 11952  is               81.025%\n",
            "The validation accuracy at iteration 11968  is               81.05%\n",
            "The validation accuracy at iteration 11984  is               81.22500000000001%\n",
            "The validation accuracy at iteration 12000  is               81.35%\n",
            "The validation accuracy at iteration 12016  is               81.05%\n",
            "The validation accuracy at iteration 12032  is               81.89999999999999%\n",
            "The validation accuracy at iteration 12048  is               80.875%\n",
            "The validation accuracy at iteration 12064  is               80.85%\n",
            "The validation accuracy at iteration 12080  is               80.75%\n",
            "The validation accuracy at iteration 12096  is               80.77499999999999%\n",
            "The validation accuracy at iteration 12112  is               80.72500000000001%\n",
            "The validation accuracy at iteration 12128  is               80.2%\n",
            "The validation accuracy at iteration 12144  is               81.0%\n",
            "The validation accuracy at iteration 12160  is               80.30000000000001%\n",
            "The validation accuracy at iteration 12176  is               81.45%\n",
            "The validation accuracy at iteration 12192  is               81.375%\n",
            "The validation accuracy at iteration 12208  is               81.625%\n",
            "The validation accuracy at iteration 12224  is               81.5%\n",
            "The validation accuracy at iteration 12240  is               80.475%\n",
            "The validation accuracy at iteration 12256  is               80.85%\n",
            "The validation accuracy at iteration 12272  is               81.075%\n",
            "The validation accuracy at iteration 12288  is               81.075%\n",
            "The validation accuracy at iteration 12304  is               81.35%\n",
            "The validation accuracy at iteration 12320  is               81.45%\n",
            "The validation accuracy at iteration 12336  is               81.2%\n",
            "The validation accuracy at iteration 12352  is               81.89999999999999%\n",
            "The validation accuracy at iteration 12368  is               80.925%\n",
            "The validation accuracy at iteration 12384  is               80.925%\n",
            "The validation accuracy at iteration 12400  is               80.85%\n",
            "The validation accuracy at iteration 12416  is               80.825%\n",
            "The validation accuracy at iteration 12432  is               80.875%\n",
            "The validation accuracy at iteration 12448  is               80.35%\n",
            "The validation accuracy at iteration 12464  is               81.075%\n",
            "The validation accuracy at iteration 12480  is               80.4%\n",
            "The validation accuracy at iteration 12496  is               81.5%\n",
            "The validation accuracy at iteration 12512  is               81.525%\n",
            "The validation accuracy at iteration 12528  is               81.65%\n",
            "The validation accuracy at iteration 12544  is               81.525%\n",
            "The validation accuracy at iteration 12560  is               80.525%\n",
            "The validation accuracy at iteration 12576  is               80.925%\n",
            "The validation accuracy at iteration 12592  is               81.25%\n",
            "The validation accuracy at iteration 12608  is               81.175%\n",
            "The validation accuracy at iteration 12624  is               81.475%\n",
            "The validation accuracy at iteration 12640  is               81.55%\n",
            "The validation accuracy at iteration 12656  is               81.2%\n",
            "The validation accuracy at iteration 12672  is               81.89999999999999%\n",
            "The validation accuracy at iteration 12688  is               81.025%\n",
            "The validation accuracy at iteration 12704  is               81.05%\n",
            "The validation accuracy at iteration 12720  is               81.05%\n",
            "The validation accuracy at iteration 12736  is               81.0%\n",
            "The validation accuracy at iteration 12752  is               81.0%\n",
            "The validation accuracy at iteration 12768  is               80.5%\n",
            "The validation accuracy at iteration 12784  is               81.15%\n",
            "The validation accuracy at iteration 12800  is               80.5%\n",
            "The validation accuracy at iteration 12816  is               81.525%\n",
            "The validation accuracy at iteration 12832  is               81.575%\n",
            "The validation accuracy at iteration 12848  is               81.85%\n",
            "The validation accuracy at iteration 12864  is               81.55%\n",
            "The validation accuracy at iteration 12880  is               80.575%\n",
            "The validation accuracy at iteration 12896  is               81.0%\n",
            "The validation accuracy at iteration 12912  is               81.25%\n",
            "The validation accuracy at iteration 12928  is               81.3%\n",
            "The validation accuracy at iteration 12944  is               81.575%\n",
            "The validation accuracy at iteration 12960  is               81.675%\n",
            "The validation accuracy at iteration 12976  is               81.25%\n",
            "The validation accuracy at iteration 12992  is               82.05%\n",
            "The validation accuracy at iteration 13008  is               81.05%\n",
            "The validation accuracy at iteration 13024  is               81.27499999999999%\n",
            "The validation accuracy at iteration 13040  is               81.2%\n",
            "The validation accuracy at iteration 13056  is               81.075%\n",
            "The validation accuracy at iteration 13072  is               81.05%\n",
            "The validation accuracy at iteration 13088  is               80.55%\n",
            "The validation accuracy at iteration 13104  is               81.25%\n",
            "The validation accuracy at iteration 13120  is               80.65%\n",
            "The validation accuracy at iteration 13136  is               81.5%\n",
            "The validation accuracy at iteration 13152  is               81.75%\n",
            "The validation accuracy at iteration 13168  is               81.95%\n",
            "The validation accuracy at iteration 13184  is               81.675%\n",
            "The validation accuracy at iteration 13200  is               80.80000000000001%\n",
            "The validation accuracy at iteration 13216  is               81.125%\n",
            "The validation accuracy at iteration 13232  is               81.25%\n",
            "The validation accuracy at iteration 13248  is               81.425%\n",
            "The validation accuracy at iteration 13264  is               81.675%\n",
            "The validation accuracy at iteration 13280  is               81.69999999999999%\n",
            "The validation accuracy at iteration 13296  is               81.35%\n",
            "The validation accuracy at iteration 13312  is               82.125%\n",
            "The validation accuracy at iteration 13328  is               81.075%\n",
            "The validation accuracy at iteration 13344  is               81.35%\n",
            "The validation accuracy at iteration 13360  is               81.3%\n",
            "The validation accuracy at iteration 13376  is               81.25%\n",
            "The validation accuracy at iteration 13392  is               81.10000000000001%\n",
            "The validation accuracy at iteration 13408  is               80.625%\n",
            "The validation accuracy at iteration 13424  is               81.27499999999999%\n",
            "The validation accuracy at iteration 13440  is               80.80000000000001%\n",
            "The validation accuracy at iteration 13456  is               81.575%\n",
            "The validation accuracy at iteration 13472  is               81.8%\n",
            "The validation accuracy at iteration 13488  is               82.025%\n",
            "The validation accuracy at iteration 13504  is               81.825%\n",
            "The validation accuracy at iteration 13520  is               80.9%\n",
            "The validation accuracy at iteration 13536  is               81.2%\n",
            "The validation accuracy at iteration 13552  is               81.375%\n",
            "The validation accuracy at iteration 13568  is               81.425%\n",
            "The validation accuracy at iteration 13584  is               81.75%\n",
            "The validation accuracy at iteration 13600  is               81.8%\n",
            "The validation accuracy at iteration 13616  is               81.425%\n",
            "The validation accuracy at iteration 13632  is               82.15%\n",
            "The validation accuracy at iteration 13648  is               81.15%\n",
            "The validation accuracy at iteration 13664  is               81.5%\n",
            "The validation accuracy at iteration 13680  is               81.35%\n",
            "The validation accuracy at iteration 13696  is               81.425%\n",
            "The validation accuracy at iteration 13712  is               81.175%\n",
            "The validation accuracy at iteration 13728  is               80.72500000000001%\n",
            "The validation accuracy at iteration 13744  is               81.325%\n",
            "The validation accuracy at iteration 13760  is               80.85%\n",
            "The validation accuracy at iteration 13776  is               81.625%\n",
            "The validation accuracy at iteration 13792  is               81.95%\n",
            "The validation accuracy at iteration 13808  is               82.19999999999999%\n",
            "The validation accuracy at iteration 13824  is               81.85%\n",
            "The validation accuracy at iteration 13840  is               81.0%\n",
            "The validation accuracy at iteration 13856  is               81.22500000000001%\n",
            "The validation accuracy at iteration 13872  is               81.425%\n",
            "The validation accuracy at iteration 13888  is               81.5%\n",
            "The validation accuracy at iteration 13904  is               81.675%\n",
            "The validation accuracy at iteration 13920  is               81.825%\n",
            "The validation accuracy at iteration 13936  is               81.6%\n",
            "The validation accuracy at iteration 13952  is               82.325%\n",
            "The validation accuracy at iteration 13968  is               81.25%\n",
            "The validation accuracy at iteration 13984  is               81.6%\n",
            "The validation accuracy at iteration 14000  is               81.45%\n",
            "The validation accuracy at iteration 14016  is               81.55%\n",
            "The validation accuracy at iteration 14032  is               81.325%\n",
            "The validation accuracy at iteration 14048  is               80.875%\n",
            "The validation accuracy at iteration 14064  is               81.39999999999999%\n",
            "The validation accuracy at iteration 14080  is               80.975%\n",
            "The validation accuracy at iteration 14096  is               81.675%\n",
            "The validation accuracy at iteration 14112  is               82.025%\n",
            "The validation accuracy at iteration 14128  is               82.19999999999999%\n",
            "The validation accuracy at iteration 14144  is               81.825%\n",
            "The validation accuracy at iteration 14160  is               81.125%\n",
            "The validation accuracy at iteration 14176  is               81.325%\n",
            "The validation accuracy at iteration 14192  is               81.525%\n",
            "The validation accuracy at iteration 14208  is               81.575%\n",
            "The validation accuracy at iteration 14224  is               81.72500000000001%\n",
            "The validation accuracy at iteration 14240  is               81.85%\n",
            "The validation accuracy at iteration 14256  is               81.625%\n",
            "The validation accuracy at iteration 14272  is               82.325%\n",
            "The validation accuracy at iteration 14288  is               81.2%\n",
            "The validation accuracy at iteration 14304  is               81.6%\n",
            "The validation accuracy at iteration 14320  is               81.575%\n",
            "The validation accuracy at iteration 14336  is               81.625%\n",
            "The validation accuracy at iteration 14352  is               81.325%\n",
            "The validation accuracy at iteration 14368  is               80.875%\n",
            "The validation accuracy at iteration 14384  is               81.45%\n",
            "The validation accuracy at iteration 14400  is               81.025%\n",
            "The validation accuracy at iteration 14416  is               81.69999999999999%\n",
            "The validation accuracy at iteration 14432  is               82.05%\n",
            "The validation accuracy at iteration 14448  is               82.27499999999999%\n",
            "The validation accuracy at iteration 14464  is               81.925%\n",
            "The validation accuracy at iteration 14480  is               81.25%\n",
            "The validation accuracy at iteration 14496  is               81.55%\n",
            "The validation accuracy at iteration 14512  is               81.55%\n",
            "The validation accuracy at iteration 14528  is               81.575%\n",
            "The validation accuracy at iteration 14544  is               81.8%\n",
            "The validation accuracy at iteration 14560  is               81.89999999999999%\n",
            "The validation accuracy at iteration 14576  is               81.72500000000001%\n",
            "The validation accuracy at iteration 14592  is               82.39999999999999%\n",
            "The validation accuracy at iteration 14608  is               81.325%\n",
            "The validation accuracy at iteration 14624  is               81.72500000000001%\n",
            "The validation accuracy at iteration 14640  is               81.625%\n",
            "The validation accuracy at iteration 14656  is               81.6%\n",
            "The validation accuracy at iteration 14672  is               81.35%\n",
            "The validation accuracy at iteration 14688  is               80.95%\n",
            "The validation accuracy at iteration 14704  is               81.625%\n",
            "The validation accuracy at iteration 14720  is               81.15%\n",
            "The validation accuracy at iteration 14736  is               81.75%\n",
            "The validation accuracy at iteration 14752  is               82.05%\n",
            "The validation accuracy at iteration 14768  is               82.39999999999999%\n",
            "The validation accuracy at iteration 14784  is               82.05%\n",
            "The validation accuracy at iteration 14800  is               81.39999999999999%\n",
            "The validation accuracy at iteration 14816  is               81.6%\n",
            "The validation accuracy at iteration 14832  is               81.675%\n",
            "The validation accuracy at iteration 14848  is               81.625%\n",
            "The validation accuracy at iteration 14864  is               81.85%\n",
            "The validation accuracy at iteration 14880  is               81.85%\n",
            "The validation accuracy at iteration 14896  is               81.625%\n",
            "The validation accuracy at iteration 14912  is               82.45%\n",
            "The validation accuracy at iteration 14928  is               81.375%\n",
            "The validation accuracy at iteration 14944  is               81.72500000000001%\n",
            "The validation accuracy at iteration 14960  is               81.625%\n",
            "The validation accuracy at iteration 14976  is               81.65%\n",
            "The validation accuracy at iteration 14992  is               81.475%\n",
            "The validation accuracy at iteration 15008  is               81.0%\n",
            "The validation accuracy at iteration 15024  is               81.675%\n",
            "The validation accuracy at iteration 15040  is               81.175%\n",
            "The validation accuracy at iteration 15056  is               81.77499999999999%\n",
            "The validation accuracy at iteration 15072  is               82.19999999999999%\n",
            "The validation accuracy at iteration 15088  is               82.425%\n",
            "The validation accuracy at iteration 15104  is               82.15%\n",
            "The validation accuracy at iteration 15120  is               81.475%\n",
            "The validation accuracy at iteration 15136  is               81.575%\n",
            "The validation accuracy at iteration 15152  is               81.72500000000001%\n",
            "The validation accuracy at iteration 15168  is               81.625%\n",
            "The validation accuracy at iteration 15184  is               81.95%\n",
            "The validation accuracy at iteration 15200  is               81.95%\n",
            "The validation accuracy at iteration 15216  is               81.77499999999999%\n",
            "The validation accuracy at iteration 15232  is               82.55%\n",
            "The validation accuracy at iteration 15248  is               81.45%\n",
            "The validation accuracy at iteration 15264  is               81.75%\n",
            "The validation accuracy at iteration 15280  is               81.65%\n",
            "The validation accuracy at iteration 15296  is               81.77499999999999%\n",
            "The validation accuracy at iteration 15312  is               81.675%\n",
            "The validation accuracy at iteration 15328  is               81.05%\n",
            "The validation accuracy at iteration 15344  is               81.675%\n",
            "The validation accuracy at iteration 15360  is               81.27499999999999%\n",
            "The validation accuracy at iteration 15376  is               81.85%\n",
            "The validation accuracy at iteration 15392  is               82.27499999999999%\n",
            "The validation accuracy at iteration 15408  is               82.425%\n",
            "The validation accuracy at iteration 15424  is               82.15%\n",
            "The validation accuracy at iteration 15440  is               81.6%\n",
            "The validation accuracy at iteration 15456  is               81.625%\n",
            "The validation accuracy at iteration 15472  is               81.75%\n",
            "The validation accuracy at iteration 15488  is               81.69999999999999%\n",
            "The validation accuracy at iteration 15504  is               81.975%\n",
            "The validation accuracy at iteration 15520  is               81.95%\n",
            "The validation accuracy at iteration 15536  is               81.85%\n",
            "The validation accuracy at iteration 15552  is               82.525%\n",
            "The validation accuracy at iteration 15568  is               81.575%\n",
            "The validation accuracy at iteration 15584  is               81.825%\n",
            "The validation accuracy at iteration 15600  is               81.675%\n",
            "The validation accuracy at iteration 15616  is               81.825%\n",
            "The validation accuracy at iteration 15632  is               81.675%\n",
            "The validation accuracy at iteration 15648  is               81.125%\n",
            "The validation accuracy at iteration 15664  is               81.72500000000001%\n",
            "The validation accuracy at iteration 15680  is               81.35%\n",
            "The validation accuracy at iteration 15696  is               81.875%\n",
            "The validation accuracy at iteration 15712  is               82.25%\n",
            "The validation accuracy at iteration 15728  is               82.475%\n",
            "The validation accuracy at iteration 15744  is               82.15%\n",
            "The validation accuracy at iteration 15760  is               81.69999999999999%\n",
            "The validation accuracy at iteration 15776  is               81.65%\n",
            "The validation accuracy at iteration 15792  is               81.77499999999999%\n",
            "The validation accuracy at iteration 15808  is               81.69999999999999%\n",
            "The validation accuracy at iteration 15824  is               82.1%\n",
            "The validation accuracy at iteration 15840  is               82.0%\n",
            "The validation accuracy at iteration 15856  is               81.95%\n",
            "The validation accuracy at iteration 15872  is               82.65%\n",
            "The validation accuracy at iteration 15888  is               81.625%\n",
            "The validation accuracy at iteration 15904  is               81.85%\n",
            "The validation accuracy at iteration 15920  is               81.75%\n",
            "The validation accuracy at iteration 15936  is               81.875%\n",
            "The validation accuracy at iteration 15952  is               81.75%\n",
            "The validation accuracy at iteration 15968  is               81.175%\n",
            "The validation accuracy at iteration 15984  is               81.8%\n",
            "The validation accuracy at iteration 16000  is               81.39999999999999%\n",
            "The validation accuracy at iteration 16000  is               81.39999999999999%\n",
            "The validation accuracy at iteration 16000  is               81.39999999999999%\n",
            "The validation accuracy at iteration 16000  is               82.875%\n",
            "The validation accuracy at iteration 16000  is               81.39999999999999%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 16000  is               81.39999999999999%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "The validation accuracy at iteration 16000  is               81.39999999999999%\n",
            "The validation accuracy at iteration 2300  is               81.75%\n",
            "The validation accuracy at iteration 16000  is               81.39999999999999%\n",
            "The validation accuracy at iteration 2300  is               81.575%\n",
            "The validation accuracy at iteration 16000  is               81.39999999999999%\n",
            "[<__main__.Solver object at 0x7f6e25755490>, <__main__.Solver object at 0x7f6e457874d0>, <__main__.Solver object at 0x7f6e5b0b1490>, <__main__.Solver object at 0x7f6e4c6b5710>, <__main__.Solver object at 0x7f6e4c79e350>]\n",
            "The validation accuracy at iteration 16  is               18.45%\n",
            "The validation accuracy at iteration 32  is               10.7%\n",
            "The validation accuracy at iteration 48  is               9.85%\n",
            "The validation accuracy at iteration 64  is               21.375%\n",
            "The validation accuracy at iteration 80  is               17.175%\n",
            "The validation accuracy at iteration 96  is               14.649999999999999%\n",
            "The validation accuracy at iteration 112  is               9.3%\n",
            "The validation accuracy at iteration 128  is               11.3%\n",
            "The validation accuracy at iteration 144  is               11.899999999999999%\n",
            "The validation accuracy at iteration 160  is               11.600000000000001%\n",
            "The validation accuracy at iteration 176  is               14.549999999999999%\n",
            "The validation accuracy at iteration 192  is               15.049999999999999%\n",
            "The validation accuracy at iteration 208  is               22.2%\n",
            "The validation accuracy at iteration 224  is               17.675%\n",
            "The validation accuracy at iteration 240  is               21.525%\n",
            "The validation accuracy at iteration 256  is               28.975%\n",
            "The validation accuracy at iteration 272  is               35.5%\n",
            "The validation accuracy at iteration 288  is               29.299999999999997%\n",
            "The validation accuracy at iteration 304  is               37.95%\n",
            "The validation accuracy at iteration 320  is               38.95%\n",
            "The validation accuracy at iteration 336  is               38.725%\n",
            "The validation accuracy at iteration 352  is               44.1%\n",
            "The validation accuracy at iteration 368  is               49.775000000000006%\n",
            "The validation accuracy at iteration 384  is               52.37500000000001%\n",
            "The validation accuracy at iteration 400  is               52.949999999999996%\n",
            "The validation accuracy at iteration 416  is               54.7%\n",
            "The validation accuracy at iteration 432  is               55.300000000000004%\n",
            "The validation accuracy at iteration 448  is               61.275%\n",
            "The validation accuracy at iteration 464  is               59.025000000000006%\n",
            "The validation accuracy at iteration 480  is               57.825%\n",
            "The validation accuracy at iteration 496  is               62.9%\n",
            "The validation accuracy at iteration 512  is               59.52499999999999%\n",
            "The validation accuracy at iteration 528  is               62.324999999999996%\n",
            "The validation accuracy at iteration 544  is               63.775000000000006%\n",
            "The validation accuracy at iteration 560  is               65.525%\n",
            "The validation accuracy at iteration 576  is               65.025%\n",
            "The validation accuracy at iteration 592  is               66.525%\n",
            "The validation accuracy at iteration 608  is               67.80000000000001%\n",
            "The validation accuracy at iteration 624  is               67.65%\n",
            "The validation accuracy at iteration 640  is               64.425%\n",
            "The validation accuracy at iteration 656  is               67.625%\n",
            "The validation accuracy at iteration 672  is               66.95%\n",
            "The validation accuracy at iteration 688  is               67.925%\n",
            "The validation accuracy at iteration 704  is               69.77499999999999%\n",
            "The validation accuracy at iteration 720  is               68.125%\n",
            "The validation accuracy at iteration 736  is               68.525%\n",
            "The validation accuracy at iteration 752  is               66.9%\n",
            "The validation accuracy at iteration 768  is               70.475%\n",
            "The validation accuracy at iteration 784  is               68.675%\n",
            "The validation accuracy at iteration 800  is               69.75%\n",
            "The validation accuracy at iteration 816  is               70.875%\n",
            "The validation accuracy at iteration 832  is               69.625%\n",
            "The validation accuracy at iteration 848  is               70.175%\n",
            "The validation accuracy at iteration 864  is               69.3%\n",
            "The validation accuracy at iteration 880  is               70.675%\n",
            "The validation accuracy at iteration 896  is               70.875%\n",
            "The validation accuracy at iteration 912  is               72.625%\n",
            "The validation accuracy at iteration 928  is               71.825%\n",
            "The validation accuracy at iteration 944  is               71.05%\n",
            "The validation accuracy at iteration 960  is               69.39999999999999%\n",
            "The validation accuracy at iteration 976  is               71.325%\n",
            "The validation accuracy at iteration 992  is               71.825%\n",
            "The validation accuracy at iteration 1008  is               71.975%\n",
            "The validation accuracy at iteration 1024  is               73.225%\n",
            "The validation accuracy at iteration 1040  is               70.8%\n",
            "The validation accuracy at iteration 1056  is               72.775%\n",
            "The validation accuracy at iteration 1072  is               71.925%\n",
            "The validation accuracy at iteration 1088  is               73.675%\n",
            "The validation accuracy at iteration 1104  is               72.52499999999999%\n",
            "The validation accuracy at iteration 1120  is               72.85000000000001%\n",
            "The validation accuracy at iteration 1136  is               74.2%\n",
            "The validation accuracy at iteration 1152  is               72.775%\n",
            "The validation accuracy at iteration 1168  is               72.425%\n",
            "The validation accuracy at iteration 1184  is               73.675%\n",
            "The validation accuracy at iteration 1200  is               73.175%\n",
            "The validation accuracy at iteration 1216  is               74.125%\n",
            "The validation accuracy at iteration 1232  is               75.3%\n",
            "The validation accuracy at iteration 1248  is               74.825%\n",
            "The validation accuracy at iteration 1264  is               74.05000000000001%\n",
            "The validation accuracy at iteration 1280  is               72.55%\n",
            "The validation accuracy at iteration 1296  is               74.8%\n",
            "The validation accuracy at iteration 1312  is               73.625%\n",
            "The validation accuracy at iteration 1328  is               74.575%\n",
            "The validation accuracy at iteration 1344  is               76.175%\n",
            "The validation accuracy at iteration 1360  is               75.25%\n",
            "The validation accuracy at iteration 1376  is               75.05%\n",
            "The validation accuracy at iteration 1392  is               74.45%\n",
            "The validation accuracy at iteration 1408  is               75.52499999999999%\n",
            "The validation accuracy at iteration 1424  is               75.175%\n",
            "The validation accuracy at iteration 1440  is               75.375%\n",
            "The validation accuracy at iteration 1456  is               76.44999999999999%\n",
            "The validation accuracy at iteration 1472  is               75.14999999999999%\n",
            "The validation accuracy at iteration 1488  is               74.9%\n",
            "The validation accuracy at iteration 1504  is               75.44999999999999%\n",
            "The validation accuracy at iteration 1520  is               75.52499999999999%\n",
            "The validation accuracy at iteration 1536  is               76.55%\n",
            "The validation accuracy at iteration 1552  is               76.97500000000001%\n",
            "The validation accuracy at iteration 1568  is               76.6%\n",
            "The validation accuracy at iteration 1584  is               75.97500000000001%\n",
            "The validation accuracy at iteration 1600  is               75.225%\n",
            "The validation accuracy at iteration 1616  is               76.14999999999999%\n",
            "The validation accuracy at iteration 1632  is               75.875%\n",
            "The validation accuracy at iteration 1648  is               76.0%\n",
            "The validation accuracy at iteration 1664  is               77.725%\n",
            "The validation accuracy at iteration 1680  is               77.17500000000001%\n",
            "The validation accuracy at iteration 1696  is               76.55%\n",
            "The validation accuracy at iteration 1712  is               75.725%\n",
            "The validation accuracy at iteration 1728  is               77.4%\n",
            "The validation accuracy at iteration 1744  is               76.425%\n",
            "The validation accuracy at iteration 1760  is               76.925%\n",
            "The validation accuracy at iteration 1776  is               77.55%\n",
            "The validation accuracy at iteration 1792  is               76.525%\n",
            "The validation accuracy at iteration 1808  is               76.275%\n",
            "The validation accuracy at iteration 1824  is               76.825%\n",
            "The validation accuracy at iteration 1840  is               77.35%\n",
            "The validation accuracy at iteration 1856  is               77.275%\n",
            "The validation accuracy at iteration 1872  is               77.67500000000001%\n",
            "The validation accuracy at iteration 1888  is               77.67500000000001%\n",
            "The validation accuracy at iteration 1904  is               76.7%\n",
            "The validation accuracy at iteration 1920  is               77.025%\n",
            "The validation accuracy at iteration 1936  is               77.825%\n",
            "The validation accuracy at iteration 1952  is               77.10000000000001%\n",
            "The validation accuracy at iteration 1968  is               77.0%\n",
            "The validation accuracy at iteration 1984  is               78.7%\n",
            "The validation accuracy at iteration 2000  is               77.97500000000001%\n",
            "The validation accuracy at iteration 2016  is               77.425%\n",
            "The validation accuracy at iteration 2032  is               76.525%\n",
            "The validation accuracy at iteration 2048  is               78.25%\n",
            "The validation accuracy at iteration 2064  is               78.0%\n",
            "The validation accuracy at iteration 2080  is               78.175%\n",
            "The validation accuracy at iteration 2096  is               79.0%\n",
            "The validation accuracy at iteration 2112  is               77.64999999999999%\n",
            "The validation accuracy at iteration 2128  is               77.10000000000001%\n",
            "The validation accuracy at iteration 2144  is               78.3%\n",
            "The validation accuracy at iteration 2160  is               78.325%\n",
            "The validation accuracy at iteration 2176  is               78.075%\n",
            "The validation accuracy at iteration 2192  is               78.875%\n",
            "The validation accuracy at iteration 2208  is               78.475%\n",
            "The validation accuracy at iteration 2224  is               77.525%\n",
            "The validation accuracy at iteration 2240  is               77.45%\n",
            "The validation accuracy at iteration 2256  is               79.14999999999999%\n",
            "The validation accuracy at iteration 2272  is               78.325%\n",
            "The validation accuracy at iteration 2288  is               78.25%\n",
            "The validation accuracy at iteration 2304  is               79.325%\n",
            "The validation accuracy at iteration 2320  is               79.2%\n",
            "The validation accuracy at iteration 2336  is               78.525%\n",
            "The validation accuracy at iteration 2352  is               77.2%\n",
            "The validation accuracy at iteration 2368  is               78.9%\n",
            "The validation accuracy at iteration 2384  is               78.60000000000001%\n",
            "The validation accuracy at iteration 2400  is               78.825%\n",
            "The validation accuracy at iteration 2416  is               79.55%\n",
            "The validation accuracy at iteration 2432  is               78.225%\n",
            "The validation accuracy at iteration 2448  is               78.05%\n",
            "The validation accuracy at iteration 2464  is               78.4%\n",
            "The validation accuracy at iteration 2480  is               78.4%\n",
            "The validation accuracy at iteration 2496  is               78.77499999999999%\n",
            "The validation accuracy at iteration 2512  is               79.60000000000001%\n",
            "The validation accuracy at iteration 2528  is               79.475%\n",
            "The validation accuracy at iteration 2544  is               78.9%\n",
            "The validation accuracy at iteration 2560  is               78.57499999999999%\n",
            "The validation accuracy at iteration 2576  is               79.525%\n",
            "The validation accuracy at iteration 2592  is               78.60000000000001%\n",
            "The validation accuracy at iteration 2608  is               79.225%\n",
            "The validation accuracy at iteration 2624  is               80.22500000000001%\n",
            "The validation accuracy at iteration 2640  is               79.80000000000001%\n",
            "The validation accuracy at iteration 2656  is               78.975%\n",
            "The validation accuracy at iteration 2672  is               77.725%\n",
            "The validation accuracy at iteration 2688  is               78.60000000000001%\n",
            "The validation accuracy at iteration 2704  is               79.425%\n",
            "The validation accuracy at iteration 2720  is               79.475%\n",
            "The validation accuracy at iteration 2736  is               80.2%\n",
            "The validation accuracy at iteration 2752  is               77.97500000000001%\n",
            "The validation accuracy at iteration 2768  is               78.9%\n",
            "The validation accuracy at iteration 2784  is               79.25%\n",
            "The validation accuracy at iteration 2800  is               79.925%\n",
            "The validation accuracy at iteration 2816  is               79.35%\n",
            "The validation accuracy at iteration 2832  is               79.475%\n",
            "The validation accuracy at iteration 2848  is               80.22500000000001%\n",
            "The validation accuracy at iteration 2864  is               79.85%\n",
            "The validation accuracy at iteration 2880  is               79.175%\n",
            "The validation accuracy at iteration 2896  is               80.175%\n",
            "The validation accuracy at iteration 2912  is               79.2%\n",
            "The validation accuracy at iteration 2928  is               79.77499999999999%\n",
            "The validation accuracy at iteration 2944  is               80.5%\n",
            "The validation accuracy at iteration 2960  is               80.22500000000001%\n",
            "The validation accuracy at iteration 2976  is               80.0%\n",
            "The validation accuracy at iteration 2992  is               78.3%\n",
            "The validation accuracy at iteration 3008  is               80.2%\n",
            "The validation accuracy at iteration 3024  is               79.4%\n",
            "The validation accuracy at iteration 3040  is               79.925%\n",
            "The validation accuracy at iteration 3056  is               80.65%\n",
            "The validation accuracy at iteration 3072  is               79.375%\n",
            "The validation accuracy at iteration 3088  is               79.57499999999999%\n",
            "The validation accuracy at iteration 3104  is               79.3%\n",
            "The validation accuracy at iteration 3120  is               80.175%\n",
            "The validation accuracy at iteration 3136  is               79.77499999999999%\n",
            "The validation accuracy at iteration 3152  is               80.025%\n",
            "The validation accuracy at iteration 3168  is               81.025%\n",
            "The validation accuracy at iteration 3184  is               79.875%\n",
            "The validation accuracy at iteration 3200  is               79.55%\n",
            "The validation accuracy at iteration 3216  is               80.60000000000001%\n",
            "The validation accuracy at iteration 3232  is               80.0%\n",
            "The validation accuracy at iteration 3248  is               80.45%\n",
            "The validation accuracy at iteration 3264  is               80.875%\n",
            "The validation accuracy at iteration 3280  is               80.5%\n",
            "The validation accuracy at iteration 3296  is               80.45%\n",
            "The validation accuracy at iteration 3312  is               79.25%\n",
            "The validation accuracy at iteration 3328  is               80.60000000000001%\n",
            "The validation accuracy at iteration 3344  is               79.9%\n",
            "The validation accuracy at iteration 3360  is               80.5%\n",
            "The validation accuracy at iteration 3376  is               80.475%\n",
            "The validation accuracy at iteration 3392  is               80.22500000000001%\n",
            "The validation accuracy at iteration 3408  is               80.175%\n",
            "The validation accuracy at iteration 3424  is               79.57499999999999%\n",
            "The validation accuracy at iteration 3440  is               81.0%\n",
            "The validation accuracy at iteration 3456  is               80.175%\n",
            "The validation accuracy at iteration 3472  is               80.525%\n",
            "The validation accuracy at iteration 3488  is               81.15%\n",
            "The validation accuracy at iteration 3504  is               80.2%\n",
            "The validation accuracy at iteration 3520  is               79.60000000000001%\n",
            "The validation accuracy at iteration 3536  is               80.475%\n",
            "The validation accuracy at iteration 3552  is               80.675%\n",
            "The validation accuracy at iteration 3568  is               80.475%\n",
            "The validation accuracy at iteration 3584  is               80.9%\n",
            "The validation accuracy at iteration 3600  is               80.65%\n",
            "The validation accuracy at iteration 3616  is               80.025%\n",
            "The validation accuracy at iteration 3632  is               80.475%\n",
            "The validation accuracy at iteration 3648  is               81.125%\n",
            "The validation accuracy at iteration 3664  is               80.0%\n",
            "The validation accuracy at iteration 3680  is               79.95%\n",
            "The validation accuracy at iteration 3696  is               81.15%\n",
            "The validation accuracy at iteration 3712  is               80.825%\n",
            "The validation accuracy at iteration 3728  is               80.22500000000001%\n",
            "The validation accuracy at iteration 3744  is               79.425%\n",
            "The validation accuracy at iteration 3760  is               80.925%\n",
            "The validation accuracy at iteration 3776  is               80.95%\n",
            "The validation accuracy at iteration 3792  is               81.025%\n",
            "The validation accuracy at iteration 3808  is               81.825%\n",
            "The validation accuracy at iteration 3824  is               80.30000000000001%\n",
            "The validation accuracy at iteration 3840  is               79.725%\n",
            "The validation accuracy at iteration 3856  is               81.15%\n",
            "The validation accuracy at iteration 3872  is               81.075%\n",
            "The validation accuracy at iteration 3888  is               80.65%\n",
            "The validation accuracy at iteration 3904  is               81.65%\n",
            "The validation accuracy at iteration 3920  is               81.425%\n",
            "The validation accuracy at iteration 3936  is               80.60000000000001%\n",
            "The validation accuracy at iteration 3952  is               80.30000000000001%\n",
            "The validation accuracy at iteration 3968  is               81.75%\n",
            "The validation accuracy at iteration 3984  is               80.65%\n",
            "The validation accuracy at iteration 4000  is               80.77499999999999%\n",
            "The validation accuracy at iteration 4016  is               81.65%\n",
            "The validation accuracy at iteration 4032  is               81.525%\n",
            "The validation accuracy at iteration 4048  is               80.625%\n",
            "The validation accuracy at iteration 4064  is               79.9%\n",
            "The validation accuracy at iteration 4080  is               81.45%\n",
            "The validation accuracy at iteration 4096  is               80.925%\n",
            "The validation accuracy at iteration 4112  is               81.10000000000001%\n",
            "The validation accuracy at iteration 4128  is               82.05%\n",
            "The validation accuracy at iteration 4144  is               80.45%\n",
            "The validation accuracy at iteration 4160  is               80.45%\n",
            "The validation accuracy at iteration 4176  is               80.975%\n",
            "The validation accuracy at iteration 4192  is               80.525%\n",
            "The validation accuracy at iteration 4208  is               81.05%\n",
            "The validation accuracy at iteration 4224  is               81.925%\n",
            "The validation accuracy at iteration 4240  is               81.45%\n",
            "The validation accuracy at iteration 4256  is               80.925%\n",
            "The validation accuracy at iteration 4272  is               80.825%\n",
            "The validation accuracy at iteration 4288  is               81.925%\n",
            "The validation accuracy at iteration 4304  is               80.95%\n",
            "The validation accuracy at iteration 4320  is               81.22500000000001%\n",
            "The validation accuracy at iteration 4336  is               81.825%\n",
            "The validation accuracy at iteration 4352  is               81.69999999999999%\n",
            "The validation accuracy at iteration 4368  is               81.475%\n",
            "The validation accuracy at iteration 4384  is               80.4%\n",
            "The validation accuracy at iteration 4400  is               81.125%\n",
            "The validation accuracy at iteration 4416  is               81.27499999999999%\n",
            "The validation accuracy at iteration 4432  is               81.375%\n",
            "The validation accuracy at iteration 4448  is               82.325%\n",
            "The validation accuracy at iteration 4464  is               80.05%\n",
            "The validation accuracy at iteration 4480  is               80.85%\n",
            "The validation accuracy at iteration 4496  is               81.55%\n",
            "The validation accuracy at iteration 4512  is               81.825%\n",
            "The validation accuracy at iteration 4528  is               81.05%\n",
            "The validation accuracy at iteration 4544  is               81.27499999999999%\n",
            "The validation accuracy at iteration 4560  is               82.05%\n",
            "The validation accuracy at iteration 4576  is               81.5%\n",
            "The validation accuracy at iteration 4592  is               80.95%\n",
            "The validation accuracy at iteration 4608  is               82.19999999999999%\n",
            "The validation accuracy at iteration 4624  is               81.5%\n",
            "The validation accuracy at iteration 4640  is               81.27499999999999%\n",
            "The validation accuracy at iteration 4656  is               81.89999999999999%\n",
            "The validation accuracy at iteration 4672  is               81.875%\n",
            "The validation accuracy at iteration 4688  is               81.69999999999999%\n",
            "The validation accuracy at iteration 4704  is               80.65%\n",
            "The validation accuracy at iteration 4720  is               82.075%\n",
            "The validation accuracy at iteration 4736  is               81.375%\n",
            "The validation accuracy at iteration 4752  is               81.6%\n",
            "The validation accuracy at iteration 4768  is               82.3%\n",
            "The validation accuracy at iteration 4784  is               81.325%\n",
            "The validation accuracy at iteration 4800  is               81.22500000000001%\n",
            "The validation accuracy at iteration 4816  is               81.69999999999999%\n",
            "The validation accuracy at iteration 4832  is               82.1%\n",
            "The validation accuracy at iteration 4848  is               81.5%\n",
            "The validation accuracy at iteration 4864  is               81.825%\n",
            "The validation accuracy at iteration 4880  is               82.525%\n",
            "The validation accuracy at iteration 4896  is               81.72500000000001%\n",
            "The validation accuracy at iteration 4912  is               81.375%\n",
            "The validation accuracy at iteration 4928  is               81.975%\n",
            "The validation accuracy at iteration 4944  is               81.825%\n",
            "The validation accuracy at iteration 4960  is               81.85%\n",
            "The validation accuracy at iteration 4976  is               82.55%\n",
            "The validation accuracy at iteration 4992  is               82.025%\n",
            "The validation accuracy at iteration 5008  is               81.89999999999999%\n",
            "The validation accuracy at iteration 5024  is               81.625%\n",
            "The validation accuracy at iteration 5040  is               82.05%\n",
            "The validation accuracy at iteration 5056  is               81.55%\n",
            "The validation accuracy at iteration 5072  is               81.77499999999999%\n",
            "The validation accuracy at iteration 5088  is               81.575%\n",
            "The validation accuracy at iteration 5104  is               81.75%\n",
            "The validation accuracy at iteration 5120  is               81.575%\n",
            "The validation accuracy at iteration 5136  is               81.15%\n",
            "The validation accuracy at iteration 5152  is               82.425%\n",
            "The validation accuracy at iteration 5168  is               81.475%\n",
            "The validation accuracy at iteration 5184  is               82.05%\n",
            "The validation accuracy at iteration 5200  is               82.39999999999999%\n",
            "The validation accuracy at iteration 5216  is               81.75%\n",
            "The validation accuracy at iteration 5232  is               81.025%\n",
            "The validation accuracy at iteration 5248  is               81.8%\n",
            "The validation accuracy at iteration 5264  is               81.95%\n",
            "The validation accuracy at iteration 5280  is               81.65%\n",
            "The validation accuracy at iteration 5296  is               82.05%\n",
            "The validation accuracy at iteration 5312  is               81.75%\n",
            "The validation accuracy at iteration 5328  is               81.45%\n",
            "The validation accuracy at iteration 5344  is               81.675%\n",
            "The validation accuracy at iteration 5350  is               81.22500000000001%\n",
            "The validation accuracy at iteration 5350  is               81.22500000000001%\n",
            "The validation accuracy at iteration 16000  is               82.875%\n",
            "The validation accuracy at iteration 5350  is               81.22500000000001%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 5350  is               81.22500000000001%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "The validation accuracy at iteration 5350  is               81.22500000000001%\n",
            "The validation accuracy at iteration 2300  is               81.75%\n",
            "The validation accuracy at iteration 5350  is               81.22500000000001%\n",
            "The validation accuracy at iteration 2300  is               81.575%\n",
            "The validation accuracy at iteration 5350  is               81.22500000000001%\n",
            "[<__main__.Solver object at 0x7f6e25755490>, <__main__.Solver object at 0x7f6e457874d0>, <__main__.Solver object at 0x7f6e5b0b1490>, <__main__.Solver object at 0x7f6e4c6b5710>, <__main__.Solver object at 0x7f6e4c79e350>]\n",
            "The validation accuracy at iteration 16  is               11.275%\n",
            "The validation accuracy at iteration 32  is               12.525%\n",
            "The validation accuracy at iteration 48  is               17.65%\n",
            "The validation accuracy at iteration 64  is               13.100000000000001%\n",
            "The validation accuracy at iteration 80  is               10.5%\n",
            "The validation accuracy at iteration 96  is               13.475000000000001%\n",
            "The validation accuracy at iteration 112  is               16.35%\n",
            "The validation accuracy at iteration 128  is               20.625%\n",
            "The validation accuracy at iteration 144  is               22.875%\n",
            "The validation accuracy at iteration 160  is               29.875%\n",
            "The validation accuracy at iteration 176  is               34.9%\n",
            "The validation accuracy at iteration 192  is               37.325%\n",
            "The validation accuracy at iteration 208  is               40.775%\n",
            "The validation accuracy at iteration 224  is               48.575%\n",
            "The validation accuracy at iteration 240  is               53.87499999999999%\n",
            "The validation accuracy at iteration 256  is               53.87499999999999%\n",
            "The validation accuracy at iteration 272  is               55.7%\n",
            "The validation accuracy at iteration 288  is               59.724999999999994%\n",
            "The validation accuracy at iteration 304  is               62.925%\n",
            "The validation accuracy at iteration 320  is               61.4%\n",
            "The validation accuracy at iteration 336  is               63.87500000000001%\n",
            "The validation accuracy at iteration 352  is               64.875%\n",
            "The validation accuracy at iteration 368  is               66.325%\n",
            "The validation accuracy at iteration 384  is               64.925%\n",
            "The validation accuracy at iteration 400  is               66.9%\n",
            "The validation accuracy at iteration 416  is               68.0%\n",
            "The validation accuracy at iteration 432  is               68.175%\n",
            "The validation accuracy at iteration 448  is               67.25%\n",
            "The validation accuracy at iteration 464  is               68.7%\n",
            "The validation accuracy at iteration 480  is               69.575%\n",
            "The validation accuracy at iteration 496  is               69.45%\n",
            "The validation accuracy at iteration 512  is               68.975%\n",
            "The validation accuracy at iteration 528  is               70.3%\n",
            "The validation accuracy at iteration 544  is               71.325%\n",
            "The validation accuracy at iteration 560  is               70.75%\n",
            "The validation accuracy at iteration 576  is               70.42500000000001%\n",
            "The validation accuracy at iteration 592  is               71.3%\n",
            "The validation accuracy at iteration 608  is               72.6%\n",
            "The validation accuracy at iteration 624  is               71.75%\n",
            "The validation accuracy at iteration 640  is               71.15%\n",
            "The validation accuracy at iteration 656  is               72.3%\n",
            "The validation accuracy at iteration 672  is               73.5%\n",
            "The validation accuracy at iteration 688  is               72.725%\n",
            "The validation accuracy at iteration 704  is               72.125%\n",
            "The validation accuracy at iteration 720  is               73.35000000000001%\n",
            "The validation accuracy at iteration 736  is               74.325%\n",
            "The validation accuracy at iteration 752  is               73.675%\n",
            "The validation accuracy at iteration 768  is               72.95%\n",
            "The validation accuracy at iteration 784  is               74.2%\n",
            "The validation accuracy at iteration 800  is               75.1%\n",
            "The validation accuracy at iteration 816  is               74.4%\n",
            "The validation accuracy at iteration 832  is               74.0%\n",
            "The validation accuracy at iteration 848  is               74.8%\n",
            "The validation accuracy at iteration 864  is               75.52499999999999%\n",
            "The validation accuracy at iteration 880  is               75.175%\n",
            "The validation accuracy at iteration 896  is               74.65%\n",
            "The validation accuracy at iteration 912  is               75.5%\n",
            "The validation accuracy at iteration 928  is               76.05%\n",
            "The validation accuracy at iteration 944  is               75.7%\n",
            "The validation accuracy at iteration 960  is               75.175%\n",
            "The validation accuracy at iteration 976  is               76.02499999999999%\n",
            "The validation accuracy at iteration 992  is               76.47500000000001%\n",
            "The validation accuracy at iteration 1008  is               76.1%\n",
            "The validation accuracy at iteration 1024  is               75.4%\n",
            "The validation accuracy at iteration 1040  is               76.325%\n",
            "The validation accuracy at iteration 1056  is               77.14999999999999%\n",
            "The validation accuracy at iteration 1072  is               76.55%\n",
            "The validation accuracy at iteration 1088  is               75.9%\n",
            "The validation accuracy at iteration 1104  is               76.85%\n",
            "The validation accuracy at iteration 1120  is               77.60000000000001%\n",
            "The validation accuracy at iteration 1136  is               76.875%\n",
            "The validation accuracy at iteration 1152  is               76.35%\n",
            "The validation accuracy at iteration 1168  is               77.25%\n",
            "The validation accuracy at iteration 1184  is               77.97500000000001%\n",
            "The validation accuracy at iteration 1200  is               77.05%\n",
            "The validation accuracy at iteration 1216  is               76.85%\n",
            "The validation accuracy at iteration 1232  is               77.525%\n",
            "The validation accuracy at iteration 1248  is               78.325%\n",
            "The validation accuracy at iteration 1264  is               77.5%\n",
            "The validation accuracy at iteration 1280  is               77.275%\n",
            "The validation accuracy at iteration 1296  is               77.825%\n",
            "The validation accuracy at iteration 1312  is               78.60000000000001%\n",
            "The validation accuracy at iteration 1328  is               78.025%\n",
            "The validation accuracy at iteration 1344  is               77.575%\n",
            "The validation accuracy at iteration 1360  is               77.97500000000001%\n",
            "The validation accuracy at iteration 1376  is               78.725%\n",
            "The validation accuracy at iteration 1392  is               78.375%\n",
            "The validation accuracy at iteration 1408  is               77.775%\n",
            "The validation accuracy at iteration 1424  is               78.2%\n",
            "The validation accuracy at iteration 1440  is               78.77499999999999%\n",
            "The validation accuracy at iteration 1456  is               78.45%\n",
            "The validation accuracy at iteration 1472  is               78.025%\n",
            "The validation accuracy at iteration 1488  is               78.475%\n",
            "The validation accuracy at iteration 1504  is               78.9%\n",
            "The validation accuracy at iteration 1520  is               78.60000000000001%\n",
            "The validation accuracy at iteration 1536  is               78.175%\n",
            "The validation accuracy at iteration 1552  is               78.675%\n",
            "The validation accuracy at iteration 1568  is               79.225%\n",
            "The validation accuracy at iteration 1584  is               79.07499999999999%\n",
            "The validation accuracy at iteration 1600  is               78.45%\n",
            "The validation accuracy at iteration 1616  is               79.025%\n",
            "The validation accuracy at iteration 1632  is               79.5%\n",
            "The validation accuracy at iteration 1648  is               79.225%\n",
            "The validation accuracy at iteration 1664  is               78.525%\n",
            "The validation accuracy at iteration 1680  is               79.14999999999999%\n",
            "The validation accuracy at iteration 1696  is               79.675%\n",
            "The validation accuracy at iteration 1712  is               79.3%\n",
            "The validation accuracy at iteration 1728  is               78.75%\n",
            "The validation accuracy at iteration 1744  is               79.325%\n",
            "The validation accuracy at iteration 1760  is               79.9%\n",
            "The validation accuracy at iteration 1776  is               79.57499999999999%\n",
            "The validation accuracy at iteration 1792  is               78.925%\n",
            "The validation accuracy at iteration 1808  is               79.475%\n",
            "The validation accuracy at iteration 1824  is               80.025%\n",
            "The validation accuracy at iteration 1840  is               79.675%\n",
            "The validation accuracy at iteration 1856  is               79.14999999999999%\n",
            "The validation accuracy at iteration 1872  is               79.45%\n",
            "The validation accuracy at iteration 1888  is               80.325%\n",
            "The validation accuracy at iteration 1904  is               79.95%\n",
            "The validation accuracy at iteration 1920  is               79.27499999999999%\n",
            "The validation accuracy at iteration 1936  is               79.625%\n",
            "The validation accuracy at iteration 1952  is               80.475%\n",
            "The validation accuracy at iteration 1968  is               80.10000000000001%\n",
            "The validation accuracy at iteration 1984  is               79.4%\n",
            "The validation accuracy at iteration 2000  is               79.7%\n",
            "The validation accuracy at iteration 2016  is               80.575%\n",
            "The validation accuracy at iteration 2032  is               80.22500000000001%\n",
            "The validation accuracy at iteration 2048  is               79.65%\n",
            "The validation accuracy at iteration 2064  is               79.77499999999999%\n",
            "The validation accuracy at iteration 2080  is               80.75%\n",
            "The validation accuracy at iteration 2096  is               80.325%\n",
            "The validation accuracy at iteration 2112  is               79.625%\n",
            "The validation accuracy at iteration 2128  is               79.9%\n",
            "The validation accuracy at iteration 2144  is               80.825%\n",
            "The validation accuracy at iteration 2160  is               80.425%\n",
            "The validation accuracy at iteration 2176  is               79.75%\n",
            "The validation accuracy at iteration 2192  is               80.05%\n",
            "The validation accuracy at iteration 2208  is               80.975%\n",
            "The validation accuracy at iteration 2224  is               80.55%\n",
            "The validation accuracy at iteration 2240  is               79.925%\n",
            "The validation accuracy at iteration 2256  is               80.125%\n",
            "The validation accuracy at iteration 2272  is               81.075%\n",
            "The validation accuracy at iteration 2288  is               80.72500000000001%\n",
            "The validation accuracy at iteration 2304  is               80.025%\n",
            "The validation accuracy at iteration 2320  is               80.25%\n",
            "The validation accuracy at iteration 2336  is               81.22500000000001%\n",
            "The validation accuracy at iteration 2352  is               80.75%\n",
            "The validation accuracy at iteration 2368  is               80.15%\n",
            "The validation accuracy at iteration 2384  is               80.375%\n",
            "The validation accuracy at iteration 2400  is               81.3%\n",
            "The validation accuracy at iteration 2416  is               80.77499999999999%\n",
            "The validation accuracy at iteration 2432  is               80.27499999999999%\n",
            "The validation accuracy at iteration 2448  is               80.425%\n",
            "The validation accuracy at iteration 2464  is               81.475%\n",
            "The validation accuracy at iteration 2480  is               80.925%\n",
            "The validation accuracy at iteration 2496  is               80.4%\n",
            "The validation accuracy at iteration 2512  is               80.525%\n",
            "The validation accuracy at iteration 2528  is               81.575%\n",
            "The validation accuracy at iteration 2544  is               81.025%\n",
            "The validation accuracy at iteration 2560  is               80.425%\n",
            "The validation accuracy at iteration 2576  is               80.525%\n",
            "The validation accuracy at iteration 2592  is               81.625%\n",
            "The validation accuracy at iteration 2608  is               81.15%\n",
            "The validation accuracy at iteration 2624  is               80.625%\n",
            "The validation accuracy at iteration 2640  is               80.7%\n",
            "The validation accuracy at iteration 2656  is               81.65%\n",
            "The validation accuracy at iteration 2672  is               81.2%\n",
            "The validation accuracy at iteration 2688  is               80.675%\n",
            "The validation accuracy at iteration 2704  is               80.85%\n",
            "The validation accuracy at iteration 2720  is               81.72500000000001%\n",
            "The validation accuracy at iteration 2736  is               81.3%\n",
            "The validation accuracy at iteration 2752  is               80.825%\n",
            "The validation accuracy at iteration 2768  is               81.05%\n",
            "The validation accuracy at iteration 2784  is               81.75%\n",
            "The validation accuracy at iteration 2800  is               81.425%\n",
            "The validation accuracy at iteration 2816  is               80.875%\n",
            "The validation accuracy at iteration 2832  is               81.125%\n",
            "The validation accuracy at iteration 2848  is               81.8%\n",
            "The validation accuracy at iteration 2864  is               81.475%\n",
            "The validation accuracy at iteration 2880  is               80.975%\n",
            "The validation accuracy at iteration 2896  is               81.175%\n",
            "The validation accuracy at iteration 2912  is               81.77499999999999%\n",
            "The validation accuracy at iteration 2928  is               81.525%\n",
            "The validation accuracy at iteration 2944  is               81.075%\n",
            "The validation accuracy at iteration 2960  is               81.2%\n",
            "The validation accuracy at iteration 2976  is               81.77499999999999%\n",
            "The validation accuracy at iteration 2992  is               81.625%\n",
            "The validation accuracy at iteration 3008  is               81.175%\n",
            "The validation accuracy at iteration 3024  is               81.25%\n",
            "The validation accuracy at iteration 3040  is               81.8%\n",
            "The validation accuracy at iteration 3056  is               81.8%\n",
            "The validation accuracy at iteration 3072  is               81.25%\n",
            "The validation accuracy at iteration 3088  is               81.35%\n",
            "The validation accuracy at iteration 3104  is               81.85%\n",
            "The validation accuracy at iteration 3120  is               81.825%\n",
            "The validation accuracy at iteration 3136  is               81.25%\n",
            "The validation accuracy at iteration 3152  is               81.425%\n",
            "The validation accuracy at iteration 3168  is               81.95%\n",
            "The validation accuracy at iteration 3184  is               81.875%\n",
            "The validation accuracy at iteration 3200  is               81.3%\n",
            "The validation accuracy at iteration 3200  is               81.3%\n",
            "The validation accuracy at iteration 3200  is               81.3%\n",
            "The validation accuracy at iteration 16000  is               82.875%\n",
            "The validation accuracy at iteration 3200  is               81.3%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 3200  is               81.3%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "The validation accuracy at iteration 3200  is               81.3%\n",
            "The validation accuracy at iteration 2300  is               81.75%\n",
            "The validation accuracy at iteration 3200  is               81.3%\n",
            "The validation accuracy at iteration 2300  is               81.575%\n",
            "The validation accuracy at iteration 3200  is               81.3%\n",
            "[<__main__.Solver object at 0x7f6e25755490>, <__main__.Solver object at 0x7f6e457874d0>, <__main__.Solver object at 0x7f6e5b0b1490>, <__main__.Solver object at 0x7f6e4c6b5710>, <__main__.Solver object at 0x7f6e4c79e350>]\n",
            "The validation accuracy at iteration 16  is               11.075%\n",
            "The validation accuracy at iteration 32  is               16.275000000000002%\n",
            "The validation accuracy at iteration 48  is               12.025%\n",
            "The validation accuracy at iteration 64  is               15.299999999999999%\n",
            "The validation accuracy at iteration 80  is               16.45%\n",
            "The validation accuracy at iteration 96  is               17.025000000000002%\n",
            "The validation accuracy at iteration 112  is               32.35%\n",
            "The validation accuracy at iteration 128  is               28.525%\n",
            "The validation accuracy at iteration 144  is               36.875%\n",
            "The validation accuracy at iteration 160  is               45.75%\n",
            "The validation accuracy at iteration 176  is               58.050000000000004%\n",
            "The validation accuracy at iteration 192  is               59.824999999999996%\n",
            "The validation accuracy at iteration 208  is               62.74999999999999%\n",
            "The validation accuracy at iteration 224  is               64.025%\n",
            "The validation accuracy at iteration 240  is               63.125%\n",
            "The validation accuracy at iteration 256  is               68.4%\n",
            "The validation accuracy at iteration 272  is               65.3%\n",
            "The validation accuracy at iteration 288  is               64.85%\n",
            "The validation accuracy at iteration 304  is               69.925%\n",
            "The validation accuracy at iteration 320  is               66.35%\n",
            "The validation accuracy at iteration 336  is               68.25%\n",
            "The validation accuracy at iteration 352  is               70.72500000000001%\n",
            "The validation accuracy at iteration 368  is               68.45%\n",
            "The validation accuracy at iteration 384  is               70.475%\n",
            "The validation accuracy at iteration 400  is               71.45%\n",
            "The validation accuracy at iteration 416  is               70.475%\n",
            "The validation accuracy at iteration 432  is               71.15%\n",
            "The validation accuracy at iteration 448  is               72.1%\n",
            "The validation accuracy at iteration 464  is               72.225%\n",
            "The validation accuracy at iteration 480  is               72.55%\n",
            "The validation accuracy at iteration 496  is               72.0%\n",
            "The validation accuracy at iteration 512  is               74.225%\n",
            "The validation accuracy at iteration 528  is               74.425%\n",
            "The validation accuracy at iteration 544  is               73.75%\n",
            "The validation accuracy at iteration 560  is               74.675%\n",
            "The validation accuracy at iteration 576  is               76.14999999999999%\n",
            "The validation accuracy at iteration 592  is               74.15%\n",
            "The validation accuracy at iteration 608  is               74.52499999999999%\n",
            "The validation accuracy at iteration 624  is               76.55%\n",
            "The validation accuracy at iteration 640  is               74.7%\n",
            "The validation accuracy at iteration 656  is               74.825%\n",
            "The validation accuracy at iteration 672  is               76.97500000000001%\n",
            "The validation accuracy at iteration 688  is               74.875%\n",
            "The validation accuracy at iteration 704  is               76.44999999999999%\n",
            "The validation accuracy at iteration 720  is               77.0%\n",
            "The validation accuracy at iteration 736  is               75.225%\n",
            "The validation accuracy at iteration 752  is               77.10000000000001%\n",
            "The validation accuracy at iteration 768  is               77.2%\n",
            "The validation accuracy at iteration 784  is               76.625%\n",
            "The validation accuracy at iteration 800  is               76.775%\n",
            "The validation accuracy at iteration 816  is               76.925%\n",
            "The validation accuracy at iteration 832  is               77.75%\n",
            "The validation accuracy at iteration 848  is               77.275%\n",
            "The validation accuracy at iteration 864  is               76.64999999999999%\n",
            "The validation accuracy at iteration 880  is               77.8%\n",
            "The validation accuracy at iteration 896  is               78.60000000000001%\n",
            "The validation accuracy at iteration 912  is               77.825%\n",
            "The validation accuracy at iteration 928  is               78.025%\n",
            "The validation accuracy at iteration 944  is               79.07499999999999%\n",
            "The validation accuracy at iteration 960  is               77.47500000000001%\n",
            "The validation accuracy at iteration 976  is               77.825%\n",
            "The validation accuracy at iteration 992  is               79.65%\n",
            "The validation accuracy at iteration 1008  is               78.0%\n",
            "The validation accuracy at iteration 1024  is               77.9%\n",
            "The validation accuracy at iteration 1040  is               79.675%\n",
            "The validation accuracy at iteration 1056  is               77.67500000000001%\n",
            "The validation accuracy at iteration 1072  is               79.025%\n",
            "The validation accuracy at iteration 1088  is               79.25%\n",
            "The validation accuracy at iteration 1104  is               78.10000000000001%\n",
            "The validation accuracy at iteration 1120  is               79.225%\n",
            "The validation accuracy at iteration 1136  is               79.025%\n",
            "The validation accuracy at iteration 1152  is               79.05%\n",
            "The validation accuracy at iteration 1168  is               78.675%\n",
            "The validation accuracy at iteration 1184  is               78.4%\n",
            "The validation accuracy at iteration 1200  is               79.975%\n",
            "The validation accuracy at iteration 1216  is               79.175%\n",
            "The validation accuracy at iteration 1232  is               78.875%\n",
            "The validation accuracy at iteration 1248  is               79.375%\n",
            "The validation accuracy at iteration 1264  is               79.9%\n",
            "The validation accuracy at iteration 1280  is               79.5%\n",
            "The validation accuracy at iteration 1296  is               79.60000000000001%\n",
            "The validation accuracy at iteration 1312  is               80.7%\n",
            "The validation accuracy at iteration 1328  is               78.675%\n",
            "The validation accuracy at iteration 1344  is               79.05%\n",
            "The validation accuracy at iteration 1360  is               81.125%\n",
            "The validation accuracy at iteration 1376  is               79.475%\n",
            "The validation accuracy at iteration 1392  is               79.77499999999999%\n",
            "The validation accuracy at iteration 1408  is               80.95%\n",
            "The validation accuracy at iteration 1424  is               79.0%\n",
            "The validation accuracy at iteration 1440  is               80.175%\n",
            "The validation accuracy at iteration 1456  is               80.45%\n",
            "The validation accuracy at iteration 1472  is               79.55%\n",
            "The validation accuracy at iteration 1488  is               80.2%\n",
            "The validation accuracy at iteration 1504  is               80.0%\n",
            "The validation accuracy at iteration 1520  is               80.4%\n",
            "The validation accuracy at iteration 1536  is               79.80000000000001%\n",
            "The validation accuracy at iteration 1552  is               79.375%\n",
            "The validation accuracy at iteration 1568  is               81.0%\n",
            "The validation accuracy at iteration 1584  is               80.175%\n",
            "The validation accuracy at iteration 1600  is               80.175%\n",
            "The validation accuracy at iteration 1616  is               80.475%\n",
            "The validation accuracy at iteration 1632  is               81.075%\n",
            "The validation accuracy at iteration 1648  is               80.625%\n",
            "The validation accuracy at iteration 1664  is               80.325%\n",
            "The validation accuracy at iteration 1680  is               81.475%\n",
            "The validation accuracy at iteration 1696  is               79.80000000000001%\n",
            "The validation accuracy at iteration 1712  is               80.27499999999999%\n",
            "The validation accuracy at iteration 1728  is               81.65%\n",
            "The validation accuracy at iteration 1744  is               80.30000000000001%\n",
            "The validation accuracy at iteration 1760  is               80.625%\n",
            "The validation accuracy at iteration 1776  is               81.875%\n",
            "The validation accuracy at iteration 1792  is               80.025%\n",
            "The validation accuracy at iteration 1808  is               80.9%\n",
            "The validation accuracy at iteration 1824  is               81.5%\n",
            "The validation accuracy at iteration 1840  is               80.475%\n",
            "The validation accuracy at iteration 1856  is               81.15%\n",
            "The validation accuracy at iteration 1872  is               80.625%\n",
            "The validation accuracy at iteration 1888  is               81.22500000000001%\n",
            "The validation accuracy at iteration 1904  is               80.77499999999999%\n",
            "The validation accuracy at iteration 1920  is               80.55%\n",
            "The validation accuracy at iteration 1936  is               82.025%\n",
            "The validation accuracy at iteration 1952  is               80.925%\n",
            "The validation accuracy at iteration 1968  is               81.075%\n",
            "The validation accuracy at iteration 1984  is               81.35%\n",
            "The validation accuracy at iteration 2000  is               81.85%\n",
            "The validation accuracy at iteration 2016  is               81.25%\n",
            "The validation accuracy at iteration 2032  is               80.85%\n",
            "The validation accuracy at iteration 2048  is               81.825%\n",
            "The validation accuracy at iteration 2064  is               80.55%\n",
            "The validation accuracy at iteration 2080  is               81.525%\n",
            "The validation accuracy at iteration 2096  is               82.39999999999999%\n",
            "The validation accuracy at iteration 2112  is               81.2%\n",
            "The validation accuracy at iteration 2128  is               81.25%\n",
            "The validation accuracy at iteration 2144  is               82.15%\n",
            "The validation accuracy at iteration 2160  is               81.05%\n",
            "The validation accuracy at iteration 2176  is               81.6%\n",
            "The validation accuracy at iteration 2192  is               82.025%\n",
            "The validation accuracy at iteration 2208  is               81.25%\n",
            "The validation accuracy at iteration 2224  is               81.625%\n",
            "The validation accuracy at iteration 2240  is               81.375%\n",
            "The validation accuracy at iteration 2256  is               81.55%\n",
            "The validation accuracy at iteration 2272  is               81.27499999999999%\n",
            "The validation accuracy at iteration 2288  is               81.15%\n",
            "The validation accuracy at iteration 2300  is               81.325%\n",
            "The validation accuracy at iteration 2300  is               81.325%\n",
            "The validation accuracy at iteration 16000  is               82.875%\n",
            "The validation accuracy at iteration 2300  is               81.325%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 2300  is               81.325%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "The validation accuracy at iteration 2300  is               81.325%\n",
            "The validation accuracy at iteration 2300  is               81.75%\n",
            "The validation accuracy at iteration 2300  is               81.325%\n",
            "The validation accuracy at iteration 2300  is               81.575%\n",
            "The validation accuracy at iteration 2300  is               81.325%\n",
            "[<__main__.Solver object at 0x7f6e25755490>, <__main__.Solver object at 0x7f6e457874d0>, <__main__.Solver object at 0x7f6e5b0b1490>, <__main__.Solver object at 0x7f6e4c6b5710>, <__main__.Solver object at 0x7f6e4c79e350>]\n",
            "The validation accuracy at iteration 16  is               9.65%\n",
            "The validation accuracy at iteration 32  is               15.325%\n",
            "The validation accuracy at iteration 48  is               9.700000000000001%\n",
            "The validation accuracy at iteration 64  is               13.975000000000001%\n",
            "The validation accuracy at iteration 80  is               19.425%\n",
            "The validation accuracy at iteration 96  is               28.275%\n",
            "The validation accuracy at iteration 112  is               36.95%\n",
            "The validation accuracy at iteration 128  is               54.50000000000001%\n",
            "The validation accuracy at iteration 144  is               52.425%\n",
            "The validation accuracy at iteration 160  is               60.150000000000006%\n",
            "The validation accuracy at iteration 176  is               61.85000000000001%\n",
            "The validation accuracy at iteration 192  is               63.849999999999994%\n",
            "The validation accuracy at iteration 208  is               63.24999999999999%\n",
            "The validation accuracy at iteration 224  is               67.375%\n",
            "The validation accuracy at iteration 240  is               69.375%\n",
            "The validation accuracy at iteration 256  is               69.25%\n",
            "The validation accuracy at iteration 272  is               72.02499999999999%\n",
            "The validation accuracy at iteration 288  is               68.45%\n",
            "The validation accuracy at iteration 304  is               71.05%\n",
            "The validation accuracy at iteration 320  is               69.69999999999999%\n",
            "The validation accuracy at iteration 336  is               71.0%\n",
            "The validation accuracy at iteration 352  is               70.3%\n",
            "The validation accuracy at iteration 368  is               72.425%\n",
            "The validation accuracy at iteration 384  is               73.825%\n",
            "The validation accuracy at iteration 400  is               74.2%\n",
            "The validation accuracy at iteration 416  is               75.64999999999999%\n",
            "The validation accuracy at iteration 432  is               72.775%\n",
            "The validation accuracy at iteration 448  is               74.5%\n",
            "The validation accuracy at iteration 464  is               73.4%\n",
            "The validation accuracy at iteration 480  is               74.775%\n",
            "The validation accuracy at iteration 496  is               74.15%\n",
            "The validation accuracy at iteration 512  is               75.52499999999999%\n",
            "The validation accuracy at iteration 528  is               76.725%\n",
            "The validation accuracy at iteration 544  is               76.47500000000001%\n",
            "The validation accuracy at iteration 560  is               77.97500000000001%\n",
            "The validation accuracy at iteration 576  is               75.425%\n",
            "The validation accuracy at iteration 592  is               76.825%\n",
            "The validation accuracy at iteration 608  is               75.64999999999999%\n",
            "The validation accuracy at iteration 624  is               76.75%\n",
            "The validation accuracy at iteration 640  is               76.1%\n",
            "The validation accuracy at iteration 656  is               77.10000000000001%\n",
            "The validation accuracy at iteration 672  is               78.175%\n",
            "The validation accuracy at iteration 688  is               78.0%\n",
            "The validation accuracy at iteration 704  is               79.125%\n",
            "The validation accuracy at iteration 720  is               77.14999999999999%\n",
            "The validation accuracy at iteration 736  is               78.375%\n",
            "The validation accuracy at iteration 752  is               77.025%\n",
            "The validation accuracy at iteration 768  is               78.125%\n",
            "The validation accuracy at iteration 784  is               77.5%\n",
            "The validation accuracy at iteration 800  is               78.125%\n",
            "The validation accuracy at iteration 816  is               79.4%\n",
            "The validation accuracy at iteration 832  is               79.225%\n",
            "The validation accuracy at iteration 848  is               79.77499999999999%\n",
            "The validation accuracy at iteration 864  is               78.35%\n",
            "The validation accuracy at iteration 880  is               79.125%\n",
            "The validation accuracy at iteration 896  is               77.775%\n",
            "The validation accuracy at iteration 912  is               78.77499999999999%\n",
            "The validation accuracy at iteration 928  is               78.35%\n",
            "The validation accuracy at iteration 944  is               78.77499999999999%\n",
            "The validation accuracy at iteration 960  is               79.75%\n",
            "The validation accuracy at iteration 976  is               80.05%\n",
            "The validation accuracy at iteration 992  is               80.375%\n",
            "The validation accuracy at iteration 1008  is               79.10000000000001%\n",
            "The validation accuracy at iteration 1024  is               79.825%\n",
            "The validation accuracy at iteration 1040  is               78.60000000000001%\n",
            "The validation accuracy at iteration 1056  is               79.60000000000001%\n",
            "The validation accuracy at iteration 1072  is               79.14999999999999%\n",
            "The validation accuracy at iteration 1088  is               79.27499999999999%\n",
            "The validation accuracy at iteration 1104  is               80.375%\n",
            "The validation accuracy at iteration 1120  is               80.625%\n",
            "The validation accuracy at iteration 1136  is               80.80000000000001%\n",
            "The validation accuracy at iteration 1152  is               79.525%\n",
            "The validation accuracy at iteration 1168  is               80.525%\n",
            "The validation accuracy at iteration 1184  is               79.2%\n",
            "The validation accuracy at iteration 1200  is               79.875%\n",
            "The validation accuracy at iteration 1216  is               79.675%\n",
            "The validation accuracy at iteration 1232  is               79.95%\n",
            "The validation accuracy at iteration 1248  is               80.875%\n",
            "The validation accuracy at iteration 1264  is               81.22500000000001%\n",
            "The validation accuracy at iteration 1280  is               81.25%\n",
            "The validation accuracy at iteration 1296  is               80.15%\n",
            "The validation accuracy at iteration 1312  is               80.925%\n",
            "The validation accuracy at iteration 1328  is               79.9%\n",
            "The validation accuracy at iteration 1344  is               80.35%\n",
            "The validation accuracy at iteration 1360  is               80.45%\n",
            "The validation accuracy at iteration 1376  is               80.475%\n",
            "The validation accuracy at iteration 1392  is               81.025%\n",
            "The validation accuracy at iteration 1408  is               81.6%\n",
            "The validation accuracy at iteration 1424  is               81.575%\n",
            "The validation accuracy at iteration 1440  is               80.575%\n",
            "The validation accuracy at iteration 1456  is               81.27499999999999%\n",
            "The validation accuracy at iteration 1472  is               80.35%\n",
            "The validation accuracy at iteration 1488  is               80.825%\n",
            "The validation accuracy at iteration 1504  is               80.80000000000001%\n",
            "The validation accuracy at iteration 1520  is               80.975%\n",
            "The validation accuracy at iteration 1536  is               81.425%\n",
            "The validation accuracy at iteration 1552  is               81.95%\n",
            "The validation accuracy at iteration 1568  is               81.55%\n",
            "The validation accuracy at iteration 1584  is               81.10000000000001%\n",
            "The validation accuracy at iteration 1600  is               81.475%\n",
            "The validation accuracy at iteration 1616  is               80.72500000000001%\n",
            "The validation accuracy at iteration 1632  is               80.975%\n",
            "The validation accuracy at iteration 1648  is               81.125%\n",
            "The validation accuracy at iteration 1664  is               81.35%\n",
            "The validation accuracy at iteration 1680  is               81.575%\n",
            "The validation accuracy at iteration 1696  is               82.22500000000001%\n",
            "The validation accuracy at iteration 1712  is               81.75%\n",
            "The validation accuracy at iteration 1728  is               81.475%\n",
            "The validation accuracy at iteration 1744  is               81.69999999999999%\n",
            "The validation accuracy at iteration 1760  is               80.975%\n",
            "The validation accuracy at iteration 1776  is               81.175%\n",
            "The validation accuracy at iteration 1792  is               81.3%\n",
            "The validation accuracy at iteration 1800  is               81.5%\n",
            "The validation accuracy at iteration 1800  is               81.5%\n",
            "The validation accuracy at iteration 16000  is               82.875%\n",
            "The validation accuracy at iteration 1800  is               81.5%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 1800  is               81.5%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "The validation accuracy at iteration 1800  is               81.5%\n",
            "The validation accuracy at iteration 2300  is               81.75%\n",
            "The validation accuracy at iteration 1800  is               81.5%\n",
            "The validation accuracy at iteration 2300  is               81.575%\n",
            "The validation accuracy at iteration 1800  is               81.5%\n",
            "[<__main__.Solver object at 0x7f6e25755490>, <__main__.Solver object at 0x7f6e457874d0>, <__main__.Solver object at 0x7f6e5b0b1490>, <__main__.Solver object at 0x7f6e4c6b5710>, <__main__.Solver object at 0x7f6e4c79e350>]\n",
            "The validation accuracy at iteration 16  is               8.625%\n",
            "The validation accuracy at iteration 32  is               8.625%\n",
            "The validation accuracy at iteration 48  is               8.625%\n",
            "The validation accuracy at iteration 64  is               8.625%\n",
            "The validation accuracy at iteration 80  is               8.625%\n",
            "The validation accuracy at iteration 96  is               8.625%\n",
            "The validation accuracy at iteration 112  is               8.625%\n",
            "The validation accuracy at iteration 128  is               8.625%\n",
            "The validation accuracy at iteration 144  is               8.625%\n",
            "The validation accuracy at iteration 160  is               8.625%\n",
            "The validation accuracy at iteration 176  is               8.625%\n",
            "The validation accuracy at iteration 192  is               8.625%\n",
            "The validation accuracy at iteration 208  is               8.625%\n",
            "The validation accuracy at iteration 224  is               8.625%\n",
            "The validation accuracy at iteration 240  is               8.625%\n",
            "The validation accuracy at iteration 256  is               8.625%\n",
            "The validation accuracy at iteration 272  is               8.625%\n",
            "The validation accuracy at iteration 288  is               8.625%\n",
            "The validation accuracy at iteration 304  is               8.625%\n",
            "The validation accuracy at iteration 320  is               8.625%\n",
            "The validation accuracy at iteration 336  is               8.625%\n",
            "The validation accuracy at iteration 352  is               8.625%\n",
            "The validation accuracy at iteration 368  is               8.625%\n",
            "The validation accuracy at iteration 384  is               8.625%\n",
            "The validation accuracy at iteration 400  is               8.625%\n",
            "The validation accuracy at iteration 416  is               8.625%\n",
            "The validation accuracy at iteration 432  is               8.625%\n",
            "The validation accuracy at iteration 448  is               8.625%\n",
            "The validation accuracy at iteration 464  is               8.625%\n",
            "The validation accuracy at iteration 480  is               8.625%\n",
            "The validation accuracy at iteration 496  is               8.625%\n",
            "The validation accuracy at iteration 512  is               8.625%\n",
            "The validation accuracy at iteration 528  is               8.625%\n",
            "The validation accuracy at iteration 544  is               8.625%\n",
            "The validation accuracy at iteration 560  is               8.625%\n",
            "The validation accuracy at iteration 576  is               8.625%\n",
            "The validation accuracy at iteration 592  is               8.625%\n",
            "The validation accuracy at iteration 608  is               8.625%\n",
            "The validation accuracy at iteration 624  is               8.625%\n",
            "The validation accuracy at iteration 640  is               8.625%\n",
            "The validation accuracy at iteration 656  is               8.625%\n",
            "The validation accuracy at iteration 672  is               8.625%\n",
            "The validation accuracy at iteration 688  is               8.625%\n",
            "The validation accuracy at iteration 704  is               8.625%\n",
            "The validation accuracy at iteration 720  is               8.625%\n",
            "The validation accuracy at iteration 736  is               8.625%\n",
            "The validation accuracy at iteration 752  is               8.625%\n",
            "The validation accuracy at iteration 768  is               8.625%\n",
            "The validation accuracy at iteration 784  is               8.625%\n",
            "The validation accuracy at iteration 800  is               8.625%\n",
            "The validation accuracy at iteration 816  is               8.625%\n",
            "The validation accuracy at iteration 832  is               8.625%\n",
            "The validation accuracy at iteration 848  is               8.625%\n",
            "The validation accuracy at iteration 864  is               8.625%\n",
            "The validation accuracy at iteration 880  is               8.625%\n",
            "The validation accuracy at iteration 896  is               8.625%\n",
            "The validation accuracy at iteration 912  is               8.625%\n",
            "The validation accuracy at iteration 928  is               8.625%\n",
            "The validation accuracy at iteration 944  is               8.625%\n",
            "The validation accuracy at iteration 960  is               8.625%\n",
            "The validation accuracy at iteration 976  is               8.625%\n",
            "The validation accuracy at iteration 992  is               8.625%\n",
            "The validation accuracy at iteration 1008  is               8.625%\n",
            "The validation accuracy at iteration 1024  is               8.625%\n",
            "The validation accuracy at iteration 1040  is               8.625%\n",
            "The validation accuracy at iteration 1056  is               8.625%\n",
            "The validation accuracy at iteration 1072  is               8.625%\n",
            "The validation accuracy at iteration 1088  is               8.625%\n",
            "The validation accuracy at iteration 1104  is               8.625%\n",
            "The validation accuracy at iteration 1120  is               8.625%\n",
            "The validation accuracy at iteration 1136  is               8.625%\n",
            "The validation accuracy at iteration 1152  is               8.625%\n",
            "The validation accuracy at iteration 1168  is               8.625%\n",
            "The validation accuracy at iteration 1184  is               8.625%\n",
            "The validation accuracy at iteration 1200  is               8.625%\n",
            "The validation accuracy at iteration 1216  is               8.625%\n",
            "The validation accuracy at iteration 1232  is               8.625%\n",
            "The validation accuracy at iteration 1248  is               8.625%\n",
            "The validation accuracy at iteration 1264  is               8.625%\n",
            "The validation accuracy at iteration 1280  is               8.625%\n",
            "The validation accuracy at iteration 1296  is               8.625%\n",
            "The validation accuracy at iteration 1312  is               8.625%\n",
            "The validation accuracy at iteration 1328  is               8.625%\n",
            "The validation accuracy at iteration 1344  is               8.625%\n",
            "The validation accuracy at iteration 1360  is               8.625%\n",
            "The validation accuracy at iteration 1376  is               8.625%\n",
            "The validation accuracy at iteration 1392  is               8.625%\n",
            "The validation accuracy at iteration 1408  is               8.625%\n",
            "The validation accuracy at iteration 1424  is               8.625%\n",
            "The validation accuracy at iteration 1440  is               8.625%\n",
            "The validation accuracy at iteration 1456  is               8.625%\n",
            "The validation accuracy at iteration 1472  is               8.625%\n",
            "The validation accuracy at iteration 1488  is               8.625%\n",
            "The validation accuracy at iteration 1504  is               8.625%\n",
            "The validation accuracy at iteration 1520  is               8.625%\n",
            "The validation accuracy at iteration 1536  is               8.625%\n",
            "The validation accuracy at iteration 1552  is               8.625%\n",
            "The validation accuracy at iteration 1568  is               8.625%\n",
            "The validation accuracy at iteration 1584  is               8.625%\n",
            "The validation accuracy at iteration 1600  is               8.625%\n",
            "The validation accuracy at iteration 1616  is               8.625%\n",
            "The validation accuracy at iteration 1632  is               8.625%\n",
            "The validation accuracy at iteration 1648  is               8.625%\n",
            "The validation accuracy at iteration 1664  is               8.625%\n",
            "The validation accuracy at iteration 1680  is               8.625%\n",
            "The validation accuracy at iteration 1696  is               8.625%\n",
            "The validation accuracy at iteration 1712  is               8.625%\n",
            "The validation accuracy at iteration 1728  is               8.625%\n",
            "The validation accuracy at iteration 1744  is               8.625%\n",
            "The validation accuracy at iteration 1760  is               8.6%\n",
            "The validation accuracy at iteration 1776  is               8.625%\n",
            "The validation accuracy at iteration 1792  is               8.6%\n",
            "The validation accuracy at iteration 1808  is               8.6%\n",
            "The validation accuracy at iteration 1824  is               8.5%\n",
            "The validation accuracy at iteration 1840  is               8.525%\n",
            "The validation accuracy at iteration 1856  is               8.450000000000001%\n",
            "The validation accuracy at iteration 1872  is               8.450000000000001%\n",
            "The validation accuracy at iteration 1888  is               8.450000000000001%\n",
            "The validation accuracy at iteration 1904  is               8.475000000000001%\n",
            "The validation accuracy at iteration 1920  is               8.425%\n",
            "The validation accuracy at iteration 1936  is               8.35%\n",
            "The validation accuracy at iteration 1952  is               8.25%\n",
            "The validation accuracy at iteration 1968  is               8.25%\n",
            "The validation accuracy at iteration 1984  is               8.325000000000001%\n",
            "The validation accuracy at iteration 2000  is               8.25%\n",
            "The validation accuracy at iteration 2016  is               7.85%\n",
            "The validation accuracy at iteration 2032  is               7.625%\n",
            "The validation accuracy at iteration 2048  is               7.625%\n",
            "The validation accuracy at iteration 2064  is               7.3%\n",
            "The validation accuracy at iteration 2080  is               6.675000000000001%\n",
            "The validation accuracy at iteration 2096  is               6.925000000000001%\n",
            "The validation accuracy at iteration 2112  is               6.625%\n",
            "The validation accuracy at iteration 2128  is               6.45%\n",
            "The validation accuracy at iteration 2144  is               6.45%\n",
            "The validation accuracy at iteration 2160  is               6.45%\n",
            "The validation accuracy at iteration 2176  is               6.1%\n",
            "The validation accuracy at iteration 2192  is               6.15%\n",
            "The validation accuracy at iteration 2208  is               6.15%\n",
            "The validation accuracy at iteration 2224  is               6.25%\n",
            "The validation accuracy at iteration 2240  is               6.125%\n",
            "The validation accuracy at iteration 2256  is               6.075%\n",
            "The validation accuracy at iteration 2272  is               5.7250000000000005%\n",
            "The validation accuracy at iteration 2288  is               5.800000000000001%\n",
            "The validation accuracy at iteration 2304  is               6.0%\n",
            "The validation accuracy at iteration 2320  is               5.875%\n",
            "The validation accuracy at iteration 2336  is               5.2749999999999995%\n",
            "The validation accuracy at iteration 2352  is               5.2%\n",
            "The validation accuracy at iteration 2368  is               5.175%\n",
            "The validation accuracy at iteration 2384  is               5.2749999999999995%\n",
            "The validation accuracy at iteration 2400  is               5.375%\n",
            "The validation accuracy at iteration 2416  is               5.4%\n",
            "The validation accuracy at iteration 2432  is               5.475%\n",
            "The validation accuracy at iteration 2448  is               5.5%\n",
            "The validation accuracy at iteration 2464  is               5.55%\n",
            "The validation accuracy at iteration 2480  is               5.5%\n",
            "The validation accuracy at iteration 2496  is               5.475%\n",
            "The validation accuracy at iteration 2512  is               5.475%\n",
            "The validation accuracy at iteration 2528  is               5.45%\n",
            "The validation accuracy at iteration 2544  is               5.4%\n",
            "The validation accuracy at iteration 2560  is               5.675%\n",
            "The validation accuracy at iteration 2576  is               6.175%\n",
            "The validation accuracy at iteration 2592  is               6.575%\n",
            "The validation accuracy at iteration 2608  is               6.45%\n",
            "The validation accuracy at iteration 2624  is               6.15%\n",
            "The validation accuracy at iteration 2640  is               6.375%\n",
            "The validation accuracy at iteration 2656  is               7.1%\n",
            "The validation accuracy at iteration 2672  is               7.55%\n",
            "The validation accuracy at iteration 2688  is               7.5249999999999995%\n",
            "The validation accuracy at iteration 2704  is               8.125%\n",
            "The validation accuracy at iteration 2720  is               8.9%\n",
            "The validation accuracy at iteration 2736  is               8.674999999999999%\n",
            "The validation accuracy at iteration 2752  is               8.924999999999999%\n",
            "The validation accuracy at iteration 2768  is               9.049999999999999%\n",
            "The validation accuracy at iteration 2784  is               9.075%\n",
            "The validation accuracy at iteration 2800  is               9.049999999999999%\n",
            "The validation accuracy at iteration 2816  is               9.175%\n",
            "The validation accuracy at iteration 2832  is               9.175%\n",
            "The validation accuracy at iteration 2848  is               9.175%\n",
            "The validation accuracy at iteration 2864  is               9.125%\n",
            "The validation accuracy at iteration 2880  is               9.275%\n",
            "The validation accuracy at iteration 2896  is               9.4%\n",
            "The validation accuracy at iteration 2912  is               9.525%\n",
            "The validation accuracy at iteration 2928  is               9.475%\n",
            "The validation accuracy at iteration 2944  is               9.4%\n",
            "The validation accuracy at iteration 2960  is               9.475%\n",
            "The validation accuracy at iteration 2976  is               9.725%\n",
            "The validation accuracy at iteration 2992  is               9.75%\n",
            "The validation accuracy at iteration 3008  is               9.775%\n",
            "The validation accuracy at iteration 3024  is               9.825000000000001%\n",
            "The validation accuracy at iteration 3040  is               9.85%\n",
            "The validation accuracy at iteration 3056  is               9.85%\n",
            "The validation accuracy at iteration 3072  is               9.85%\n",
            "The validation accuracy at iteration 3088  is               9.85%\n",
            "The validation accuracy at iteration 3104  is               9.85%\n",
            "The validation accuracy at iteration 3120  is               9.85%\n",
            "The validation accuracy at iteration 3136  is               9.85%\n",
            "The validation accuracy at iteration 3152  is               9.85%\n",
            "The validation accuracy at iteration 3168  is               9.875%\n",
            "The validation accuracy at iteration 3184  is               9.875%\n",
            "The validation accuracy at iteration 3200  is               9.875%\n",
            "The validation accuracy at iteration 3216  is               9.875%\n",
            "The validation accuracy at iteration 3232  is               9.875%\n",
            "The validation accuracy at iteration 3248  is               9.875%\n",
            "The validation accuracy at iteration 3264  is               9.875%\n",
            "The validation accuracy at iteration 3280  is               9.875%\n",
            "The validation accuracy at iteration 3296  is               9.875%\n",
            "The validation accuracy at iteration 3312  is               9.875%\n",
            "The validation accuracy at iteration 3328  is               9.875%\n",
            "The validation accuracy at iteration 3344  is               9.875%\n",
            "The validation accuracy at iteration 3360  is               9.85%\n",
            "The validation accuracy at iteration 3376  is               9.85%\n",
            "The validation accuracy at iteration 3392  is               9.875%\n",
            "The validation accuracy at iteration 3408  is               9.875%\n",
            "The validation accuracy at iteration 3424  is               9.875%\n",
            "The validation accuracy at iteration 3440  is               9.875%\n",
            "The validation accuracy at iteration 3456  is               9.875%\n",
            "The validation accuracy at iteration 3472  is               9.875%\n",
            "The validation accuracy at iteration 3488  is               9.875%\n",
            "The validation accuracy at iteration 3504  is               9.875%\n",
            "The validation accuracy at iteration 3520  is               9.875%\n",
            "The validation accuracy at iteration 3536  is               9.875%\n",
            "The validation accuracy at iteration 3552  is               9.875%\n",
            "The validation accuracy at iteration 3568  is               9.875%\n",
            "The validation accuracy at iteration 3584  is               9.875%\n",
            "The validation accuracy at iteration 3600  is               9.875%\n",
            "The validation accuracy at iteration 3616  is               9.875%\n",
            "The validation accuracy at iteration 3632  is               9.875%\n",
            "The validation accuracy at iteration 3648  is               9.875%\n",
            "The validation accuracy at iteration 3664  is               9.875%\n",
            "The validation accuracy at iteration 3680  is               9.875%\n",
            "The validation accuracy at iteration 3696  is               9.875%\n",
            "The validation accuracy at iteration 3712  is               9.875%\n",
            "The validation accuracy at iteration 3728  is               9.875%\n",
            "The validation accuracy at iteration 3744  is               9.875%\n",
            "The validation accuracy at iteration 3760  is               9.875%\n",
            "The validation accuracy at iteration 3776  is               9.875%\n",
            "The validation accuracy at iteration 3792  is               9.875%\n",
            "The validation accuracy at iteration 3808  is               9.875%\n",
            "The validation accuracy at iteration 3824  is               9.875%\n",
            "The validation accuracy at iteration 3840  is               9.875%\n",
            "The validation accuracy at iteration 3856  is               9.875%\n",
            "The validation accuracy at iteration 3872  is               9.875%\n",
            "The validation accuracy at iteration 3888  is               9.875%\n",
            "The validation accuracy at iteration 3904  is               9.85%\n",
            "The validation accuracy at iteration 3920  is               9.85%\n",
            "The validation accuracy at iteration 3936  is               9.875%\n",
            "The validation accuracy at iteration 3952  is               9.875%\n",
            "The validation accuracy at iteration 3968  is               9.875%\n",
            "The validation accuracy at iteration 3984  is               9.875%\n",
            "The validation accuracy at iteration 4000  is               9.875%\n",
            "The validation accuracy at iteration 4016  is               9.875%\n",
            "The validation accuracy at iteration 4032  is               9.875%\n",
            "The validation accuracy at iteration 4048  is               9.875%\n",
            "The validation accuracy at iteration 4064  is               9.875%\n",
            "The validation accuracy at iteration 4080  is               9.875%\n",
            "The validation accuracy at iteration 4096  is               9.875%\n",
            "The validation accuracy at iteration 4112  is               9.875%\n",
            "The validation accuracy at iteration 4128  is               9.875%\n",
            "The validation accuracy at iteration 4144  is               9.85%\n",
            "The validation accuracy at iteration 4160  is               9.875%\n",
            "The validation accuracy at iteration 4176  is               9.875%\n",
            "The validation accuracy at iteration 4192  is               9.85%\n",
            "The validation accuracy at iteration 4208  is               9.85%\n",
            "The validation accuracy at iteration 4224  is               9.85%\n",
            "The validation accuracy at iteration 4240  is               9.85%\n",
            "The validation accuracy at iteration 4256  is               9.875%\n",
            "The validation accuracy at iteration 4272  is               9.875%\n",
            "The validation accuracy at iteration 4288  is               9.875%\n",
            "The validation accuracy at iteration 4304  is               9.875%\n",
            "The validation accuracy at iteration 4320  is               9.875%\n",
            "The validation accuracy at iteration 4336  is               9.875%\n",
            "The validation accuracy at iteration 4352  is               9.875%\n",
            "The validation accuracy at iteration 4368  is               9.875%\n",
            "The validation accuracy at iteration 4384  is               9.875%\n",
            "The validation accuracy at iteration 4400  is               9.875%\n",
            "The validation accuracy at iteration 4416  is               9.875%\n",
            "The validation accuracy at iteration 4432  is               9.875%\n",
            "The validation accuracy at iteration 4448  is               9.85%\n",
            "The validation accuracy at iteration 4464  is               9.85%\n",
            "The validation accuracy at iteration 4480  is               9.85%\n",
            "The validation accuracy at iteration 4496  is               9.85%\n",
            "The validation accuracy at iteration 4512  is               9.85%\n",
            "The validation accuracy at iteration 4528  is               9.85%\n",
            "The validation accuracy at iteration 4544  is               9.85%\n",
            "The validation accuracy at iteration 4560  is               9.85%\n",
            "The validation accuracy at iteration 4576  is               9.875%\n",
            "The validation accuracy at iteration 4592  is               9.875%\n",
            "The validation accuracy at iteration 4608  is               9.875%\n",
            "The validation accuracy at iteration 4624  is               9.875%\n",
            "The validation accuracy at iteration 4640  is               9.875%\n",
            "The validation accuracy at iteration 4656  is               9.875%\n",
            "The validation accuracy at iteration 4672  is               9.875%\n",
            "The validation accuracy at iteration 4688  is               9.85%\n",
            "The validation accuracy at iteration 4704  is               9.875%\n",
            "The validation accuracy at iteration 4720  is               9.875%\n",
            "The validation accuracy at iteration 4736  is               9.85%\n",
            "The validation accuracy at iteration 4752  is               9.875%\n",
            "The validation accuracy at iteration 4768  is               9.85%\n",
            "The validation accuracy at iteration 4784  is               9.85%\n",
            "The validation accuracy at iteration 4800  is               9.85%\n",
            "The validation accuracy at iteration 4816  is               9.85%\n",
            "The validation accuracy at iteration 4832  is               9.85%\n",
            "The validation accuracy at iteration 4848  is               9.85%\n",
            "The validation accuracy at iteration 4864  is               9.85%\n",
            "The validation accuracy at iteration 4880  is               9.85%\n",
            "The validation accuracy at iteration 4896  is               9.85%\n",
            "The validation accuracy at iteration 4912  is               9.875%\n",
            "The validation accuracy at iteration 4928  is               9.875%\n",
            "The validation accuracy at iteration 4944  is               9.875%\n",
            "The validation accuracy at iteration 4960  is               9.875%\n",
            "The validation accuracy at iteration 4976  is               9.875%\n",
            "The validation accuracy at iteration 4992  is               9.875%\n",
            "The validation accuracy at iteration 5008  is               9.85%\n",
            "The validation accuracy at iteration 5024  is               9.875%\n",
            "The validation accuracy at iteration 5040  is               9.875%\n",
            "The validation accuracy at iteration 5056  is               9.875%\n",
            "The validation accuracy at iteration 5072  is               9.875%\n",
            "The validation accuracy at iteration 5088  is               9.85%\n",
            "The validation accuracy at iteration 5104  is               9.85%\n",
            "The validation accuracy at iteration 5120  is               9.85%\n",
            "The validation accuracy at iteration 5136  is               9.85%\n",
            "The validation accuracy at iteration 5152  is               9.85%\n",
            "The validation accuracy at iteration 5168  is               9.85%\n",
            "The validation accuracy at iteration 5184  is               9.85%\n",
            "The validation accuracy at iteration 5200  is               9.85%\n",
            "The validation accuracy at iteration 5216  is               9.875%\n",
            "The validation accuracy at iteration 5232  is               9.875%\n",
            "The validation accuracy at iteration 5248  is               9.875%\n",
            "The validation accuracy at iteration 5264  is               9.875%\n",
            "The validation accuracy at iteration 5280  is               9.875%\n",
            "The validation accuracy at iteration 5296  is               9.875%\n",
            "The validation accuracy at iteration 5312  is               9.875%\n",
            "The validation accuracy at iteration 5328  is               9.875%\n",
            "The validation accuracy at iteration 5344  is               9.875%\n",
            "The validation accuracy at iteration 5360  is               9.875%\n",
            "The validation accuracy at iteration 5376  is               9.875%\n",
            "The validation accuracy at iteration 5392  is               9.875%\n",
            "The validation accuracy at iteration 5408  is               9.875%\n",
            "The validation accuracy at iteration 5424  is               9.85%\n",
            "The validation accuracy at iteration 5440  is               9.875%\n",
            "The validation accuracy at iteration 5456  is               9.85%\n",
            "The validation accuracy at iteration 5472  is               9.85%\n",
            "The validation accuracy at iteration 5488  is               9.85%\n",
            "The validation accuracy at iteration 5504  is               9.85%\n",
            "The validation accuracy at iteration 5520  is               9.85%\n",
            "The validation accuracy at iteration 5536  is               9.875%\n",
            "The validation accuracy at iteration 5552  is               9.875%\n",
            "The validation accuracy at iteration 5568  is               9.875%\n",
            "The validation accuracy at iteration 5584  is               9.875%\n",
            "The validation accuracy at iteration 5600  is               9.875%\n",
            "The validation accuracy at iteration 5616  is               9.875%\n",
            "The validation accuracy at iteration 5632  is               9.875%\n",
            "The validation accuracy at iteration 5648  is               9.875%\n",
            "The validation accuracy at iteration 5664  is               9.875%\n",
            "The validation accuracy at iteration 5680  is               9.875%\n",
            "The validation accuracy at iteration 5696  is               9.875%\n",
            "The validation accuracy at iteration 5712  is               9.875%\n",
            "The validation accuracy at iteration 5728  is               9.875%\n",
            "The validation accuracy at iteration 5744  is               9.875%\n",
            "The validation accuracy at iteration 5760  is               9.875%\n",
            "The validation accuracy at iteration 5776  is               9.875%\n",
            "The validation accuracy at iteration 5792  is               9.875%\n",
            "The validation accuracy at iteration 5808  is               9.875%\n",
            "The validation accuracy at iteration 5824  is               9.875%\n",
            "The validation accuracy at iteration 5840  is               9.875%\n",
            "The validation accuracy at iteration 5856  is               9.875%\n",
            "The validation accuracy at iteration 5872  is               9.875%\n",
            "The validation accuracy at iteration 5888  is               9.875%\n",
            "The validation accuracy at iteration 5904  is               9.875%\n",
            "The validation accuracy at iteration 5920  is               9.875%\n",
            "The validation accuracy at iteration 5936  is               9.875%\n",
            "The validation accuracy at iteration 5952  is               9.875%\n",
            "The validation accuracy at iteration 5968  is               9.875%\n",
            "The validation accuracy at iteration 5984  is               9.875%\n",
            "The validation accuracy at iteration 6000  is               9.875%\n",
            "The validation accuracy at iteration 6016  is               9.875%\n",
            "The validation accuracy at iteration 6032  is               9.875%\n",
            "The validation accuracy at iteration 6048  is               9.875%\n",
            "The validation accuracy at iteration 6064  is               9.875%\n",
            "The validation accuracy at iteration 6080  is               9.875%\n",
            "The validation accuracy at iteration 6096  is               9.875%\n",
            "The validation accuracy at iteration 6112  is               9.875%\n",
            "The validation accuracy at iteration 6128  is               9.875%\n",
            "The validation accuracy at iteration 6144  is               9.875%\n",
            "The validation accuracy at iteration 6160  is               9.875%\n",
            "The validation accuracy at iteration 6176  is               9.875%\n",
            "The validation accuracy at iteration 6192  is               9.875%\n",
            "The validation accuracy at iteration 6208  is               9.875%\n",
            "The validation accuracy at iteration 6224  is               9.875%\n",
            "The validation accuracy at iteration 6240  is               9.875%\n",
            "The validation accuracy at iteration 6256  is               9.875%\n",
            "The validation accuracy at iteration 6272  is               9.875%\n",
            "The validation accuracy at iteration 6288  is               9.875%\n",
            "The validation accuracy at iteration 6304  is               9.875%\n",
            "The validation accuracy at iteration 6320  is               9.875%\n",
            "The validation accuracy at iteration 6336  is               9.875%\n",
            "The validation accuracy at iteration 6352  is               9.875%\n",
            "The validation accuracy at iteration 6368  is               9.875%\n",
            "The validation accuracy at iteration 6384  is               9.875%\n",
            "The validation accuracy at iteration 6400  is               9.875%\n",
            "The validation accuracy at iteration 6416  is               9.875%\n",
            "The validation accuracy at iteration 6432  is               9.875%\n",
            "The validation accuracy at iteration 6448  is               9.875%\n",
            "The validation accuracy at iteration 6464  is               9.875%\n",
            "The validation accuracy at iteration 6480  is               9.875%\n",
            "The validation accuracy at iteration 6496  is               9.875%\n",
            "The validation accuracy at iteration 6512  is               9.875%\n",
            "The validation accuracy at iteration 6528  is               9.875%\n",
            "The validation accuracy at iteration 6544  is               9.875%\n",
            "The validation accuracy at iteration 6560  is               9.875%\n",
            "The validation accuracy at iteration 6576  is               9.875%\n",
            "The validation accuracy at iteration 6592  is               9.875%\n",
            "The validation accuracy at iteration 6608  is               9.875%\n",
            "The validation accuracy at iteration 6624  is               9.875%\n",
            "The validation accuracy at iteration 6640  is               9.875%\n",
            "The validation accuracy at iteration 6656  is               9.875%\n",
            "The validation accuracy at iteration 6672  is               9.875%\n",
            "The validation accuracy at iteration 6688  is               9.875%\n",
            "The validation accuracy at iteration 6704  is               9.875%\n",
            "The validation accuracy at iteration 6720  is               9.875%\n",
            "The validation accuracy at iteration 6736  is               9.875%\n",
            "The validation accuracy at iteration 6752  is               9.875%\n",
            "The validation accuracy at iteration 6768  is               9.875%\n",
            "The validation accuracy at iteration 6784  is               9.875%\n",
            "The validation accuracy at iteration 6800  is               9.875%\n",
            "The validation accuracy at iteration 6816  is               9.875%\n",
            "The validation accuracy at iteration 6832  is               9.875%\n",
            "The validation accuracy at iteration 6848  is               9.875%\n",
            "The validation accuracy at iteration 6864  is               9.875%\n",
            "The validation accuracy at iteration 6880  is               9.85%\n",
            "The validation accuracy at iteration 6896  is               9.875%\n",
            "The validation accuracy at iteration 6912  is               9.875%\n",
            "The validation accuracy at iteration 6928  is               9.875%\n",
            "The validation accuracy at iteration 6944  is               9.875%\n",
            "The validation accuracy at iteration 6960  is               9.875%\n",
            "The validation accuracy at iteration 6976  is               9.875%\n",
            "The validation accuracy at iteration 6992  is               9.875%\n",
            "The validation accuracy at iteration 7008  is               9.875%\n",
            "The validation accuracy at iteration 7024  is               9.875%\n",
            "The validation accuracy at iteration 7040  is               9.875%\n",
            "The validation accuracy at iteration 7056  is               9.875%\n",
            "The validation accuracy at iteration 7072  is               9.875%\n",
            "The validation accuracy at iteration 7088  is               9.875%\n",
            "The validation accuracy at iteration 7104  is               9.875%\n",
            "The validation accuracy at iteration 7120  is               9.875%\n",
            "The validation accuracy at iteration 7136  is               9.875%\n",
            "The validation accuracy at iteration 7152  is               9.875%\n",
            "The validation accuracy at iteration 7168  is               9.875%\n",
            "The validation accuracy at iteration 7184  is               9.85%\n",
            "The validation accuracy at iteration 7200  is               9.85%\n",
            "The validation accuracy at iteration 7216  is               9.85%\n",
            "The validation accuracy at iteration 7232  is               9.85%\n",
            "The validation accuracy at iteration 7248  is               9.875%\n",
            "The validation accuracy at iteration 7264  is               9.875%\n",
            "The validation accuracy at iteration 7280  is               9.85%\n",
            "The validation accuracy at iteration 7296  is               9.875%\n",
            "The validation accuracy at iteration 7312  is               9.85%\n",
            "The validation accuracy at iteration 7328  is               9.875%\n",
            "The validation accuracy at iteration 7344  is               9.875%\n",
            "The validation accuracy at iteration 7360  is               9.875%\n",
            "The validation accuracy at iteration 7376  is               9.875%\n",
            "The validation accuracy at iteration 7392  is               9.875%\n",
            "The validation accuracy at iteration 7408  is               9.875%\n",
            "The validation accuracy at iteration 7424  is               9.875%\n",
            "The validation accuracy at iteration 7440  is               9.875%\n",
            "The validation accuracy at iteration 7456  is               9.85%\n",
            "The validation accuracy at iteration 7472  is               9.85%\n",
            "The validation accuracy at iteration 7488  is               9.85%\n",
            "The validation accuracy at iteration 7504  is               9.85%\n",
            "The validation accuracy at iteration 7520  is               9.85%\n",
            "The validation accuracy at iteration 7536  is               9.85%\n",
            "The validation accuracy at iteration 7552  is               9.85%\n",
            "The validation accuracy at iteration 7568  is               9.85%\n",
            "The validation accuracy at iteration 7584  is               9.85%\n",
            "The validation accuracy at iteration 7600  is               9.85%\n",
            "The validation accuracy at iteration 7616  is               9.85%\n",
            "The validation accuracy at iteration 7632  is               9.85%\n",
            "The validation accuracy at iteration 7648  is               9.85%\n",
            "The validation accuracy at iteration 7664  is               9.85%\n",
            "The validation accuracy at iteration 7680  is               9.85%\n",
            "The validation accuracy at iteration 7696  is               9.85%\n",
            "The validation accuracy at iteration 7712  is               9.85%\n",
            "The validation accuracy at iteration 7728  is               9.85%\n",
            "The validation accuracy at iteration 7744  is               9.85%\n",
            "The validation accuracy at iteration 7760  is               9.85%\n",
            "The validation accuracy at iteration 7776  is               9.85%\n",
            "The validation accuracy at iteration 7792  is               9.85%\n",
            "The validation accuracy at iteration 7808  is               9.85%\n",
            "The validation accuracy at iteration 7824  is               9.85%\n",
            "The validation accuracy at iteration 7840  is               9.85%\n",
            "The validation accuracy at iteration 7856  is               9.85%\n",
            "The validation accuracy at iteration 7872  is               9.85%\n",
            "The validation accuracy at iteration 7888  is               9.85%\n",
            "The validation accuracy at iteration 7904  is               9.85%\n",
            "The validation accuracy at iteration 7920  is               9.85%\n",
            "The validation accuracy at iteration 7936  is               9.85%\n",
            "The validation accuracy at iteration 7952  is               9.85%\n",
            "The validation accuracy at iteration 7968  is               9.85%\n",
            "The validation accuracy at iteration 7984  is               9.85%\n",
            "The validation accuracy at iteration 8000  is               9.85%\n",
            "The validation accuracy at iteration 8016  is               9.85%\n",
            "The validation accuracy at iteration 8032  is               9.85%\n",
            "The validation accuracy at iteration 8048  is               9.85%\n",
            "The validation accuracy at iteration 8064  is               9.85%\n",
            "The validation accuracy at iteration 8080  is               9.85%\n",
            "The validation accuracy at iteration 8096  is               9.85%\n",
            "The validation accuracy at iteration 8112  is               9.85%\n",
            "The validation accuracy at iteration 8128  is               9.85%\n",
            "The validation accuracy at iteration 8144  is               9.85%\n",
            "The validation accuracy at iteration 8160  is               9.85%\n",
            "The validation accuracy at iteration 8176  is               9.85%\n",
            "The validation accuracy at iteration 8192  is               9.85%\n",
            "The validation accuracy at iteration 8208  is               9.85%\n",
            "The validation accuracy at iteration 8224  is               9.85%\n",
            "The validation accuracy at iteration 8240  is               9.85%\n",
            "The validation accuracy at iteration 8256  is               9.85%\n",
            "The validation accuracy at iteration 8272  is               9.85%\n",
            "The validation accuracy at iteration 8288  is               9.85%\n",
            "The validation accuracy at iteration 8304  is               9.85%\n",
            "The validation accuracy at iteration 8320  is               9.85%\n",
            "The validation accuracy at iteration 8336  is               9.85%\n",
            "The validation accuracy at iteration 8352  is               9.85%\n",
            "The validation accuracy at iteration 8368  is               9.85%\n",
            "The validation accuracy at iteration 8384  is               9.85%\n",
            "The validation accuracy at iteration 8400  is               9.85%\n",
            "The validation accuracy at iteration 8416  is               9.85%\n",
            "The validation accuracy at iteration 8432  is               9.85%\n",
            "The validation accuracy at iteration 8448  is               9.85%\n",
            "The validation accuracy at iteration 8464  is               9.85%\n",
            "The validation accuracy at iteration 8480  is               9.85%\n",
            "The validation accuracy at iteration 8496  is               9.85%\n",
            "The validation accuracy at iteration 8512  is               9.85%\n",
            "The validation accuracy at iteration 8528  is               9.85%\n",
            "The validation accuracy at iteration 8544  is               9.85%\n",
            "The validation accuracy at iteration 8560  is               9.85%\n",
            "The validation accuracy at iteration 8576  is               9.85%\n",
            "The validation accuracy at iteration 8592  is               9.85%\n",
            "The validation accuracy at iteration 8608  is               9.85%\n",
            "The validation accuracy at iteration 8624  is               9.85%\n",
            "The validation accuracy at iteration 8640  is               9.85%\n",
            "The validation accuracy at iteration 8656  is               9.85%\n",
            "The validation accuracy at iteration 8672  is               9.85%\n",
            "The validation accuracy at iteration 8688  is               9.85%\n",
            "The validation accuracy at iteration 8704  is               9.85%\n",
            "The validation accuracy at iteration 8720  is               9.85%\n",
            "The validation accuracy at iteration 8736  is               9.85%\n",
            "The validation accuracy at iteration 8752  is               9.85%\n",
            "The validation accuracy at iteration 8768  is               9.85%\n",
            "The validation accuracy at iteration 8784  is               9.85%\n",
            "The validation accuracy at iteration 8800  is               9.85%\n",
            "The validation accuracy at iteration 8816  is               9.85%\n",
            "The validation accuracy at iteration 8832  is               9.85%\n",
            "The validation accuracy at iteration 8848  is               9.85%\n",
            "The validation accuracy at iteration 8864  is               9.85%\n",
            "The validation accuracy at iteration 8880  is               9.85%\n",
            "The validation accuracy at iteration 8896  is               9.85%\n",
            "The validation accuracy at iteration 8912  is               9.85%\n",
            "The validation accuracy at iteration 8928  is               9.85%\n",
            "The validation accuracy at iteration 8944  is               9.85%\n",
            "The validation accuracy at iteration 8960  is               9.85%\n",
            "The validation accuracy at iteration 8976  is               9.85%\n",
            "The validation accuracy at iteration 8992  is               9.85%\n",
            "The validation accuracy at iteration 9008  is               9.85%\n",
            "The validation accuracy at iteration 9024  is               9.85%\n",
            "The validation accuracy at iteration 9040  is               9.85%\n",
            "The validation accuracy at iteration 9056  is               9.85%\n",
            "The validation accuracy at iteration 9072  is               9.85%\n",
            "The validation accuracy at iteration 9088  is               9.85%\n",
            "The validation accuracy at iteration 9104  is               9.85%\n",
            "The validation accuracy at iteration 9120  is               9.85%\n",
            "The validation accuracy at iteration 9136  is               9.85%\n",
            "The validation accuracy at iteration 9152  is               9.85%\n",
            "The validation accuracy at iteration 9168  is               9.85%\n",
            "The validation accuracy at iteration 9184  is               9.85%\n",
            "The validation accuracy at iteration 9200  is               9.85%\n",
            "The validation accuracy at iteration 9216  is               9.85%\n",
            "The validation accuracy at iteration 9232  is               9.85%\n",
            "The validation accuracy at iteration 9248  is               9.85%\n",
            "The validation accuracy at iteration 9264  is               9.85%\n",
            "The validation accuracy at iteration 9280  is               9.85%\n",
            "The validation accuracy at iteration 9296  is               9.85%\n",
            "The validation accuracy at iteration 9312  is               9.85%\n",
            "The validation accuracy at iteration 9328  is               9.85%\n",
            "The validation accuracy at iteration 9344  is               9.85%\n",
            "The validation accuracy at iteration 9360  is               9.85%\n",
            "The validation accuracy at iteration 9376  is               9.85%\n",
            "The validation accuracy at iteration 9392  is               9.85%\n",
            "The validation accuracy at iteration 9408  is               9.85%\n",
            "The validation accuracy at iteration 9424  is               9.85%\n",
            "The validation accuracy at iteration 9440  is               9.85%\n",
            "The validation accuracy at iteration 9456  is               9.85%\n",
            "The validation accuracy at iteration 9472  is               9.85%\n",
            "The validation accuracy at iteration 9488  is               9.85%\n",
            "The validation accuracy at iteration 9504  is               9.85%\n",
            "The validation accuracy at iteration 9520  is               9.85%\n",
            "The validation accuracy at iteration 9536  is               9.85%\n",
            "The validation accuracy at iteration 9552  is               9.85%\n",
            "The validation accuracy at iteration 9568  is               9.85%\n",
            "The validation accuracy at iteration 9584  is               9.85%\n",
            "The validation accuracy at iteration 9600  is               9.85%\n",
            "The validation accuracy at iteration 9616  is               9.85%\n",
            "The validation accuracy at iteration 9632  is               9.85%\n",
            "The validation accuracy at iteration 9648  is               9.85%\n",
            "The validation accuracy at iteration 9664  is               9.85%\n",
            "The validation accuracy at iteration 9680  is               9.85%\n",
            "The validation accuracy at iteration 9696  is               9.85%\n",
            "The validation accuracy at iteration 9712  is               9.85%\n",
            "The validation accuracy at iteration 9728  is               9.85%\n",
            "The validation accuracy at iteration 9744  is               9.85%\n",
            "The validation accuracy at iteration 9760  is               9.85%\n",
            "The validation accuracy at iteration 9776  is               9.85%\n",
            "The validation accuracy at iteration 9792  is               9.85%\n",
            "The validation accuracy at iteration 9808  is               9.85%\n",
            "The validation accuracy at iteration 9824  is               9.85%\n",
            "The validation accuracy at iteration 9840  is               9.85%\n",
            "The validation accuracy at iteration 9856  is               9.85%\n",
            "The validation accuracy at iteration 9872  is               9.85%\n",
            "The validation accuracy at iteration 9888  is               9.85%\n",
            "The validation accuracy at iteration 9904  is               9.85%\n",
            "The validation accuracy at iteration 9920  is               9.85%\n",
            "The validation accuracy at iteration 9936  is               9.85%\n",
            "The validation accuracy at iteration 9952  is               9.85%\n",
            "The validation accuracy at iteration 9968  is               9.85%\n",
            "The validation accuracy at iteration 9984  is               9.85%\n",
            "The validation accuracy at iteration 10000  is               9.85%\n",
            "The validation accuracy at iteration 10016  is               9.85%\n",
            "The validation accuracy at iteration 10032  is               9.85%\n",
            "The validation accuracy at iteration 10048  is               9.85%\n",
            "The validation accuracy at iteration 10064  is               9.85%\n",
            "The validation accuracy at iteration 10080  is               9.85%\n",
            "The validation accuracy at iteration 10096  is               9.85%\n",
            "The validation accuracy at iteration 10112  is               9.85%\n",
            "The validation accuracy at iteration 10128  is               9.85%\n",
            "The validation accuracy at iteration 10144  is               9.85%\n",
            "The validation accuracy at iteration 10160  is               9.85%\n",
            "The validation accuracy at iteration 10176  is               9.85%\n",
            "The validation accuracy at iteration 10192  is               9.85%\n",
            "The validation accuracy at iteration 10208  is               9.85%\n",
            "The validation accuracy at iteration 10224  is               9.85%\n",
            "The validation accuracy at iteration 10240  is               9.85%\n",
            "The validation accuracy at iteration 10256  is               9.85%\n",
            "The validation accuracy at iteration 10272  is               9.85%\n",
            "The validation accuracy at iteration 10288  is               9.85%\n",
            "The validation accuracy at iteration 10304  is               9.85%\n",
            "The validation accuracy at iteration 10320  is               9.85%\n",
            "The validation accuracy at iteration 10336  is               9.85%\n",
            "The validation accuracy at iteration 10352  is               9.85%\n",
            "The validation accuracy at iteration 10368  is               9.85%\n",
            "The validation accuracy at iteration 10384  is               9.85%\n",
            "The validation accuracy at iteration 10400  is               9.85%\n",
            "The validation accuracy at iteration 10416  is               9.85%\n",
            "The validation accuracy at iteration 10432  is               9.85%\n",
            "The validation accuracy at iteration 10448  is               9.85%\n",
            "The validation accuracy at iteration 10464  is               9.85%\n",
            "The validation accuracy at iteration 10480  is               9.85%\n",
            "The validation accuracy at iteration 10496  is               9.85%\n",
            "The validation accuracy at iteration 10512  is               9.85%\n",
            "The validation accuracy at iteration 10528  is               9.85%\n",
            "The validation accuracy at iteration 10544  is               9.85%\n",
            "The validation accuracy at iteration 10560  is               9.85%\n",
            "The validation accuracy at iteration 10576  is               9.85%\n",
            "The validation accuracy at iteration 10592  is               9.85%\n",
            "The validation accuracy at iteration 10608  is               9.85%\n",
            "The validation accuracy at iteration 10624  is               9.85%\n",
            "The validation accuracy at iteration 10640  is               9.85%\n",
            "The validation accuracy at iteration 10656  is               9.85%\n",
            "The validation accuracy at iteration 10672  is               9.85%\n",
            "The validation accuracy at iteration 10688  is               9.85%\n",
            "The validation accuracy at iteration 10704  is               9.85%\n",
            "The validation accuracy at iteration 10720  is               9.85%\n",
            "The validation accuracy at iteration 10736  is               9.85%\n",
            "The validation accuracy at iteration 10752  is               9.85%\n",
            "The validation accuracy at iteration 10768  is               9.85%\n",
            "The validation accuracy at iteration 10784  is               9.85%\n",
            "The validation accuracy at iteration 10800  is               9.85%\n",
            "The validation accuracy at iteration 10816  is               9.85%\n",
            "The validation accuracy at iteration 10832  is               9.85%\n",
            "The validation accuracy at iteration 10848  is               9.85%\n",
            "The validation accuracy at iteration 10864  is               9.85%\n",
            "The validation accuracy at iteration 10880  is               9.85%\n",
            "The validation accuracy at iteration 10896  is               9.85%\n",
            "The validation accuracy at iteration 10912  is               9.85%\n",
            "The validation accuracy at iteration 10928  is               9.85%\n",
            "The validation accuracy at iteration 10944  is               9.85%\n",
            "The validation accuracy at iteration 10960  is               9.85%\n",
            "The validation accuracy at iteration 10976  is               9.85%\n",
            "The validation accuracy at iteration 10992  is               9.85%\n",
            "The validation accuracy at iteration 11008  is               9.85%\n",
            "The validation accuracy at iteration 11024  is               9.85%\n",
            "The validation accuracy at iteration 11040  is               9.85%\n",
            "The validation accuracy at iteration 11056  is               9.85%\n",
            "The validation accuracy at iteration 11072  is               9.85%\n",
            "The validation accuracy at iteration 11088  is               9.85%\n",
            "The validation accuracy at iteration 11104  is               9.85%\n",
            "The validation accuracy at iteration 11120  is               9.85%\n",
            "The validation accuracy at iteration 11136  is               9.85%\n",
            "The validation accuracy at iteration 11152  is               9.85%\n",
            "The validation accuracy at iteration 11168  is               9.85%\n",
            "The validation accuracy at iteration 11184  is               9.85%\n",
            "The validation accuracy at iteration 11200  is               9.85%\n",
            "The validation accuracy at iteration 11216  is               9.85%\n",
            "The validation accuracy at iteration 11232  is               9.85%\n",
            "The validation accuracy at iteration 11248  is               9.85%\n",
            "The validation accuracy at iteration 11264  is               9.85%\n",
            "The validation accuracy at iteration 11280  is               9.85%\n",
            "The validation accuracy at iteration 11296  is               9.85%\n",
            "The validation accuracy at iteration 11312  is               9.85%\n",
            "The validation accuracy at iteration 11328  is               9.85%\n",
            "The validation accuracy at iteration 11344  is               9.85%\n",
            "The validation accuracy at iteration 11360  is               9.85%\n",
            "The validation accuracy at iteration 11376  is               9.85%\n",
            "The validation accuracy at iteration 11392  is               9.85%\n",
            "The validation accuracy at iteration 11408  is               9.85%\n",
            "The validation accuracy at iteration 11424  is               9.85%\n",
            "The validation accuracy at iteration 11440  is               9.85%\n",
            "The validation accuracy at iteration 11456  is               9.85%\n",
            "The validation accuracy at iteration 11472  is               9.85%\n",
            "The validation accuracy at iteration 11488  is               9.85%\n",
            "The validation accuracy at iteration 11504  is               9.85%\n",
            "The validation accuracy at iteration 11520  is               9.85%\n",
            "The validation accuracy at iteration 11536  is               9.85%\n",
            "The validation accuracy at iteration 11552  is               9.85%\n",
            "The validation accuracy at iteration 11568  is               9.85%\n",
            "The validation accuracy at iteration 11584  is               9.85%\n",
            "The validation accuracy at iteration 11600  is               9.85%\n",
            "The validation accuracy at iteration 11616  is               9.85%\n",
            "The validation accuracy at iteration 11632  is               9.85%\n",
            "The validation accuracy at iteration 11648  is               9.85%\n",
            "The validation accuracy at iteration 11664  is               9.85%\n",
            "The validation accuracy at iteration 11680  is               9.85%\n",
            "The validation accuracy at iteration 11696  is               9.85%\n",
            "The validation accuracy at iteration 11712  is               9.85%\n",
            "The validation accuracy at iteration 11728  is               9.85%\n",
            "The validation accuracy at iteration 11744  is               9.85%\n",
            "The validation accuracy at iteration 11760  is               9.85%\n",
            "The validation accuracy at iteration 11776  is               9.85%\n",
            "The validation accuracy at iteration 11792  is               9.85%\n",
            "The validation accuracy at iteration 11808  is               9.85%\n",
            "The validation accuracy at iteration 11824  is               9.85%\n",
            "The validation accuracy at iteration 11840  is               9.85%\n",
            "The validation accuracy at iteration 11856  is               9.85%\n",
            "The validation accuracy at iteration 11872  is               9.85%\n",
            "The validation accuracy at iteration 11888  is               9.85%\n",
            "The validation accuracy at iteration 11904  is               9.85%\n",
            "The validation accuracy at iteration 11920  is               9.85%\n",
            "The validation accuracy at iteration 11936  is               9.85%\n",
            "The validation accuracy at iteration 11952  is               9.85%\n",
            "The validation accuracy at iteration 11968  is               9.85%\n",
            "The validation accuracy at iteration 11984  is               9.85%\n",
            "The validation accuracy at iteration 12000  is               9.85%\n",
            "The validation accuracy at iteration 12016  is               9.85%\n",
            "The validation accuracy at iteration 12032  is               9.85%\n",
            "The validation accuracy at iteration 12048  is               9.85%\n",
            "The validation accuracy at iteration 12064  is               9.85%\n",
            "The validation accuracy at iteration 12080  is               9.85%\n",
            "The validation accuracy at iteration 12096  is               9.85%\n",
            "The validation accuracy at iteration 12112  is               9.85%\n",
            "The validation accuracy at iteration 12128  is               9.85%\n",
            "The validation accuracy at iteration 12144  is               9.85%\n",
            "The validation accuracy at iteration 12160  is               9.85%\n",
            "The validation accuracy at iteration 12176  is               9.85%\n",
            "The validation accuracy at iteration 12192  is               9.85%\n",
            "The validation accuracy at iteration 12208  is               9.85%\n",
            "The validation accuracy at iteration 12224  is               9.85%\n",
            "The validation accuracy at iteration 12240  is               9.85%\n",
            "The validation accuracy at iteration 12256  is               9.85%\n",
            "The validation accuracy at iteration 12272  is               9.85%\n",
            "The validation accuracy at iteration 12288  is               9.85%\n",
            "The validation accuracy at iteration 12304  is               9.85%\n",
            "The validation accuracy at iteration 12320  is               9.85%\n",
            "The validation accuracy at iteration 12336  is               9.85%\n",
            "The validation accuracy at iteration 12352  is               9.85%\n",
            "The validation accuracy at iteration 12368  is               9.85%\n",
            "The validation accuracy at iteration 12384  is               9.85%\n",
            "The validation accuracy at iteration 12400  is               9.85%\n",
            "The validation accuracy at iteration 12416  is               9.85%\n",
            "The validation accuracy at iteration 12432  is               9.85%\n",
            "The validation accuracy at iteration 12448  is               9.85%\n",
            "The validation accuracy at iteration 12464  is               9.85%\n",
            "The validation accuracy at iteration 12480  is               9.85%\n",
            "The validation accuracy at iteration 12496  is               9.85%\n",
            "The validation accuracy at iteration 12512  is               9.85%\n",
            "The validation accuracy at iteration 12528  is               9.85%\n",
            "The validation accuracy at iteration 12544  is               9.85%\n",
            "The validation accuracy at iteration 12560  is               9.85%\n",
            "The validation accuracy at iteration 12576  is               9.85%\n",
            "The validation accuracy at iteration 12592  is               9.85%\n",
            "The validation accuracy at iteration 12608  is               9.85%\n",
            "The validation accuracy at iteration 12624  is               9.85%\n",
            "The validation accuracy at iteration 12640  is               9.85%\n",
            "The validation accuracy at iteration 12656  is               9.85%\n",
            "The validation accuracy at iteration 12672  is               9.85%\n",
            "The validation accuracy at iteration 12688  is               9.85%\n",
            "The validation accuracy at iteration 12704  is               9.85%\n",
            "The validation accuracy at iteration 12720  is               9.85%\n",
            "The validation accuracy at iteration 12736  is               9.85%\n",
            "The validation accuracy at iteration 12752  is               9.85%\n",
            "The validation accuracy at iteration 12768  is               9.85%\n",
            "The validation accuracy at iteration 12784  is               9.85%\n",
            "The validation accuracy at iteration 12800  is               9.85%\n",
            "The validation accuracy at iteration 12816  is               9.85%\n",
            "The validation accuracy at iteration 12832  is               9.85%\n",
            "The validation accuracy at iteration 12848  is               9.85%\n",
            "The validation accuracy at iteration 12864  is               9.85%\n",
            "The validation accuracy at iteration 12880  is               9.85%\n",
            "The validation accuracy at iteration 12896  is               9.85%\n",
            "The validation accuracy at iteration 12912  is               9.85%\n",
            "The validation accuracy at iteration 12928  is               9.85%\n",
            "The validation accuracy at iteration 12944  is               9.85%\n",
            "The validation accuracy at iteration 12960  is               9.85%\n",
            "The validation accuracy at iteration 12976  is               9.875%\n",
            "The validation accuracy at iteration 12992  is               9.85%\n",
            "The validation accuracy at iteration 13008  is               9.875%\n",
            "The validation accuracy at iteration 13024  is               9.875%\n",
            "The validation accuracy at iteration 13040  is               9.9%\n",
            "The validation accuracy at iteration 13056  is               9.9%\n",
            "The validation accuracy at iteration 13072  is               9.9%\n",
            "The validation accuracy at iteration 13088  is               9.9%\n",
            "The validation accuracy at iteration 13104  is               9.9%\n",
            "The validation accuracy at iteration 13120  is               9.875%\n",
            "The validation accuracy at iteration 13136  is               9.9%\n",
            "The validation accuracy at iteration 13152  is               9.9%\n",
            "The validation accuracy at iteration 13168  is               9.9%\n",
            "The validation accuracy at iteration 13184  is               9.9%\n",
            "The validation accuracy at iteration 13200  is               9.9%\n",
            "The validation accuracy at iteration 13216  is               9.9%\n",
            "The validation accuracy at iteration 13232  is               9.9%\n",
            "The validation accuracy at iteration 13248  is               9.9%\n",
            "The validation accuracy at iteration 13264  is               9.9%\n",
            "The validation accuracy at iteration 13280  is               9.9%\n",
            "The validation accuracy at iteration 13296  is               9.9%\n",
            "The validation accuracy at iteration 13312  is               9.9%\n",
            "The validation accuracy at iteration 13328  is               9.9%\n",
            "The validation accuracy at iteration 13344  is               9.925%\n",
            "The validation accuracy at iteration 13360  is               9.925%\n",
            "The validation accuracy at iteration 13376  is               9.925%\n",
            "The validation accuracy at iteration 13392  is               9.925%\n",
            "The validation accuracy at iteration 13408  is               9.925%\n",
            "The validation accuracy at iteration 13424  is               9.925%\n",
            "The validation accuracy at iteration 13440  is               9.9%\n",
            "The validation accuracy at iteration 13456  is               9.925%\n",
            "The validation accuracy at iteration 13472  is               9.925%\n",
            "The validation accuracy at iteration 13488  is               9.925%\n",
            "The validation accuracy at iteration 13504  is               9.975000000000001%\n",
            "The validation accuracy at iteration 13520  is               9.975000000000001%\n",
            "The validation accuracy at iteration 13536  is               9.975000000000001%\n",
            "The validation accuracy at iteration 13552  is               9.975000000000001%\n",
            "The validation accuracy at iteration 13568  is               9.975000000000001%\n",
            "The validation accuracy at iteration 13584  is               9.925%\n",
            "The validation accuracy at iteration 13600  is               9.925%\n",
            "The validation accuracy at iteration 13616  is               10.0%\n",
            "The validation accuracy at iteration 13632  is               9.975000000000001%\n",
            "The validation accuracy at iteration 13648  is               10.0%\n",
            "The validation accuracy at iteration 13664  is               10.025%\n",
            "The validation accuracy at iteration 13680  is               10.100000000000001%\n",
            "The validation accuracy at iteration 13696  is               10.05%\n",
            "The validation accuracy at iteration 13712  is               10.05%\n",
            "The validation accuracy at iteration 13728  is               10.075000000000001%\n",
            "The validation accuracy at iteration 13744  is               10.100000000000001%\n",
            "The validation accuracy at iteration 13760  is               10.025%\n",
            "The validation accuracy at iteration 13776  is               10.05%\n",
            "The validation accuracy at iteration 13792  is               10.100000000000001%\n",
            "The validation accuracy at iteration 13808  is               10.075000000000001%\n",
            "The validation accuracy at iteration 13824  is               10.15%\n",
            "The validation accuracy at iteration 13840  is               10.15%\n",
            "The validation accuracy at iteration 13856  is               10.125%\n",
            "The validation accuracy at iteration 13872  is               10.15%\n",
            "The validation accuracy at iteration 13888  is               10.15%\n",
            "The validation accuracy at iteration 13904  is               10.100000000000001%\n",
            "The validation accuracy at iteration 13920  is               10.075000000000001%\n",
            "The validation accuracy at iteration 13936  is               10.15%\n",
            "The validation accuracy at iteration 13952  is               10.15%\n",
            "The validation accuracy at iteration 13968  is               10.15%\n",
            "The validation accuracy at iteration 13984  is               10.2%\n",
            "The validation accuracy at iteration 14000  is               10.225%\n",
            "The validation accuracy at iteration 14016  is               10.225%\n",
            "The validation accuracy at iteration 14032  is               10.2%\n",
            "The validation accuracy at iteration 14048  is               10.225%\n",
            "The validation accuracy at iteration 14064  is               10.225%\n",
            "The validation accuracy at iteration 14080  is               10.15%\n",
            "The validation accuracy at iteration 14096  is               10.2%\n",
            "The validation accuracy at iteration 14112  is               10.225%\n",
            "The validation accuracy at iteration 14128  is               10.225%\n",
            "The validation accuracy at iteration 14144  is               10.25%\n",
            "The validation accuracy at iteration 14160  is               10.25%\n",
            "The validation accuracy at iteration 14176  is               10.225%\n",
            "The validation accuracy at iteration 14192  is               10.25%\n",
            "The validation accuracy at iteration 14208  is               10.25%\n",
            "The validation accuracy at iteration 14224  is               10.225%\n",
            "The validation accuracy at iteration 14240  is               10.2%\n",
            "The validation accuracy at iteration 14256  is               10.25%\n",
            "The validation accuracy at iteration 14272  is               10.25%\n",
            "The validation accuracy at iteration 14288  is               10.25%\n",
            "The validation accuracy at iteration 14304  is               10.299999999999999%\n",
            "The validation accuracy at iteration 14320  is               10.35%\n",
            "The validation accuracy at iteration 14336  is               10.299999999999999%\n",
            "The validation accuracy at iteration 14352  is               10.299999999999999%\n",
            "The validation accuracy at iteration 14368  is               10.325%\n",
            "The validation accuracy at iteration 14384  is               10.35%\n",
            "The validation accuracy at iteration 14400  is               10.274999999999999%\n",
            "The validation accuracy at iteration 14416  is               10.299999999999999%\n",
            "The validation accuracy at iteration 14432  is               10.35%\n",
            "The validation accuracy at iteration 14448  is               10.35%\n",
            "The validation accuracy at iteration 14464  is               10.424999999999999%\n",
            "The validation accuracy at iteration 14480  is               10.375%\n",
            "The validation accuracy at iteration 14496  is               10.375%\n",
            "The validation accuracy at iteration 14512  is               10.375%\n",
            "The validation accuracy at iteration 14528  is               10.424999999999999%\n",
            "The validation accuracy at iteration 14544  is               10.35%\n",
            "The validation accuracy at iteration 14560  is               10.35%\n",
            "The validation accuracy at iteration 14576  is               10.45%\n",
            "The validation accuracy at iteration 14592  is               10.4%\n",
            "The validation accuracy at iteration 14608  is               10.45%\n",
            "The validation accuracy at iteration 14624  is               10.525%\n",
            "The validation accuracy at iteration 14640  is               10.625%\n",
            "The validation accuracy at iteration 14656  is               10.575%\n",
            "The validation accuracy at iteration 14672  is               10.575%\n",
            "The validation accuracy at iteration 14688  is               10.575%\n",
            "The validation accuracy at iteration 14704  is               10.625%\n",
            "The validation accuracy at iteration 14720  is               10.475%\n",
            "The validation accuracy at iteration 14736  is               10.575%\n",
            "The validation accuracy at iteration 14752  is               10.625%\n",
            "The validation accuracy at iteration 14768  is               10.549999999999999%\n",
            "The validation accuracy at iteration 14784  is               10.674999999999999%\n",
            "The validation accuracy at iteration 14800  is               10.674999999999999%\n",
            "The validation accuracy at iteration 14816  is               10.674999999999999%\n",
            "The validation accuracy at iteration 14832  is               10.674999999999999%\n",
            "The validation accuracy at iteration 14848  is               10.674999999999999%\n",
            "The validation accuracy at iteration 14864  is               10.575%\n",
            "The validation accuracy at iteration 14880  is               10.549999999999999%\n",
            "The validation accuracy at iteration 14896  is               10.674999999999999%\n",
            "The validation accuracy at iteration 14912  is               10.674999999999999%\n",
            "The validation accuracy at iteration 14928  is               10.674999999999999%\n",
            "The validation accuracy at iteration 14944  is               10.85%\n",
            "The validation accuracy at iteration 14960  is               10.95%\n",
            "The validation accuracy at iteration 14976  is               10.875%\n",
            "The validation accuracy at iteration 14992  is               10.85%\n",
            "The validation accuracy at iteration 15008  is               10.95%\n",
            "The validation accuracy at iteration 15024  is               10.975%\n",
            "The validation accuracy at iteration 15040  is               10.775%\n",
            "The validation accuracy at iteration 15056  is               10.85%\n",
            "The validation accuracy at iteration 15072  is               10.975%\n",
            "The validation accuracy at iteration 15088  is               10.95%\n",
            "The validation accuracy at iteration 15104  is               11.125%\n",
            "The validation accuracy at iteration 15120  is               11.125%\n",
            "The validation accuracy at iteration 15136  is               11.125%\n",
            "The validation accuracy at iteration 15152  is               11.125%\n",
            "The validation accuracy at iteration 15168  is               11.125%\n",
            "The validation accuracy at iteration 15184  is               10.95%\n",
            "The validation accuracy at iteration 15200  is               10.9%\n",
            "The validation accuracy at iteration 15216  is               11.125%\n",
            "The validation accuracy at iteration 15232  is               11.125%\n",
            "The validation accuracy at iteration 15248  is               11.15%\n",
            "The validation accuracy at iteration 15264  is               11.275%\n",
            "The validation accuracy at iteration 15280  is               11.3%\n",
            "The validation accuracy at iteration 15296  is               11.325000000000001%\n",
            "The validation accuracy at iteration 15312  is               11.275%\n",
            "The validation accuracy at iteration 15328  is               11.325000000000001%\n",
            "The validation accuracy at iteration 15344  is               11.325000000000001%\n",
            "The validation accuracy at iteration 15360  is               11.275%\n",
            "The validation accuracy at iteration 15376  is               11.275%\n",
            "The validation accuracy at iteration 15392  is               11.35%\n",
            "The validation accuracy at iteration 15408  is               11.375%\n",
            "The validation accuracy at iteration 15424  is               11.55%\n",
            "The validation accuracy at iteration 15440  is               11.525%\n",
            "The validation accuracy at iteration 15456  is               11.475%\n",
            "The validation accuracy at iteration 15472  is               11.450000000000001%\n",
            "The validation accuracy at iteration 15488  is               11.55%\n",
            "The validation accuracy at iteration 15504  is               11.375%\n",
            "The validation accuracy at iteration 15520  is               11.3%\n",
            "The validation accuracy at iteration 15536  is               11.475%\n",
            "The validation accuracy at iteration 15552  is               11.525%\n",
            "The validation accuracy at iteration 15568  is               11.575000000000001%\n",
            "The validation accuracy at iteration 15584  is               11.700000000000001%\n",
            "The validation accuracy at iteration 15600  is               11.825%\n",
            "The validation accuracy at iteration 15616  is               11.725%\n",
            "The validation accuracy at iteration 15632  is               11.675%\n",
            "The validation accuracy at iteration 15648  is               11.75%\n",
            "The validation accuracy at iteration 15664  is               11.774999999999999%\n",
            "The validation accuracy at iteration 15680  is               11.625%\n",
            "The validation accuracy at iteration 15696  is               11.799999999999999%\n",
            "The validation accuracy at iteration 15712  is               11.899999999999999%\n",
            "The validation accuracy at iteration 15728  is               11.899999999999999%\n",
            "The validation accuracy at iteration 15744  is               12.075%\n",
            "The validation accuracy at iteration 15760  is               12.075%\n",
            "The validation accuracy at iteration 15776  is               12.0%\n",
            "The validation accuracy at iteration 15792  is               12.025%\n",
            "The validation accuracy at iteration 15808  is               12.075%\n",
            "The validation accuracy at iteration 15824  is               11.899999999999999%\n",
            "The validation accuracy at iteration 15840  is               11.875%\n",
            "The validation accuracy at iteration 15856  is               12.049999999999999%\n",
            "The validation accuracy at iteration 15872  is               12.049999999999999%\n",
            "The validation accuracy at iteration 15888  is               12.075%\n",
            "The validation accuracy at iteration 15904  is               12.2%\n",
            "The validation accuracy at iteration 15920  is               12.325%\n",
            "The validation accuracy at iteration 15936  is               12.325%\n",
            "The validation accuracy at iteration 15952  is               12.15%\n",
            "The validation accuracy at iteration 15968  is               12.325%\n",
            "The validation accuracy at iteration 15984  is               12.375%\n",
            "The validation accuracy at iteration 16000  is               12.174999999999999%\n",
            "The validation accuracy at iteration 16000  is               12.174999999999999%\n",
            "The validation accuracy at iteration 16000  is               12.174999999999999%\n",
            "The validation accuracy at iteration 16000  is               82.875%\n",
            "The validation accuracy at iteration 16000  is               12.174999999999999%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 16000  is               12.174999999999999%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "The validation accuracy at iteration 16000  is               12.174999999999999%\n",
            "The validation accuracy at iteration 2300  is               81.75%\n",
            "The validation accuracy at iteration 16000  is               12.174999999999999%\n",
            "The validation accuracy at iteration 2300  is               81.575%\n",
            "The validation accuracy at iteration 16000  is               12.174999999999999%\n",
            "[<__main__.Solver object at 0x7f6e25755490>, <__main__.Solver object at 0x7f6e457874d0>, <__main__.Solver object at 0x7f6e5b0b1490>, <__main__.Solver object at 0x7f6e4c6b5710>, <__main__.Solver object at 0x7f6e4c79e350>]\n",
            "The validation accuracy at iteration 16  is               8.9%\n",
            "The validation accuracy at iteration 32  is               8.9%\n",
            "The validation accuracy at iteration 48  is               8.9%\n",
            "The validation accuracy at iteration 64  is               8.9%\n",
            "The validation accuracy at iteration 80  is               8.9%\n",
            "The validation accuracy at iteration 96  is               8.9%\n",
            "The validation accuracy at iteration 112  is               8.9%\n",
            "The validation accuracy at iteration 128  is               8.9%\n",
            "The validation accuracy at iteration 144  is               8.9%\n",
            "The validation accuracy at iteration 160  is               8.9%\n",
            "The validation accuracy at iteration 176  is               8.9%\n",
            "The validation accuracy at iteration 192  is               8.9%\n",
            "The validation accuracy at iteration 208  is               8.9%\n",
            "The validation accuracy at iteration 224  is               8.9%\n",
            "The validation accuracy at iteration 240  is               8.9%\n",
            "The validation accuracy at iteration 256  is               8.9%\n",
            "The validation accuracy at iteration 272  is               8.9%\n",
            "The validation accuracy at iteration 288  is               8.9%\n",
            "The validation accuracy at iteration 304  is               8.9%\n",
            "The validation accuracy at iteration 320  is               8.9%\n",
            "The validation accuracy at iteration 336  is               8.9%\n",
            "The validation accuracy at iteration 352  is               8.9%\n",
            "The validation accuracy at iteration 368  is               8.9%\n",
            "The validation accuracy at iteration 384  is               8.9%\n",
            "The validation accuracy at iteration 400  is               8.9%\n",
            "The validation accuracy at iteration 416  is               8.9%\n",
            "The validation accuracy at iteration 432  is               8.9%\n",
            "The validation accuracy at iteration 448  is               8.9%\n",
            "The validation accuracy at iteration 464  is               8.9%\n",
            "The validation accuracy at iteration 480  is               8.9%\n",
            "The validation accuracy at iteration 496  is               8.9%\n",
            "The validation accuracy at iteration 512  is               8.9%\n",
            "The validation accuracy at iteration 528  is               8.9%\n",
            "The validation accuracy at iteration 544  is               8.9%\n",
            "The validation accuracy at iteration 560  is               8.9%\n",
            "The validation accuracy at iteration 576  is               8.924999999999999%\n",
            "The validation accuracy at iteration 592  is               8.95%\n",
            "The validation accuracy at iteration 608  is               8.95%\n",
            "The validation accuracy at iteration 624  is               8.95%\n",
            "The validation accuracy at iteration 640  is               9.15%\n",
            "The validation accuracy at iteration 656  is               9.075%\n",
            "The validation accuracy at iteration 672  is               9.275%\n",
            "The validation accuracy at iteration 688  is               10.225%\n",
            "The validation accuracy at iteration 704  is               11.325000000000001%\n",
            "The validation accuracy at iteration 720  is               11.25%\n",
            "The validation accuracy at iteration 736  is               13.05%\n",
            "The validation accuracy at iteration 752  is               13.425%\n",
            "The validation accuracy at iteration 768  is               13.100000000000001%\n",
            "The validation accuracy at iteration 784  is               13.100000000000001%\n",
            "The validation accuracy at iteration 800  is               13.55%\n",
            "The validation accuracy at iteration 816  is               13.600000000000001%\n",
            "The validation accuracy at iteration 832  is               13.450000000000001%\n",
            "The validation accuracy at iteration 848  is               12.1%\n",
            "The validation accuracy at iteration 864  is               13.025%\n",
            "The validation accuracy at iteration 880  is               12.325%\n",
            "The validation accuracy at iteration 896  is               12.625%\n",
            "The validation accuracy at iteration 912  is               11.75%\n",
            "The validation accuracy at iteration 928  is               11.975%\n",
            "The validation accuracy at iteration 944  is               11.25%\n",
            "The validation accuracy at iteration 960  is               11.125%\n",
            "The validation accuracy at iteration 976  is               11.25%\n",
            "The validation accuracy at iteration 992  is               11.25%\n",
            "The validation accuracy at iteration 1008  is               11.025%\n",
            "The validation accuracy at iteration 1024  is               10.95%\n",
            "The validation accuracy at iteration 1040  is               11.05%\n",
            "The validation accuracy at iteration 1056  is               10.85%\n",
            "The validation accuracy at iteration 1072  is               10.95%\n",
            "The validation accuracy at iteration 1088  is               10.95%\n",
            "The validation accuracy at iteration 1104  is               10.95%\n",
            "The validation accuracy at iteration 1120  is               10.95%\n",
            "The validation accuracy at iteration 1136  is               10.85%\n",
            "The validation accuracy at iteration 1152  is               10.875%\n",
            "The validation accuracy at iteration 1168  is               10.85%\n",
            "The validation accuracy at iteration 1184  is               10.875%\n",
            "The validation accuracy at iteration 1200  is               10.875%\n",
            "The validation accuracy at iteration 1216  is               10.9%\n",
            "The validation accuracy at iteration 1232  is               10.875%\n",
            "The validation accuracy at iteration 1248  is               10.9%\n",
            "The validation accuracy at iteration 1264  is               10.85%\n",
            "The validation accuracy at iteration 1280  is               10.825%\n",
            "The validation accuracy at iteration 1296  is               10.85%\n",
            "The validation accuracy at iteration 1312  is               10.9%\n",
            "The validation accuracy at iteration 1328  is               10.85%\n",
            "The validation accuracy at iteration 1344  is               10.825%\n",
            "The validation accuracy at iteration 1360  is               10.875%\n",
            "The validation accuracy at iteration 1376  is               10.825%\n",
            "The validation accuracy at iteration 1392  is               10.825%\n",
            "The validation accuracy at iteration 1408  is               10.85%\n",
            "The validation accuracy at iteration 1424  is               10.925%\n",
            "The validation accuracy at iteration 1440  is               10.85%\n",
            "The validation accuracy at iteration 1456  is               10.85%\n",
            "The validation accuracy at iteration 1472  is               10.85%\n",
            "The validation accuracy at iteration 1488  is               10.825%\n",
            "The validation accuracy at iteration 1504  is               10.9%\n",
            "The validation accuracy at iteration 1520  is               10.9%\n",
            "The validation accuracy at iteration 1536  is               10.925%\n",
            "The validation accuracy at iteration 1552  is               10.925%\n",
            "The validation accuracy at iteration 1568  is               10.9%\n",
            "The validation accuracy at iteration 1584  is               10.9%\n",
            "The validation accuracy at iteration 1600  is               10.85%\n",
            "The validation accuracy at iteration 1616  is               10.925%\n",
            "The validation accuracy at iteration 1632  is               10.95%\n",
            "The validation accuracy at iteration 1648  is               10.95%\n",
            "The validation accuracy at iteration 1664  is               10.925%\n",
            "The validation accuracy at iteration 1680  is               11.025%\n",
            "The validation accuracy at iteration 1696  is               10.925%\n",
            "The validation accuracy at iteration 1712  is               10.925%\n",
            "The validation accuracy at iteration 1728  is               11.025%\n",
            "The validation accuracy at iteration 1744  is               11.05%\n",
            "The validation accuracy at iteration 1760  is               11.05%\n",
            "The validation accuracy at iteration 1776  is               11.025%\n",
            "The validation accuracy at iteration 1792  is               11.075%\n",
            "The validation accuracy at iteration 1808  is               11.025%\n",
            "The validation accuracy at iteration 1824  is               11.075%\n",
            "The validation accuracy at iteration 1840  is               11.125%\n",
            "The validation accuracy at iteration 1856  is               11.25%\n",
            "The validation accuracy at iteration 1872  is               11.25%\n",
            "The validation accuracy at iteration 1888  is               11.15%\n",
            "The validation accuracy at iteration 1904  is               11.25%\n",
            "The validation accuracy at iteration 1920  is               11.1%\n",
            "The validation accuracy at iteration 1936  is               11.375%\n",
            "The validation accuracy at iteration 1952  is               11.425%\n",
            "The validation accuracy at iteration 1968  is               11.600000000000001%\n",
            "The validation accuracy at iteration 1984  is               11.425%\n",
            "The validation accuracy at iteration 2000  is               12.075%\n",
            "The validation accuracy at iteration 2016  is               11.625%\n",
            "The validation accuracy at iteration 2032  is               11.625%\n",
            "The validation accuracy at iteration 2048  is               12.3%\n",
            "The validation accuracy at iteration 2064  is               12.675%\n",
            "The validation accuracy at iteration 2080  is               12.55%\n",
            "The validation accuracy at iteration 2096  is               12.475%\n",
            "The validation accuracy at iteration 2112  is               12.925%\n",
            "The validation accuracy at iteration 2128  is               12.725%\n",
            "The validation accuracy at iteration 2144  is               13.15%\n",
            "The validation accuracy at iteration 2160  is               13.625000000000002%\n",
            "The validation accuracy at iteration 2176  is               14.274999999999999%\n",
            "The validation accuracy at iteration 2192  is               14.374999999999998%\n",
            "The validation accuracy at iteration 2208  is               13.900000000000002%\n",
            "The validation accuracy at iteration 2224  is               14.7%\n",
            "The validation accuracy at iteration 2240  is               13.975000000000001%\n",
            "The validation accuracy at iteration 2256  is               14.924999999999999%\n",
            "The validation accuracy at iteration 2272  is               15.225%\n",
            "The validation accuracy at iteration 2288  is               15.5%\n",
            "The validation accuracy at iteration 2304  is               15.4%\n",
            "The validation accuracy at iteration 2320  is               16.0%\n",
            "The validation accuracy at iteration 2336  is               15.575%\n",
            "The validation accuracy at iteration 2352  is               15.575%\n",
            "The validation accuracy at iteration 2368  is               16.375%\n",
            "The validation accuracy at iteration 2384  is               16.55%\n",
            "The validation accuracy at iteration 2400  is               16.5%\n",
            "The validation accuracy at iteration 2416  is               16.5%\n",
            "The validation accuracy at iteration 2432  is               16.8%\n",
            "The validation accuracy at iteration 2448  is               16.6%\n",
            "The validation accuracy at iteration 2464  is               16.775000000000002%\n",
            "The validation accuracy at iteration 2480  is               17.1%\n",
            "The validation accuracy at iteration 2496  is               17.525%\n",
            "The validation accuracy at iteration 2512  is               17.625%\n",
            "The validation accuracy at iteration 2528  is               17.549999999999997%\n",
            "The validation accuracy at iteration 2544  is               17.75%\n",
            "The validation accuracy at iteration 2560  is               17.5%\n",
            "The validation accuracy at iteration 2576  is               17.775%\n",
            "The validation accuracy at iteration 2592  is               17.775%\n",
            "The validation accuracy at iteration 2608  is               17.724999999999998%\n",
            "The validation accuracy at iteration 2624  is               17.75%\n",
            "The validation accuracy at iteration 2640  is               17.7%\n",
            "The validation accuracy at iteration 2656  is               17.775%\n",
            "The validation accuracy at iteration 2672  is               17.775%\n",
            "The validation accuracy at iteration 2688  is               17.5%\n",
            "The validation accuracy at iteration 2704  is               17.5%\n",
            "The validation accuracy at iteration 2720  is               17.575%\n",
            "The validation accuracy at iteration 2736  is               17.575%\n",
            "The validation accuracy at iteration 2752  is               16.950000000000003%\n",
            "The validation accuracy at iteration 2768  is               17.349999999999998%\n",
            "The validation accuracy at iteration 2784  is               17.150000000000002%\n",
            "The validation accuracy at iteration 2800  is               16.425%\n",
            "The validation accuracy at iteration 2816  is               15.9%\n",
            "The validation accuracy at iteration 2832  is               16.05%\n",
            "The validation accuracy at iteration 2848  is               16.150000000000002%\n",
            "The validation accuracy at iteration 2864  is               15.65%\n",
            "The validation accuracy at iteration 2880  is               16.1%\n",
            "The validation accuracy at iteration 2896  is               15.275%\n",
            "The validation accuracy at iteration 2912  is               15.1%\n",
            "The validation accuracy at iteration 2928  is               14.75%\n",
            "The validation accuracy at iteration 2944  is               14.924999999999999%\n",
            "The validation accuracy at iteration 2960  is               14.475%\n",
            "The validation accuracy at iteration 2976  is               14.649999999999999%\n",
            "The validation accuracy at iteration 2992  is               14.825%\n",
            "The validation accuracy at iteration 3008  is               13.65%\n",
            "The validation accuracy at iteration 3024  is               12.925%\n",
            "The validation accuracy at iteration 3040  is               13.025%\n",
            "The validation accuracy at iteration 3056  is               13.450000000000001%\n",
            "The validation accuracy at iteration 3072  is               12.075%\n",
            "The validation accuracy at iteration 3088  is               12.775%\n",
            "The validation accuracy at iteration 3104  is               12.425%\n",
            "The validation accuracy at iteration 3120  is               11.450000000000001%\n",
            "The validation accuracy at iteration 3136  is               10.424999999999999%\n",
            "The validation accuracy at iteration 3152  is               11.1%\n",
            "The validation accuracy at iteration 3168  is               11.0%\n",
            "The validation accuracy at iteration 3184  is               10.35%\n",
            "The validation accuracy at iteration 3200  is               10.9%\n",
            "The validation accuracy at iteration 3216  is               9.75%\n",
            "The validation accuracy at iteration 3232  is               9.475%\n",
            "The validation accuracy at iteration 3248  is               9.2%\n",
            "The validation accuracy at iteration 3264  is               9.2%\n",
            "The validation accuracy at iteration 3280  is               9.2%\n",
            "The validation accuracy at iteration 3296  is               9.2%\n",
            "The validation accuracy at iteration 3312  is               9.325%\n",
            "The validation accuracy at iteration 3328  is               8.924999999999999%\n",
            "The validation accuracy at iteration 3344  is               8.9%\n",
            "The validation accuracy at iteration 3360  is               8.9%\n",
            "The validation accuracy at iteration 3376  is               8.9%\n",
            "The validation accuracy at iteration 3392  is               8.9%\n",
            "The validation accuracy at iteration 3408  is               8.9%\n",
            "The validation accuracy at iteration 3424  is               8.9%\n",
            "The validation accuracy at iteration 3440  is               8.9%\n",
            "The validation accuracy at iteration 3456  is               8.9%\n",
            "The validation accuracy at iteration 3472  is               8.9%\n",
            "The validation accuracy at iteration 3488  is               8.9%\n",
            "The validation accuracy at iteration 3504  is               8.9%\n",
            "The validation accuracy at iteration 3520  is               8.9%\n",
            "The validation accuracy at iteration 3536  is               8.9%\n",
            "The validation accuracy at iteration 3552  is               8.9%\n",
            "The validation accuracy at iteration 3568  is               8.9%\n",
            "The validation accuracy at iteration 3584  is               8.9%\n",
            "The validation accuracy at iteration 3600  is               8.9%\n",
            "The validation accuracy at iteration 3616  is               8.9%\n",
            "The validation accuracy at iteration 3632  is               8.9%\n",
            "The validation accuracy at iteration 3648  is               8.9%\n",
            "The validation accuracy at iteration 3664  is               8.9%\n",
            "The validation accuracy at iteration 3680  is               8.9%\n",
            "The validation accuracy at iteration 3696  is               8.9%\n",
            "The validation accuracy at iteration 3712  is               8.9%\n",
            "The validation accuracy at iteration 3728  is               8.9%\n",
            "The validation accuracy at iteration 3744  is               8.9%\n",
            "The validation accuracy at iteration 3760  is               8.9%\n",
            "The validation accuracy at iteration 3776  is               8.9%\n",
            "The validation accuracy at iteration 3792  is               8.9%\n",
            "The validation accuracy at iteration 3808  is               8.9%\n",
            "The validation accuracy at iteration 3824  is               8.9%\n",
            "The validation accuracy at iteration 3840  is               8.9%\n",
            "The validation accuracy at iteration 3856  is               8.9%\n",
            "The validation accuracy at iteration 3872  is               8.9%\n",
            "The validation accuracy at iteration 3888  is               8.9%\n",
            "The validation accuracy at iteration 3904  is               8.9%\n",
            "The validation accuracy at iteration 3920  is               8.9%\n",
            "The validation accuracy at iteration 3936  is               8.9%\n",
            "The validation accuracy at iteration 3952  is               8.9%\n",
            "The validation accuracy at iteration 3968  is               8.9%\n",
            "The validation accuracy at iteration 3984  is               8.9%\n",
            "The validation accuracy at iteration 4000  is               8.9%\n",
            "The validation accuracy at iteration 4016  is               8.9%\n",
            "The validation accuracy at iteration 4032  is               8.9%\n",
            "The validation accuracy at iteration 4048  is               8.9%\n",
            "The validation accuracy at iteration 4064  is               8.9%\n",
            "The validation accuracy at iteration 4080  is               8.9%\n",
            "The validation accuracy at iteration 4096  is               8.9%\n",
            "The validation accuracy at iteration 4112  is               8.9%\n",
            "The validation accuracy at iteration 4128  is               8.9%\n",
            "The validation accuracy at iteration 4144  is               8.9%\n",
            "The validation accuracy at iteration 4160  is               8.9%\n",
            "The validation accuracy at iteration 4176  is               8.9%\n",
            "The validation accuracy at iteration 4192  is               8.9%\n",
            "The validation accuracy at iteration 4208  is               8.9%\n",
            "The validation accuracy at iteration 4224  is               8.9%\n",
            "The validation accuracy at iteration 4240  is               8.9%\n",
            "The validation accuracy at iteration 4256  is               8.9%\n",
            "The validation accuracy at iteration 4272  is               8.9%\n",
            "The validation accuracy at iteration 4288  is               8.9%\n",
            "The validation accuracy at iteration 4304  is               8.9%\n",
            "The validation accuracy at iteration 4320  is               8.9%\n",
            "The validation accuracy at iteration 4336  is               8.9%\n",
            "The validation accuracy at iteration 4352  is               8.9%\n",
            "The validation accuracy at iteration 4368  is               8.9%\n",
            "The validation accuracy at iteration 4384  is               8.9%\n",
            "The validation accuracy at iteration 4400  is               8.9%\n",
            "The validation accuracy at iteration 4416  is               8.9%\n",
            "The validation accuracy at iteration 4432  is               8.9%\n",
            "The validation accuracy at iteration 4448  is               8.9%\n",
            "The validation accuracy at iteration 4464  is               8.9%\n",
            "The validation accuracy at iteration 4480  is               8.9%\n",
            "The validation accuracy at iteration 4496  is               8.9%\n",
            "The validation accuracy at iteration 4512  is               8.9%\n",
            "The validation accuracy at iteration 4528  is               8.9%\n",
            "The validation accuracy at iteration 4544  is               8.9%\n",
            "The validation accuracy at iteration 4560  is               8.9%\n",
            "The validation accuracy at iteration 4576  is               8.9%\n",
            "The validation accuracy at iteration 4592  is               8.9%\n",
            "The validation accuracy at iteration 4608  is               8.9%\n",
            "The validation accuracy at iteration 4624  is               8.9%\n",
            "The validation accuracy at iteration 4640  is               8.9%\n",
            "The validation accuracy at iteration 4656  is               8.9%\n",
            "The validation accuracy at iteration 4672  is               8.9%\n",
            "The validation accuracy at iteration 4688  is               8.9%\n",
            "The validation accuracy at iteration 4704  is               8.9%\n",
            "The validation accuracy at iteration 4720  is               8.9%\n",
            "The validation accuracy at iteration 4736  is               8.9%\n",
            "The validation accuracy at iteration 4752  is               8.9%\n",
            "The validation accuracy at iteration 4768  is               8.9%\n",
            "The validation accuracy at iteration 4784  is               8.9%\n",
            "The validation accuracy at iteration 4800  is               8.9%\n",
            "The validation accuracy at iteration 4816  is               8.9%\n",
            "The validation accuracy at iteration 4832  is               8.9%\n",
            "The validation accuracy at iteration 4848  is               8.9%\n",
            "The validation accuracy at iteration 4864  is               8.9%\n",
            "The validation accuracy at iteration 4880  is               8.9%\n",
            "The validation accuracy at iteration 4896  is               8.9%\n",
            "The validation accuracy at iteration 4912  is               8.9%\n",
            "The validation accuracy at iteration 4928  is               8.9%\n",
            "The validation accuracy at iteration 4944  is               8.9%\n",
            "The validation accuracy at iteration 4960  is               8.9%\n",
            "The validation accuracy at iteration 4976  is               8.9%\n",
            "The validation accuracy at iteration 4992  is               8.9%\n",
            "The validation accuracy at iteration 5008  is               8.9%\n",
            "The validation accuracy at iteration 5024  is               8.9%\n",
            "The validation accuracy at iteration 5040  is               8.9%\n",
            "The validation accuracy at iteration 5056  is               8.9%\n",
            "The validation accuracy at iteration 5072  is               8.9%\n",
            "The validation accuracy at iteration 5088  is               8.9%\n",
            "The validation accuracy at iteration 5104  is               8.9%\n",
            "The validation accuracy at iteration 5120  is               8.9%\n",
            "The validation accuracy at iteration 5136  is               8.9%\n",
            "The validation accuracy at iteration 5152  is               8.9%\n",
            "The validation accuracy at iteration 5168  is               8.9%\n",
            "The validation accuracy at iteration 5184  is               8.9%\n",
            "The validation accuracy at iteration 5200  is               8.9%\n",
            "The validation accuracy at iteration 5216  is               8.9%\n",
            "The validation accuracy at iteration 5232  is               8.9%\n",
            "The validation accuracy at iteration 5248  is               8.9%\n",
            "The validation accuracy at iteration 5264  is               8.9%\n",
            "The validation accuracy at iteration 5280  is               8.9%\n",
            "The validation accuracy at iteration 5296  is               8.9%\n",
            "The validation accuracy at iteration 5312  is               8.9%\n",
            "The validation accuracy at iteration 5328  is               8.9%\n",
            "The validation accuracy at iteration 5344  is               8.9%\n",
            "The validation accuracy at iteration 5350  is               8.9%\n",
            "The validation accuracy at iteration 5350  is               8.9%\n",
            "The validation accuracy at iteration 16000  is               82.875%\n",
            "The validation accuracy at iteration 5350  is               8.9%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 5350  is               8.9%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "The validation accuracy at iteration 5350  is               8.9%\n",
            "The validation accuracy at iteration 2300  is               81.75%\n",
            "The validation accuracy at iteration 5350  is               8.9%\n",
            "The validation accuracy at iteration 2300  is               81.575%\n",
            "The validation accuracy at iteration 5350  is               8.9%\n",
            "[<__main__.Solver object at 0x7f6e25755490>, <__main__.Solver object at 0x7f6e457874d0>, <__main__.Solver object at 0x7f6e5b0b1490>, <__main__.Solver object at 0x7f6e4c6b5710>, <__main__.Solver object at 0x7f6e4c79e350>]\n",
            "The validation accuracy at iteration 16  is               8.9%\n",
            "The validation accuracy at iteration 32  is               8.9%\n",
            "The validation accuracy at iteration 48  is               8.9%\n",
            "The validation accuracy at iteration 64  is               8.9%\n",
            "The validation accuracy at iteration 80  is               8.9%\n",
            "The validation accuracy at iteration 96  is               8.9%\n",
            "The validation accuracy at iteration 112  is               8.9%\n",
            "The validation accuracy at iteration 128  is               8.9%\n",
            "The validation accuracy at iteration 144  is               8.9%\n",
            "The validation accuracy at iteration 160  is               8.9%\n",
            "The validation accuracy at iteration 176  is               8.9%\n",
            "The validation accuracy at iteration 192  is               8.9%\n",
            "The validation accuracy at iteration 208  is               8.9%\n",
            "The validation accuracy at iteration 224  is               8.9%\n",
            "The validation accuracy at iteration 240  is               8.9%\n",
            "The validation accuracy at iteration 256  is               8.9%\n",
            "The validation accuracy at iteration 272  is               8.9%\n",
            "The validation accuracy at iteration 288  is               8.9%\n",
            "The validation accuracy at iteration 304  is               8.9%\n",
            "The validation accuracy at iteration 320  is               8.95%\n",
            "The validation accuracy at iteration 336  is               8.95%\n",
            "The validation accuracy at iteration 352  is               9.0%\n",
            "The validation accuracy at iteration 368  is               9.025%\n",
            "The validation accuracy at iteration 384  is               9.175%\n",
            "The validation accuracy at iteration 400  is               9.15%\n",
            "The validation accuracy at iteration 416  is               9.825000000000001%\n",
            "The validation accuracy at iteration 432  is               10.0%\n",
            "The validation accuracy at iteration 448  is               10.325%\n",
            "The validation accuracy at iteration 464  is               10.2%\n",
            "The validation accuracy at iteration 480  is               11.35%\n",
            "The validation accuracy at iteration 496  is               11.450000000000001%\n",
            "The validation accuracy at iteration 512  is               12.0%\n",
            "The validation accuracy at iteration 528  is               11.700000000000001%\n",
            "The validation accuracy at iteration 544  is               12.7%\n",
            "The validation accuracy at iteration 560  is               12.825000000000001%\n",
            "The validation accuracy at iteration 576  is               13.125%\n",
            "The validation accuracy at iteration 592  is               12.875%\n",
            "The validation accuracy at iteration 608  is               13.775%\n",
            "The validation accuracy at iteration 624  is               13.850000000000001%\n",
            "The validation accuracy at iteration 640  is               14.025000000000002%\n",
            "The validation accuracy at iteration 656  is               13.850000000000001%\n",
            "The validation accuracy at iteration 672  is               14.524999999999999%\n",
            "The validation accuracy at iteration 688  is               14.524999999999999%\n",
            "The validation accuracy at iteration 704  is               14.75%\n",
            "The validation accuracy at iteration 720  is               14.45%\n",
            "The validation accuracy at iteration 736  is               15.1%\n",
            "The validation accuracy at iteration 752  is               15.1%\n",
            "The validation accuracy at iteration 768  is               15.049999999999999%\n",
            "The validation accuracy at iteration 784  is               14.95%\n",
            "The validation accuracy at iteration 800  is               15.275%\n",
            "The validation accuracy at iteration 816  is               15.275%\n",
            "The validation accuracy at iteration 832  is               15.375%\n",
            "The validation accuracy at iteration 848  is               15.125%\n",
            "The validation accuracy at iteration 864  is               15.575%\n",
            "The validation accuracy at iteration 880  is               15.65%\n",
            "The validation accuracy at iteration 896  is               15.575%\n",
            "The validation accuracy at iteration 912  is               15.375%\n",
            "The validation accuracy at iteration 928  is               15.7%\n",
            "The validation accuracy at iteration 944  is               15.7%\n",
            "The validation accuracy at iteration 960  is               15.675%\n",
            "The validation accuracy at iteration 976  is               15.675%\n",
            "The validation accuracy at iteration 992  is               15.825%\n",
            "The validation accuracy at iteration 1008  is               15.825%\n",
            "The validation accuracy at iteration 1024  is               15.8%\n",
            "The validation accuracy at iteration 1040  is               15.75%\n",
            "The validation accuracy at iteration 1056  is               15.975%\n",
            "The validation accuracy at iteration 1072  is               15.950000000000001%\n",
            "The validation accuracy at iteration 1088  is               15.950000000000001%\n",
            "The validation accuracy at iteration 1104  is               15.75%\n",
            "The validation accuracy at iteration 1120  is               16.025%\n",
            "The validation accuracy at iteration 1136  is               16.025%\n",
            "The validation accuracy at iteration 1152  is               16.0%\n",
            "The validation accuracy at iteration 1168  is               15.775%\n",
            "The validation accuracy at iteration 1184  is               16.1%\n",
            "The validation accuracy at iteration 1200  is               16.0%\n",
            "The validation accuracy at iteration 1216  is               16.025%\n",
            "The validation accuracy at iteration 1232  is               15.775%\n",
            "The validation accuracy at iteration 1248  is               16.150000000000002%\n",
            "The validation accuracy at iteration 1264  is               16.0%\n",
            "The validation accuracy at iteration 1280  is               16.05%\n",
            "The validation accuracy at iteration 1296  is               15.8%\n",
            "The validation accuracy at iteration 1312  is               16.150000000000002%\n",
            "The validation accuracy at iteration 1328  is               15.975%\n",
            "The validation accuracy at iteration 1344  is               16.0%\n",
            "The validation accuracy at iteration 1360  is               15.825%\n",
            "The validation accuracy at iteration 1376  is               16.075%\n",
            "The validation accuracy at iteration 1392  is               16.0%\n",
            "The validation accuracy at iteration 1408  is               16.0%\n",
            "The validation accuracy at iteration 1424  is               15.75%\n",
            "The validation accuracy at iteration 1440  is               15.975%\n",
            "The validation accuracy at iteration 1456  is               16.0%\n",
            "The validation accuracy at iteration 1472  is               16.05%\n",
            "The validation accuracy at iteration 1488  is               15.7%\n",
            "The validation accuracy at iteration 1504  is               15.975%\n",
            "The validation accuracy at iteration 1520  is               15.950000000000001%\n",
            "The validation accuracy at iteration 1536  is               15.975%\n",
            "The validation accuracy at iteration 1552  is               15.675%\n",
            "The validation accuracy at iteration 1568  is               15.950000000000001%\n",
            "The validation accuracy at iteration 1584  is               15.65%\n",
            "The validation accuracy at iteration 1600  is               15.725%\n",
            "The validation accuracy at iteration 1616  is               15.625%\n",
            "The validation accuracy at iteration 1632  is               15.625%\n",
            "The validation accuracy at iteration 1648  is               15.625%\n",
            "The validation accuracy at iteration 1664  is               15.725%\n",
            "The validation accuracy at iteration 1680  is               15.525%\n",
            "The validation accuracy at iteration 1696  is               15.625%\n",
            "The validation accuracy at iteration 1712  is               15.6%\n",
            "The validation accuracy at iteration 1728  is               15.65%\n",
            "The validation accuracy at iteration 1744  is               15.475%\n",
            "The validation accuracy at iteration 1760  is               15.575%\n",
            "The validation accuracy at iteration 1776  is               15.5%\n",
            "The validation accuracy at iteration 1792  is               15.575%\n",
            "The validation accuracy at iteration 1808  is               15.375%\n",
            "The validation accuracy at iteration 1824  is               15.525%\n",
            "The validation accuracy at iteration 1840  is               15.45%\n",
            "The validation accuracy at iteration 1856  is               15.475%\n",
            "The validation accuracy at iteration 1872  is               15.1%\n",
            "The validation accuracy at iteration 1888  is               15.4%\n",
            "The validation accuracy at iteration 1904  is               15.275%\n",
            "The validation accuracy at iteration 1920  is               15.25%\n",
            "The validation accuracy at iteration 1936  is               14.95%\n",
            "The validation accuracy at iteration 1952  is               15.225%\n",
            "The validation accuracy at iteration 1968  is               15.049999999999999%\n",
            "The validation accuracy at iteration 1984  is               15.0%\n",
            "The validation accuracy at iteration 2000  is               14.549999999999999%\n",
            "The validation accuracy at iteration 2016  is               14.95%\n",
            "The validation accuracy at iteration 2032  is               14.85%\n",
            "The validation accuracy at iteration 2048  is               14.825%\n",
            "The validation accuracy at iteration 2064  is               14.35%\n",
            "The validation accuracy at iteration 2080  is               14.674999999999999%\n",
            "The validation accuracy at iteration 2096  is               14.374999999999998%\n",
            "The validation accuracy at iteration 2112  is               14.399999999999999%\n",
            "The validation accuracy at iteration 2128  is               14.124999999999998%\n",
            "The validation accuracy at iteration 2144  is               14.325%\n",
            "The validation accuracy at iteration 2160  is               14.299999999999999%\n",
            "The validation accuracy at iteration 2176  is               14.274999999999999%\n",
            "The validation accuracy at iteration 2192  is               13.8%\n",
            "The validation accuracy at iteration 2208  is               14.099999999999998%\n",
            "The validation accuracy at iteration 2224  is               13.950000000000001%\n",
            "The validation accuracy at iteration 2240  is               13.925%\n",
            "The validation accuracy at iteration 2256  is               13.600000000000001%\n",
            "The validation accuracy at iteration 2272  is               13.825000000000001%\n",
            "The validation accuracy at iteration 2288  is               13.675%\n",
            "The validation accuracy at iteration 2304  is               13.625000000000002%\n",
            "The validation accuracy at iteration 2320  is               13.275%\n",
            "The validation accuracy at iteration 2336  is               13.600000000000001%\n",
            "The validation accuracy at iteration 2352  is               13.475000000000001%\n",
            "The validation accuracy at iteration 2368  is               13.425%\n",
            "The validation accuracy at iteration 2384  is               13.075000000000001%\n",
            "The validation accuracy at iteration 2400  is               13.275%\n",
            "The validation accuracy at iteration 2416  is               13.125%\n",
            "The validation accuracy at iteration 2432  is               13.100000000000001%\n",
            "The validation accuracy at iteration 2448  is               12.6%\n",
            "The validation accuracy at iteration 2464  is               13.075000000000001%\n",
            "The validation accuracy at iteration 2480  is               12.8%\n",
            "The validation accuracy at iteration 2496  is               12.725%\n",
            "The validation accuracy at iteration 2512  is               12.2%\n",
            "The validation accuracy at iteration 2528  is               12.625%\n",
            "The validation accuracy at iteration 2544  is               12.475%\n",
            "The validation accuracy at iteration 2560  is               12.35%\n",
            "The validation accuracy at iteration 2576  is               11.95%\n",
            "The validation accuracy at iteration 2592  is               12.2%\n",
            "The validation accuracy at iteration 2608  is               12.2%\n",
            "The validation accuracy at iteration 2624  is               12.049999999999999%\n",
            "The validation accuracy at iteration 2640  is               11.65%\n",
            "The validation accuracy at iteration 2656  is               12.025%\n",
            "The validation accuracy at iteration 2672  is               11.799999999999999%\n",
            "The validation accuracy at iteration 2688  is               11.75%\n",
            "The validation accuracy at iteration 2704  is               11.325000000000001%\n",
            "The validation accuracy at iteration 2720  is               11.725%\n",
            "The validation accuracy at iteration 2736  is               11.600000000000001%\n",
            "The validation accuracy at iteration 2752  is               11.450000000000001%\n",
            "The validation accuracy at iteration 2768  is               11.0%\n",
            "The validation accuracy at iteration 2784  is               11.325000000000001%\n",
            "The validation accuracy at iteration 2800  is               11.175%\n",
            "The validation accuracy at iteration 2816  is               11.05%\n",
            "The validation accuracy at iteration 2832  is               10.6%\n",
            "The validation accuracy at iteration 2848  is               11.025%\n",
            "The validation accuracy at iteration 2864  is               10.85%\n",
            "The validation accuracy at iteration 2880  is               10.75%\n",
            "The validation accuracy at iteration 2896  is               10.424999999999999%\n",
            "The validation accuracy at iteration 2912  is               10.65%\n",
            "The validation accuracy at iteration 2928  is               10.625%\n",
            "The validation accuracy at iteration 2944  is               10.525%\n",
            "The validation accuracy at iteration 2960  is               10.25%\n",
            "The validation accuracy at iteration 2976  is               10.424999999999999%\n",
            "The validation accuracy at iteration 2992  is               10.375%\n",
            "The validation accuracy at iteration 3008  is               10.325%\n",
            "The validation accuracy at iteration 3024  is               9.975000000000001%\n",
            "The validation accuracy at iteration 3040  is               10.274999999999999%\n",
            "The validation accuracy at iteration 3056  is               10.174999999999999%\n",
            "The validation accuracy at iteration 3072  is               10.05%\n",
            "The validation accuracy at iteration 3088  is               9.875%\n",
            "The validation accuracy at iteration 3104  is               10.0%\n",
            "The validation accuracy at iteration 3120  is               9.950000000000001%\n",
            "The validation accuracy at iteration 3136  is               9.925%\n",
            "The validation accuracy at iteration 3152  is               9.8%\n",
            "The validation accuracy at iteration 3168  is               9.875%\n",
            "The validation accuracy at iteration 3184  is               9.9%\n",
            "The validation accuracy at iteration 3200  is               9.825000000000001%\n",
            "The validation accuracy at iteration 3200  is               9.825000000000001%\n",
            "The validation accuracy at iteration 3200  is               9.825000000000001%\n",
            "The validation accuracy at iteration 16000  is               82.875%\n",
            "The validation accuracy at iteration 3200  is               9.825000000000001%\n",
            "The validation accuracy at iteration 16000  is               82.5%\n",
            "The validation accuracy at iteration 3200  is               9.825000000000001%\n",
            "The validation accuracy at iteration 3200  is               81.925%\n",
            "The validation accuracy at iteration 3200  is               9.825000000000001%\n",
            "The validation accuracy at iteration 2300  is               81.75%\n",
            "The validation accuracy at iteration 3200  is               9.825000000000001%\n",
            "The validation accuracy at iteration 2300  is               81.575%\n",
            "The validation accuracy at iteration 3200  is               9.825000000000001%\n",
            "[<__main__.Solver object at 0x7f6e25755490>, <__main__.Solver object at 0x7f6e457874d0>, <__main__.Solver object at 0x7f6e5b0b1490>, <__main__.Solver object at 0x7f6e4c6b5710>, <__main__.Solver object at 0x7f6e4c79e350>]\n",
            "The validation accuracy at iteration 16  is               8.625%\n",
            "The validation accuracy at iteration 32  is               8.625%\n",
            "The validation accuracy at iteration 48  is               8.625%\n",
            "The validation accuracy at iteration 64  is               8.625%\n",
            "The validation accuracy at iteration 80  is               8.575000000000001%\n",
            "The validation accuracy at iteration 96  is               6.950000000000001%\n",
            "The validation accuracy at iteration 112  is               2.825%\n",
            "The validation accuracy at iteration 128  is               8.075000000000001%\n",
            "The validation accuracy at iteration 144  is               10.825%\n",
            "The validation accuracy at iteration 160  is               10.825%\n",
            "The validation accuracy at iteration 176  is               10.825%\n",
            "The validation accuracy at iteration 192  is               10.825%\n",
            "The validation accuracy at iteration 208  is               10.825%\n",
            "The validation accuracy at iteration 224  is               10.825%\n",
            "The validation accuracy at iteration 240  is               10.825%\n",
            "The validation accuracy at iteration 256  is               10.825%\n",
            "The validation accuracy at iteration 272  is               10.825%\n",
            "The validation accuracy at iteration 288  is               10.825%\n",
            "The validation accuracy at iteration 304  is               10.825%\n",
            "The validation accuracy at iteration 320  is               10.825%\n",
            "The validation accuracy at iteration 336  is               10.825%\n",
            "The validation accuracy at iteration 352  is               10.825%\n",
            "The validation accuracy at iteration 368  is               10.825%\n",
            "The validation accuracy at iteration 384  is               10.825%\n",
            "The validation accuracy at iteration 400  is               10.825%\n",
            "The validation accuracy at iteration 416  is               10.825%\n",
            "The validation accuracy at iteration 432  is               10.825%\n",
            "The validation accuracy at iteration 448  is               10.825%\n",
            "The validation accuracy at iteration 464  is               10.825%\n",
            "The validation accuracy at iteration 480  is               10.825%\n",
            "The validation accuracy at iteration 496  is               10.825%\n",
            "The validation accuracy at iteration 512  is               10.825%\n",
            "The validation accuracy at iteration 528  is               10.825%\n",
            "The validation accuracy at iteration 544  is               10.825%\n",
            "The validation accuracy at iteration 560  is               10.825%\n",
            "The validation accuracy at iteration 576  is               10.825%\n",
            "The validation accuracy at iteration 592  is               10.825%\n",
            "The validation accuracy at iteration 608  is               10.825%\n",
            "The validation accuracy at iteration 624  is               10.825%\n",
            "The validation accuracy at iteration 640  is               10.825%\n",
            "The validation accuracy at iteration 656  is               10.825%\n",
            "The validation accuracy at iteration 672  is               10.825%\n",
            "The validation accuracy at iteration 688  is               10.825%\n",
            "The validation accuracy at iteration 704  is               10.825%\n",
            "The validation accuracy at iteration 720  is               10.825%\n",
            "The validation accuracy at iteration 736  is               10.825%\n",
            "The validation accuracy at iteration 752  is               10.825%\n",
            "The validation accuracy at iteration 768  is               10.825%\n",
            "The validation accuracy at iteration 784  is               10.825%\n",
            "The validation accuracy at iteration 800  is               10.825%\n",
            "The validation accuracy at iteration 816  is               10.825%\n",
            "The validation accuracy at iteration 832  is               10.825%\n",
            "The validation accuracy at iteration 848  is               10.825%\n",
            "The validation accuracy at iteration 864  is               10.825%\n",
            "The validation accuracy at iteration 880  is               10.825%\n",
            "The validation accuracy at iteration 896  is               10.825%\n",
            "The validation accuracy at iteration 912  is               10.825%\n",
            "The validation accuracy at iteration 928  is               10.825%\n",
            "The validation accuracy at iteration 944  is               10.825%\n",
            "The validation accuracy at iteration 960  is               10.825%\n",
            "The validation accuracy at iteration 976  is               10.825%\n",
            "The validation accuracy at iteration 992  is               10.825%\n",
            "The validation accuracy at iteration 1008  is               10.825%\n",
            "The validation accuracy at iteration 1024  is               10.825%\n",
            "The validation accuracy at iteration 1040  is               10.825%\n",
            "The validation accuracy at iteration 1056  is               10.825%\n",
            "The validation accuracy at iteration 1072  is               10.825%\n",
            "The validation accuracy at iteration 1088  is               10.825%\n",
            "The validation accuracy at iteration 1104  is               10.825%\n",
            "The validation accuracy at iteration 1120  is               10.825%\n",
            "The validation accuracy at iteration 1136  is               10.825%\n",
            "The validation accuracy at iteration 1152  is               10.825%\n",
            "The validation accuracy at iteration 1168  is               10.825%\n",
            "The validation accuracy at iteration 1184  is               10.825%\n",
            "The validation accuracy at iteration 1200  is               10.825%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NN_best_models = best_models"
      ],
      "metadata": {
        "id": "OUHsBWL0TPpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the testing performance of your top-5 performing NN models on the test set and print the results. You can add additional cells below."
      ],
      "metadata": {
        "id": "zi1hTKxU-Kap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for solvr in NN_best_models: \n",
        "  solvr.X_val = x_test\n",
        "  solvr.y_val = y_test\n",
        "  acc = solvr.accuracy()\n",
        "  print(acc)"
      ],
      "metadata": {
        "id": "QL6IbrNo-PTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** visualization for the `W1` weights of the *best* performing NN models. There are `hidden_dim` many of them per model. You should visualize a subset of the weights. You can select the columns at random. \n",
        "\n",
        "You can add additional cells below."
      ],
      "metadata": {
        "id": "qC8IL-RNdCOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''## select columns \n",
        "number_of_columns = 10\n",
        "random_indices = np.random.choice(number_of_columns, size=10, replace=False)\n",
        "\n",
        "random_rows = x_train[random_indices, :]'''"
      ],
      "metadata": {
        "id": "_fN8KtFyJvJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NN_weights_to_img(solver):\n",
        "  print(solvr.model.params['W1'].shape)\n",
        "  r,c = solvr.model.params['W1'].shape\n",
        "  random_indices = np.random.choice(c, size=10, replace=False)\n",
        "  random_columns = solvr.model.params['W1'][random_indices, :]\n",
        "\n",
        "  weights = random_columns.copy()\n",
        "\n",
        "  ## first we want to normalize over all pixels \n",
        "  weights *=(255.0/weights.max())\n",
        "  ## then for each pixel subtract the average for that class\n",
        "  for i in range(784):\n",
        "    weights[i,:]= weights[i,:]-weights[i,:].mean()\n",
        "\n",
        "\n",
        "  for i in range(10): \n",
        "    img = weights[:,i]\n",
        "    \n",
        "    img = img.reshape((28,28))\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qsWgECu-JZrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for solver in NN_best_models: \n",
        "  NN_weights_to_img(solver)\n"
      ],
      "metadata": {
        "id": "R-CGHrOtdCb9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}